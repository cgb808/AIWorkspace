{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Extracting falsifiable predictions from sloppy models"}, {"role": "assistant", "content": "Successful predictions are among the most compelling validations of any\nmodel. Extracting falsifiable predictions from nonlinear multiparameter models\nis complicated by the fact that such models are commonly sloppy, possessing\nsensitivities to different parameter combinations that range over many decades.\nHere we discuss how sloppiness affects the sorts of data that best constrain\nmodel predictions, makes linear uncertainty approximations dangerous, and\nintroduces computational difficulties in Monte-Carlo uncertainty analysis. We\nalso present a useful test problem and suggest refinements to the standards by\nwhich models are communicated."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Converting genetic network oscillations into somite spatial pattern"}, {"role": "assistant", "content": "In most vertebrate species, the body axis is generated by the formation of\nrepeated transient structures called somites. This spatial periodicity in\nsomitogenesis has been related to the temporally sustained oscillations in\ncertain mRNAs and their associated gene products in the cells forming the\npresomatic mesoderm. The mechanism underlying these oscillations have been\nidentified as due to the delays involved in the synthesis of mRNA and\ntranslation into protein molecules [J. Lewis, Current Biol. {\\bf 13}, 1398\n(2003)]. In addition, in the zebrafish embryo intercellular Notch signalling\ncouples these oscillators and a longitudinal positional information signal in\nthe form of an Fgf8 gradient exists that could be used to transform these\ncoupled temporal oscillations into the observed spatial periodicity of somites.\nHere we consider a simple model based on this known biology and study its\nconsequences for somitogenesis. Comparison is made with the known properties of\nsomite formation in the zebrafish embryo . We also study the effects of\nlocalized Fgf8 perturbations on somite patterning."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Theoretical Analysis of Subthreshold Oscillatory Behaviors in Nonlinear\n  Autonomous Systems"}, {"role": "assistant", "content": "We have developed a linearization method to investigate the subthreshold\noscillatory behaviors in nonlinear autonomous systems. By considering firstly\nthe neuronal system as an example, we show that this theoretical approach can\npredict quantitatively the subthreshold oscillatory activities, including the\ndamping coefficients and the oscillatory frequencies which are in good\nagreement with those observed in experiments. Then we generalize the\nlinearization method to an arbitrary autonomous nonlinear system. The detailed\nextension of this theoretical approach is also presented and further discussed."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Detection of Aneuploidy with Digital PCR"}, {"role": "assistant", "content": "The widespread use of genetic testing in high risk pregnancies has created\nstrong interest in rapid and accurate molecular diagnostics for common\nchromosomal aneuploidies. We show here that digital polymerase chain reaction\n(dPCR) can be used for accurate measurement of trisomy 21 (Down's Syndrome),\nthe most common human aneuploidy. dPCR is generally applicable to any\naneuploidy, does not depend on allelic distribution or gender, and is able to\ndetect signals in the presence of mosaics or contaminating maternal DNA."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Visual Data Mining of Genomic Databases by Immersive Graph-Based\n  Exploration"}, {"role": "assistant", "content": "Biologists are leading current research on genome characterization\n(sequencing, alignment, transcription), providing a huge quantity of raw data\nabout many genome organisms. Extracting knowledge from this raw data is an\nimportant process for biologists, using usually data mining approaches.\nHowever, it is difficult to deals with these genomic information using actual\nbioinformatics data mining tools, because data are heterogeneous, huge in\nquantity and geographically distributed. In this paper, we present a new\napproach between data mining and virtual reality visualization, called visual\ndata mining. Indeed Virtual Reality becomes ripe, with efficient display\ndevices and intuitive interaction in an immersive context. Moreover, biologists\nuse to work with 3D representation of their molecules, but in a desktop\ncontext. We present a software solution, Genome3DExplorer, which addresses the\nproblem of genomic data visualization, of scene management and interaction.\nThis solution is based on a well-adapted graphical and interaction paradigm,\nwhere local and global topological characteristics of data are easily visible,\non the contrary to traditional genomic database browsers, always focused on the\nzoom and details level."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A passivity-based stability criterion for a class of interconnected\n  systems and applications to biochemical reaction networks"}, {"role": "assistant", "content": "This paper presents a stability test for a class of interconnected nonlinear\nsystems motivated by biochemical reaction networks. One of the main results\ndetermines global asymptotic stability of the network from the diagonal\nstability of a \"dissipativity matrix\" which incorporates information about the\npassivity properties of the subsystems, the interconnection structure of the\nnetwork, and the signs of the interconnection terms. This stability test\nencompasses the \"secant criterion\" for cyclic networks presented in our\nprevious paper, and extends it to a general interconnection structure\nrepresented by a graph. A second main result allows one to accommodate state\nproducts. This extension makes the new stability criterion applicable to a\nbroader class of models, even in the case of cyclic systems. The new stability\ntest is illustrated on a mitogen activated protein kinase (MAPK) cascade model,\nand on a branched interconnection structure motivated by metabolic networks.\nFinally, another result addresses the robustness of stability in the presence\nof diffusion terms in a compartmental system made out of identical systems."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Analytic steady-state space use patterns and rapid computations in\n  mechanistic home range analysis"}, {"role": "assistant", "content": "Mechanistic home range models are important tools in modeling animal dynamics\nin spatially-complex environments. We introduce a class of stochastic models\nfor animal movement in a habitat of varying preference. Such models interpolate\nbetween spatially-implicit resource selection analysis (RSA) and\nadvection-diffusion models, possessing these two models as limiting cases. We\nfind a closed-form solution for the steady-state (equilibrium) probability\ndistribution u* using a factorization of the redistribution operator into\nsymmetric and diagonal parts. How space use is controlled by the preference\nfunction w then depends on the characteristic width of the redistribution\nkernel: when w changes rapidly compared to this width, u* ~ w, whereas on\nglobal scales large compared to this width, u* ~ w^2. We analyse the behavior\nat discontinuities in w which occur at habitat type boundaries. We simulate the\ndynamics of space use given two-dimensional prey-availability data and explore\nthe effect of the redistribution kernel width. Our factorization allows such\nnumerical simulations to be done extremely fast; we expect this to aid the\ncomputationally-intensive task of model parameter fitting and inverse modeling."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: DIA-MCIS. An Importance Sampling Network Randomizer for Network Motif\n  Discovery and Other Topological Observables in Transcription Networks"}, {"role": "assistant", "content": "Transcription networks, and other directed networks can be characterized by\nsome topological observables such as for example subgraph occurrence (network\nmotifs). In order to perform such kind of analysis, it is necessary to be able\nto generate suitable randomized network ensembles. Typically, one considers\nnull networks with the same degree sequences of the original ones. The commonly\nused algorithms sometimes have long convergence times, and sampling problems.\nWe present here an alternative, based on a variant of the importance sampling\nMontecarlo developed by Chen et al. [1]."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Spectral plots and the representation and interpretation of biological\n  data"}, {"role": "assistant", "content": "It is basic question in biology and other fields to identify the char-\nacteristic properties that on one hand are shared by structures from a\nparticular realm, like gene regulation, protein-protein interaction or neu- ral\nnetworks or foodwebs, and that on the other hand distinguish them from other\nstructures. We introduce and apply a general method, based on the spectrum of\nthe normalized graph Laplacian, that yields repre- sentations, the spectral\nplots, that allow us to find and visualize such properties systematically. We\npresent such visualizations for a wide range of biological networks and compare\nthem with those for networks derived from theoretical schemes. The differences\nthat we find are quite striking and suggest that the search for universal\nproperties of biological networks should be complemented by an understanding of\nmore specific features of biological organization principles at different\nscales."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Attenuation Regulation as a Term Rewriting System"}, {"role": "assistant", "content": "The classical attenuation regulation of gene expression in bacteria is\nconsidered. We propose to represent the secondary RNA structure in the leader\nregion of a gene or an operon by a term, and we give a probabilistic term\nrewriting system modeling the whole process of such a regulation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Persistence of direction increases the drift velocity of run and tumble\n  chemotaxis"}, {"role": "assistant", "content": "Escherichia coli is a motile bacterium that moves up a chemoattractant\ngradient by performing a biased random walk composed of alternating runs and\ntumbles. Previous models of run and tumble chemotaxis neglect one or more\nfeatures of the motion, namely (i) a cell cannot directly detect a\nchemoattractant gradient but rather makes temporal comparisons of\nchemoattractant concentration, (ii) rather than being entirely random, tumbles\nexhibit persistence of direction, meaning that the new direction after a tumble\nis more likely to be in the forward hemisphere, and (iii) rotational Brownian\nmotion makes it impossible for an E. coli cell to swim in a straight line\nduring a run. This paper presents an analytic calculation of the chemotactic\ndrift velocity taking account of (i), (ii) and (iii), for weak chemotaxis. The\nanalytic results are verified by Monte Carlo simulation. The results reveal a\nsynergy between temporal comparisons and persistence that enhances the drift\nvelocity, while rotational Brownian motion reduces the drift velocity."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Eutacticity in sea urchin evolution"}, {"role": "assistant", "content": "An eutactic star, in a n-dimensional space, is a set of N vectors which can\nbe viewed as the projection of N orthogonal vectors in a N-dimensional space.\nBy adequately associating a star of vectors to a particular sea urchin we\npropose that a measure of the eutacticity of the star constitutes a measure of\nthe regularity of the sea urchin. Then we study changes of regularity\n(eutacticity) in a macroevolutive and taxonomic level of sea urchins belonging\nto the Echinoidea Class. An analysis considering changes through geological\ntime suggests a high degree of regularity in the shape of these organisms\nthrough their evolution. Rare deviations from regularity measured in\nHolasteroida order are discussed."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A First Exposure to Statistical Mechanics for Life Scientists"}, {"role": "assistant", "content": "Statistical mechanics is one of the most powerful and elegant tools in the\nquantitative sciences. One key virtue of statistical mechanics is that it is\ndesigned to examine large systems with many interacting degrees of freedom,\nproviding a clue that it might have some bearing on the analysis of the\nmolecules of living matter. As a result of data on biological systems becoming\nincreasingly quantitative, there is a concomitant demand that the models set\nforth to describe biological systems be themselves quantitative. We describe\nhow statistical mechanics is part of the quantitative toolkit that is needed to\nrespond to such data. The power of statistical mechanics is not limited to\ntraditional physical and chemical problems and there are a host of interesting\nways in which these ideas can be applied in biology. This article reports on\nour efforts to teach statistical mechanics to life science students and\nprovides a framework for others interested in bringing these tools to a\nnontraditional audience in the life sciences."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: THEA: ontology-driven analysis of microarray data"}, {"role": "assistant", "content": "MOTIVATION: Microarray technology makes it possible to measure thousands of\nvariables and to compare their values under hundreds of conditions. Once\nmicroarray data are quantified, normalized and classified, the analysis phase\nis essentially a manual and subjective task based on visual inspection of\nclasses in the light of the vast amount of information available. Currently,\ndata interpretation clearly constitutes the bottleneck of such analyses and\nthere is an obvious need for tools able to fill the gap between data processed\nwith mathematical methods and existing biological knowledge. RESULTS: THEA\n(Tools for High-throughput Experiments Analysis) is an integrated information\nprocessing system allowing convenient handling of data. It allows to\nautomatically annotate data issued from classification systems with selected\nbiological information coming from a knowledge base and to either manually\nsearch and browse through these annotations or automatically generate\nmeaningful generalizations according to statistical criteria (data mining).\nAVAILABILITY: The software is available on the website http://thea.unice.fr/"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Parameter Estimation in Biokinetic Degradation Models in Wastewater\n  Treatment - A Novel Approach Relevant for Micro-pollutant Removal"}, {"role": "assistant", "content": "In this paper we address a general parameter estimation methodology for an\nextended biokinetic degradation model [1] for poorly degradable\nmicropollutants. In particular we concentrate on parameter estimation of the\nmicropollutant degradation sub-model by specialised microorganisms. In this\ncase we focus on the case when only substrate degradation data are available\nand prove the structural identifiability of the model. Further we consider the\nproblem of practical identifiability and propose experimental and related\nnumerical methods for unambiguous parameter estimation based on multiple\nsubstrate degradation curves with different initial concentrations. Finally by\nmeans of simulated pseudo-experiments we have found convincing indications that\nthe proposed algorithm is stable and yields appropriate parameter estimates\neven in unfavourable regimes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Kernel methods for in silico chemogenomics"}, {"role": "assistant", "content": "Predicting interactions between small molecules and proteins is a crucial\ningredient of the drug discovery process. In particular, accurate predictive\nmodels are increasingly used to preselect potential lead compounds from large\nmolecule databases, or to screen for side-effects. While classical in silico\napproaches focus on predicting interactions with a given specific target, new\nchemogenomics approaches adopt cross-target views. Building on recent\ndevelopments in the use of kernel methods in bio- and chemoinformatics, we\npresent a systematic framework to screen the chemical space of small molecules\nfor interaction with the biological space of proteins. We show that this\nframework allows information sharing across the targets, resulting in a\ndramatic improvement of ligand prediction accuracy for three important classes\nof drug targets: enzymes, GPCR and ion channels."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Probabilistic annotation of protein sequences based on functional\n  classifications"}, {"role": "assistant", "content": "BACKGROUND: One of the most evident achievements of bioinformatics is the\ndevelopment of methods that transfer biological knowledge from characterised\nproteins to uncharacterised sequences. This mode of protein function assignment\nis mostly based on the detection of sequence similarity and the premise that\nfunctional properties are conserved during evolution. Most automatic approaches\ndeveloped to date rely on the identification of clusters of homologous proteins\nand the mapping of new proteins onto these clusters, which are expected to\nshare functional characteristics. RESULTS: Here, we inverse the logic of this\nprocess, by considering the mapping of sequences directly to a functional\nclassification instead of mapping functions to a sequence clustering. In this\nmode, the starting point is a database of labelled proteins according to a\nfunctional classification scheme, and the subsequent use of sequence similarity\nallows defining the membership of new proteins to these functional classes. In\nthis framework, we define the Correspondence Indicators as measures of\nrelationship between sequence and function and further formulate two Bayesian\napproaches to estimate the probability for a sequence of unknown function to\nbelong to a functional class. This approach allows the parametrisation of\ndifferent sequence search strategies and provides a direct measure of\nannotation error rates. We validate this approach with a database of enzymes\nlabelled by their corresponding four-digit EC numbers and analyse specific\ncases. CONCLUSION: The performance of this method is significantly higher than\nthe simple strategy consisting in transferring the annotation from the highest\nscoring BLAST match and is expected to find applications in automated\nfunctional annotation pipelines."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Diffusive hidden Markov model characterization of DNA looping dynamics\n  in tethered particle experiments"}, {"role": "assistant", "content": "In many biochemical processes, proteins bound to DNA at distant sites are\nbrought into close proximity by loops in the underlying DNA. For example, the\nfunction of some gene-regulatory proteins depends on such DNA looping\ninteractions. We present a new technique for characterizing the kinetics of\nloop formation in vitro, as observed using the tethered particle method, and\napply it to experimental data on looping induced by lambda repressor. Our\nmethod uses a modified (diffusive) hidden Markov analysis that directly\nincorporates the Brownian motion of the observed tethered bead. We compare\nlooping lifetimes found with our method (which we find are consistent over a\nrange of sampling frequencies) to those obtained via the traditional\nthreshold-crossing analysis (which can vary depending on how the raw data are\nfiltered in the time domain). Our method does not involve any time filtering\nand can detect sudden changes in looping behavior. For example, we show how our\nmethod can identify transitions between long-lived, kinetically distinct states\nthat would otherwise be difficult to discern."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Geometric Aspects of Biological Sequence Comparison"}, {"role": "assistant", "content": "We propose a general framework for converting global and local similarities\nbetween biological sequences to quasi-metrics. In contrast to previous works,\nour formulation allows asymmetric distances, originating from uneven weighting\nof strings, that may induce non-trivial partial orders on sets of biosequences.\nFurthermore, the $\\ell^p$-type distances considered are more general than\ntraditional generalized string edit distances corresponding to the $\\ell^1$\ncase, and enable conversion of sequence similarities to distances for a much\nwider class of scoring schemes. Our constructions require much less restrictive\ngap penalties than the ones regularly used. Numerous examples are provided to\nillustrate the concepts introduced and their potential applications."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Identification of specificity determining residues in enzymes using\n  environment specific substitution tables"}, {"role": "assistant", "content": "Environment specific substitution tables have been used effectively for\ndistinguishing structural and functional constraints on proteins and thereby\nidentify their active sites (Chelliah et al. (2004)). This work explores\nwhether a similar approach can be used to identify specificity determining\nresidues (SDRs) responsible for cofactor dependence, substrate specificity or\nsubtle catalytic variations. We combine structure-sequence information and\nfunctional annotation from various data sources to create structural alignments\nfor homologous enzymes and functional partitions therein. We develop a scoring\nprocedure to predict SDRs and assess their accuracy using information from\nbound specific ligands and published literature."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A mathematical model quantifies proliferation and motility effects of\n  TGF--$\\beta$ on cancer cells"}, {"role": "assistant", "content": "Transforming growth factor (TGF) $\\beta$ is known to have properties of both\na tumor suppressor and a tumor promoter. While it inhibits cell proliferation,\nit also increases cell motility and decreases cell--cell adhesion. Coupling\nmathematical modeling and experiments, we investigate the growth and motility\nof oncogene--expressing human mammary epithelial cells under exposure to\nTGF--$\\beta$. We use a version of the well--known Fisher--Kolmogorov equation,\nand prescribe a procedure for its parametrization. We quantify the simultaneous\neffects of TGF--$\\beta$ to increase the tendency of individual cells and cell\nclusters to move randomly and to decrease overall population growth. We\ndemonstrate that in experiments with TGF--$\\beta$ treated cells \\textit{in\nvitro}, TGF--$\\beta$ increases cell motility by a factor of 2 and decreases\ncell proliferation by a factor of 1/2 in comparison with untreated cells."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: CLePAPS: Fast Pair Alignment of Protein Structures Based on\n  Conformational Letters"}, {"role": "assistant", "content": "Fast, efficient and reliable algorithms for pairwise alignment of protein\nstructures are in ever increasing demand for analyzing the rapidly growing data\nof protein structures. CLePAPS is a tool developed for this purpose. It\ndistinguishes itself from other existing algorithms by the use of\nconformational letters, which are discretized states of 3D segmental structural\nstates. A letter corresponds to a cluster of combinations of the three angles\nformed by C_alpha pseudobonds of four contiguous residues. A substitution\nmatrix called CLESUM is available to measure similarity between any two such\nletters. CLePAPS regards an aligned fragment pair (AFP) as an ungapped string\npair with a high sum of pairwise CLESUM scores. Using CLESUM scores as the\nsimilarity measure, CLePAPS searches for AFPs by simple string comparison. The\ntransformation which best superimposes a highly similar AFP can be used to\nsuperimpose the structure pairs under comparison. A highly scored AFP which is\nconsistent with several other AFPs determines an initial alignment. CLePAPS\nthen joins consistent AFPs guided by their similarity scores to extend the\nalignment by several `zoom-in' iteration steps. A follow-up refinement produces\nthe final alignment. CLePAPS does not implement dynamic programming. The\nutility of CLePAPS is tested on various protein structure pairs."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Inherent flexibility and protein function: the open/closed\n  conformational transition of the N-terminal domain of calmodulin"}, {"role": "assistant", "content": "The key to understanding a protein's function often lies in its\nconformational dynamics. We develop a coarse-grained variational model to\ninvestigate the interplay between structural transitions, conformational\nflexibility and function of N-terminal calmodulin (nCaM) domain. In this model,\ntwo energy basins corresponding to the ``closed'' apo conformation and ``open''\nholo conformation of nCaM domain are connected by a uniform interpolation\nparameter. The resulting detailed transition route from our model is largely\nconsistent with the recently proposed EF$\\beta$-scaffold mechanism in EF-hand\nfamily proteins. We find that the N-terminal part in calcium binding loops I\nand II shows higher flexibility than the C-terminal part which form this\nEF$\\beta$-scaffold structure. The structural transition of binding loops I and\nII are compared in detail. Our model predicts that binding loop II, with higher\nflexibility and early structural change than binding loop I, dominates the\nconformational transition in nCaM domain."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Dependence of nucleotide physical properties on their placement in\n  codons and determinative degree"}, {"role": "assistant", "content": "Various physical properties such as dipole moment, heat of formation and\nenergy of the most stable formation of nucleotides and bases were calculated by\nPM3 (modified neglect of diatomic overlap, parametric method number 3) and AM1\n(Austin model 1) methods. As distinct from previous calculations, for\nnucleotides the interaction with neighbours is taken into account up to\ngradient of convergence equaling 1. The dependences of these variables from the\nplace in the codon and the determinative degree were obtained. The difference\nof these variables for codons and anticodons is shown."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Towards Structural Classification of Proteins based on Contact Map\n  Overlap"}, {"role": "assistant", "content": "A multitude of measures have been proposed to quantify the similarity between\nprotein 3-D structure. Among these measures, contact map overlap (CMO)\nmaximization deserved sustained attention during past decade because it offers\na fine estimation of the natural homology relation between proteins. Despite\nthis large involvement of the bioinformatics and computer science community,\nthe performance of known algorithms remains modest. Due to the complexity of\nthe problem, they got stuck on relatively small instances and are not\napplicable for large scale comparison. This paper offers a clear improvement\nover past methods in this respect. We present a new integer programming model\nfor CMO and propose an exact B &B algorithm with bounds computed by solving\nLagrangian relaxation. The efficiency of the approach is demonstrated on a\npopular small benchmark (Skolnick set, 40 domains). On this set our algorithm\nsignificantly outperforms the best existing exact algorithms, and yet provides\nlower and upper bounds of better quality. Some hard CMO instances have been\nsolved for the first time and within reasonable time limits. From the values of\nthe running time and the relative gap (relative difference between upper and\nlower bounds), we obtained the right classification for this test. These\nencouraging result led us to design a harder benchmark to better assess the\nclassification capability of our approach. We constructed a large scale set of\n300 protein domains (a subset of ASTRAL database) that we have called Proteus\n300. Using the relative gap of any of the 44850 couples as a similarity\nmeasure, we obtained a classification in very good agreement with SCOP. Our\nalgorithm provides thus a powerful classification tool for large structure\ndatabases."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Network reconstruction based on quasi-steady state data"}, {"role": "assistant", "content": "This note discusses a theoretical issue regarding the application of the\n\"Modular Response Analysis\" method to quasi-steady state (rather than\nsteady-state) data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The effect of time distribution shape on simulated epidemic models"}, {"role": "assistant", "content": "By convention, and even more often, as an unintentional consequence of\ndesign, time distributions of latency and infectious durations in stochastic\nepidemic simulations are often exponential. The skewed distribtion typically\nleads to unrealistically short times. We examine the effects of altering the\ndistribution latency and infectious times by comparing the key results after\nsimulation with exponential and gamma distributions in a homogeneous mixing\nmodel aswell as a model with regional divisions connected by a travel intensity\nmatrix. We show a delay in spread with more realistic latency times and offer\nan explanation of the effect."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Cross-Scale Sensitivity Analysis of a Non-Small Cell Lung Cancer Model:\n  Linking Molecular Signaling Properties to Cellular Behavior"}, {"role": "assistant", "content": "Sensitivity analysis is an effective tool for systematically identifying\nspecific perturbations in parameters that have significant effects on the\nbehavior of a given biosystem, at the scale investigated. In this work, using a\ntwo-dimensional, multiscale non-small cell lung cancer (NSCLC) model, we\nexamine the effects of perturbations in system parameters which span both\nmolecular and cellular levels, i.e. across scales of interest. This is achieved\nby first linking molecular and cellular activities and then assessing the\ninfluence of parameters at the molecular level on the tumor's spatio-temporal\nexpansion rate, which serves as the output behavior at the cellular level.\nOverall, the algorithm operated reliably over relatively large variations of\nmost parameters, hence confirming the robustness of the model. However, three\npathway components (proteins PKC, MEK, and ERK) and eleven reaction steps were\ndetermined to be of critical importance by employing a sensitivity coefficient\nas an evaluation index. Each of these sensitive parameters exhibited a similar\nchanging pattern in that a relatively larger increase or decrease in its value\nresulted in a lesser influence on the system's cellular performance. This study\nprovides a novel cross-scaled approach to analyzing sensitivities of\ncomputational model parameters and proposes its application to\ninterdisciplinary biomarker studies."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: On fitting power laws to ecological data"}, {"role": "assistant", "content": "Heavy-tailed or power-law distributions are becoming increasingly common in\nbiological literature. A wide range of biological data has been fitted to\ndistributions with heavy tails. Many of these studies use simple fitting\nmethods to find the parameters in the distribution, which can give highly\nmisleading results. The potential pitfalls that can occur when using these\nmethods are pointed out, and a step-by-step guide to fitting power-law\ndistributions and assessing their goodness-of-fit is offered."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Integrating heterogeneous knowledges for understanding biological\n  behaviors: a probabilistic approach"}, {"role": "assistant", "content": "Despite recent molecular technique improvements, biological knowledge remains\nincomplete. Reasoning on living systems hence implies to integrate\nheterogeneous and partial informations. Although current investigations\nsuccessfully focus on qualitative behaviors of macromolecular networks, others\napproaches show partial quantitative informations like protein concentration\nvariations over times. We consider that both informations, qualitative and\nquantitative, have to be combined into a modeling method to provide a better\nunderstanding of the biological system. We propose here such a method using a\nprobabilistic-like approach. After its exhaustive description, we illustrate\nits advantages by modeling the carbon starvation response in Escherichia coli.\nIn this purpose, we build an original qualitative model based on available\nobservations. After the formal verification of its qualitative properties, the\nprobabilistic model shows quantitative results corresponding to biological\nexpectations which confirm the interest of our probabilistic approach."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Offdiagonal complexity: A computationally quick network complexity\n  measure. Application to protein networks and cell division"}, {"role": "assistant", "content": "Many complex biological, social, and economical networks show topologies\ndrastically differing from random graphs. But, what is a complex network, i.e.\\\nhow can one quantify the complexity of a graph? Here the Offdiagonal Complexity\n(OdC), a new, and computationally cheap, measure of complexity is defined,\nbased on the node-node link cross-distribution, whose nondiagonal elements\ncharacterize the graph structure beyond link distribution, cluster coefficient\nand average path length. The OdC apporach is applied to the {\\sl Helicobacter\npylori} protein interaction network and randomly rewired surrogates thereof. In\naddition, OdC is used to characterize the spatial complexity of cell\naggregates. We investigate the earliest embryo development states of\nCaenorhabditis elegans. The development states of the premorphogenetic phase\nare represented by symmetric binary-valued cell connection matrices with\ndimension growing from 4 to 385. These matrices can be interpreted as adjacency\nmatrix of an undirected graph, or network. The OdC approach allows to describe\nquantitatively the complexity of the cell aggregate geometry."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Rediscovering the power of pairwise interactions"}, {"role": "assistant", "content": "Two recent streams of work suggest that pairwise interactions may be\nsufficient to capture the complexity of biological systems ranging from protein\nstructure to networks of neurons. In one approach, possible amino acid\nsequences in a family of proteins are generated by Monte Carlo annealing of a\n\"Hamiltonian\" that forces pairwise correlations among amino acid substitutions\nto be close to the observed correlations. In the other approach, the observed\ncorrelations among pairs of neurons are used to construct a maximum entropy\nmodel for the states of the network as a whole. We show that, in certain\nlimits, these two approaches are mathematically equivalent, and we comment on\nopen problems suggested by this framework"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Computing knock out strategies in metabolic networks"}, {"role": "assistant", "content": "Given a metabolic network in terms of its metabolites and reactions, our goal\nis to efficiently compute the minimal knock out sets of reactions required to\nblock a given behaviour. We describe an algorithm which improves the\ncomputation of these knock out sets when the elementary modes (minimal\nfunctional subsystems) of the network are given. We also describe an algorithm\nwhich computes both the knock out sets and the elementary modes containing the\nblocked reactions directly from the description of the network and whose\nworst-case computational complexity is better than the algorithms currently in\nuse for these problems. Computational results are included."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Analysis of a Gibbs sampler method for model based clustering of gene\n  expression data"}, {"role": "assistant", "content": "Over the last decade, a large variety of clustering algorithms have been\ndeveloped to detect coregulatory relationships among genes from microarray gene\nexpression data. Model based clustering approaches have emerged as\nstatistically well grounded methods, but the properties of these algorithms\nwhen applied to large-scale data sets are not always well understood. An\nin-depth analysis can reveal important insights about the performance of the\nalgorithm, the expected quality of the output clusters, and the possibilities\nfor extracting more relevant information out of a particular data set. We have\nextended an existing algorithm for model based clustering of genes to\nsimultaneously cluster genes and conditions, and used three large compendia of\ngene expression data for S. cerevisiae to analyze its properties. The algorithm\nuses a Bayesian approach and a Gibbs sampling procedure to iteratively update\nthe cluster assignment of each gene and condition. For large-scale data sets,\nthe posterior distribution is strongly peaked on a limited number of\nequiprobable clusterings. A GO annotation analysis shows that these local\nmaxima are all biologically equally significant, and that simultaneously\nclustering genes and conditions performs better than only clustering genes and\nassuming independent conditions. A collection of distinct equivalent\nclusterings can be summarized as a weighted graph on the set of genes, from\nwhich we extract fuzzy, overlapping clusters using a graph spectral method. The\ncores of these fuzzy clusters contain tight sets of strongly coexpressed genes,\nwhile the overlaps exhibit relations between genes showing only partial\ncoexpression."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Virtual screening of GPCRs: an in silico chemogenomics approach"}, {"role": "assistant", "content": "The G-protein coupled receptor (GPCR) superfamily is currently the largest\nclass of therapeutic targets. \\textit{In silico} prediction of interactions\nbetween GPCRs and small molecules is therefore a crucial step in the drug\ndiscovery process, which remains a daunting task due to the difficulty to\ncharacterize the 3D structure of most GPCRs, and to the limited amount of known\nligands for some members of the superfamily. Chemogenomics, which attempts to\ncharacterize interactions between all members of a target class and all small\nmolecules simultaneously, has recently been proposed as an interesting\nalternative to traditional docking or ligand-based virtual screening\nstrategies. We propose new methods for in silico chemogenomics and validate\nthem on the virtual screening of GPCRs. The methods represent an extension of a\nrecently proposed machine learning strategy, based on support vector machines\n(SVM), which provides a flexible framework to incorporate various information\nsources on the biological space of targets and on the chemical space of small\nmolecules. We investigate the use of 2D and 3D descriptors for small molecules,\nand test a variety of descriptors for GPCRs. We show fo instance that\nincorporating information about the known hierarchical classification of the\ntarget family and about key residues in their inferred binding pockets\nsignificantly improves the prediction accuracy of our model. In particular we\nare able to predict ligands of orphan GPCRs with an estimated accuracy of\n78.1%."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Transition from 12 to near-24 hours glucose circadian rhythm on\n  relaxation of a hyperglycemic condition"}, {"role": "assistant", "content": "A composite, exponential relaxation function, modulated by a periodic\ncomponent, was used to fit to an experimental time series of blood glucose\nlevels. The 11 parameters function that allows for the detection of a possible\nrhythm transition was fitted to the experimental time series using a genetic\nalgorithm. It has been found that the relaxation from a hyperglycemic condition\nfollowing a change in the anti-diabetic treatment, can be characterized by a\nchange from an initial 12 hours ultradian rhythm to a near-24 hours circadian\nrhythm."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Toolbox for analyzing finite two-state trajectories"}, {"role": "assistant", "content": "In many experiments, the aim is to deduce an underlying multi-substate on-off\nkinetic scheme (KS) from the statistical properties of a two-state trajectory.\nHowever, the mapping of a KS into a two-state trajectory leads to the loss of\ninformation about the KS, and so, in many cases, more than one KS can be\nassociated with the data. We recently showed that the optimal way to solve this\nproblem is to use canonical forms of reduced dimensions (RD). RD forms are\non-off networks with connections only between substates of different states,\nwhere the connections can have non-exponential waiting time probability density\nfunctions (WT-PDFs). In theory, only a single RD form can be associated with\nthe data. To utilize RD forms in the analysis of the data, a RD form should be\nassociated with the data. Here, we give a toolbox for building a RD form from a\nfinite two-state trajectory. The methods in the toolbox are based on known\nstatistical methods in data analysis, combined with statistical methods and\nnumerical algorithms designed specifically for the current problem. Our toolbox\nis self-contained - it builds a mechanism based only on the information it\nextracts from the data, and its implementation on the data is fast (analyzing a\n10^6 cycle trajectory from a thirty-parameter mechanism takes a couple of hours\non a PC with a 2.66 GHz processor). The toolbox is automated and is freely\navailable for academic research upon electronic request."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: GoArrays: highly dynamic and efficient microarray probe design"}, {"role": "assistant", "content": "MOTIVATION: The use of oligonucleotide microarray technology requires a very\ndetailed attention to the design of specific probes spotted on the solid phase.\nThese problems are far from being commonplace since they refer to complex\nphysicochemical constraints. Whereas there are more and more publicly available\nprograms for microarray oligonucleotide design, most of them use the same\nalgorithm or criteria to design oligos, with only little variation. RESULTS: We\nshow that classical approaches used in oligo design software may be inefficient\nunder certain experimental conditions, especially when dealing with complex\ntarget mixtures. Indeed, our biological model is a human obligate parasite, the\nmicrosporidia Encephalitozoon cuniculi. Targets that are extracted from\nbiological samples are composed of a mixture of pathogen transcripts and host\ncell transcripts. We propose a new approach to design oligonucleotides which\ncombines good specificity with a potentially high sensitivity. This approach is\noriginal in the biological point of view as well as in the algorithmic point of\nview. We also present an experimental validation of this new strategy by\ncomparing results obtained with standard oligos and with our composite oligos.\nA specific E.cuniculi microarray will overcome the difficulty to discriminate\nthe parasite mRNAs from the host cell mRNAs demonstrating the power of the\nmicroarray approach to elucidate the lifestyle of an intracellular pathogen\nusing mix mRNAs."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: SIRENE: Supervised Inference of Regulatory Networks"}, {"role": "assistant", "content": "Living cells are the product of gene expression programs that involve the\nregulated transcription of thousands of genes. The elucidation of\ntranscriptional regulatory networks in thus needed to understand the cell's\nworking mechanism, and can for example be useful for the discovery of novel\ntherapeutic targets. Although several methods have been proposed to infer gene\nregulatory networks from gene expression data, a recent comparison on a\nlarge-scale benchmark experiment revealed that most current methods only\npredict a limited number of known regulations at a reasonable precision level.\nWe propose SIRENE, a new method for the inference of gene regulatory networks\nfrom a compendium of expression data. The method decomposes the problem of gene\nregulatory network inference into a large number of local binary classification\nproblems, that focus on separating target genes from non-targets for each TF.\nSIRENE is thus conceptually simple and computationally efficient. We test it on\na benchmark experiment aimed at predicting regulations in E. coli, and show\nthat it retrieves of the order of 6 times more known regulations than other\nstate-of-the-art inference methods."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Data compression and genomes: a two dimensional life domain map"}, {"role": "assistant", "content": "We define the complexity of DNA sequences as the information content per\nnucleotide, calculated by means of some Lempel-Ziv data compression algorithm.\nIt is possible to use the statistics of the complexity values of the functional\nregions of different complete genomes to distinguish among genomes of different\ndomains of life (Archaea, Bacteria and Eukarya). We shall focus on the\ndistribution function of the complexity of noncoding regions. We show that the\nthree domains may be plotted in separate regions within the two-dimensional\nspace where the axes are the skewness coefficient and the curtosis coefficient\nof the aforementioned distribution. Preliminary results on 15 genomes are\nintroduced."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Temporal Logic Patterns for Querying Dynamic Models of Cellular\n  Interaction Networks"}, {"role": "assistant", "content": "Models of the dynamics of cellular interaction networks have become\nincreasingly larger in recent years. Formal verification based on model\nchecking provides a powerful technology to keep up with this increase in scale\nand complexity. The application of model-checking approaches is hampered,\nhowever, by the difficulty for non-expert users to formulate appropriate\nquestions in temporal logic. In order to deal with this problem, we propose the\nuse of patterns, that is, high-level query templates that capture recurring\nbiological questions and that can be automatically translated into temporal\nlogic. The applicability of the developed set of patterns has been investigated\nby the analysis of an extended model of the network of global regulators\ncontrolling the carbon starvation response in Escherichia coli."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Search algorithms as a framework for the optimization of drug\n  combinations"}, {"role": "assistant", "content": "Combination therapies are often needed for effective clinical outcomes in the\nmanagement of complex diseases, but presently they are generally based on\nempirical clinical experience. Here we suggest a novel application of search\nalgorithms, originally developed for digital communication, modified to\noptimize combinations of therapeutic interventions. In biological experiments\nmeasuring the restoration of the decline with age in heart function and\nexercise capacity in Drosophila melanogaster, we found that search algorithms\ncorrectly identified optimal combinations of four drugs with only one third of\nthe tests performed in a fully factorial search. In experiments identifying\ncombinations of three doses of up to six drugs for selective killing of human\ncancer cells, search algorithms resulted in a highly significant enrichment of\nselective combinations compared with random searches. In simulations using a\nnetwork model of cell death, we found that the search algorithms identified the\noptimal combinations of 6-9 interventions in 80-90% of tests, compared with\n15-30% for an equivalent random search. These findings suggest that modified\nsearch algorithms from information theory have the potential to enhance the\ndiscovery of novel therapeutic drug combinations. This report also helps to\nframe a biomedical problem that will benefit from an interdisciplinary effort\nand suggests a general strategy for its solution."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Python - All a Scientist Needs"}, {"role": "assistant", "content": "Any cutting-edge scientific research project requires a myriad of\ncomputational tools for data generation, management, analysis and\nvisualization. Python is a flexible and extensible scientific programming\nplatform that offered the perfect solution in our recent comparative genomics\ninvestigation (J. B. Lucks, D. R. Nelson, G. Kudla, J. B. Plotkin. Genome\nlandscapes and bacteriophage codon usage, PLoS Computational Biology, 4,\n1000001, 2008). In this paper, we discuss the challenges of this project, and\nhow the combined power of Biopython, Matplotlib and SWIG were utilized for the\nrequired computational tasks. We finish by discussing how python goes beyond\nbeing a convenient programming language, and promotes good scientific practice\nby enabling clean code, integration with professional programming techniques\nsuch as unit testing, and strong data provenance."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: RAId DbS: A Mass-Spectrometry Based Peptide Identification Web Server\n  with Knowledge Integration"}, {"role": "assistant", "content": "Summary: In anticipation of the individualized proteomics era and the need to\nintegrate knowledge from disease studies, we have augmented our peptide\nidentification software RAId DbS to take into account annotated single amino\nacid polymorphisms, post-translational modifications, and their documented\ndisease associations while analyzing a tandem mass spectrum. To facilitate new\ndiscoveries, RAId DbS allows users to conduct searches permitting novel\npolymorphisms. Availability: The webserver link is http://www.ncbi.nlm.nih.gov/\n/CBBResearch/qmbp/raid dbs/index.html. The relevant databases and binaries of\nRAId DbS for Linux, Windows, and Mac OS X are available from the same web page.\nContact: yyu@ncbi.nlm.nih.gov"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Efficient stochastic sampling of first-passage times with applications\n  to self-assembly simulations"}, {"role": "assistant", "content": "Models of reaction chemistry based on the stochastic simulation algorithm\n(SSA) have become a crucial tool for simulating complicated biological reaction\nnetworks due to their ability to handle extremely complicated reaction networks\nand to represent noise in small-scale chemistry. These methods can, however,\nbecome highly inefficient for stiff reaction systems, those in which different\nreaction channels operate on widely varying time scales. In this paper, we\ndevelop two methods for accelerating sampling in SSA models: an exact method\nand a scheme allowing for sampling accuracy up to any arbitrary error bound.\nBoth methods depend on analysis of the eigenvalues of continuous time Markov\nmodel graphs that define the behavior of the SSA. We demonstrate these methods\nfor the specific application of sampling breakage times for multiply-connected\nbond networks, a class of stiff system important to models of self-assembly\nprocesses. We show theoretically and empirically that our eigenvalue methods\nprovide substantially reduced sampling times for a wide range of network\nbreakage models. These techniques are also likely to have broad use in\naccelerating SSA models so as to apply them to systems and parameter ranges\nthat are currently computationally intractable."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Inference of genetic networks from time course expression data using\n  functional regression with lasso penalty"}, {"role": "assistant", "content": "Statistical inference of genetic regulatory networks is essential for\nunderstanding temporal interactions of regulatory elements inside the cells.\nFor inferences of large networks, identification of network structure is\ntypical achieved under the assumption of sparsity of the networks.\n  When the number of time points in the expression experiment is not too small,\nwe propose to infer the parameters in the ordinary differential equations using\nthe techniques from functional data analysis (FDA) by regarding the observed\ntime course expression data as continuous-time curves. For networks with a\nlarge number of genes, we take advantage of the sparsity of the networks by\npenalizing the linear coefficients with a L_1 norm. The ability of the\nalgorithm to infer network structure is demonstrated using the cell-cycle time\ncourse data for Saccharomyces cerevisiae."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Protein Sequencing with an Adaptive Genetic Algorithm from Tandem Mass\n  Spectrometry"}, {"role": "assistant", "content": "In Proteomics, only the de novo peptide sequencing approach allows a partial\namino acid sequence of a peptide to be found from a MS/MS spectrum. In this\narticle a preliminary work is presented to discover a complete protein sequence\nfrom spectral data (MS and MS/MS spectra). For the moment, our approach only\nuses MS spectra. A Genetic Algorithm (GA) has been designed with a new\nevaluation function which works directly with a complete MS spectrum as input\nand not with a mass list like the other methods using this kind of data. Thus\nthe mono isotopic peak extraction step which needs a human intervention is\ndeleted. The goal of this approach is to discover the sequence of unknown\nproteins and to allow a better understanding of the differences between\nexperimental proteins and proteins from databases."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Notes on the mathematical basis of the UK Non-Native Organism Risk\n  Assessment Scheme"}, {"role": "assistant", "content": "Some problems with the mathematical analysis on which the UK Non-Native\nOrganism Risk Assessment Scheme is based are outlined."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Fine-grained parallelization of similarity search between protein\n  sequences"}, {"role": "assistant", "content": "This report presents the implementation of a protein sequence comparison\nalgorithm specifically designed for speeding up time consuming part on parallel\nhardware such as SSE instructions, multicore architectures or graphic boards.\nThree programs have been developed: PLAST-P, TPLAST-N and PLAST-X. They provide\nequivalent results compared to the NCBI BLAST family programs (BLAST-P,\nTBLAST-N and BLAST-X) with a speed-up factor ranging from 5 to 10."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Applications of information theory in plant disease management"}, {"role": "assistant", "content": "Information theory is a branch of probability and statistics involving the\nanalysis of communications. Information theory enables us to analyze and\nquantify the information content of predictions made in the context of plant\ndisease management and related disciplines. In this article, some applications\nof information theory in plant disease management are outlined."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Sloppiness, robustness, and evolvability in systems biology"}, {"role": "assistant", "content": "The functioning of many biochemical networks is often robust -- remarkably\nstable under changes in external conditions and internal reaction parameters.\nMuch recent work on robustness and evolvability has focused on the structure of\nneutral spaces, in which system behavior remains invariant to mutations.\nRecently we have shown that the collective behavior of multiparameter models is\nmost often 'sloppy': insensitive to changes except along a few 'stiff'\ncombinations of parameters, with an enormous sloppy neutral subspace.\nRobustness is often assumed to be an emergent evolved property, but the\nsloppiness natural to biochemical networks offers an alternative non-adaptive\nexplanation. Conversely, ideas developed to study evolvability in robust\nsystems can be usefully extended to characterize sloppy systems."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Reconstruction of biological networks by supervised machine learning\n  approaches"}, {"role": "assistant", "content": "We review a recent trend in computational systems biology which aims at using\npattern recognition algorithms to infer the structure of large-scale biological\nnetworks from heterogeneous genomic data. We present several strategies that\nhave been proposed and that lead to different pattern recognition problems and\nalgorithms. The strenght of these approaches is illustrated on the\nreconstruction of metabolic, protein-protein and regulatory networks of model\norganisms. In all cases, state-of-the-art performance is reported."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: On the Estimation of the Proportion of True Recent Infections Using the\n  BED Capture Enzyme Immunoassay"}, {"role": "assistant", "content": "In this short note, we analyze the assumptions made by McDougal et al (2006),\nboth explicit and implicit, in their estimation of the proportion of \"true\nrecent infections\" using the BED CEIA. This enables us to write down\nexpressions for the sensitivity, short term specificity and long term\nspecificity of a test for recent infection defined by a BED ODn below a\nthreshold. We then derive an identity which shows the relationship between\nthese parameters, allowing the elimination of sensitivity and short term\nspecificity from an expression relating the proportion of \"true recent\ninfections\" to the proportion of seropositive individuals testing below\nthreshold. This has two important consequences. Firstly, the simplified formula\nis substantially more amenable to calibration. Secondly, naively treating the\nparameters as independent would lead to an incorrect estimate of uncertainty\ndue to imperfect calibration."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Statistical Characterization of a 1D Random Potential Problem - with\n  applications in score statistics of MS-based peptide sequencing"}, {"role": "assistant", "content": "We provide a complete thermodynamic solution of a 1D hopping model in the\npresence of a random potential by obtaining the density of states. Since the\npartition function is related to the density of states by a Laplace transform,\nthe density of states determines completely the thermodynamic behavior of the\nsystem. We have also shown that the transfer matrix technique, or the so-called\ndynamic programming, used to obtain the density of states in the 1D hopping\nmodel may be generalized to tackle a long-standing problem in statistical\nsignificance assessment for one of the most important proteomic tasks - peptide\nsequencing using tandem mass spectrometry data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: RAId_aPS: MS/MS analysis with multiple scoring functions and\n  spectrum-specific statistics"}, {"role": "assistant", "content": "Statistically meaningful comparison/combination of peptide identification\nresults from various search methods is impeded by the lack of a universal\nstatistical standard. Providing an E-value calibration protocol, we\ndemonstrated earlier the feasibility of translating either the score or\nheuristic E-value reported by any method into the textbook-defined E-value,\nwhich may serve as the universal statistical standard. This protocol, although\nrobust, may lose spectrum-specific statistics and might require a new\ncalibration when changes in experimental setup occur. To mitigate these issues,\nwe developed a new MS/MS search tool, RAId_aPS, that is able to provide\nspectrum-specific E-values for additive scoring functions. Given a selection of\nscoring functions out of RAId score, K-score, Hyperscore and XCorr, RAId_aPS\ngenerates the corresponding score histograms of all possible peptides using\ndynamic programming. Using these score histograms to assign E-values enables a\ncalibration-free protocol for accurate significance assignment for each scoring\nfunction. RAId_aPS features four different modes: (i) compute the total number\nof possible peptides for a given molecular mass range, (ii) generate the score\nhistogram given a MS/MS spectrum and a scoring function, (iii) reassign\nE-values for a list of candidate peptides given a MS/MS spectrum and the\nscoring functions chosen, and (iv) perform database searches using selected\nscoring functions. In modes (iii) and (iv), RAId_aPS is also capable of\ncombining results from different scoring functions using spectrum-specific\nstatistics. The web link is\nhttp://www.ncbi.nlm.nih.gov/CBBresearch/Yu/raid_aps/index.html. Relevant\nbinaries for Linux, Windows, and Mac OS X are available from the same page."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Spread of infectious diseases through clustered populations"}, {"role": "assistant", "content": "Networks of person-person contacts form the substrate along which infectious\ndiseases spread. Most network-based studies of the spread focus on the impact\nof variations in degree (the number of contacts an individual has). However,\nother effects such as clustering, variations in infectiousness or\nsusceptibility, or variations in closeness of contacts may play a significant\nrole. We develop analytic techniques to predict how these effects alter the\ngrowth rate, probability, and size of epidemics and validate the predictions\nwith a realistic social network. We find that (for given degree distribution\nand average transmissibility) clustering is the dominant factor controlling the\ngrowth rate, heterogeneity in infectiousness is the dominant factor controlling\nthe probability of an epidemic, and heterogeneity in susceptibility is the\ndominant factor controlling the size of an epidemic. Edge weights (measuring\ncloseness or duration of contacts) have impact only if correlations exist\nbetween different edges. Combined, these effects can play a minor role in\nreinforcing one another, with the impact of clustering largest when the\npopulation is maximally heterogeneous or if the closer contacts are also\nstrongly clustered. Our most significant contribution is a systematic way to\naddress clustering in infectious disease models, and our results have a number\nof implications for the design of interventions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Annotation of Tribolium nuclear receptors reveals an evolutionary\n  overacceleration of a network controlling the ecdysone cascade"}, {"role": "assistant", "content": "The Tribolium genome contains 21 nuclear receptors, representing all of the\nsix known subfamilies. When compared to other species, this first complete set\nfor a Coleoptera reveals a strong conservation of the number and identity of\nnuclear receptors in holometabolous insects. Two novelties are observed: the\natypical NR0 gene knirps is present only in brachyceran flies, while the NR2E6\ngene is found only in Tribolium and in Apis. Using a quantitative analysis of\nthe evolutionary rate, we discovered that nuclear receptors could be divided\ninto two groups. In one group of 13 proteins, the rates follow the trend of the\nMecopterida genome-wide acceleration. In a second group of five nuclear\nreceptors, all acting together at the top of the ecdysone cascade, we observed\nan overacceleration of the evolutionary rate during the early divergence of\nMecopterida. We thus extended our analysis to the twelve classic ecdysone\ntranscriptional regulators and found that six of them (ECR, USP, HR3, E75, HR4\nand Kr-h1) underwent an overacceleration at the base of the Mecopterida\nlineage. By contrast, E74, E93, BR, HR39, FTZ-F1 and E78 do not show this\ndivergence. We suggest that coevolution occurred within a network of regulators\nthat control the ecdysone cascade. The advent of Tribolium as a powerful model\nshould allow a better understanding of this evolution."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Preterm Birth Analysis Using Nonlinear Methods (a preliminary study)"}, {"role": "assistant", "content": "In this report we review modern nonlinearity methods that can be used in the\npreterm birth analysis. The nonlinear analysis of uterine contraction signals\ncan provide information regarding physiological changes during the menstrual\ncycle and pregnancy. This information can be used both for the preterm birth\nprediction and the preterm labor control.\n  Keywords: preterm birth, complex data analysis, nonlinear methods"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: MIC: Mutual Information based hierarchical Clustering"}, {"role": "assistant", "content": "Clustering is a concept used in a huge variety of applications. We review a\nconceptually very simple algorithm for hierarchical clustering called in the\nfollowing the {\\it mutual information clustering} (MIC) algorithm. It uses\nmutual information (MI) as a similarity measure and exploits its grouping\nproperty: The MI between three objects X, Y, and Z is equal to the sum of the\nMI between X and Y, plus the MI between Z and the combined object (XY). We use\nMIC both in the Shannon (probabilistic) version of information theory, where\nthe \"objects\" are probability distributions represented by random samples, and\nin the Kolmogorov (algorithmic) version, where the \"objects\" are symbol\nsequences. We apply our method to the construction of phylogenetic trees from\nmitochondrial DNA sequences and we reconstruct the fetal ECG from the output of\nindependent components analysis (ICA) applied to the ECG of a pregnant woman."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Kohonen neural networks and genetic classification"}, {"role": "assistant", "content": "We discuss the property of a.e. and in mean convergence of the Kohonen\nalgorithm considered as a stochastic process. The various conditions ensuring\nthe a.e. convergence are described and the connection with the rate decay of\nthe learning parameter is analyzed. The rate of convergence is discussed for\ndifferent choices of learning parameters. We proof rigorously that the rate of\ndecay of the learning parameter which is most used in the applications is a\nsufficient condition for a.e. convergence and we check it numerically. The aim\nof the paper is also to clarify the state of the art on the convergence\nproperty of the algorithm in view of the growing number of applications of the\nKohonen neural networks. We apply our theorem and considerations to the case of\ngenetic classification which is a rapidly developing field."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Scar-Driven Shape-Changes of Virus Capsids"}, {"role": "assistant", "content": "We propose that certain patterns (scars) -- theoretically and numerically\npredicted to be formed by electrons arranged on a sphere to minimize the\nrepulsive Coulomb potential (the Thomson problem) and experimentally found in\nspherical crystals formed by self-assembled polystyrene beads (an instance of\nthe {\\it generalized} Thomson problem) -- could be relevant to extend the\nclassic Caspar and Klug construction for icosahedrally-shaped virus capsids.\nThe main idea is that scars could be produced on the capsid at an intermediate\nstage of its evolution and the release of the bending energy present in scars\ninto stretching energy could allow for shape-changes. The conjecture can be\ntested in experiments and/or in numerical simulations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Inference of higher order substitution dynamics by Markov chain lumping"}, {"role": "assistant", "content": "We apply Markov chain lumping techniques to aggregate codons from an\nempirical substitution matrix. The standard genetic code as well as higher\norder amino acid substitution groups are identified. Since the aggregates are\nderived from first principles they do not rely on system dependent assumptions\nmade beforehand, e.g. regarding criteria on what should constitute an amino\nacid group. We therefore argue that the acquired aggregations more accurately\ncapture the multi-level structure of the substitution dynamics than alternative\ntechniques."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Efficient seeding techniques for protein similarity search"}, {"role": "assistant", "content": "We apply the concept of subset seeds proposed in [1] to similarity search in\nprotein sequences. The main question studied is the design of efficient seed\nalphabets to construct seeds with optimal sensitivity/selectivity trade-offs.\nWe propose several different design methods and use them to construct several\nalphabets.We then perform an analysis of seeds built over those alphabet and\ncompare them with the standard Blastp seeding method [2,3], as well as with the\nfamily of vector seeds proposed in [4]. While the formalism of subset seed is\nless expressive (but less costly to implement) than the accumulative principle\nused in Blastp and vector seeds, our seeds show a similar or even better\nperformance than Blastp on Bernoulli models of proteins compatible with the\ncommon BLOSUM62 matrix."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Parallel multi-objective algorithms for the molecular docking problem"}, {"role": "assistant", "content": "Molecular docking is an essential tool for drug design. It helps the\nscientist to rapidly know if two molecules, respectively called ligand and\nreceptor, can be combined together to obtain a stable complex. We propose a new\nmulti-objective model combining an energy term and a surface term to gain such\ncomplexes. The aim of our model is to provide complexes with a low energy and\nlow surface. This model has been validated with two multi-objective genetic\nalgorithms on instances from the literature dedicated to the docking\nbenchmarking."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Communicability in complex brain networks"}, {"role": "assistant", "content": "Recent advances in experimental neuroscience allow, for the first time,\nnon-invasive studies of the white matter tracts in the human central nervous\nsystem, thus making available cutting-edge brain anatomical data describing\nthese global connectivity patterns. This new, non-invasive, technique uses\nmagnetic resonance imaging to construct a snap-shot of the cortical network\nwithin the living human brain. Here, we report on the initial success of a new\nweighted network communicability measure in distinguishing local and global\ndifferences between diseased patients and controls. This approach builds on\nrecent advances in network science, where an underlying connectivity structure\nis used as a means to measure the ease with which information can flow between\nnodes. One advantage of our method is that it deals directly with the\nreal-valued connectivity data, thereby avoiding the need to discretise the\ncorresponding adjacency matrix, that is, to round weights up to 1 or down to 0,\ndepending upon some threshold value. Experimental results indicate that the new\napproach is able to highlight biologically relevant features that are not\nimmediately apparent from the raw connectivity data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Simultaneous Qualitative And Quantitative Identification Of Multiple\n  Targets By Polymerase Chain Reaction On Microarray"}, {"role": "assistant", "content": "An approach for multiplex qualitative and quantitative microarray-based PCR\nanalysis has been proposed. The characteristics of PCR executed on a gel-based\noligonucleotide microarray with immobilized forward primers and a single common\nreverse primer in solution were investigated for several DNA targets. One-stage\nmultiplex on-chip PCR was studied for simultaneous amplification of herpes\nsimplex viruses types 1 and 2, cytomegalovirus DNA, and bacteriophage lambda\nDNA as an internal control. Additionally the joint analysis of increased number\nof targets (with addition of Chlamydia trachomatis, Mycoplasma hominis, and\nUreaplasma urealyticum DNA) was done in two-stage version of assay: first stage\nwas in-tube PCR with target-specific primers, while the reverse ones contained\n5'-adapter region; the second stage was on-chip amplification with immobilized\ntarget-specific forward primers and adapter as common reverse primer in\nsolution. The possible application of one-stage reaction for human cDNA\nanalysis was additionally demonstrated with utilization of a common\npoly-T-containing primer in solution. SYBR green I; and Cy-5 labeled dUTP were\nused for real-time and end-point detection of specific PCR products. The\nefficiencies of both one-stage and two-stage reactions was shown to be strongly\ndependent on magnesium and primers concentrations. Quantitative PCR in the both\nversions was studied with 10-fold serial dilutions of phage lambda DNA. The\nmethod enabled detection of 6 DNA copies per reaction for both versions of\nassay. The quantitative interval for one-stage reaction covered eight orders of\nconcentration. The revealed significant effect of gel pad size on microarray\nPCR effectiveness has been discussed."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Classification of Supersecondary Structures in Proteins Using the\n  Automated Protein Structure Analysis Method"}, {"role": "assistant", "content": "The Automated Protein Structure Analysis (APSA) method is used for the\nclassification of supersecondary structures. Basis for the classification is\nthe encoding of three-dimensional (3D) residue conformations into a 16-letter\ncode (3D-1D projection). It is shown that the letter code of the protein makes\nit possible to reconstruct its overall shape without ambiguity (1D-3D\ntranslation). Accordingly, the letter code is used for the development of\nclassification rules that distinguish supersecondary structures by the\nproperties of their turns and the orientation of the flanking helix or strand\nstructures. The orientations of turn and flanking structures are collected in\nan octant system that helps to specify 196 supersecondary groups for\n(alpha,alpha)-, (alpha,beta)-, (beta,alpha)-, (beta,beta)-class. 391 protein\nchains leading to 2499 super secondary structures were analyzed. Frequently\noccurring super secondary structures are identified with the help of the octant\nclassification system and explained on the basis of their letter and\nclassification codes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Automated and accurate protein structure description: Distribution of\n  Ideal Secondary Structural Units in Natural Proteins"}, {"role": "assistant", "content": "A new method for the Automated Protein Structure Analysis (APSA) is derived,\nwhich simplifies the protein backbone to a smooth curve in 3-dimensional space.\nFor the purpose of obtaining this smooth line each amino acid is represented by\nits C$_{\\alpha}$ atom, which serves as suitable anchor point for a cubic spline\nfit. The backbone line is characterized by arc length $s$, curvature\n$\\kappa(s)$, and torsion $\\tau(s)$. The $\\kappa(s)$ and $\\tau(s)$ diagrams of\nthe protein backbone suppress, because of the level of coarse graining applied,\ndetails of the bond framework of the backbone, however reveal accurately all\nsecondary structure features of a protein. Advantages of APSA are its\nquantitative representation and analysis of 3-dimensional structure in form of\n2-dimensional curvature and torsion patterns, its easy visualization of\ncomplicated conformational features, and its general applicability. Typical\ndifferences between 3$_{10}$-,$\\alpha$-, $\\pi$-helices, and $\\beta$-strands are\nquantified with the help of the $\\kappa(s)$ and $\\tau(s)$ diagrams. For a test\nset of 20 proteins, 63 % of all helical residues and 48.5 % of all extended\nresidues are identified to be in ideal conformational environments with the\nhelp of APSA. APSA is compared with other methods for protein structure\nanalysis and its applicability to higher levels of protein structure is\ndiscussed."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantitative transcription factor binding kinetics at the\n  single-molecule level"}, {"role": "assistant", "content": "We have investigated the binding interaction between the bacteriophage lambda\nrepressor CI and its target DNA using total internal reflection fluorescence\nmicroscopy. Large, step-wise changes in the intensity of the red fluorescent\nprotein fused to CI were observed as it associated and dissociated from\nindividually labeled single molecule DNA targets. The stochastic association\nand dissociation were characterized by Poisson statistics. Dark and bright\nintervals were measured for thousands of individual events. The exponential\ndistribution of the intervals allowed direct determination of the association\nand dissociation rate constants, ka and kd respectively. We resolved in detail\nhow ka and kd varied as a function of 3 control parameters, the DNA length L,\nthe CI dimer concentration, and the binding affinity. Our results show that\nalthough interaction with non-operator DNA sequences are observable, CI binding\nto the operator site is not dependent on the length of flanking non-operator\nDNA."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Remarks on Feedforward Circuits, Adaptation, and Pulse Memory"}, {"role": "assistant", "content": "This note studies feedforward circuits as models for perfect adaptation to\nstep signals in biological systems. A global convergence theorem is proved in a\ngeneral framework, which includes examples from the literature as particular\ncases. A notable aspect of these circuits is that they do not adapt to pulse\nsignals, because they display a memory phenomenon. Estimates are given of the\nmagnitude of this effect."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Revealing subnetwork roles using contextual visualization: comparison of\n  metabolic networks"}, {"role": "assistant", "content": "This article is addressing a recurrent problem in biology: mining newly built\nlarge scale networks. Our approach consists in comparing these new networks to\nwell known ones. The visual backbone of this comparative analysis is provided\nby a network classification hierarchy. This method makes sense when dealing\nwith metabolic networks since comparison could be done using pathways\n(clusters). Moreover each network models an organism and it exists organism\nclassification such as taxonomies. Video demonstration:\nhttp://www.labri.fr/perso/bourqui/video.wmv"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Maximal Information Transfer and Behavior Diversity in Random Threshold\n  Networks"}, {"role": "assistant", "content": "Random Threshold Networks (RTNs) are an idealized model of diluted, non\nsymmetric spin glasses, neural networks or gene regulatory networks. RTNs also\nserve as an interesting general example of any coordinated causal system. Here\nwe study the conditions for maximal information transfer and behavior diversity\nin RTNs. These conditions are likely to play a major role in physical and\nbiological systems, perhaps serving as important selective traits in biological\nsystems. We show that the pairwise mutual information is maximized in\ndynamically critical networks. Also, we show that the correlated behavior\ndiversity is maximized for slightly chaotic networks, close to the critical\nregion. Importantly, critical networks maximize coordinated, diverse dynamical\nbehavior across the network and across time: the information transmission\nbetween source and receiver nodes and the diversity of dynamical behaviors,\nwhen measured with a time delay between the source and receiver, are maximized\nfor critical networks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: On subset seeds for protein alignment"}, {"role": "assistant", "content": "We apply the concept of subset seeds proposed in [1] to similarity search in\nprotein sequences. The main question studied is the design of efficient seed\nalphabets to construct seeds with optimal sensitivity/selectivity trade-offs.\nWe propose several different design methods and use them to construct several\nalphabets. We then perform a comparative analysis of seeds built over those\nalphabets and compare them with the standard BLASTP seeding method [2], [3], as\nwell as with the family of vector seeds proposed in [4]. While the formalism of\nsubset seeds is less expressive (but less costly to implement) than the\ncumulative principle used in BLASTP and vector seeds, our seeds show a similar\nor even better performance than BLASTP on Bernoulli models of proteins\ncompatible with the common BLOSUM62 matrix. Finally, we perform a large-scale\nbenchmarking of our seeds against several main databases of protein alignments.\nHere again, the results show a comparable or better performance of our seeds\nvs. BLASTP."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multiseed Lossless Filtration"}, {"role": "assistant", "content": "We study a method of seed-based lossless filtration for approximate string\nmatching and related bioinformatics applications. The method is based on a\nsimultaneous use of several spaced seeds rather than a single seed as studied\nby Burkhardt and K\\\"arkk\\\"ainen [1]. We present algorithms to compute several\nimportant parameters of seed families, study their combinatorial properties,\nand describe several techniques to construct efficient families. We also report\na large-scale application of the proposed technique to the problem of\noligonucleotide selection for an EST sequence database."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Solving Maximum Clique Problem for Protein Structure Similarity"}, {"role": "assistant", "content": "A basic assumption of molecular biology is that proteins sharing close\nthree-dimensional (3D) structures are likely to share a common function and in\nmost cases derive from a same ancestor. Computing the similarity between two\nprotein structures is therefore a crucial task and has been extensively\ninvestigated. Evaluating the similarity of two proteins can be done by finding\nan optimal one-to-one matching between their components, which is equivalent to\nidentifying a maximum weighted clique in a specific \"alignment graph\". In this\npaper we present a new integer programming formulation for solving such clique\nproblems. The model has been implemented using the ILOG CPLEX Callable Library.\nIn addition, we designed a dedicated branch and bound algorithm for solving the\nmaximum cardinality clique problem. Both approaches have been integrated in\nVAST (Vector Alignment Search Tool) - a software for aligning protein 3D\nstructures largely used in NCBI (National Center for Biotechnology\nInformation). The original VAST clique solver uses the well known Bron and\nKerbosh algorithm (BK). Our computational results on real life protein\nalignment instances show that our branch and bound algorithm is up to 116 times\nfaster than BK for the largest proteins."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: CoPreTHi: a Web tool which combines transmembrane protein segment\n  prediction methods"}, {"role": "assistant", "content": "CoPreTHi is a Java based web application, which combines the results of\nmethods that predict the location of transmembrane segments in protein\nsequences into a joint prediction histogram. Clearly, the joint prediction\nalgorithm, produces superior quality results than individual prediction\nschemes. The program is available at http://o2.db.uoa.gr/CoPreTHi"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A novel method for predicting transmembrane segments in proteins based\n  on a statistical analysis of the SwissProt database: the PRED-TMR algorithm"}, {"role": "assistant", "content": "We present a novel method that predicts transmembrane domains in proteins\nusing solely information contained in the sequence itself. The PRED-TMR\nalgorithm described, refines a standard hydrophobicity analysis with a\ndetection of potential termini ('edges', starts and ends) of transmembrane\nregions. This allows one both to discard highly hydrophobic regions not\ndelimited by clear start and end configurations and to confirm putative\ntransmembrane segments not distinguishable by their hydrophobic composition.\nThe accuracy obtained on a test set of 101 non-homologous transmembrane\nproteins with reliable topologies compares well with that of other popular\nexisting methods. Only a slight decrease in prediction accuracy was observed\nwhen the algorithm was applied to all transmembrane proteins of the SwissProt\ndatabase (release 35). A WWW server running the PRED-TMR algorithm is available\nat http://o2.db.uoa. gr/PRED-TMR/"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A web server to locate periodicities in a sequence"}, {"role": "assistant", "content": "Summary : FT is a tool written in C++, which implements the Fourier analysis\nmethod to locate periodicities in aminoacid or DNA sequences. It is provided\nfor free public use on a WWW server with a Java interface. Availability : The\nserver address is http://o2.db.uoa.gr/FT Contact : shamodr@atlas.uoa.gr"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: PRED-CLASS: cascading neural networks for generalized protein\n  classification and genome-wide applications"}, {"role": "assistant", "content": "A cascading system of hierarchical, artificial neural networks (named\nPRED-CLASS) is presented for the generalized classification of proteins into\nfour distinct classes-transmembrane, fibrous, globular, and mixed-from\ninformation solely encoded in their amino acid sequences. The architecture of\nthe individual component networks is kept very simple, reducing the number of\nfree parameters (network synaptic weights) for faster training, improved\ngeneralization, and the avoidance of data overfitting. Capturing information\nfrom as few as 50 protein sequences spread among the four target classes (6\ntransmembrane, 10 fibrous, 13 globular, and 17 mixed), PRED-CLASS was able to\nobtain 371 correct predictions out of a set of 387 proteins (success rate\napproximately 96%) unambiguously assigned into one of the target classes. The\napplication of PRED-CLASS to several test sets and complete proteomes of\nseveral organisms demonstrates that such a method could serve as a valuable\ntool in the annotation of genomic open reading frames with no functional\nassignment or as a preliminary step in fold recognition and ab initio structure\nprediction methods. Detailed results obtained for various data sets and\ncompleted genomes, along with a web sever running the PRED-CLASS algorithm, can\nbe accessed over the World Wide Web at http://o2.biol.uoa.gr/PRED-CLASS"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Biological data integration using Semantic Web technologies"}, {"role": "assistant", "content": "Current research in biology heavily depends on the availability and efficient\nuse of information. In order to build new knowledge, various sources of\nbiological data must often be combined. Semantic Web technologies, which\nprovide a common framework allowing data to be shared and reused between\napplications, can be applied to the management of disseminated biological data.\nHowever, due to some specificities of biological data, the application of these\ntechnologies to life science constitutes a real challenge. Through a use case\nof biological data integration, we show in this paper that current Semantic Web\ntechnologies start to become mature and can be applied for the development of\nlarge applications. However, in order to get the best from these technologies,\nimprovements are needed both at the level of tool performance and knowledge\nmodeling."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: An hierarchical artificial neural network system for the classification\n  of transmembrane proteins"}, {"role": "assistant", "content": "This work presents a simple artificial neural network which classifies\nproteins into two classes from their sequences alone: the membrane protein\nclass and the non-membrane protein class. This may be important in the\nfunctional assignment and analysis of open reading frames (ORF's) identified in\ncomplete genomes and, especially, those ORF's that correspond to proteins with\nunknown function. The network described here has a simple hierarchical\nfeed-forward topology and a limited number of neurons which makes it very fast.\nBy using only information contained in 11 protein sequences, the method was\nable to identify, with 100% accuracy, all membrane proteins with reliable\ntopologies collected from several papers in the literature. Applied to a test\nset of 995 globular, water-soluble proteins, the neural network classified\nfalsely 23 of them in the membrane protein class (97.7% of correct assignment).\nThe method was also applied to the complete SWISS-PROT database with\nconsiderable success and on ORF's of several complete genomes. The neural\nnetwork developed was associated with the PRED-TMR algorithm (Pasquier,C.,\nPromponas,V.J., Palaios,G.A., Hamodrakas,J.S. and Hamodrakas,S.J., 1999) in a\nnew application package called PRED-TMR2. A WWW server running the PRED-TMR2\nsoftware is available at http://o2.db.uoa.gr/PRED-TMR2"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Current source density reconstruction from incomplete data"}, {"role": "assistant", "content": "We propose two ways of estimating the current source density (CSD) from\nmeasurements of voltage on a Cartesian grid with missing recording points using\nthe inverse CSD method. The simplest approach is to substitute local averages\n(LA) in place of missing data. A more elaborate alternative is to estimate a\nsmaller number of CSD parameters than the actual number of recordings and to\ntake the least-squares fit (LS). We compare the two approaches in the three\ndimensional case on several sets of surrogate and experimental data, for\nvarying numbers of missing data points, and discuss their advantages and\ndrawbacks. One can construct CSD distributions for which one or the other\napproach is better. However, in general, LA method is to be recommended being\nmore stable and more robust to variations in the recorded fields."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Model Error Correction for Linear Methods of Reversible Radioligand\n  Binding Measurements in PET Studies"}, {"role": "assistant", "content": "Graphical analysis methods are widely used in positron emission tomography\nquantification because of their simplicity and model independence. But they\nmay, particularly for reversible kinetics, lead to bias in the estimated\nparameters. The source of the bias is commonly attributed to noise in the data.\nAssuming a two-tissue compartmental model, we investigate the bias that\noriginates from model error. This bias is an intrinsic property of the\nsimplified linear models used for limited scan durations, and it is exaggerated\nby random noise and numerical quadrature error. Conditions are derived under\nwhich Logan's graphical method either over- or under-estimates the distribution\nvolume in the noise-free case. The bias caused by model error is quantified\nanalytically. The presented analysis shows that the bias of graphical methods\nis inversely proportional to the dissociation rate. Furthermore, visual\nexamination of the linearity of the Logan plot is not sufficient for\nguaranteeing that equilibrium has been reached. A new model which retains the\nelegant properties of graphical analysis methods is presented, along with a\nnumerical algorithm for its solution. We perform simulations with the fibrillar\namyloid-beta radioligand [11C] benzothiazole-aniline using published data from\nthe University of Pittsburgh and Rotterdam groups. The results show that the\nproposed method significantly reduces the bias due to model error. Moreover,\nthe results for data acquired over a 70 minutes scan duration are at least as\ngood as those obtained using existing methods for data acquired over a 90\nminutes scan duration."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Reducing the noise effects in Logan graphic analysis for PET receptor\n  measurements"}, {"role": "assistant", "content": "Logan's graphical analysis (LGA) is a widely-used approach for quantification\nof biochemical and physiological processes from Positron emission tomography\n(PET) image data. A well-noted problem associated with the LGA method is the\nbias in the estimated parameters. We recently systematically evaluated the bias\nassociated with the linear model approximation and developed an alternative to\nminimize the bias due to model error. In this study, we examined the noise\nstructure in the equations defining linear quantification methods, including\nLGA. The noise structure conflicts with the conditions given by the\nGauss-Markov theorem for the least squares (LS) solution to generate the best\nlinear unbiased estimator. By carefully taking care of the data error\nstructure, we propose to use structured total least squares (STLS) to obtain\nthe solution using a one-dimensional optimization problem. Simulations of PET\ndata for [11C] benzothiazole-aniline (Pittsburgh Compound-B [PIB]) show that\nthe proposed method significantly reduces the bias. We conclude that the bias\nassociated with noise is primarily due to the unusual structure of he\ncorrelated noise and it can be reduced with the proposed STLS method."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: FDG-PET Parametric Imaging by Total Variation Minimization"}, {"role": "assistant", "content": "Parametric imaging of the cerebral metabolic rate for glucose (CMRGlc) using\n[18F]-fluorodeoxyglucose positron emission tomography is considered.\nTraditional imaging is hindered due to low signal to noise ratios at individual\nvoxels. We propose to minimize the total variation of the tracer uptake rates\nwhile requiring good fit of traditional Patlak equations. This minimization\nguarantees spatial homogeneity within brain regions and good distinction\nbetween brain regions. Brain phantom simulations demonstrate significant\nimprovement in quality of images by the proposed method as compared to Patlak\nimages with post-filtering using Gaussian or median filters."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Geometric Characteristics of Dynamic Correlations for Combinatorial\n  Regulation in Gene Expression Noise"}, {"role": "assistant", "content": "Knowing which mode of combinatorial regulation (typically, AND or OR logic\noperation) that a gene employs is important for determining its function in\nregulatory networks. Here, we introduce a dynamic cross-correlation function\nbetween the output of a gene and its upstream regulator concentrations for\nsignatures of combinatorial regulation in gene expression noise. We find that\nthe correlation function is always upwards convex for the AND operation whereas\ndownwards convex for the OR operation, whichever sources of noise (intrinsic or\nextrinsic or both). In turn, this fact implies a means for inferring regulatory\nsynergies from available experimental data. The extensions and applications are\ndiscussed."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Percolation in clustered networks"}, {"role": "assistant", "content": "The social networks that infectious diseases spread along are typically\nclustered. Because of the close relation between percolation and epidemic\nspread, the behavior of percolation in such networks gives insight into\ninfectious disease dynamics. A number of authors have studied clustered\nnetworks, but the networks often contain preferential mixing between high\ndegree nodes. We introduce a class of random clustered networks and another\nclass of random unclustered networks with the same preferential mixing. We\nanalytically show that percolation in the clustered networks reduces the\ncomponent sizes and increases the epidemic threshold compared to the\nunclustered networks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Distance Maps and Plant Development #1: Uniform Production and\n  Proportional Destruction"}, {"role": "assistant", "content": "Experimental data regarding auxin and venation formation exist at both\nmacroscopic and molecular scales, and we attempt to unify them into a\ncomprehensive model for venation formation. We begin with a set of principles\nto guide an abstract model of venation formation, from which we show how\npatterns in plant development are related to the representation of global\ndistance information locally as cellular-level signals. Venation formation, in\nparticular, is a function of distances between cells and their locations. The\nfirst principle, that auxin is produced at a constant rate in all cells, leads\nto a (Poisson) reaction-diffusion equation. Equilibrium solutions uniquely\ncodify information about distances, thereby providing cells with the signal to\nbegin differentiation from ground to vascular. A uniform destruction hypothesis\nand scaling by cell size leads to a more biologically-relevant (Helmholtz)\nmodel, and simulations demonstrate its capability to predict leaf and root\nauxin distributions and venation patterns. The mathematical development is\ncentered on properties of the distance map, and provides a mechanism by which\nglobal information about shape can be presented locally to individual cells.\nThe principles provide the foundation for an elaboration of these models in a\ncompanion paper \\cite{plos-paper2}, and together they provide a framework for\nunderstanding organ- and plant-scale organization."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Parameter inference and model selection in signaling pathway models"}, {"role": "assistant", "content": "To support and guide an extensive experimental research into systems biology\nof signaling pathways, increasingly more mechanistic models are being developed\nwith hopes of gaining further insight into biological processes. In order to\nanalyse these models, computational and statistical techniques are needed to\nestimate the unknown kinetic parameters. This chapter reviews methods from\nfrequentist and Bayesian statistics for estimation of parameters and for\nchoosing which model is best for modeling the underlying system. Approximate\nBayesian Computation (ABC) techniques are introduced and employed to explore\ndifferent hypothesis about the JAK-STAT signaling pathway."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Distance Maps and Plant Development #2: Facilitated Transport and\n  Uniform Gradient"}, {"role": "assistant", "content": "The principles underlying plant development are extended to allow a more\nmolecular mechanism to elaborate the schema by which ground cells differentiate\ninto vascular cells. Biophysical considerations dictate that linear dynamics\nare not sufficent to capture facilitated auxin transport (e.g., through PIN).\nWe group these transport facilitators into a non-linear model under the\nassumption that they attempt to minimize certain {\\em differences} of auxin\nconcentration. This Constant Gradient Hypothesis greatly increases the\ndescriptive power of our model to include complex dynamical behaviour.\nSpecifically, we show how the early pattern of PIN1 expression appears in the\nembryo, how the leaf primordium emerges, how convergence points arise on the\nleaf margin, how the first loop is formed, and how the intricate pattern of PIN\nshifts during the early establishment of vein patterns in incipient leaves of\nArabidopsis. Given our results, we submit that the model provides evidence that\nmany of the salient structural characteristics that have been described at\nvarious stages of plant development can arise from the uniform application of a\nsmall number of abstract principles."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A new class of highly efficient exact stochastic simulation algorithms\n  for chemical reaction networks"}, {"role": "assistant", "content": "We introduce an alternative formulation of the exact stochastic simulation\nalgorithm (SSA) for sampling trajectories of the chemical master equation for a\nwell-stirred system of coupled chemical reactions. Our formulation is based on\nfactored-out, partial reaction propensities. This novel exact SSA, called the\npartial propensity direct method (PDM), is highly efficient and has a\ncomputational cost that scales at most linearly with the number of chemical\nspecies, irrespective of the degree of coupling of the reaction network. In\naddition, we propose a sorting variant, SPDM, which is especially efficient for\nmultiscale reaction networks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Mass data exploration in oncology: An information synthesis approach"}, {"role": "assistant", "content": "New technologies and equipment allow for mass treatment of samples and\nresearch teams share acquired data on an always larger scale. In this context\nscientists are facing a major data exploitation problem. More precisely, using\nthese data sets through data mining tools or introducing them in a classical\nexperimental approach require a preliminary understanding of the information\nspace, in order to direct the process. But acquiring this grasp on the data is\na complex activity, which is seldom supported by current software tools. The\ngoal of this paper is to introduce a solution to this scientific data grasp\nproblem. Illustrated in the Tissue MicroArrays application domain, the proposal\nis based on the synthesis notion, which is inspired by Information Retrieval\nparadigms. The envisioned synthesis model gives a central role to the study the\nresearcher wants to conduct, through the task notion. It allows for the\nimplementation of a task-oriented Information Retrieval prototype system. Cases\nstudies and user studies were used to validate this prototype system. It opens\ninteresting prospects for the extension of the model or extensions towards\nother application domains."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Bayesian inference of biochemical kinetic parameters using the linear\n  noise approximation"}, {"role": "assistant", "content": "Fluorescent and luminescent gene reporters allow us to dynamically quantify\nchanges in molecular species concentration over time on the single cell level.\nThe mathematical modeling of their interaction through multivariate dynamical\nmodels requires the development of effective statistical methods to calibrate\nsuch models against available data. Given the prevalence of stochasticity and\nnoise in biochemical systems inference for stochastic models is of special\ninterest. In this paper we present a simple and computationally efficient\nalgorithm for the estimation of biochemical kinetic parameters from gene\nreporter data. We use the linear noise approximation to model biochemical\nreactions through a stochastic dynamic model which essentially approximates a\ndiffusion model by an ordinary differential equation model with an\nappropriately defined noise process. An explicit formula for the likelihood\nfunction can be derived allowing for computationally efficient parameter\nestimation. The proposed algorithm is embedded in a Bayesian framework and\ninference is performed using Markov chain Monte Carlo. The major advantage of\nthe method is that in contrast to the more established diffusion approximation\nbased methods the computationally costly methods of data augmentation are not\nnecessary. Our approach also allows for unobserved variables and measurement\nerror. The application of the method to both simulated and experimental data\nshows that the proposed methodology provides a useful alternative to diffusion\napproximation based methods."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Bayesian approach to the probability of coronary heart disease subject\n  to the --308 tumor necrosis factor-$\\alpha$ SNP"}, {"role": "assistant", "content": "We study the correlation of the occurrence of coronary heart disease (CHD)\nwith the presence of the single-nucleotide polymorphism (SNP) at the -308\nposition of the tumor necrosis factor alpha (TNF-$\\alpha$) gene. We also\nconsider the influence of the occurrence of type 2 diabetes (t2DM). Using\nBayesian inference, we first pursue a bottom-up approach to compute the working\nhypothesis and the probabilities derivable from the data. We then pursue a\ntop-down approach by modelling the signal pathway that causally connects the\nSNP with the emergence of CHD. We compute the functional form of the\nprobability of CHD conditional on the presence of the SNP in terms of both the\nstatistical and biochemical properties of the system. From the probability of\noccurrence of a disease conditional on a given risk factor, we explore the\npossibility of extracting information on the pathways involved in the\noccurrence of the disease. This is a first study that we want to systematise\ninto a comprehensive formalism to be applied to the inference of the mechanism\nconnecting the risk factors to the disease."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Attraction to natural stimuli in Drosophila melanogaster"}, {"role": "assistant", "content": "The animals, in particular insects (Drosophila melanogaster), response\ntowards odor stimuli in nature can be established by measuring the dynamic of\nthe odor response. Such an approach is innovative since responses to odors were\ntested only at certain time point so far, not in hour intervals for several\nhours. The odor attraction to 14 natural and ecologically relevant odor stimuli\nsuch as fruits- ripe and rotten, yeast and vinegar was tested. A mathematical\nmodel to evaluate obtained data is proposed in this study in which the number\nof flies caught over several time points is presented as one simple parameter\nshowing trapping potential of the trap housing particular odor stimuli. The\nknowledge concerning dynamic of the odor response in Drosophila melanogaster\nmay enlighten the principles of flies behavior in context of exposure towards\nodor stimulus."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Isoprene and acetone concentration profiles during exercise on an\n  ergometer"}, {"role": "assistant", "content": "A real-time recording setup combining exhaled breath VOC measurements by\nproton transfer reaction mass spectrometry (PTR-MS) with hemodynamic and\nrespiratory data is presented. Continuous automatic sampling of exhaled breath\nis implemented on the basis of measured respiratory flow: a flow-controlled\nshutter mechanism guarantees that only end-tidal exhalation segments are drawn\ninto the mass spectrometer for analysis.\n  Exhaled breath concentration profiles of two prototypic compounds, isoprene\nand acetone, during several exercise regimes were acquired, reaffirming and\ncomplementing earlier experimental findings regarding the dynamic response of\nthese compounds reported by Senthilmohan et al. [1] and Karl et al. [2]. While\nisoprene tends to react very sensitively to changes in pulmonary ventilation\nand perfusion due to its lipophilic behavior and low Henry constant,\nhydrophilic acetone shows a rather stable behavior. Characteristic (median)\nvalues for breath isoprene concentration and molar flow, i.e., the amount of\nisoprene exhaled per minute are 100 ppb and 29 nmol/min, respectively, with\nsome intra-individual day-to-day variation. At the onset of exercise breath\nisoprene concentration increases drastically, usually by a factor of ~3-4\nwithin about one minute. Due to a simultaneous increase in ventilation, the\nassociated rise in molar flow is even more pronounced, leading to a ratio\nbetween peak molar flow and molar flow at rest of ~11.\n  Our setup holds great potential in capturing continuous dynamics of\nnon-polar, low-soluble VOCs over a wide measurement range with simultaneous\nappraisal of decisive physiological factors affecting exhalation kinetics."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Information and (co-)variances in discrete evolutionary genetics\n  involving solely selection"}, {"role": "assistant", "content": "The purpose of this Note is twofold: First, we introduce the general\nformalism of evolutionary genetics dynamics involving fitnesses, under both the\ndeterministic and stochastic setups, and chiefly in discrete-time. In the\nprocess, we particularize it to a one-parameter model where only a selection\nparameter is unknown. Then and in a parallel manner, we discuss the estimation\nproblems of the selection parameter based on a single-generation frequency\ndistribution shift under both deterministic and stochastic evolutionary\ndynamics. In the stochastics, we consider both the celebrated Wright-Fisher and\nMoran models."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Calibrating the self-thinning frontier"}, {"role": "assistant", "content": "Calibration of the self-thinning frontier in even-aged monocultures is\nhampered by scarce data and by subjective decisions about the proximity of data\nto the frontier. We present a simple model that applies to observations of the\nfull trajectory of stand mean diameter across a range of densities not close to\nthe frontier. Development of the model is based on a consideration of the slope\ns=ln(Nt/Nt 1)/ln(Dt/Dt 1) of a log-transformed plot of stocking Nt and mean\nstem diameter Dt at time t. This avoids the need for subjective decisions about\nlimiting density and allows the use of abundant data further from the\nself-thinning frontier. The model can be solved analytically and yields\nequations for the stocking and the stand basal area as an explicit function of\nstem diameter. It predicts that self-thinning may be regulated by the maximum\nbasal area with a slope of -2. The significance of other predictor variables\noffers an effective test of competing self-thinning theories such Yoda's -3/2\npower rule and Reineke's stand density index."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Joint segmentation of many aCGH profiles using fast group LARS"}, {"role": "assistant", "content": "Array-Based Comparative Genomic Hybridization (aCGH) is a method used to\nsearch for genomic regions with copy numbers variations. For a given aCGH\nprofile, one challenge is to accurately segment it into regions of constant\ncopy number. Subjects sharing the same disease status, for example a type of\ncancer, often have aCGH profiles with similar copy number variations, due to\nduplications and deletions relevant to that particular disease. We introduce a\nconstrained optimization algorithm that jointly segments aCGH profiles of many\nsubjects. It simultaneously penalizes the amount of freedom the set of profiles\nhave to jump from one level of constant copy number to another, at genomic\nlocations known as breakpoints. We show that breakpoints shared by many\ndifferent profiles tend to be found first by the algorithm, even in the\npresence of significant amounts of noise. The algorithm can be formulated as a\ngroup LARS problem. We propose an extremely fast way to find the solution path,\ni.e., a sequence of shared breakpoints in order of importance. For no extra\ncost the algorithm smoothes all of the aCGH profiles into piecewise-constant\nregions of equal copy number, giving low-dimensional versions of the original\ndata. These can be shown for all profiles on a single graph, allowing for\nintuitive visual interpretation. Simulations and an implementation of the\nalgorithm on bladder cancer aCGH profiles are provided."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Measuring the Degree of Modularity from Gene Expression Noise in Gene\n  Regulatory Circuits"}, {"role": "assistant", "content": "Gene regulatory circuits show significant stochastic fluctuations in their\ncircuit signals due to the low copy number of transcription factors. When a\ngene circuit component is connected to an existing circuit, the dynamic\nproperties of the existing circuit can be affected by the connected component.\nIn this paper, we investigate modularity in the dynamics of the gene circuit\nbased on stochastic fluctuations in the circuit signals. We show that the noise\nin the output signal of the existing circuit can be affected significantly when\nthe output is connected to the input of another circuit component. More\nspecifically, the output signal noise can show significantly longer\ncorrelations when the two components are connected. This equivalently means\nthat the noise power spectral density becomes narrower. We define the relative\nchange in the correlation time or the spectrum bandwidth by stochastic\nretroactivity, which is shown to be directly related to the retroactivity\ndefined in the deterministic framework by del Vecchio et al. This provides an\ninsight on how to measure retroactivity, by investigating stochastic\nfluctuations in gene expression levels, more specifically, by obtaining an\nautocorrelation function of the fluctuations. We also provide an interesting\naspect of the frequency response of the circuit. We show that depending on the\nmagnitude of operating frequencies, different kinds of signals need to be\npreferably chosen for circuit description in a modular fashion: at low enough\nfrequency, expression level of transcription factor that are not bound to their\nspecific promoter region needs to be chosen, and at high enough frequency, that\nof the total transcription factor, both bound and unbound, does."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Using profiles based on hydropathy properties to define essential\n  regions for splicing"}, {"role": "assistant", "content": "We define new profiles based on hydropathy properties and point out specific\nprofiles for regions surrounding splice sites. We built a set T of flanking\nregions of genes with 1-3 introns from 21st and 22nd chromosomes. These genes\ncontained 313 introns and 385 exons and were extracted from GenBank. They were\nused in order to define hydropathy profiles. Most human introns, around 99.66%,\nare likely to be U2- type introns. They have highly degenerate sequence motifs\nand many different sequences can function as U2-type splice sites. Our new\nprofiles allow to identify regions which have conservative biochemical features\nthat are essential for recognition by spliceosome. We have also found\ndifferences between hydropathy profiles for U2 or U12-types of introns on sets\nof spice sites extracted from SpliceRack database in order to distinguish GT?AG\nintrons belonging to U2 and U12-types. Indeed, intron type cannot be simply\ndetermined by the dinucleotide termini. We show that there is a similarity of\nhydropathy profiles inside intron types. On the one hand, GT?AG and GC?AG\nintrons belonging to U2-type have resembling hydropathy profiles as well as\nAT?AC and GT?AG introns belonging to U12-type. On the other hand, hydropathy\nprofiles of U2 and U12-types GT?AG introns are completely different. Finally,\nwe define and compute a pvalue; we compare our profiles with the profiles\nprovided by a classical method, Pictogram."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Linear model for fast background subtraction in oligonucleotide\n  microarrays"}, {"role": "assistant", "content": "One important preprocessing step in the analysis of microarray data is\nbackground subtraction. In high-density oligonucleotide arrays this is\nrecognized as a crucial step for the global performance of the data analysis\nfrom raw intensities to expression values.\n  We propose here an algorithm for background estimation based on a model in\nwhich the cost function is quadratic in a set of fitting parameters such that\nminimization can be performed through linear algebra. The model incorporates\ntwo effects: 1) Correlated intensities between neighboring features in the chip\nand 2) sequence-dependent affinities for non-specific hybridization fitted by\nan extended nearest-neighbor model.\n  The algorithm has been tested on 360 GeneChips from publicly available data\nof recent expression experiments. The algorithm is fast and accurate. Strong\ncorrelations between the fitted values for different experiments as well as\nbetween the free-energy parameters and their counterparts in aqueous solution\nindicate that the model captures a significant part of the underlying physical\nchemistry."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Computing spatial information from Fourier coefficient distributions"}, {"role": "assistant", "content": "We present an approach to computing spatial information based on Fourier\ncoefficient distributions. The Fourier transform (FT) of an image contains a\ncomplete description of the image, and the values of the FT coefficients are\nuniquely associated with that image. For an image where the distribution of\npixels is uncorrelated, the FT coefficients are normally distributed and\nuncorrelated. Further, the probability distribution for the FT coefficients of\nsuch an image can readily be obtained by Parseval's theorem. We take advantage\nof these properties to compute the spatial information in an image by\ndetermining the probability of each coefficient (both real and imaginary parts)\nin the FT, then using the Shannon formalism to calculate information. By using\nthe probability distribution obtained from Parseval's theorem, an effective\ndistance from the completely uncorrelated or most uncertain case is obtained.\nThe resulting quantity is an information computed in k-space (kSI). This\napproach provides a robust, facile and highly flexible framework for\nquantifying spatial information in images and other types of data (of arbitrary\ndimensions). The kSI metric is tested on a 2D Ising ferromagnet, and the\ntemperature-dependent phase transition is accurately determined from the\nspatial information in configurations of the system."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Drop on demand in a microfluidic chip"}, {"role": "assistant", "content": "In this work, we introduce the novel technique of in-chip drop on demand,\nwhich consists in dispensing picoliter to nanoliter drops on demand directly in\nthe liquid-filled channels of a polymer microfluidic chip, at frequencies up to\n2.5 kHz and with precise volume control. The technique involves a PDMS chip\nwith one or several microliter-size chambers driven by piezoelectric actuators.\nIndividual aqueous microdrops are dispensed from the chamber to a main\ntransport channel filled with an immiscible fluid, in a process analogous to\natmospheric drop on demand dispensing. In this article, the drop formation\nprocess is characterized with respect to critical dispense parameters such as\nthe shape and duration of the driving pulse, and the size of both the fluid\nchamber and the nozzle. Several features of the in-chip drop on demand\ntechnique with direct relevance to lab on a chip applications are presented and\ndiscussed, such as the precise control of the dispensed volume, the ability to\nmerge drops of different reagents and the ability to move a drop from the\nshooting area of one nozzle to another for multi-step reactions. The\npossibility to drive the microfluidic chip with inexpensive audio electronics\ninstead of research-grade equipment is also examined and verified. Finally, we\nshow that the same piezoelectric technique can be used to generate a single gas\nbubble on demand in a microfluidic chip."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The Risk Distribution Curve and its Derivatives"}, {"role": "assistant", "content": "Risk stratification is most directly and informatively summarized as a risk\ndistribution curve. From this curve the ROC curve, predictiveness curve, and\nother curves depicting risk stratification can be derived, demonstrating that\nthey present similar information. A mathematical expression for the ROC curve\nAUC is derived which clarifies how this measure of discrimination quantifies\nthe overlap between patients who have and don't have events. This expression is\nused to define the positive correlation between the dispersion of the risk\ndistribution curve and the ROC curve AUC. As more disperse risk distributions\nand greater separation between patients with and without events characterize\nsuperior risk stratification, the ROC curve AUC provides useful information."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Noise and nonlinearities in high-throughput data"}, {"role": "assistant", "content": "High-throughput data analyses are becoming common in biology, communications,\neconomics and sociology. The vast amounts of data are usually represented in\nthe form of matrices and can be considered as knowledge networks. Spectra-based\napproaches have proved useful in extracting hidden information within such\nnetworks and for estimating missing data, but these methods are based\nessentially on linear assumptions. The physical models of matching, when\napplicable, often suggest non-linear mechanisms, that may sometimes be\nidentified as noise. The use of non-linear models in data analysis, however,\nmay require the introduction of many parameters, which lowers the statistical\nweight of the model. According to the quality of data, a simpler linear\nanalysis may be more convenient than more complex approaches.\n  In this paper, we show how a simple non-parametric Bayesian model may be used\nto explore the role of non-linearities and noise in synthetic and experimental\ndata sets."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The Discordance of Individual Risk Estimates and the Reference Class\n  Problem"}, {"role": "assistant", "content": "Multivariate methods that relate outcomes to risk factors have been adopted\nclinically to individualize treatment. This has promoted the belief that\nindividuals have a true or unique risk.\n  The logic of assigning an individual a single risk value has been criticized\nsince 1866. The reason is that any individual can be simultaneously considered\na member of different groups, with each group having its own risk level (the\nreference class problem).\n  Lemeshow et al. provided well-documented examples of remarkable discordance\nbetween predictions for an individual by different valid predictive methods\nutilizing different risk factors. The prevalence of such discordance is unknown\nas it is rarely evaluated, but must be substantial due to the abundance of risk\nfactors.\n  Lemeshow et al. cautioned against using ICU mortality predictions for the\nprovision of care to individual patients. If individual risk estimates are used\nclinically, users should be aware that valid methods may give very different\nresults."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Back-translation for discovering distant protein homologies"}, {"role": "assistant", "content": "Frameshift mutations in protein-coding DNA sequences produce a drastic change\nin the resulting protein sequence, which prevents classic protein alignment\nmethods from revealing the proteins' common origin. Moreover, when a large\nnumber of substitutions are additionally involved in the divergence, the\nhomology detection becomes difficult even at the DNA level. To cope with this\nsituation, we propose a novel method to infer distant homology relations of two\nproteins, that accounts for frameshift and point mutations that may have\naffected the coding sequences. We design a dynamic programming alignment\nalgorithm over memory-efficient graph representations of the complete set of\nputative DNA sequences of each protein, with the goal of determining the two\nputative DNA sequences which have the best scoring alignment under a powerful\nscoring system designed to reflect the most probable evolutionary process. This\nallows us to uncover evolutionary information that is not captured by\ntraditional alignment methods, which is confirmed by biologically significant\nexamples."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Tracking of individual freely diffusing fluorescent protein molecules in\n  the bacterial cytoplasm"}, {"role": "assistant", "content": "We combine stroboscopic laser excitation with stochastic photoactivation and\nsuper-resolution fluorescence imaging. This makes it possible to record\nhundreds of diffusion trajectories of small protein molecules in single\nbacterial cells with millisecond time resolution and sub-diffraction limited\nspatial precision. We conclude that the small protein mEos2 exhibits normal\ndiffusion in the bacterial cytoplasm with a diffusion coefficient of 13.1 -+\n1.2 \\mu m^2 s^(-1). This investigation lays the groundwork for studying\nsingle-molecule binding and dissociation events for a wide range of\nintracellular processes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Prediction in the Hypothesis-Rich Regime"}, {"role": "assistant", "content": "We describe the fundamental difference between the nature of problems in\ntraditional physics and that of many problems arising today in systems biology\nand other complex settings. The difference hinges on the much larger number of\na priori plausible alternative laws for explaining the phenomena at hand in the\nlatter case. An approach and a mathematical framework for prediction in this\nhypothesis-rich regime are introduced."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A mathematical model for breath gas analysis of volatile organic\n  compounds with special emphasis on acetone"}, {"role": "assistant", "content": "Recommended standardized procedures for determining exhaled lower respiratory\nnitric oxide and nasal nitric oxide have been developed by task forces of the\nEuropean Respiratory Society and the American Thoracic Society. These\nrecommendations have paved the way for the measurement of nitric oxide to\nbecome a diagnostic tool for specific clinical applications. It would be\ndesirable to develop similar guidelines for the sampling of other trace gases\nin exhaled breath, especially volatile organic compounds (VOCs) which reflect\nongoing metabolism. The concentrations of water-soluble, blood-borne substances\nin exhaled breath are influenced by: (i) breathing patterns affecting gas\nexchange in the conducting airways; (ii) the concentrations in the\ntracheo-bronchial lining fluid; (iii) the alveolar and systemic concentrations\nof the compound. The classical Farhi equation takes only the alveolar\nconcentrations into account. Real-time measurements of acetone in end-tidal\nbreath under an ergometer challenge show characteristics which cannot be\nexplained within the Farhi setting. Here we develop a compartment model that\nreliably captures these profiles and is capable of relating breath to the\nsystemic concentrations of acetone. By comparison with experimental data it is\ninferred that the major part of variability in breath acetone concentrations\n(e.g., in response to moderate exercise or altered breathing patterns) can be\nattributed to airway gas exchange, with minimal changes of the underlying blood\nand tissue concentrations. Moreover, it is deduced that measured end-tidal\nbreath concentrations of acetone determined during resting conditions and free\nbreathing will be rather poor indicators for endogenous levels. Particularly,\nthe current formulation includes the classical Farhi and the Scheid series\ninhomogeneity model as special limiting cases."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantifying the Bicoid morphogen gradient in living fly embryos"}, {"role": "assistant", "content": "In multicellular organisms, patterns of gene expression are established in\nresponse to gradients of signaling molecules. During fly development in early\nDrosophila embryos, the Bicoid (Bcd) morphogen gradient is established within\nthe first hour after fertilization. Bcd acts as a transcription factor,\ninitiating the expression of a cascade of genes that determine the segmentation\npattern of the embryo, which serves as a blueprint for the future adult\norganism. A robust understanding of the mechanisms that govern this\nsegmentation cascade is still lacking, and a new generation of quantitative\nmeasurements of the spatio-temporal concentration dynamics of the individual\nplayers of this cascade are necessary for further progress. Here we describe a\nseries of methods that are meant to represent a start of such a quantification\nusing Bcd as an example. We describe the generation of a transgenic fly line\nexpressing a Bcd-eGFP fusion protein, and we use this line to carefully analyze\nthe Bcd concentration dynamics and to measure absolute Bcd expression levels in\nliving fly embryos using two-photon microscopy. These experiments have proven\nto be a fruitful tool generating new insights into the mechanisms that lead to\nthe establishment and the readout of the Bcd gradient. Generalization of these\nmethods to other genes in the Drosophila segmentation cascade is\nstraightforward and should further our understanding of the early patterning\nprocesses and the architecture of the underlying genetic network structure."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Robust and accurate data enrichment statistics via distribution function\n  of sum of weights"}, {"role": "assistant", "content": "Term enrichment analysis facilitates biological interpretation by assigning\nto experimentally/computationally obtained data annotation associated with\nterms from controlled vocabularies. This process usually involves obtaining\nstatistical significance for each vocabulary term and using the most\nsignificant terms to describe a given set of biological entities, often\nassociated with weights. Many existing enrichment methods require selections of\n(arbitrary number of) the most significant entities and/or do not account for\nweights of entities. Others either mandate extensive simulations to obtain\nstatistics or assume normal weight distribution. In addition, most methods have\ndifficulty assigning correct statistical significance to terms with few\nentities. Implementing the well-known Lugananni-Rice formula, we have developed\na novel approach, called SaddleSum, that is free from all the aforementioned\nconstraints and evaluated it against several existing methods. With entity\nweights properly taken into account, SaddleSum is internally consistent and\nstable with respect to the choice of number of most significant entities\nselected. Making few assumptions on the input data, the proposed method is\nuniversal and can thus be applied to areas beyond analysis of microarrays.\nEmploying asymptotic approximation, SaddleSum provides a term-size dependent\nscore distribution function that gives rise to accurate statistical\nsignificance even for terms with few entities. As a consequence, SaddleSum\nenables researchers to place confidence in its significance assignments to\nsmall terms that are often biologically most specific."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Efficient parameter search for qualitative models of regulatory networks\n  using symbolic model checking"}, {"role": "assistant", "content": "Investigating the relation between the structure and behavior of complex\nbiological networks often involves posing the following two questions: Is a\nhypothesized structure of a regulatory network consistent with the observed\nbehavior? And can a proposed structure generate a desired behavior? Answering\nthese questions presupposes that we are able to test the compatibility of\nnetwork structure and behavior. We cast these questions into a parameter search\nproblem for qualitative models of regulatory networks, in particular\npiecewise-affine differential equation models. We develop a method based on\nsymbolic model checking that avoids enumerating all possible parametrizations,\nand show that this method performs well on real biological problems, using the\nIRMA synthetic network and benchmark experimental data sets. We test the\nconsistency between the IRMA network structure and the time-series data, and\nsearch for parameter modifications that would improve the robustness of the\nexternal control of the system behavior."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: C Library for Simulated Evolution of Biological Networks"}, {"role": "assistant", "content": "Simulated evolution of biological networks can be used to generate functional\nnetworks as well as investigate hypotheses regarding natural evolution. A\nhandful of studies have shown how simulated evolution can be used for studying\nthe functional space spanned by biochemical networks, studying natural\nevolution, or designing new synthetic networks. If there was a method for\neasily performing such studies, it can allow the community to further\nexperiment with simulated evolution and explore all of its uses. As a result,\nwe have developed a library written in the C language that performs all the\nbasic functions needed to carry out simulated evolution of biological networks.\nThe library comes with a generic genetic algorithm as well as genetic\nalgorithms for specifically evolving genetic networks, protein networks, or\nmass-action networks. The library also comes with functions for simulating\nthese networks. A user needs to specify a desired function. A GUI is provided\nfor users to become oriented with all the options available in the library. The\nlibrary is free and open source under the BSD lisence and can be obtained at\nevolvenetworks.sourceforge.net. It can be built on all major platforms. The\ncode can be most conveniently compiled using cross-platform make (CMake)."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: NTRFINDER: A Software Tool to Find Nested Tandem Repeats"}, {"role": "assistant", "content": "We introduce the software tool NTRFinder to find the complex repetitive\nstructure in DNA we call a nested tandem repeat (NTR). An NTR is a recurrence\nof two or more distinct tandem motifs interspersed with each other. We propose\nthat nested tandem repeats can be used as phylogenetic and population markers.\nWe have tested our algorithm on both real and simulated data, and present some\nreal nested tandem repeats of interest. We discuss how the NTR found in the\nribosomal DNA of taro (Colocasia esculenta) may assist in determining the\ncultivation prehistory of this ancient staple food crop. NTRFinder can be\ndownloaded from http://www.maths.otago.ac.nz/? aamatroud/."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Pair HMM based gap statistics for re-evaluation of indels in alignments\n  with affine gap penalties: Extended Version"}, {"role": "assistant", "content": "Although computationally aligning sequence is a crucial step in the vast\nmajority of comparative genomics studies our understanding of alignment biases\nstill needs to be improved. To infer true structural or homologous regions\ncomputational alignments need further evaluation. It has been shown that the\naccuracy of aligned positions can drop substantially in particular around gaps.\nHere we focus on re-evaluation of score-based alignments with affine gap\npenalty costs. We exploit their relationships with pair hidden Markov models\nand develop efficient algorithms by which to identify gaps which are\nsignificant in terms of length and multiplicity. We evaluate our statistics\nwith respect to the well-established structural alignments from SABmark and\nfind that indel reliability substantially increases with their significance in\nparticular in worst-case twilight zone alignments. This points out that our\nstatistics can reliably complement other methods which mostly focus on the\nreliability of match positions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Efficient chaining of seeds in ordered trees"}, {"role": "assistant", "content": "We consider here the problem of chaining seeds in ordered trees. Seeds are\nmappings between two trees Q and T and a chain is a subset of non overlapping\nseeds that is consistent with respect to postfix order and ancestrality. This\nproblem is a natural extension of a similar problem for sequences, and has\napplications in computational biology, such as mining a database of RNA\nsecondary structures. For the chaining problem with a set of m constant size\nseeds, we describe an algorithm with complexity O(m2 log(m)) in time and O(m2)\nin space."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Optimal pooling strategies for laboratory testing"}, {"role": "assistant", "content": "We consider the optimal strategy for laboratory testing of biological samples\nwhen we wish to know the results for each sample rather than the average\nprevalence of positive samples. If the proportion of positive samples is low\nconsiderable resources may be devoted to testing samples most of which are\nnegative. An attractive strategy is to pool samples. If the pooled samples test\npositive one must then test the individual samples, otherwise they can all be\nassumed to be negative. The pool should be big enough to reduce the number of\ntests but not so big that the pooled samples are almost all positive. We show\nthat if the prevalence of positive samples is greater than 30% it is never\nworth pooling. From 30% down to 1% pools of size 4 are close to optimal. Below\n1% substantial gains can be made by pooling, especially if the samples are\npooled twice. However, with large pools the sensitivity of the test will fall\ncorrespondingly and this must be taken into consideration. We derive simple\nexpressions for the optimal pool size and for the corresponding proportion of\nsamples tested."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Markov invariants for phylogenetic rate matrices derived from embedded\n  submodels"}, {"role": "assistant", "content": "We consider novel phylogenetic models with rate matrices that arise via the\nembedding of a progenitor model on a small number of character states, into a\ntarget model on a larger number of character states. Adapting\nrepresentation-theoretic results from recent investigations of Markov\ninvariants for the general rate matrix model, we give a prescription for\nidentifying and counting Markov invariants for such `symmetric embedded'\nmodels, and we provide enumerations of these for low-dimensional cases. The\nsimplest example is a target model on 3 states, constructed from a general 2\nstate model; the `2->3' embedding. We show that for 2 taxa, there exist two\ninvariants of quadratic degree, that can be used to directly infer pairwise\ndistances from observed sequences under this model. A simple simulation study\nverifies their theoretical expected values, and suggests that, given the\nappropriateness of the model class, they have greater statistical power than\nthe standard (log) Det invariant (which is of cubic degree for this case)."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantitative Analysis of the Effective Functional Structure in Yeast\n  Glycolysis"}, {"role": "assistant", "content": "Yeast glycolysis is considered the prototype of dissipative biochemical\noscillators. In cellular conditions, under sinusoidal source of glucose, the\nactivity of glycolytic enzymes can display either periodic, quasiperiodic or\nchaotic behavior.\n  In order to quantify the functional connectivity for the glycolytic enzymes\nin dissipative conditions we have analyzed different catalytic patterns using\nthe non-linear statistical tool of Transfer Entropy. The data were obtained by\nmeans of a yeast glycolytic model formed by three delay differential equations\nwhere the enzymatic speed functions of the irreversible stages have been\nexplicitly considered. These enzymatic activity functions were previously\nmodeled and tested experimentally by other different groups. In agreement with\nexperimental conditions, the studied time series corresponded to a\nquasi-periodic route to chaos. The results of the analysis are three-fold:\nfirst, in addition to the classical topological structure characterized by the\nspecific location of enzymes, substrates, products and feedback regulatory\nmetabolites, an effective functional structure emerges in the modeled\nglycolytic system, which is dynamical and characterized by notable variations\nof the functional interactions. Second, the dynamical structure exhibits a\nmetabolic invariant which constrains the functional attributes of the enzymes.\nFinally, in accordance with the classical biochemical studies, our numerical\nanalysis reveals in a quantitative manner that the enzyme phosphofructokinase\nis the key-core of the metabolic system, behaving for all conditions as the\nmain source of the effective causal flows in yeast glycolysis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Phylogenetic tree calculations using the Grid with DAG job"}, {"role": "assistant", "content": "The goal of the work is to implement molecular phylogenetic calculations\nusing the Grid paradigm by means of the MrBayes software using Directed Acyclic\nGraphs (DAG) jobs. In this method, a set of jobs depends on the input or the\noutput of other jobs. Once the runs have been successfully done, all the\nresults can be collected by a specific Perl script inside the defined DAG job.\nFor testing this methodology, we calculate the evolution of papillomavirus with\n121 sequences."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantitative Analysis by the Point-Centered Quarter Method"}, {"role": "assistant", "content": "This document is an introduction to the use of the point-centered quarter\nmethod. It briefly outlines its history, its methodology, and some of the\npractical issues (and modifications) that inevitably arise with its use in the\nfield. Additionally this paper shows how data collected using point-centered\nquarter method sampling may be used to determine importance values of different\nspecies of trees and describes and derives several methods of estimating plant\ndensity and corresponding confidence intervals. New to this revision is an\nappendix of R functions to carry out these calculations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Inferring hidden Markov models from noisy time sequences: a method to\n  alleviate degeneracy in molecular dynamics"}, {"role": "assistant", "content": "We present a new method for inferring hidden Markov models from noisy time\nsequences without the necessity of assuming a model architecture, thus allowing\nfor the detection of degenerate states. This is based on the statistical\nprediction techniques developed by Crutchfield et al., and generates so called\ncausal state models, equivalent to hidden Markov models. This method is\napplicable to any continuous data which clusters around discrete values and\nexhibits multiple transitions between these values such as tethered particle\nmotion data or Fluorescence Resonance Energy Transfer (FRET) spectra. The\nalgorithms developed have been shown to perform well on simulated data,\ndemonstrating the ability to recover the model used to generate the data under\nhigh noise, sparse data conditions and the ability to infer the existence of\ndegenerate states. They have also been applied to new experimental FRET data of\nHolliday Junction dynamics, extracting the expected two state model and\nproviding values for the transition rates in good agreement with previous\nresults and with results obtained using existing maximum likelihood based\nmethods."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: When the optimal is not the best: parameter estimation in complex\n  biological models"}, {"role": "assistant", "content": "Background: The vast computational resources that became available during the\npast decade enabled the development and simulation of increasingly complex\nmathematical models of cancer growth. These models typically involve many free\nparameters whose determination is a substantial obstacle to model development.\nDirect measurement of biochemical parameters in vivo is often difficult and\nsometimes impracticable, while fitting them under data-poor conditions may\nresult in biologically implausible values.\n  Results: We discuss different methodological approaches to estimate\nparameters in complex biological models. We make use of the high computational\npower of the Blue Gene technology to perform an extensive study of the\nparameter space in a model of avascular tumor growth. We explicitly show that\nthe landscape of the cost function used to optimize the model to the data has a\nvery rugged surface in parameter space. This cost function has many local\nminima with unrealistic solutions, including the global minimum corresponding\nto the best fit.\n  Conclusions: The case studied in this paper shows one example in which model\nparameters that optimally fit the data are not necessarily the best ones from a\nbiological point of view. To avoid force-fitting a model to a dataset, we\npropose that the best model parameters should be found by choosing, among\nsuboptimal parameters, those that match criteria other than the ones used to\nfit the model. We also conclude that the model, data and optimization approach\nform a new complex system, and point to the need of a theory that addresses\nthis problem more generally."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Information theory and adaptation"}, {"role": "assistant", "content": "In this Chapter, we ask questions (1) What is the right way to measure the\nquality of information processing in a biological system? and (2) What can\nreal-life organisms do in order to improve their performance in\ninformation-processing tasks? We then review the body of work that investigates\nthese questions experimentally, computationally, and theoretically in\nbiological domains as diverse as cell biology, population biology, and\ncomputational neuroscience"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Conan: a platform for complex network analysis"}, {"role": "assistant", "content": "Conan is a C++ library created for the accurate and efficient modelling,\ninference and analysis of complex networks. It implements the generation and\nmodification of graphs according to several published models, as well as the\nunexpensive computation of global and local network properties. Other features\ninclude network inference and community detection. Furthermore, Conan provides\na Python interface to facilitate the use of the library and its integration in\ncurrently existing applications.\n  Conan is available at http://github.com/rhz/conan/."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Detection of mixed-culture growth in the total biomass data by wavelet\n  transforms"}, {"role": "assistant", "content": "We have shown elsewhere that the presence of mixed-culture growth of\nmicrobial species in fermentation processes can be detected with high accuracy\nby employing the wavelet transform. This is achieved because the crosses in the\ndifferent growth processes contributing to the total biomass signal appear as\nsingularities that are very well evidenced through their singularity cones in\nthe wavelet transform. However, we used very simple two-species cases. In this\nwork, we extend the wavelet method to a more complicated illustrative\nfermentation case of three microbial species for which we employ several\nwavelets of different number of vanishing moments in order to eliminate\npossible numerical artifacts. Working in this way allows to filter in a more\nprecise way the numerical values of the H\\\"older exponents. Therefore, we were\nable to determine the characteristic H\\\"older exponents for the corresponding\ncrossing singularities of the microbial growth processes and their stability\nlogarithmic scale ranges up to the first decimal in the value of the\ncharacteristic exponents. Since calibrating the mixed microbial growth by means\nof their H\\\"older exponents could have potential industrial applications, the\ndependence of the H\\\"older exponents on the kinetic and physical parameters of\nthe growth models remains as a future experimental task"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A robust two-gene oscillator at the core of Ostreococcus tauri circadian\n  clock"}, {"role": "assistant", "content": "The microscopic green alga Ostreococcus tauri is rapidly emerging as a\npromising model organism in the green lineage. In particular, recent results by\nCorellou et al. [Plant Cell, 21, 3436 (2009)] and Thommen et al. [PLoS Comput.\nBiol. 6, e1000990 (2010)] strongly suggest that its circadian clock is a\nsimplified version of Arabidopsis thaliana clock, and that it is architectured\nso as to be robust to natural daylight fluctuations. In this work, we analyze\ntime series data from luminescent reporters for the two central clock genes\nTOC1 and CCA1 and correlate them with microarray data previously analyzed. Our\nmathematical analysis strongly supports both the existence of a simple two-gene\noscillator at the core of Ostreococcus tauri clock and the fact that its\ndynamics is not affected by light in normal entrainment conditions, a signature\nof its robustness."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Distributed computing applied applied to the identification of new drugs"}, {"role": "assistant", "content": "This work emphasizes the assets of implementing the distributed computing for\nthe intensive use in computational science devoted to the search of new\nmedicines that could be applied in public healthy problems."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Genetic Classification of Populations using Supervised Learning"}, {"role": "assistant", "content": "There are many instances in genetics in which we wish to determine whether\ntwo candidate populations are distinguishable on the basis of their genetic\nstructure. Examples include populations which are geographically separated,\ncase--control studies and quality control (when participants in a study have\nbeen genotyped at different laboratories). This latter application is of\nparticular importance in the era of large scale genome wide association\nstudies, when collections of individuals genotyped at different locations are\nbeing merged to provide increased power. The traditional method for detecting\nstructure within a population is some form of exploratory technique such as\nprincipal components analysis. Such methods, which do not utilise our prior\nknowledge of the membership of the candidate populations. are termed\n\\emph{unsupervised}. Supervised methods, on the other hand are able to utilise\nthis prior knowledge when it is available.\n  In this paper we demonstrate that in such cases modern supervised approaches\nare a more appropriate tool for detecting genetic differences between\npopulations. We apply two such methods, (neural networks and support vector\nmachines) to the classification of three populations (two from Scotland and one\nfrom Bulgaria). The sensitivity exhibited by both these methods is considerably\nhigher than that attained by principal components analysis and in fact\ncomfortably exceeds a recently conjectured theoretical limit on the sensitivity\nof unsupervised methods. In particular, our methods can distinguish between the\ntwo Scottish populations, where principal components analysis cannot. We\nsuggest, on the basis of our results that a supervised learning approach should\nbe the method of choice when classifying individuals into pre-defined\npopulations, particularly in quality control for large scale genome wide\nassociation studies."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Investigations of a compartmental model for leucine kinetics using\n  nonlinear mixed effects models with ordinary and stochastic differential\n  equations"}, {"role": "assistant", "content": "Nonlinear mixed effects models represent a powerful tool to simultaneously\nanalyze data from several individuals. In this study a compartmental model of\nleucine kinetics is examined and extended with a stochastic differential\nequation to model non-steady state concentrations of free leucine in the\nplasma. Data obtained from tracer/tracee experiments for a group of healthy\ncontrol individuals and a group of individuals suffering from diabetes mellitus\ntype 2 are analyzed. We find that the interindividual variation of the model\nparameters is much smaller for the nonlinear mixed effects models, compared to\ntraditional estimates obtained from each individual separately. Using the mixed\neffects approach, the population parameters are estimated well also when only\nhalf of the data are used for each individual. For a typical individual the\namount of free leucine is predicted to vary with a standard deviation of 8.9%\naround a mean value during the experiment. Moreover, leucine degradation and\nprotein uptake of leucine is smaller, proteolysis larger, and the amount of\nfree leucine in the body is much larger for the diabetic individuals than the\ncontrol individuals. In conclusion nonlinear mixed effects models offers\nimproved estimates for model parameters in complex models based on\ntracer/tracee data and may be a suitable tool to reduce data sampling in\nclinical studies."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Numerical Solution of a Complete Formulation of Flow in a Perfusion\n  Bone-Tissue Bioreactor Using Lattice Boltzmann Equation Method"}, {"role": "assistant", "content": "We report the key findings from numerical solutions of a model of transport\nwithin an established perfusion bioreactor design. The model includes a\ncomplete formulation of transport with fully coupled convection-diffusion and\nscaffold cell attachment. It also includes the experimentally determined\ninternal (Poly-L-Lactic Acid (PLLA)) scaffold boundary, together with the\nexternal vessel and flow-port boundaries. Our findings, obtained using parallel\nlattice Boltzmann equation method, relate to (i) whole-device, steady-state\nflow and species distribution and (ii) the properties of the scaffold. In\nparticular the results identify which elements of the problem may be addressed\nby coarse grained methods such as the Darcy approximation and those which\nrequire a more complete description. The work demonstrates that appropriate\nnumerical modelling will make a key contribution to the design and development\nof large scale bioreactors."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: GSGS: A Computational Framework to Reconstruct Signaling Pathways from\n  Gene Sets"}, {"role": "assistant", "content": "We propose a novel two-stage Gene Set Gibbs Sampling (GSGS) framework, to\nreverse engineer signaling pathways from gene sets inferred from molecular\nprofiling data. We hypothesize that signaling pathways are structurally an\nensemble of overlapping linear signal transduction events which we encode as\nInformation Flow Gene Sets (IFGS's). We infer pathways from gene sets\ncorresponding to these events subjected to a random permutation of genes within\neach set. In Stage I, we use a source separation algorithm to derive unordered\nand overlapping IFGS's from molecular profiling data, allowing cross talk among\nIFGS's. In Stage II, we develop a Gibbs sampling like algorithm, Gene Set Gibbs\nSampler, to reconstruct signaling pathways from the latent IFGS's derived in\nStage I. The novelty of this framework lies in the seamless integration of the\ntwo stages and the hypothesis of IFGS's as the basic building blocks for signal\npathways. In the proof-of-concept studies, our approach is shown to outperform\nthe existing Bayesian network approaches using both continuous and discrete\ndata generated from benchmark networks in the DREAM initiative. We perform a\ncomprehensive sensitivity analysis to assess the robustness of the approach.\nFinally, we implement the GSGS framework to reconstruct signaling pathways in\nbreast cancer cells."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Models of Membrane Electrostatics"}, {"role": "assistant", "content": "I derive formulas for the electrostatic potential of a charge in or near a\nmembrane modeled as one or more dielectric slabs lying between two\nsemi-infinite dielectrics. One can use these formulas in Monte Carlo codes to\ncompute the distribution of ions near cell membranes more accurately than by\nusing Poisson-Boltzmann theory or its linearized version. Here I use them to\ndiscuss the electric field of a uniformly charged membrane, the image charges\nof an ion, the distribution of salt ions near a charged membrane, the energy of\na zwitterion near a lipid slab, and the effect of including the phosphate head\ngroups as thin layers of high electric permittivity."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The Quasi-Steady State Assumption in an Enzymatically Open System"}, {"role": "assistant", "content": "The quasi-steady state assumption (QSSA) forms the basis for rigorous\nmathematical justification of the Michaelis-Menten formalism commonly used in\nmodeling a broad range of intracellular phenomena. A critical supposition of\nQSSA-based analyses is that the underlying biochemical reaction is\nenzymatically \"closed,\" so that free enzyme is neither added to nor removed\nfrom the reaction over the relevant time period. Yet there are multiple\ncircumstances in living cells under which this assumption may not hold, e.g.\nduring translation of genetic elements or metabolic regulatory events. Here we\nconsider a modified version of the most basic enzyme-catalyzed reaction which\nincorporates enzyme input and removal. We extend the QSSA to this enzymatically\n\"open\" system, computing inner approximations to its dynamics, and we compare\nthe behavior of the full open system, our approximations, and the closed system\nunder broad range of kinetic parameters. We also derive conditions under which\nour new approximations are provably valid; numerical simulations demonstrate\nthat our approximations remain quite accurate even when these conditions are\nnot satisfied. Finally, we investigate the possibility of damped oscillatory\nbehavior in the enzymatically open reaction."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Finding Complex Biological Relationships in Recent PubMed Articles Using\n  Bio-LDA"}, {"role": "assistant", "content": "The overwhelming amount of available scholarly literature in the life\nsciences poses significant challenges to scientists wishing to keep up with\nimportant developments related to their research, but also provides a useful\nresource for the discovery of recent information concerning genes, diseases,\ncompounds and the interactions between them. In this paper, we describe an\nalgorithm called Bio-LDA that uses extracted biological terminology to\nautomatically identify latent topics, and provides a variety of measures to\nuncover putative relations among topics and bio-terms. Relationships identified\nusing those approaches are combined with existing data in life science datasets\nto provide additional insight. Three case studies demonstrate the utility of\nthe Bio-LDA model, including association predication, association search and\nconnectivity map generation. This combined approach offers new opportunities\nfor knowledge discovery in many areas of biology including target\nidentification, lead hopping and drug repurposing."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: High-Throughput Biologically Optimized Search Engineering Approach to\n  Synthetic Biology"}, {"role": "assistant", "content": "Synthetic Biology is the new engineering-based approach to biology that\nincludes applications of designing complex biological devices. At present, it\nis not yet clear what will emerge as the defining principles of Synthetic\nBiology. One proposed approach is to build Synthetic Biology around the\nclassical engineering principles of standardization, modularity/decoupling and\nabstraction/modeling to facilitate component-based design. In this article we\nsuggest and discuss an alternative paradigm, which we call High-throughput\nBiologically Optimized Search Engineering (HT-BOSE). Stemming from directed\nevolution, in HT-BOSE the focal point is a biological knowledge based rational\noptimization of the search process in the space of device design possibilities.\nThe HT-BOSE approach may also be relevant in other contexts and we briefly\nhighlight how it could be applicable to the development of multi-drug cocktails\nin a biomedical setting."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Spectral sum rules and search for periodicities in DNA sequences"}, {"role": "assistant", "content": "Periodic patterns play the important regulatory and structural roles in\ngenomic DNA sequences. Commonly, the underlying periodicities should be\nunderstood in a broad statistical sense, since the corresponding periodic\npatterns have been strongly distorted by the random point mutations and\ninsertions/deletions during molecular evolution. The latent periodicities in\nDNA sequences can be efficiently displayed by Fourier transform. The criteria\nof significance for observed periodicities are obtained via the comparison\nversus the counterpart characteristics of the reference random sequences. We\nshow that the restrictions imposed on the significance criteria by the rigorous\nspectral sum rules can be rationally described with De Finetti distribution.\nThis distribution provides the convenient intermediate asymptotic form between\nRayleigh distribution and exact combinatoric theory."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Kinetics of binding and geometry of cells on molecular biochips"}, {"role": "assistant", "content": "We examine how the shape of cells and the geometry of experiment affect the\nreaction-diffusion kinetics at the binding between target and probe molecules\non molecular biochips. In particular, we compare the binding kinetics for the\nprobes immobilized on surface of the semispherical and flat circular cells, the\nlimit of thin slab of analyte solution over probe cell as well as hemispherical\ngel pads and cells printed in gel slab over a substrate. It is shown that\nhemispherical geometry provides significantly faster binding kinetics and\nensures more spatially homogeneous distribution of local (from a pixel) signals\nover a cell in the transient regime. The advantage of using thin slabs with\nsmall volume of analyte solution may be hampered by the much longer binding\nkinetics needing the auxiliary mixing devices. Our analysis proves that the\nshape of cells and the geometry of experiment should be included to the list of\nessential factors at biochip designing."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Algorithm engineering for optimal alignment of protein structure\n  distance matrices"}, {"role": "assistant", "content": "Protein structural alignment is an important problem in computational\nbiology. In this paper, we present first successes on provably optimal pairwise\nalignment of protein inter-residue distance matrices, using the popular Dali\nscoring function. We introduce the structural alignment problem formally, which\nenables us to express a variety of scoring functions used in previous work as\nspecial cases in a unified framework. Further, we propose the first\nmathematical model for computing optimal structural alignments based on dense\ninter-residue distance matrices. We therefore reformulate the problem as a\nspecial graph problem and give a tight integer linear programming model. We\nthen present algorithm engineering techniques to handle the huge integer linear\nprograms of real-life distance matrix alignment problems. Applying these\ntechniques, we can compute provably optimal Dali alignments for the very first\ntime."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Towards a New Spatial Representation of Bone Remodeling"}, {"role": "assistant", "content": "Irregular bone remodeling is associated with a number of bone diseases such\nas osteoporosis and multiple myeloma.\n  Computational and mathematical modeling can aid in therapy and treatment as\nwell as understanding fundamental biology. Different approaches to modeling\ngive insight into different aspects of a phenomena so it is useful to have an\narsenal of various computational and mathematical models.\n  Here we develop a mathematical representation of bone remodeling that can\neffectively describe many aspects of the complicated geometries and spatial\nbehavior observed.\n  There is a sharp interface between bone and marrow regions. Also the surface\nof bone moves in and out, i.e. in the normal direction, due to remodeling.\nBased on these observations we employ the use of a level-set function to\nrepresent the spatial behavior of remodeling. We elaborate on a temporal model\nfor osteoclast and osteoblast population dynamics to determine the change in\nbone mass which influences how the interface between bone and marrow changes.\n  We exhibit simulations based on our computational model that show the motion\nof the interface between bone and marrow as a consequence of bone remodeling.\nThe simulations show that it is possible to capture spatial behavior of bone\nremodeling in complicated geometries as they occur \\emph{in vitro} and \\emph{in\nvivo}.\n  By employing the level set approach it is possible to develop computational\nand mathematical representations of the spatial behavior of bone remodeling. By\nincluding in this formalism further details, such as more complex cytokine\ninteractions and accurate parameter values, it is possible to obtain\nsimulations of phenomena related to bone remodeling with spatial behavior much\nas \\emph{in vitro} and \\emph{in vivo}. This makes it possible to perform\n\\emph{in silica} experiments more closely resembling experimental observations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: HiTRACE: High-throughput robust analysis for capillary electrophoresis"}, {"role": "assistant", "content": "Motivation: Capillary electrophoresis (CE) of nucleic acids is a workhorse\ntechnology underlying high-throughput genome analysis and large-scale chemical\nmapping for nucleic acid structural inference. Despite the wide availability of\nCE-based instruments, there remain challenges in leveraging their full power\nfor quantitative analysis of RNA and DNA structure, thermodynamics, and\nkinetics. In particular, the slow rate and poor automation of available\nanalysis tools have bottlenecked a new generation of studies involving hundreds\nof CE profiles per experiment.\n  Results: We propose a computational method called high-throughput robust\nanalysis for capillary electrophoresis (HiTRACE) to automate the key tasks in\nlarge-scale nucleic acid CE analysis, including the profile alignment that has\nheretofore been a rate-limiting step in the highest throughput experiments. We\nillustrate the application of HiTRACE on thirteen data sets representing 4\ndifferent RNAs, three chemical modification strategies, and up to 480 single\nmutant variants; the largest data sets each include 87,360 bands. By applying a\nseries of robust dynamic programming algorithms, HiTRACE outperforms prior\ntools in terms of alignment and fitting quality, as assessed by measures\nincluding the correlation between quantified band intensities between replicate\ndata sets. Furthermore, while the smallest of these data sets required 7 to 10\nhours of manual intervention using prior approaches, HiTRACE quantitation of\neven the largest data sets herein was achieved in 3 to 12 minutes. The HiTRACE\nmethod therefore resolves a critical barrier to the efficient and accurate\nanalysis of nucleic acid structure in experiments involving tens of thousands\nof electrophoretic bands."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Stochastic Modeling in Systems Biology"}, {"role": "assistant", "content": "Many cellular behaviors are regulated by gene regulation networks, kinetics\nof which is one of the main subjects in the study of systems biology. Because\nof the low number molecules in these reacting systems, stochastic effects are\nsignificant. In recent years, stochasticity in modeling the kinetics of gene\nregulation networks have been drawing the attention of many researchers. This\npaper is a self contained review trying to provide an overview of stochastic\nmodeling. I will introduce the derivation of the main equations in modeling the\nbiochemical systems with intrinsic noise (chemical master equation, Fokker-Plan\nequation, reaction rate equation, chemical Langevin equation), and will discuss\nthe relations between these formulations. The mathematical formulations for\nsystems with fluctuations in kinetic parameters are also discussed. Finally, I\nwill introduce the exact stochastic simulation algorithm and the approximate\nexplicit tau-leaping method for making numerical simulations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A General Theory for Direct Quantitative Analysis of Antigen"}, {"role": "assistant", "content": "A theory for direct quantitative analysis of an antigen is proposed. It is\nbased on a potential homogenous immunoreaction system. It establishes an\nequation to describe the concentration change of the antigen and antibody\ncomplex. A maximum point is found in the concentration profile of the complex\nwhich can be used to calculate the concentration of the antigen. An\nexperimental scheme was designed for a commercial time-resolved\nfluoroimmunoassay kit for HBsAg, which is based heterogeneous immunoreaction.\nThe results showed that the theory is practically applicable."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Errors in Length-weight Parameters at FishBase.org"}, {"role": "assistant", "content": "To investigate possible errors, length-weight parameters from FishBase.org\nwere used to graph length-weight curves for six different species: channel\ncatfish, black crappie, largemouth bass, rainbow trout, flathead catfish, and\nlake trout along with the standard weight curves (Anderson and Neumann 1996,\nBister et al. 2000). Parameters noted as doubtful by FishBase were excluded.\nFor each species, variations in curves were noted, and the minimum and maximum\npredicted weights for a 30 cm long fish were compared with each other and with\nthe standard weight for that length. For lake trout, additional comparisons\nwere made between the parameters and study details reported in FishBase.org for\n6 of 8 length-weight relationships and those reported in the reference\n(Carlander 1969) for those 6 relationships. In all species studied, minimum and\nmaximum curves produced with the length-weight parameters at FishBase.org are\nnotably different from each other, and in many cases predict weights that are\nclearly absurd. For example, one set of parameters predicts a 30 cm rainbow\ntrout weighing 44 g. For 30 cm length, the range of weights (relative to the\nstandard weight) for each species are: channel catfish (31.4% to 193.1%), black\ncrappie (54.0% to 149.0%), largemouth bass (28.8% to 130.4%), rainbow trout\n(14.9% to 113.4%), flathead catfish (29.3% to 250.7%), and lake trout (44.0% to\n152.7%). Length-weight tables at FishBase.org are not generally reliable and\nthe on-line database contains dubious parameters. Assurance of quality probably\nwill require a systematic review with more careful and comprehensive methods\nthan those currently employed."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: In Silico Synchronization of Cellular Populations Through Expression\n  Data Deconvolution"}, {"role": "assistant", "content": "Cellular populations are typically heterogenous collections of cells at\ndifferent points in their respective cell cycles, each with a cell cycle time\nthat varies from individual to individual. As a result, true single-cell\nbehavior, particularly that which is cell-cycle--dependent, is often obscured\nin population-level (averaged) measurements. We have developed a simple\ndeconvolution method that can be used to remove the effects of asynchronous\nvariability from population-level time-series data. In this paper, we summarize\nsome recent progress in the development and application of our approach, and\nprovide technical updates that result in increased biological fidelity. We also\nexplore several preliminary validation results and discuss several ongoing\napplications that highlight the method's usefulness for estimating parameters\nin differential equation models of single-cell gene regulation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Biological and Statistical Heterogeneity in Malaria Transmission"}, {"role": "assistant", "content": "In a study of the heterogeneity in malaria infection rates among children\nSmith et al.1 fitted several mathematical models to data from community studies\nin Africa. They concluded that 20% of children receive 80% of infections, that\ninfections last about six months on average, that children who clear infections\nare not immune to new infections, and that the sensitivity and specificity of\nmicroscopy for the detection of malaria parasites are 95.8% and 88.4%,\nrespectively. These findings would have important implications for disease\ncontrol, but we show here that the statistical analysis is unsound and that the\ndata do not support their conclusions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: How important is the acute phase in HIV epidemiology?"}, {"role": "assistant", "content": "At present, the best hope for eliminating HIV transmission and bringing the\nepidemic of HIV to an end lies in the use of anti-retroviral therapy for\nprevention, a strategy referred to variously as Test and Treat (T&T), Treatment\nas Prevention (TasP) or Treatment centred Prevention (TcP). One of the key\nobjections to the use of T&T to stop transmission concerns the role of the\nacute phase in HIV transmission. The acute phase of infection lasts for one to\nthree months after HIV-seroconversion during which time the risk of\ntransmission may be ten to twenty times higher, per sexual encounter, than it\nis during the chronic phase which lasts for the next ten years. Regular testing\nfor HIV is more likely to miss people who are in the acute phase than in the\nchronic phase and it is essential to determine the extent to which this might\ncompromise the impact of T&T on HIV-transmission.\n  Here we show that 1) provided the initial epidemic doubling time is about 1.0\nto 1.5 years, as observed in South Africa, random testing with an average test\ninterval of one year will still bring the epidemic close to elimination even if\nthe acute phase lasts for 3 months during which time transmission is 26 times\nhigher than in the chronic phase; 2) testing people regularly at yearly\nintervals is significantly more effective then testing them randomly; 3)\ntesting people regularly at six monthly intervals and starting them on ART\nimmediately, will almost certainly guarantee elimination.\n  In general it seems unlikely that elevated transmission during the acute\nphase is likely to change predictions of the impact of treatment on\ntransmission significantly. Other factors, in particular age structure, the\nstructure of sexual networks and variation in set-point viral load are likely\nto be more important and should be given priority in further analyses."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Combinatorial Framework for Designing (Pseudoknotted) RNA Algorithms"}, {"role": "assistant", "content": "We extend an hypergraph representation, introduced by Finkelstein and\nRoytberg, to unify dynamic programming algorithms in the context of RNA folding\nwith pseudoknots. Classic applications of RNA dynamic programming energy\nminimization, partition function, base-pair probabilities...) are reformulated\nwithin this framework, giving rise to very simple algorithms. This\nreformulation allows one to conceptually detach the conformation space/energy\nmodel -- captured by the hypergraph model -- from the specific application,\nassuming unambiguity of the decomposition. To ensure the latter property, we\npropose a new combinatorial methodology based on generating functions. We\nextend the set of generic applications by proposing an exact algorithm for\nextracting generalized moments in weighted distribution, generalizing a prior\ncontribution by Miklos and al. Finally, we illustrate our full-fledged\nprogramme on three exemplary conformation spaces (secondary structures,\nAkutsu's simple type pseudoknots and kissing hairpins). This readily gives sets\nof algorithms that are either novel or have complexity comparable to classic\nimplementations for minimization and Boltzmann ensemble applications of dynamic\nprogramming."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Automated Quantification of the Impact of the Wood-decay fungus\n  Physisporinus vitreus on the Cell Wall Structure of Norway spruce by\n  Tomographic Microscopy"}, {"role": "assistant", "content": "Wood-decay fungi decompose their substrate by extracellular, degradative\nenzymes and play an important role in natural ecosystems by recycling carbon\nand minerals fixed in plants. Thereby, they cause significant damage to the\nwood structure and limit the use of wood as building material. Besides their\nrole as biodeteriorators wood-decay fungi can be used for biotechnological\npurposes, e.g. the white-rot fungus Physisporinus vitreus for improving the\nuptake of preservatives and wood-modification substances of refractory wood.\nTherefore, the visualization and the quantification of microscopic decay\npatterns are important for the study of the impact of wood-decay fungi in\ngeneral, as well as for wood-decay fungi and microorganisms with possible\napplications in biotechnology. In the present work, we developed a method for\nthe automated localization and quantification of microscopic cell wall elements\n(CWE) of Norway spruce wood such as bordered pits, intrinsic defects, hyphae or\nalterations induced by P. vitreus using high resolution X-ray computed\ntomographic microscopy. In addition to classical destructive wood anatomical\nmethods such as light or laser scanning microscopy, our method allows for the\nfirst time to compute the properties (e.g. area, orientation and\nsize-distribution) of CWE of the tracheids in a sample. This is essential for\nmodeling the influence of microscopic CWE to macroscopic properties such as\nwood strength and permeability."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Analysis of Hepatitis C Viral Dynamics Using Latin Hypercube Sampling"}, {"role": "assistant", "content": "We consider a mathematical model comprising of four coupled ordinary\ndifferential equations (ODEs) for studying the hepatitis C (HCV) viral\ndynamics. The model embodies the efficacies of a combination therapy of\ninterferon and ribavirin. A condition for the stability of the uninfected and\nthe infected steady states is presented. A large number of sample points for\nthe model parameters (which were physiologically feasible) were generated using\nLatin hypercube sampling. Analysis of our simulated values indicated\napproximately 24% cases as having an uninfected steady state. Statistical tests\nlike the chi-square-test and the Spearman's test were also done on the sample\nvalues. The results of these tests indicate a distinctly differently\ndistribution of certain parameter values and not in case of others, vis-a-vis,\nthe stability of the uninfected and the infected steady states."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Demonstrating an Improved Length-weight Model in Largemouth Bass, Chain\n  Pickerel, Yellow Perch, Black Crappie, and Brown Bullhead in Stilwell\n  Reservoir, West Point, New York"}, {"role": "assistant", "content": "The traditional power law model, W(L) = aL^b, is widely applied to describe\nweight (W) vs. length (L) in fish. The model, W(L) = (L/L1)^b, is proposed as\nan improvement. The Levenberg-Marquardt non-linear least squares technique is\nused to determine the best-fit parameters L1 and b. This model has the\nadvantages that L1 has the same units (length) independent of the value of the\nexponent and has an easily interpreted physical meaning as the typical length\nof a fish with one unit of weight. This proposed model is compared with the\ntraditional model on length-weight data sets for black crappie, largemouth\nbass, chain pickerel, yellow perch, and brown bullhead obtained from Stilwell\nReservoir, West Point, New York. The resulting best-fit parameters, parameter\nstandard errors, and covariances are compared between the two models. The\naverage relative weight for these species is determined, along with typical\nmeat yields for four species. For the five species, using the logarithmic\napproach and a linear least-squares, standard errors in the coefficient, a,\nrange from 60.2% to 136.5% for the traditional model. Using a non-linear least\nsquares technique to determine best fit parameters, the standard errors for the\ncoefficient, a, range from 68.5% to 164.0% in the traditional model. In the\nimproved model, standard errors in the parameter L1 range from 0.94% to 15.0%.\nThe covariance between a and b in the traditional model has a magnitude between\n0.999 and 1.000 in both linear and non-linear parameter estimation methods. In\nthe improved model, the covariances between L1 and b are smaller. The improved\nmodel, W(L) = (L/L1)^b, is preferable for weight vs. length in fish, because\nthe estimated parameter uncertainties and covariances are smaller in magnitude.\nFurthermore, the parameters both have consistent units and an easily\ninterpreted physical meaning."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Structural requirements and discrimination of cell differentiation\n  networks"}, {"role": "assistant", "content": "Mathematical models of stem cell differentiation are commonly based upon the\nconcept of subsequent cell fate decisions, each controlled by a gene regulatory\nnetwork. These networks exhibit a multistable behavior and cause the system to\nswitch between qualitatively distinct stable steady states. However, the\nnetwork structure of such a switching module is often uncertain, and there is\nlack of knowledge about the exact reaction kinetics. In this paper, we\ntherefore perform an elementary study of small networks consisting of three\ninteracting transcriptional regulators responsible for cell differentiation: We\ninvestigate which network structures can reproduce a certain multistable\nbehavior, and how robustly this behavior is realized by each network. In order\nto approach these questions, we use a modeling framework which only uses\nqualitative information about the network, yet allows model discrimination as\nwell as to evaluate the robustness of the desired multistability properties. We\nreveal structural network properties which are necessary and sufficient to\nrealize distinct steady state patterns required for cell differentiation. Our\nresults also show that structural and robustness properties of the networks are\nrelated to each other."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Model for competing pathways in protein-aggregation: role of membrane\n  bound proteins"}, {"role": "assistant", "content": "Motivated by the biologically important and complex phenomena of A\\beta\\\npeptide aggregation in Alzheimer's disease, we introduce a model and simulation\nmethodology for studying protein aggregation that includes extra-cellular\naggregation, aggregation on the cell-surface assisted by a membrane bound\nprotein, and in addition, supply, clearance, production and sequestration of\npeptides and proteins. The model is used to produce equilibrium and\nkinetic-aggregation phase diagrams for aggregation onset and of reduced stable\nA\\beta\\ monomer concentrations due to aggregation. The methodology we\nimplemented permits modeling of a phenomenon involving orders of magnitude\ndifferences in time scales and concentrations which can be retained in the\nsimulation. We demonstrate how to identify ranges of parameter values that give\nmonomer concentration depletion upon aggregation similar to that observed in\nAlzheimer's disease. We show how very different behavior can be obtained as\nreaction parameters and protein concentrations vary, and discuss the difficulty\nreconciling results of experiments from two vastly different concentration\nregimes. The latter is an important general issue in relating in-vitro and mice\nbased experiments to humans."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: An Assessment of Weight-Length Relationships for Muskellunge,Northern\n  Pike, and Chain Pickerel In Carlander's Handbook of Freshwater Fishery\n  Biology"}, {"role": "assistant", "content": "Carlander's Handbook of Freshwater Fishery Biology (1969) contains life\nhistory data from many species of freshwater fish found in North America. It\nhas been cited over 1200 times and used to produce standard-weight curves for\nsome species. Recent work (Cole-Fletcher et al. 2011) suggests Carlander (1969)\ncontains numerous errors in listed weight-length equations. This paper assesses\nthe weight-length relationships listed in Carlander for muskellunge, northern\npike, and chain pickerel by comparing graphs of the weight vs. length equations\nwith other data listed and with standard weight curves published by independent\nsources. A number of discrepancies are identified through this analysis and new\nweight-length relationships are produced from listed data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Coexistence of different base periodicities in prokaryotic genomes as\n  related to DNA curvature, supercoiling, and transcription"}, {"role": "assistant", "content": "We analyzed the periodic patterns in E. coli promoters and compared the\ndistributions of the corresponding patterns in promoters and in the complete\ngenome to elucidate their function. Except the three-base periodicity,\ncoincident with that in the coding regions and growing stronger in the region\ndownstream from the transcriptions start (TS), all other salient periodicities\nare peaked upstream of TS. We found that helical periodicities with the lengths\nabout B-helix pitch ~10.2-10.5 bp and A-helix pitch ~10.8-11.1 bp coexist in\nthe genomic sequences. We mapped the distributions of stretches with A-, B-,\nand Z- like DNA periodicities onto E.coli genome. All three periodicities tend\nto concentrate within non-coding regions when their intensity becomes stronger\nand prevail in the promoter sequences. The comparison with available\nexperimental data indicates that promoters with the most pronounced\nperiodicities may be related to the supercoiling-sensitive genes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Remarks on invariance of population distributions for systems with\n  equivariant internal dynamics"}, {"role": "assistant", "content": "For velocity-jump Markov processes with equivariant internal dynamics, we\nremark that population distributions are invariant. This provides a\nformalization of the fact that FCD (scale) and other symmetry invariant systems\nperform identical spatial searches under input transformations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Trail formation based on directed pheromone deposition"}, {"role": "assistant", "content": "We propose an Individual-Based Model of ant-trail formation. The ants are\nmodeled as self-propelled particles which deposit directed pheromones and\ninteract with them through alignment interaction. The directed pheromones\nintend to model pieces of trails, while the alignment interaction translates\nthe tendency for an ant to follow a trail when it meets it. Thanks to adequate\nquantitative descriptors of the trail patterns, the existence of a phase\ntransition as the ant-pheromone interaction frequency is increased can be\nevidenced. Finally, we propose both kinetic and fluid descriptions of this\nmodel and analyze the capabilities of the fluid model to develop trail\npatterns. We observe that the development of patterns by fluid models require\nextra trail amplification mechanisms that are not needed at the\nIndividual-Based Model level."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Optimal Therapy of Hepatitis C Dynamics and Sampling Based Analysis"}, {"role": "assistant", "content": "We examine two models for hepatitis C viral (HCV) dynamics, one for\nmonotherapy with interferon (IFN) and the other for combination therapy with\nIFN and ribavirin. Optimal therapy for both the models is determined using the\nsteepest gradient method, by defining an objective functional which minimizes\nthe infected hepatocyte levels, virion population and the side-effects of the\ndrug(s). The optimal therapy for both the models shows an initial period of\nhigh efficacy, followed by a gradual decline. The period of high efficacy\ncoincides with a significant decrease in the infected hepatocyte levels as well\nas viral load, whereas the efficacy drops after liver regeneration through\nrestored hepatocyte levels. The period of high efficacy is not altered\nsignificantly when the cost coefficients are varied, as long as the side\neffects are relatively small. This suggests a higher dependence of the optimal\ntherapy on the model parameters in case of drugs with minimal side effects.\n  We use the Latin hypercube sampling technique to randomly generate a large\nnumber of patient scenarios (i.e, model parameter sets) and study the dynamics\nof each set under the optimal therapy already determined. Results show an\nincrease in the percentage of responders (as indicated by drop in viral load\nbelow detection levels) in case of combination therapy as compared to\nmonotherapy. Statistical tests performed to study the correlations between\nsample parameters and the time required for the viral load to fall below\ndetection level, show a strong monotonic correlation with the death rate of\ninfected hepatocytes, identifying it to be an important factor in deciding\nindividual drug regimens."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Single-base mismatch profiles for NGS samples"}, {"role": "assistant", "content": "Within the preprocessing pipeline of a Next Generation Sequencing sample, its\nset of Single-Base Mismatches is one of the first outcomes, together with the\nnumber of correctly aligned reads. The union of these two sets provides a 4x4\nmatrix (called Single Base Indicator, SBI in what follows) representing a\nblueprint of the sample and its preprocessing ingredients such as the\nsequencer, the alignment software, the pipeline parameters. In this note we\nshow that, under the same technological conditions, there is a strong relation\nbetween the SBI and the biological nature of the sample. To reach this goal we\nneed to introduce a similarity measure between SBIs: we also show how two\nmeasures commonly used in machine learning can be of help in this context."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: HIV/AIDS in South Africa: the beginning of the end?"}, {"role": "assistant", "content": "In several countries in southern Africa, including South Africa, the\nprevalence of HIV remains stubbornly high in spite of considerable efforts to\nreduce transmission and to provide anti-retroviral therapy (ART). It is\nimportant to know the extent to which the high prevalence of HIV reflects the\nincreasing number of people on ART in which case the prevalence of those not on\nART may be falling. Unfortunately, direct measures of the proportion of\nHIV-positive people who are on ART are lacking in most countries and we need to\nuse dynamical models to estimate the impact of ART on the prevalence of HIV. In\nthis paper we show that the current level of ART provision in South Africa has\nprobably reduced the prevalence of HIV among those not on ART by 1.9 million,\naverted 259 thousand new infections and 428 thousand deaths."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Rigidity sensing explained by active matter theory"}, {"role": "assistant", "content": "The magnitude of traction forces exerted by living animal cells on their\nenvironment is a monotonically increasing and approximately sigmoidal function\nof the stiffness of the external medium. This observation is rationalized using\nactive matter theory: adaptation to substrate rigidity results from an\ninterplay between passive elasticity and active contractility."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Inferring genotyping error rates from genotyped trios"}, {"role": "assistant", "content": "Genotyping errors are known to influence the power of both family-based and\ncase-control studies in the genetics of complex disease. Estimating genotyping\nerror rate in a given dataset can be complex, but when family information is\navailable error rates can be inferred from the patterns of Mendelian\ninheritance between parents and offspring. I introduce a novel likelihood-based\nmethod for calculating error rates from family data, given known allele\nfrequencies. I apply this to an example dataset, demonstrating a low genotyping\nerror rate in genotyping data from a personal genomics company."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Exact Green's Function of the reversible diffusion-influenced reaction\n  for an isolated pair in 2D"}, {"role": "assistant", "content": "We derive an exact Green's function of the diffusion equation for a pair of\nspherical interacting particles in 2D subject to a back-reaction boundary\ncondition."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Monitoring and prediction of an epidemic outbreak using syndromic\n  observations"}, {"role": "assistant", "content": "The paper presents an algorithm for syndromic surveillance of an epidemic\noutbreak formulated in the context of stochastic nonlinear filtering. The\ndynamics of the epidemic is modeled using a generalized compartmental\nepidemiological model with inhomogeneous mixing. The syndromic (typically\nnon-medical) observations of the number of infected people (e.g. visits to\npharmacies, sale of certain products, absenteeism from work/study etc.) are\nused for estimation. The state of the epidemic, including the number of\ninfected people and the unknown parameters of the model, are estimated via a\nparticle filter. The numerical results indicate that the proposed framework can\nprovide useful early prediction of the epidemic peak if the uncertainty in\nprior knowledge of model parameters is not excessive."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: CytoSaddleSum: a functional enrichment analysis plugin for Cytoscape\n  based on sum-of-weights scores"}, {"role": "assistant", "content": "Summary: CytoSaddleSum provides Cytoscape users with access to the\nfunctionality of SaddleSum, a functional enrichment tool based on sum-of-weight\nscores. It operates by querying SaddleSum locally (using the standalone\nversion) or remotely (through an HTTP request to a web server). The functional\nenrichment results are shown as a term relationship network, where nodes\nrepresent terms and edges show term relationships. Furthermore, query results\nare written as Cytoscape attributes allowing easy saving, retrieval and\nintegration into network-based data analysis workflows.\n  Availability: www.ncbi.nlm.nih.gov/CBBresearch/Yu/downloads The source code\nis placed in Public Domain."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A simple mathematical model for assessment of anti-toxin antibodies"}, {"role": "assistant", "content": "The toxins associated with infectious diseases are potential targets for\ninhibitors which have the potential for prophylactic or therapeutic use. Many\nantibodies have been generated for this purpose, and the objective of this\nstudy was to develop a simple mathematical model that may be used to evaluate\nthe potential protective effect of antibodies. This model was used to evaluate\nthe contributions of antibody affinity and concentration to reducing\nantibody-receptor complex formation and internalization. The model also enables\nprediction of the antibody kinetic constants and concentration required to\nprovide a specified degree of protection. We hope that this model, once\nvalidated experimentally, will be a useful tool for in vitro selection of\npotentially protective antibodies for progression to in vivo evaluation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A null model for testing thermodynamic optimization in ecological\n  systems"}, {"role": "assistant", "content": "Several authors have hypothesized that ecological systems are subject to\nthermodynamic optimization, which, if proven correct, could represent a long\nsought general principle of organization in ecology. Although there have been\nrecent advances, this still remains as an unresolved topic, and ecologists lack\na general method to test thermodynamic optimization hypotheses in specific\nsystems. Here we present a general, novel approach that allows generating a\nnull model for testing thermodynamic optimization on ecological systems. We\nfirst describe the general methodology, which is based in the analysis of a\nparametrized mathematical model of the system and the explicit consideration of\nconstraints. Next we present an application example to an animal population\nusing a general age-structured population model and physiological parameters\nfrom the literature. We finalize discussing the relevance of this work in the\ncontext of the current state of ecology, and implications for the further\ndevelopment of a thermodynamic ecological theory."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Reconstructing fiber networks from confocal image stacks"}, {"role": "assistant", "content": "We present a numerically efficient method to reconstruct a disordered network\nof thin biopolymers, such as collagen gels, from three-dimensional (3D) image\nstacks recorded with a confocal microscope. Our method is based on a template\nmatching algorithm that simultaneously performs a binarization and\nskeletonization of the network. The size and intensity pattern of the template\nis automatically adapted to the input data so that the method is scale\ninvariant and generic. Furthermore, the template matching threshold is\niteratively optimized to ensure that the final skeletonized network obeys a\nuniversal property of voxelized random line networks, namely, solid-phase\nvoxels have most likely three solid-phase neighbors in a $3\\times3$\nneighborhood. This optimization criterion makes our method free of user-defined\nparameters and the output exceptionally robust against imaging noise."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Statistical analysis of co-expression properties of sets of genes in the\n  mouse brain"}, {"role": "assistant", "content": "We propose a quantitative method to estimate the statistical properties of\nsets of genes for which expression data are available and co-registered to a\nreference atlas of the brain. It is based on graph-theoretic properties of\nco-expression coefficients between pairs of genes. We apply this method to\nmouse genes from the Allen Gene Expression Atlas. Co-expression patterns of a\nlist of several hundreds of genes related to addiction are analyzed, using ISH\ndata produced for the mouse brain at the Allen Institute. It appears that large\nsubsets of this set of genes are much more highly co-expressed than expected by\nchance."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Optimal conditions for slow passive release of heparin-binding growth\n  factors from an affinity-based delivery system"}, {"role": "assistant", "content": "We consider a mathematical model that describes the release of\nheparin-binding growth factors from an affinity-based delivery system. In the\ndelivery system, heparin binds to a peptide which has been covalently\ncross-linked to a fibrin matrix. Growth factor in turn binds to the heparin,\nand growth factor release is governed by both binding and diffusion mechanisms,\nthe purpose of the binding being to slow growth factor release. The governing\nmathematical model, which in its original formulation consists of five partial\ndifferential equations, is reduced to a system of just two equations. We\nidentify the governing non-dimensional parameters that can be varied to tune\nthe growth factor release rate. In particular, we identify a parameter regime\nthat ensures slow passive release (usually desirable) of at least a fraction of\nthe growth factor. It is found that slow release is assured if the matrix is\nprepared with the concentration of cross-linked peptide greatly exceeding the\ndissociation constant of heparin from the peptide, and with the concentration\nof heparin greatly exceeding the dissociation constant of the growth factor\nfrom heparin. Also, for the first time, in vitro experimental release data is\ndirectly compared with theoretical release profiles generated by the model. We\npropose that the two stage release behaviour frequently seen in experiments is\ndue to an initial rapid out-diffusion of free growth factor over a diffusion\ntime scale (typically days), followed by a much slower release of the bound\nfraction over a time scale depending on both diffusion and binding parameters\n(frequently months)."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Unbiased degree-preserving randomisation of directed binary networks"}, {"role": "assistant", "content": "Randomising networks using a naive `accept-all' edge-swap algorithm is\ngenerally biased. Building on recent results for nondirected graphs, we\nconstruct an ergodic detailed balance Markov chain with non-trivial acceptance\nprobabilities for directed graphs, which converges to a strictly uniform\nmeasure and is based on edge swaps that conserve all in- and out-degrees. The\nacceptance probabilities can also be generalized to define Markov chains that\ntarget any alternative desired measure on the space of directed graphs, in\norder to generate graphs with more sophisticated topological features. This is\ndemonstrated by defining a process tailored to the production of directed\ngraphs with specified degree-degree correlation functions. The theory is\nimplemented numerically and tested on synthetic and biological network\nexamples."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: An Exactly Solvable Model of Random Site-Specific Recombinations"}, {"role": "assistant", "content": "Cre-lox and other systems are used as genetic tools to control site-specific\nrecombination (SSR) events in genomic DNA. If multiple recombination sites are\norganized in a compact cluster within the same genome, a series of random\nrecombination events may generate substantial cell specific genomic diversity.\nThis diversity is used, for example, to distinguish neurons in the brain of the\nsame multicellular mosaic organism, within the brainbow approach to neuronal\nconnectome. In this paper we study an exactly solvable statistical model for\nSSR operating on a cluster of recombination sites. We consider two types of\nrecombination events: inversions and excisions. Both of these events are\navailable in the Cre-lox system. We derive three properties of the sequences\ngenerated by multiple recombination events. First, we describe the set of\nsequences that can in principle be generated by multiple inversions operating\non the given initial sequence. We call this description the ergodicity theorem.\nOn the basis of this description we calculate the number of sequences that can\nbe generated from an initial sequence. This number of sequences is\nexperimentally testable. Second, we demonstrate that after a large number of\nrandom inversions every sequence that can be generated is generated with equal\nprobability. Lastly, we derive the equations for the probability to find a\nsequence as a function of time in the limit when excisions are much less\nfrequent than inversions, such as in shufflon sequences."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: CSA: Comprehensive comparison of pairwise protein structure alignments"}, {"role": "assistant", "content": "CSA is a web server for the comprehensive comparison of pairwise protein\nstructure alignments. Its exact alignment engine computes either optimal,\ntop-scoring alignments or heuristic alignments with quality guarantee for the\ninter-residue distance based scorings of contact map overlap, PAUL, DALI and\nMATRAS. These and additional, uploaded alignments are compared using a number\nof quality measures and intuitive visualizations. CSA brings new insight into\nthe structural relationship of the protein pairs under investigation and is a\nvaluable tool for studying structural similarities. It is available at\nhttp://csa.project.cwi.nl"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Searching for Synergism Among Combinations of Drugs of Abuse and the Use\n  of Isobolographic Analysis"}, {"role": "assistant", "content": "It is well known that individuals who abuse drugs usually use more than one\nsubstance. Toxic consequences of single and multiple drug use are well\ndocumented in the Treatment Episodes Data Set that lists combinations that\nresult in hospital admissions. Using this list as a guide, we focused our\nattention on combinations that result in the most hospital admissions and\nsearched the PubMed database to determine the number of publications dealing\nwith these toxic combinations. Of special interest were those publications that\nlooked for or used the term synergism in their titles or abstracts, a search\nthat produced an extensive list of published articles. However, a further\nintersection of these with the term isobole revealed a surprisingly small\nnumber of literature reports. Because the method of isoboles is the most common\nquantitative method for distinguishing between drug synergism and simple\nadditivity, the small number of investigations that actually employed this\nquantitation suggests that the term synergism is not properly documented in\ndescribing the toxicity among these abused substances. The possible reasons for\nthis lack of quantitation may be related to a misunderstanding of the modeling\nequations. The theory and modeling are discussed here."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Euclidean distance geometry and applications"}, {"role": "assistant", "content": "Euclidean distance geometry is the study of Euclidean geometry based on the\nconcept of distance. This is useful in several applications where the input\ndata consists of an incomplete set of distances, and the output is a set of\npoints in Euclidean space that realizes the given distances. We survey some of\nthe theory of Euclidean distance geometry and some of the most important\napplications: molecular conformation, localization of sensor networks and\nstatics."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Blank measurement based time-alignment in LC-MS"}, {"role": "assistant", "content": "Here are presenting the blank based time-alignment (BBTA) as a strong\nanalytical approach for treatment of non-linear shift in time occurring in\nHPLC-MS data. Need of such tool in recent large dataset produced by analytical\nchemistry and so-called omics studies is evident. Proposed approach is based on\nmeasurement and comparison of blank and analyzed sample evident features. In\nthe first step of BBTA procedure, the number of compounds is reduced by\nmax-to-mean ratio thresholding, which extensively reduce the computational\ntime. Simple thresholding is followed by selection of time markers defined from\nblank inflex points which are then used for the transformation function,\npolynomial of second degree, in the example. BBTA approach was compared on real\nHPLC-MS measurement with Correlation Optimized Warping (COW) method. It was\nproved to have distinctively shorter computational time as well as lower level\nof mathematical presumptions. The BBTA is computationally much easier, quicker\n(more then 1000x) and accurate in comparison with warping. Moreover, markers\nselection works efficiently without any peak detection. It is sufficient to\nanalyze only baseline contribution in the analyte measurement with sparse\nknowledge of blank behavior. Finally, BBTA does not required usage of extra\ninternal standards and due to its simplicity it has a potential to be\nwidespread tool in HPLC-MS data treatment."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Susceptible-Exposed-Infected-Removed (Seir) Model For The 2009-2010\n  A/H1N1 Epidemic In Istanbul"}, {"role": "assistant", "content": "A/H1N1 epidemic data from Istanbul, Turkey during the period June\n2009-February 2010 is analyzed with SEIR (Susceptible-Exposed-Infected-Removed)\nmodel. The data consist of the daily adult hospitalization numbers and\nfatalities recorded in various state hospitals serving an adult population of\nabout 1.5-2 million. June 2009-August 2009 period corresponds to the initial\nstage of the epidemic where the hospitalization rate is nearly %100 and it is\nexcluded from further consideration. The analysis covers the September\n2009-February 2010 period, the total number of hospitalizations and fatalities\nbeing respectively 869 and 46. It is shown that the maximum correlation between\nthe number of fatalities and hospitalizations occur with a time shift of 9 days\nand the proportionality constant is {\\delta}=0.0537. The SEIR epidemic model is\napplied to the data by back-shifting the number of fatalities. The\ndetermination of the best fitting model is based on the L2 norms of errors\nbetween the model and the data and the errors are around %10 and %2.6 for the\nnumber of hospitalizations and fatalities, respectively. The parameters in the\nmodel are I0, {\\eta}, {\\epsilon} and {\\beta}, where I0 is the percentage of\npeople infected initially, {\\eta} and {\\epsilon} are related to the inverses of\nthe infection and incubation periods and {\\beta}/{\\eta} is the representative\nof the basic reproduction number. These parameters are determined as\n{\\eta}=0.09 (1/{\\eta} =11.11days), I0=10^-7.4, {\\epsilon}=0.32 (1/{\\epsilon}\n=3.125 days), {\\beta}=0.585, {\\beta}/{\\eta}=6.5."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Computational neuroanatomy and gene expression: optimal sets of marker\n  genes for brain regions"}, {"role": "assistant", "content": "The three-dimensional data-driven Allen Gene Expression Atlas of the adult\nmouse brain consists of numerized in-situ hybridization data for thousands of\ngenes, co-registered to the Allen Reference Atlas. We propose quantitative\ncriteria to rank genes as markers of a brain region, based on the localization\nof the gene expression and on its functional fitting to the shape of the\nregion. These criteria lead to natural generalizations to sets of genes. We\nfind sets of genes weighted with coefficients of both signs with almost perfect\nlocalization in all major regions of the left hemisphere of the brain, except\nthe pallidum. Generalization of the fitting criterion with positivity\nconstraint provides a lesser improvement of the markers, but requires sparser\nsets of genes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: High Sensitivity Mass Spectrometric Quantification of Serum Growth\n  Hormone by Amphiphilic Peptide Conjugation"}, {"role": "assistant", "content": "Amphiphilic peptide conjugation affords a significant increase in sensitivity\nwith protein quantification by electrospray-ionization mass spectrometry. This\nhas been demonstrated here for human growth hormone in serum using\nN-(3-iodopropyl)-N,N,N-dimethyloctylammonium iodide (IPDOA-iodide) as\nderivatizing reagent. The signal enhancement achieved in comparison to the\nmethod without derivatization enables extension of the applicable concentration\nrange down to the very low concentrations as encountered with clinical glucose\nsuppression tests for patients with acromegaly. The method has been validated\nusing a set of serum samples spiked with known amounts of recombinant 22 kDa\ngrowth hormone in the range of 0.48 to 7.65 \\mug/L. The coefficient of\nvariation (CV) calculated, based on the deviation of results from the expected\nconcentrations, was 3.5% and the limit of quantification (LoQ) was determined\nas 0.4 \\mug/L. The potential of the method as a tool in clinical practice has\nbeen demonstrated with patient samples of about 1 \\mug/L."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantitative Analysis of Narrative Reports of Psychedelic Drugs"}, {"role": "assistant", "content": "Background: Psychedelic drugs facilitate profound changes in consciousness\nand have potential to provide insights into the nature of human mental\nprocesses and their relation to brain physiology. Yet published scientific\nliterature reflects a very limited understanding of the effects of these drugs,\nespecially for newer synthetic compounds. The number of clinical trials and\nrange of drugs formally studied is dwarfed by the number of written\ndescriptions of the many drugs taken by people. Analysis of these descriptions\nusing machine-learning techniques can provide a framework for learning about\nthese drug use experiences. Methods: We collected 1000 reports of 10 drugs from\nthe drug information website Erowid.org and formed a term-document frequency\nmatrix. Using variable selection and a random-forest classifier, we identified\na subset of words that differentiated between drugs. Results: A random forest\nusing a subset of 110 predictor variables classified with accuracy comparable\nto a random forest using the full set of 3934 predictors. Our estimated\naccuracy was 51.1%, which compares favorably to the 10% expected from chance.\nReports of MDMA had the highest accuracy at 86.9%; those describing DPT had the\nlowest at 20.1%. Hierarchical clustering suggested similarities between certain\ndrugs, such as DMT and Salvia divinorum. Conclusion: Machine-learning\ntechniques can reveal consistencies in descriptions of drug use experiences\nthat vary by drug class. This may be useful for developing hypotheses about the\npharmacology and toxicity of new and poorly characterized drugs."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: 1D analysis of 2D isotropic random walks"}, {"role": "assistant", "content": "Many stochastic systems in physics and biology are investigated by recording\nthe two-dimensional (2D) positions of a moving test particle in regular time\nintervals. The resulting sample trajectories are then used to induce the\nproperties of the underlying stochastic process. Often, it can be assumed a\npriori that the underlying discrete-time random walk model is independent from\nabsolute position (homogeneity), direction (isotropy) and time (stationarity),\nas well as ergodic. In this article we first review some common statistical\nmethods for analyzing 2D trajectories, based on quantities with built-in\nrotational invariance. We then discuss an alternative approach in which the\ntwo-dimensional trajectories are reduced to one dimension by projection onto an\narbitrary axis and rotational averaging. Each step of the resulting 1D\ntrajectory is further factorized into sign and magnitude. The statistical\nproperties of the signs and magnitudes are mathematically related to those of\nthe step lengths and turning angles of the original 2D trajectories,\ndemonstrating that no essential information is lost by this data reduction. The\nresulting binary sequence of signs lends itself for a pattern counting\nanalysis, revealing temporal properties of the random process that are not\neasily deduced from conventional measures such as the velocity autocorrelation\nfunction. In order to highlight this simplified 1D description, we apply it to\na 2D random walk with restricted turning angles (RTA model), defined by a\nfinite-variance distribution $p(L)$ of step length and a narrow turning angle\ndistribution $p(\\phi)$, assuming that the lengths and directions of the steps\nare independent."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Scaling properties of correlated random walks"}, {"role": "assistant", "content": "Many stochastic time series can be modelled by discrete random walks in which\na step of random sign but constant length $\\delta x$ is performed after each\ntime interval $\\delta t$. In correlated discrete time random walks (CDTRWs),\nthe probability $q$ for two successive steps having the same sign is unequal\n1/2. The resulting probability distribution $P(\\Delta x,\\Delta t)$ that a\ndisplacement $\\Delta x$ is observed after a lagtime $\\Delta t$ is known\nanalytically for arbitrary persistence parameters $q$. In this short note we\nshow how a CDTRW with parameters $[\\delta t, \\delta x, q]$ can be mapped onto\nanother CDTRW with rescaled parameters $[\\delta t/s, \\delta x\\cdot g(q,s),\nq^{\\prime}(q,s)]$, for arbitrary scaling parameters $s$, so that both walks\nhave the same displacement distributions $P(\\Delta x,\\Delta t)$ on long time\nscales. The nonlinear scaling functions $g(q,s)$ and $q^{\\prime}(q,s)$ and\nderived explicitely. This scaling method can be used to model time series\nmeasured at discrete sample intervals $\\delta t$ but actually corresponding to\ncontinuum processes with variations occuring on a much shorter time scale\n$\\delta t/s$."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Hi-throughput gene expression analysis at the level of single proteins\n  using a microfluidic turbidostat and automated cell tracking"}, {"role": "assistant", "content": "We have developed a method combining microfluidics, time-lapsed\nsingle-molecule microscopy and automated image analysis allowing for the\nobservation of an excess of 3000 complete cell cycles of exponentially growing\nEscherichia coli cells per experiment. The method makes it possible to analyze\nthe rate of gene expression at the level of single proteins over the bacterial\ncell cycle. We also demonstrate that it is possible to count the number of\nnon-specifically DNA binding LacI-Venus molecules using short excitation light\npulses. The transcription factors are localized on the nucleoids in the cell\nand appear to be uniformly distributed on chromosomal DNA. An increase of the\nexpression of LacI is observed at the beginning of the cell cycle, possibly\nbecause some gene copies are de-repressed as a result of partitioning\ninequalities at cell division. Finally, observe a size-growth rate uncertainty\nrelation where cells living in rich media vary more in the length at birth than\nin generation time and the opposite is true for cells living in poorer media."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: An exact reduction of the master equation to a strictly stable system\n  with an explicit expression for the stationary distribution"}, {"role": "assistant", "content": "The evolution of a continuous time Markov process with a finite number of\nstates is usually calculated by the Master equation - a linear differential\nequations with a singular generator matrix. We derive a general method for\nreducing the dimensionality of the Master equation by one by using the\nprobability normalization constraint, thus obtaining a affine differential\nequation with a (non-singular) stable generator matrix. Additionally, the\nreduced form yields a simple explicit expression for the stationary probability\ndistribution, which is usually derived implicitly. Finally, we discuss the\napplication of this method to stochastic differential equations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Iterative Approximate Solutions of Kinetic Equations for Reversible\n  Enzyme Reactions"}, {"role": "assistant", "content": "We study kinetic models of reversible enzyme reactions and compare two\ntechniques for analytic approximate solutions of the model. Analytic\napproximate solutions of non-linear reaction equations for reversible enzyme\nreactions are calculated using the Homotopy Perturbation Method (HPM) and the\nSimple Iteration Method (SIM). The results of the approximations are similar.\nThe Matlab programs are included in appendices."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Statistical inference of the generation probability of T-cell receptors\n  from sequence repertoires"}, {"role": "assistant", "content": "Stochastic rearrangement of germline DNA by VDJ recombination is at the\norigin of immune system diversity. This process is implemented via a series of\nstochastic molecular events involving gene choices and random nucleotide\ninsertions between, and deletions from, genes. We use large sequence\nrepertoires of the variable CDR3 region of human CD4+ T-cell receptor beta\nchains to infer the statistical properties of these basic biochemical events.\nSince any given CDR3 sequence can be produced in multiple ways, the probability\ndistribution of hidden recombination events cannot be inferred directly from\nthe observed sequences; we therefore develop a maximum likelihood inference\nmethod to achieve this end. To separate the properties of the molecular\nrearrangement mechanism from the effects of selection, we focus on\nnon-productive CDR3 sequences in T-cell DNA. We infer the joint distribution of\nthe various generative events that occur when a new T-cell receptor gene is\ncreated. We find a rich picture of correlation (and absence thereof), providing\ninsight into the molecular mechanisms involved. The generative event statistics\nare consistent between individuals, suggesting a universal biochemical process.\nOur distribution predicts the generation probability of any specific CDR3\nsequence by the primitive recombination process, allowing us to quantify the\npotential diversity of the T-cell repertoire and to understand why some\nsequences are shared between individuals. We argue that the use of formal\nstatistical inference methods, of the kind presented in this paper, will be\nessential for quantitative understanding of the generation and evolution of\ndiversity in the adaptive immune system."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Identifying dynamical systems with bifurcations from noisy partial\n  observation"}, {"role": "assistant", "content": "Dynamical systems are used to model a variety of phenomena in which the\nbifurcation structure is a fundamental characteristic. Here we propose a\nstatistical machine-learning approach to derive lowdimensional models that\nautomatically integrate information in noisy time-series data from partial\nobservations. The method is tested using artificial data generated from two\ncell-cycle control system models that exhibit different bifurcations, and the\nlearned systems are shown to robustly inherit the bifurcation structure."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Accounting for the Use of Different Length Scale Factors in x, y and z\n  Directions"}, {"role": "assistant", "content": "This short article presents a mathematical formula required for metric\ncorrections in image extraction and processing when using different length\nscale factors in three-dimensional space which is normally encountered in\ncryomicrotome image construction techniques."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: On separation of time scales in pharmacokinetics"}, {"role": "assistant", "content": "A lot of criticism against the standard formulation of pharmacokinetics has\nbeen raised by several authors. It seems that the natural reaction for that\ncriticism is to comment it from the point of view of the theory of conservation\nlaws. Simple example of balance equations for the intravenous administration of\ndrug has been given in 2011 and the corresponding equations for extravasal\nadministration are in the text. In principle, the equations of that kind allow\none to describe in the self consistent manner different processes of\nadministration, distribution, metabolism and elimination of drugs. Moreover, it\nis possible to model different pharmacokinetic parameters of the\nnon-compartmental pharmacokinetics and therefore to comment criticism of\nRosigno. However, for practical purposes one needs approximate methods, in\nparticular, those based on separation of the time scales. In this text, such\nmethod is described and its effectiveness is discussed. Basic equations are in\nthe next chapter. Final remarks are at the end of the text."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Stability of the genetic code and optimal parameters of amino acids"}, {"role": "assistant", "content": "The standard genetic code is known to be much more efficient in minimizing\nadverse effects of misreading errors and one-point mutations in comparison with\na random code having the same structure, i.e. the same number of codons coding\nfor each particular amino acid. We study the inverse problem, how the code\nstructure affects the optimal physico-chemical parameters of amino acids\nensuring the highest stability of the genetic code. It is shown that the choice\nof two or more amino acids with given properties determines unambiguously all\nthe others. In this sense the code structure determines strictly the optimal\nparameters of amino acids. In the code with the structure of the standard\ngenetic code the resulting values for hydrophobicity obtained in the scheme\nleave one out and in the scheme with fixed maximum and minimum parameters\ncorrelate significantly with the natural scale. This indicates the co-evolution\nof the genetic code and physico-chemical properties of amino acids."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A quantitative system for discriminating induced pluripotent stem cells,\n  embryonic stem cells and somatic cells"}, {"role": "assistant", "content": "Embryonic stem cells (ESCs) and induced pluripotent stem cells (iPSCs)\nderived from somatic cells (SCs) provide promising resources for regenerative\nmedicine and medical research, leading to a daily identification of new cell\nlines. However, an efficient system to discriminate the cell lines is lacking.\nHere, we developed a quantitative system to discriminate the three cell types,\niPSCs, ESCs and SCs. The system contains DNA-methylation biomarkers and\nmathematical models, including an artificial neural network and support vector\nmachines. All biomarkers were unbiasedly selected by calculating an eigengene\nscore derived from analysis of genome-wide DNA methylations. With 30\nbiomarkers, or even with as few as 3 top biomarkers, this system can\ndiscriminate SCs from ESCs and iPSCs with almost 100% accuracy, and with\napproximately 100 biomarkers, the system can distinguish ESCs from iPSCs with\nan accuracy of 95%. This robust system performs precisely with raw data without\nnormalization as well as with converted data in which the continuous\nmethylation levels are accounted. Strikingly, this system can even accurately\npredict new samples generated from different microarray platforms and the\nnext-generation sequencing. The subtypes of cells, such as female and male\niPSCs and fetal and adult SCs, can also be discriminated with this system.\nThus, this quantitative system works as a novel general and accurate framework\nfor discriminating the three cell types, iPSCs, ESCs, and SCs and this strategy\nsupports the notion that DNA-methylation generally varies among the three cell\ntypes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Parameter space exploration of ecological models"}, {"role": "assistant", "content": "In recent years, we are seeing the formulation and use of elaborate and\ncomplex models in ecological studies. The questions related to the efficient,\nsystematic and error-proof exploration of parameter spaces are of great\nimportance to better understand, estimate confidences and make use of the\noutput from these models. In this work, we investigate some of the relevant\nquestions related to parameter space exploration, in particular using the\ntechnique known as Latin Hypercube Sampling and focusing in quantitative output\nanalysis. We present the analysis of a structured population growth model and\ncontrast our findings with results from previously used techniques, known as\nsensitivity and elasticity analyses. We also assess how are the questions\nrelated to parameter space analysis being currently addressed in the ecological\nliterature."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Who Watches the Watchmen? An Appraisal of Benchmarks for Multiple\n  Sequence Alignment"}, {"role": "assistant", "content": "Multiple sequence alignment (MSA) is a fundamental and ubiquitous technique\nin bioinformatics used to infer related residues among biological sequences.\nThus alignment accuracy is crucial to a vast range of analyses, often in ways\ndifficult to assess in those analyses. To compare the performance of different\naligners and help detect systematic errors in alignments, a number of\nbenchmarking strategies have been pursued. Here we present an overview of the\nmain strategies--based on simulation, consistency, protein structure, and\nphylogeny--and discuss their different advantages and associated risks. We\noutline a set of desirable characteristics for effective benchmarking, and\nevaluate each strategy in light of them. We conclude that there is currently no\nuniversally applicable means of benchmarking MSA, and that developers and users\nof alignment tools should base their choice of benchmark depending on the\ncontext of application--with a keen awareness of the assumptions underlying\neach benchmarking strategy."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: HIV, TB and ART: the CD4 enigma"}, {"role": "assistant", "content": "The concentration of CD4 T-lymphocytes (CD4 count), in a person's plasma is\nwidely used to decide when to start HIV-positive people on anti-retroviral\ntherapy (ART) and to predict the impact of ART on the future course of HIV and\ntuberculosis (TB). However, CD4 cell-counts vary widely within and among\npopulations and depend on many factors besides HIV-infection. The way in which\nCD4 counts decline over the course of HIV infection is neither well understood\nnor widely agreed. We review what is known about CD4 counts in relation to HIV\nand TB and discuss areas in which more research is needed to build a consensus\non how to interpret and use CD4 counts in clinical practice and to develop a\nbetter understanding of the dynamics and control of HIV and HIV-related TB."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Improving basic and translational science by accounting for\n  litter-to-litter variation in animal models"}, {"role": "assistant", "content": "Background: Animals from the same litter are often more alike compared with\nanimals from different litters. This litter-to-litter variation, or \"litter\neffects\", can influence the results in addition to the experimental factors of\ninterest. Furthermore, an experimental treatment can be applied to whole\nlitters rather than to individual offspring. For example, in the valproic acid\n(VPA) model of autism, VPA is administered to pregnant females thereby inducing\nthe disease phenotype in the offspring. With this type of experiment the sample\nsize is the number of litters and not the total number of offspring. If such\nexperiments are not appropriately designed and analysed, the results can be\nseverely biased as well as extremely underpowered.\n  Results: A review of the VPA literature showed that only 9% (3/34) of studies\ncorrectly determined that the experimental unit (n) was the litter and\ntherefore made valid statistical inferences. In addition, litter effects\naccounted for up to 61% (p <0.001) of the variation in behavioural outcomes,\nwhich was larger than the treatment effects. In addition, few studies reported\nusing randomisation (12%) or blinding (18%), and none indicated that a sample\nsize calculation or power analysis had been conducted.\n  Conclusions: Litter effects are common, large, and ignoring them can make\nreplication of findings difficult and can contribute to the low rate of\ntranslating preclinical in vivo studies into successful therapies. Only a\nminority of studies reported using rigorous experimental methods, which is\nconsistent with much of the preclinical in vivo literature."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A stochastic model of social interaction in wild house mice"}, {"role": "assistant", "content": "We investigate to what extent the interaction dynamics of a population of\nwild house mouse (Mus musculus domesticus) in their environment can be\nexplained by a simple stochastic model. We use a Markov chain model to describe\nthe transitions of mice in a discrete space of nestboxes, and implement a\nmulti-agent simulation of the model. We find that some important features of\nour behavioural dataset can be reproduced using this simplified stochastic\nrepresentation, and discuss the improvements that could be made to our model in\norder to increase the accuracy of its predictions. Our findings have\nimplications for the understanding of the complexity underlying social\nbehaviour in the animal kingdom and the cognitive requirements of such\nbehaviour."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Foliar area measurement by a new technique that utilizes the\n  conservative nature of fresh leaf surface density"}, {"role": "assistant", "content": "Leaf area LA, is a plant biometric index important to agroforestry and crop\nproduction. Previous works have demonstrated the conservativeness of the\ninverse of the product of the fresh leaf density and thickness, the so-called\nHughes constant, K. We use this fact to develop LAMM, an absolute method of LA\nmeasurement, i.e. no regression fits or prior calibrations with planimeters.\nNor does it require drying the leaves. The concept involves the in situ\ndetermination of K using geometrical shapes and their weights obtained from a\nsubset of fresh leaves of the set whose areas are desired. Subsequently the\nLAs, at any desired stratification level, are derived by utilizing K and the\npreviously measured masses of the fresh leaves. The concept was first tested in\nthe simulated ideal case of complete planarity and uniform thickness by using\nplastic film covered card-paper sheets. Next the species-specific\nconservativeness of K over individual leaf zones and different leaf types from\nleaves of plants from two species, Mandevilla splendens and Spathiphyllum\nwallisii, was quantitatively validated. Using the global average K values, the\nLA of these and additional plants, were obtained. LAMM was found to be a rapid,\nsimple, economic technique with accuracies, as measured for the geometrical\nshapes, that were comparable to those obtained by the planimetric method that\nutilizes digital image analysis, DIA. For the leaves themselves, there were no\nstatistically significant differences between the LAs measured by LAMM and by\nthe DIA and the linear correlation between the two methods was excellent."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: On modelling of bioavailability of drugs in terms of conservation laws"}, {"role": "assistant", "content": "In the text S.Piekarski, M.Rewekant,(arXiv:1208.3847)it has been mentioned\nthat some information on bioavailability and bioequivalence of drugs can be\nobtained from simulations based on the conservation laws. Here we shortly\ndiscuss that possibility starting from the fundamental pharmacokinetic\nparameter called AUC (Area Under the Curve). The curve is is the profile shape\nof plasma drug concentration in time intervals after drug administration into\norganism. Our aim here is to give some information on the subject for the\nreader with no experience in pharmacokinetics."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Could ART increase the population level incidence of TB?"}, {"role": "assistant", "content": "HIV increases the likelihood that a person will develop TB. Starting them on\nanti-retroviral therapy (ART) reduces their risk of TB but not to the level in\nHIV negative people. Since HIV-positive people who are on ART can expect to\nlive a normal life for several decades this raises the possibility that their\nelevated risk of infection, lasting for a long time, could lead to an increase\nin the population level incidence of TB. Here we investigate the conditions\nunder which this could happen and show that provided HIV-positive people start\nART when their CD4+ cell count is greater than 350/microL and that there is\nhigh coverage, ART will not lead to a long-term increase in HIV. Only if people\nstart ART very late and there is low coverage of ART might starting people on\nART increase the population level incidence of TB."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Unified Approach to Integration and Optimization of Parametric\n  Ordinary Differential Equations"}, {"role": "assistant", "content": "Parameter estimation in ordinary differential equations, although applied and\nrefined in various fields of the quantitative sciences, is still confronted\nwith a variety of difficulties. One major challenge is finding the global\noptimum of a log-likelihood function that has several local optima, e.g. in\noscillatory systems. In this publication, we introduce a formulation based on\ncontinuation of the log-likelihood function that allows to restate the\nparameter estimation problem as a boundary value problem. By construction, the\nordinary differential equations are solved and the parameters are estimated\nboth in one step. The formulation as a boundary value problem enables an\noptimal transfer of information given by the measurement time courses to the\nsolution of the estimation problem, thus favoring convergence to the global\noptimum. This is demonstrated explicitly for the fully as well as the partially\nobserved Lotka-Volterra system."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: OpenSPIM - an open access platform for light sheet microscopy"}, {"role": "assistant", "content": "Light sheet microscopy promises to revolutionize developmental biology by\nenabling live in toto imaging of entire embryos with minimal phototoxicity. We\npresent detailed instructions for building a compact and customizable Selective\nPlane Illumination Microscopy (SPIM) system. The integrated OpenSPIM hardware\nand software platform is shared with the scientific community through a public\nwebsite, thereby making light sheet microscopy accessible for widespread use\nand optimization to various applications."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Remarks on a population-level model of chemotaxis: advection-diffusion\n  approximation and simulations"}, {"role": "assistant", "content": "This note works out an advection-diffusion approximation to the density of a\npopulation of E. coli bacteria undergoing chemotaxis in a one-dimensional\nspace. Simulations show the high quality of predictions under a\nshallow-gradient regime."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Pooling single-cell recordings: Scalable inference through heterogeneous\n  kinetics"}, {"role": "assistant", "content": "Mathematical methods together with measurements of single-cell dynamics\nprovide unprecedented means to reconstruct intracellular processes that are\nonly partly or indirectly accessible experimentally. To obtain reliable\nreconstructions the pooling of measurements from several cells of a clonal\npopulation is mandatory. The population's considerable cell-to-cell variability\noriginating from diverse sources poses novel computational challenges for\nprocess reconstruction. We introduce an exact Bayesian inference framework that\nproperly accounts for the population heterogeneity but also retains scalability\nwith respect to the number of pooled cells. The key ingredient is a stochastic\nprocess that captures the heterogeneous kinetics of a population. The method\nallows to infer inaccessible molecular states, kinetic parameters, compute\nBayes factors and to dissect intrinsic, extrinsic and technical contributions\nto the variability in the data. We also show how additional single-cell\nreadouts such as morphological features can be included into the analysis. We\nthen reconstruct the expression dynamics of a gene under an inducible GAL1\npromoter in yeast from time-lapse microscopy data. Based on Bayesian model\nselection the data yields no evidence of a refractory period for this promoter."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Cancer Diagnosis with QUIRE: QUadratic Interactions among infoRmative\n  fEatures"}, {"role": "assistant", "content": "Responsible for many complex human diseases including cancers, disrupted or\nabnormal gene interactions can be identified through their expression changes\ncorrelating with the progression of a disease. However, the examination of all\npossible combinatorial interactions between gene features in a genome-wide\ncase-control study is computationally infeasible as the search space is\nexponential in nature.\n  In this paper, we propose a novel computational approach, QUIRE, to identify\ndiscriminative complex interactions among informative gene features for cancer\ndiagnosis. QUIRE works in two stages, where it first identifies functionally\nrelevant feature groups for the disease and, then explores the search space\ncapturing the combinatorial relationships among the genes from the selected\ninformative groups. Using QUIRE, we explore the differential patterns and the\ninteractions among informative gene features in three different types of\ncancers, Renal Cell Carcinoma(RCC), Ovarian Cancer(OVC) and Colorectal Cancer\n(CRC). Our experimental results show that QUIRE identifies gene-gene\ninteractions that can better identify the different cancer stages of samples\nand can predict CRC recurrence and death from CRC more successfully, as\ncompared to other state-of-the-art feature selection methods. A literature\nsurvey shows that many of the interactions identified by QUIRE play important\nroles in the development of cancer."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Input-output equivalence and identifiability: some simple\n  generalizations of the differential algebra approach"}, {"role": "assistant", "content": "In this paper, we give an overview of the differential algebra approach to\nidentifiability, and then note a very simple observation about input-output\nequivalence and identifiability, that describes the identifiability equivalence\nbetween input-output equivalent models. We then give several simple\nconsequences of this observation that can be useful in showing identifiability,\nincluding examining non-first order ODE models, nondimensionalization and\nrescaling, model reducibility, and a modular approach to evaluating\nidentifiability. We also examine how input-output equivalence can allow us to\ngenerate input output equations in the differential algebra approach through a\nwider range of methods (e.g. substitution and differential or standard Groebner\nbasis approaches)."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Gold particle quantification in immuno-gold labelled sections for\n  transmission electron microscopy"}, {"role": "assistant", "content": "We briefly outline an algorithm for accurate quantification of specific\nbinding of gold particles to fixed biological tissue samples prepared for\nimmuno-transmission electron microscopy (TEM). The algorithm is based on\nexisting protocols for rational accounting of colloidal gold particles used in\nsecondary antibodies for immuno-gold labeling."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A New Procedure for Microarray Experiments to Account for Experimental\n  Noise and the Uncertainty of Probe Response"}, {"role": "assistant", "content": "Although microarrays are routine analysis tools in biomedical research, they\nstill yield noisy output that often requires experimental confirmation. Many\nstudies have aimed at optimizing probe design and statistical analysis to\ntackle this problem. However, less emphasis has been placed on controlling the\nnoise inherent to the experimental approach. To address this problem, we\ninvestigate here a procedure that controls for such experimental variance and\ncombine it with an assessment of probe performance. Two custom arrays were used\nto evaluate the procedure: one based on 25mer probes from an Affymetrix design\nand the other based on 60mer probes from an Agilent design. To assess\nexperimental variance, all probes were replicated ten times. To assess probe\nperformance, the probes were calibrated using a dilution series of target\nmolecules and the signal response was fitted to an absorption model. We found\nthat significant variance of the signal could be controlled by averaging across\nprobes and removing probes that are nonresponsive. Thus, a more reliable signal\ncould be obtained using our procedure than conventional approaches. We suggest\nthat once an array is properly calibrated, absolute quantification of signals\nbecomes straight forward, alleviating the need for normalization and reference\nhybridizations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Color Perception: Opening up the Chromaticity Cone"}, {"role": "assistant", "content": "In the XYZ color space, the subset of the tri-stimuli corresponding to\nspike-type (monochromatic) impingement of energy is the chromaticity cone, CC.\nUsing a family of concentric spheres, we describe a nonlinear transformation\nover the CC and construct a bijection from the CC onto the flat plane. In the\nprocess, we open up the CC and view it as a chart on the plane. Because the map\nis a bijection, the color perception information is preserved (invariant)\nthrough the transformation. We discuss stereographic projection of the\nchromaticity chart and some examples."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Designing Experiments to Understand the Variability in Biochemical\n  Reaction Networks"}, {"role": "assistant", "content": "Exploiting the information provided by the molecular noise of a biological\nprocess has proven to be valuable in extracting knowledge about the underlying\nkinetic parameters and sources of variability from single cell measurements.\nHowever, quantifying this additional information a priori, to decide whether a\nsingle cell experiment might be beneficial, is currently only possibly in very\nsimple systems where either the chemical master equation is computationally\ntractable or a Gaussian approximation is appropriate. Here we show how the\ninformation provided by distribution measurements can be approximated from the\nfirst four moments of the underlying process. The derived formulas are\ngenerally valid for any stochastic kinetic model including models that comprise\nboth intrinsic and extrinsic noise. This allows us to propose an optimal\nexperimental design framework for heterogeneous cell populations which we\nemploy to compare the utility of dual reporter and perturbation experiments for\nseparating extrinsic and intrinsic noise in a simple model of gene expression.\nSubsequently, we compare the information content of different experiments which\nhave been performed in an engineered light-switch gene expression system in\nyeast and show that well chosen gene induction patterns may allow one to\nidentify features of the system which remain hidden in unplanned experiments."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Rapid quantitative pharmacodynamic imaging by a novel method: theory,\n  simulation testing and proof of principle"}, {"role": "assistant", "content": "Pharmacological challenge imaging has mapped, but rarely quantified, the\nsensitivity of a biological system to a given drug. We describe a novel method\ncalled rapid quantitative pharmacodynamic imaging. This method combines\npharmacokinetic-pharmacodynamic modeling, repeated small doses of a challenge\ndrug over a short time scale, and functional imaging to rapidly provide\nquantitative estimates of drug sensitivity including EC50 (the concentration of\ndrug that produces half the maximum possible effect). We first test the method\nwith simulated data, assuming a typical sigmoidal dose-response curve and\nassuming imperfect imaging that includes artifactual baseline signal drift and\nrandom error. With these few assumptions, rapid quantitative pharmacodynamic\nimaging reliably estimates EC50 from the simulated data, except when noise\noverwhelms the drug effect or when the effect occurs only at high doses. In\npreliminary fMRI studies of primate brain using a dopamine agonist, the\nobserved noise level is modest compared with observed drug effects, and a\nquantitative EC50 can be obtained from some regional time-signal curves. Taken\ntogether, these results suggest that research and clinical applications for\nrapid quantitative pharmacodynamic imaging are realistic."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Automated Alignment of Imperfect EM Images for Neural Reconstruction"}, {"role": "assistant", "content": "The most established method of reconstructing neural circuits from animals\ninvolves slicing tissue very thin, then taking mosaics of electron microscope\n(EM) images. To trace neurons across different images and through different\nsections, these images must be accurately aligned, both with the others in the\nsame section and to the sections above and below. Unfortunately, sectioning and\nimaging are not ideal processes - some of the problems that make alignment\ndifficult include lens distortion, tissue shrinkage during imaging, tears and\nfolds in the sectioned tissue, and dust and other artifacts. In addition the\ndata sets are large (hundreds of thousands of images) and each image must be\naligned with many neighbors, so the process must be automated and reliable.\nThis paper discusses methods of dealing with these problems, with numeric\nresults describing the accuracy of the resulting alignments."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The new science of metagenomics and the challenges of its use in both\n  developed and developing countries"}, {"role": "assistant", "content": "Our view of the microbial world and its impact on human health is changing\nradically with the ability to sequence uncultured or unculturable microbes\nsampled directly from their habitats, ability made possible by fast and cheap\nnext generation sequencing technologies. Such recent developments represents a\nparadigmatic shift in the analysis of habitat biodiversity, be it the human,\nsoil or ocean microbiome. We review here some research examples and results\nthat indicate the importance of the microbiome in our lives and then discus\nsome of the challenges faced by metagenomic experiments and the subsequent\nanalysis of the generated data. We then analyze the economic and social impact\non genomic-medicine and research in both developing and developed countries. We\nsupport the idea that there are significant benefits in building capacities for\ndeveloping high-level scientific research in metagenomics in developing\ncountries. Indeed, the notion that developing countries should wait for\ndeveloped countries to make advances in science and technology that they later\nimport at great cost has recently been challenged."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: HiTRACE-Web: an online tool for robust analysis of high-throughput\n  capillary electrophoresis"}, {"role": "assistant", "content": "To facilitate the analysis of large-scale high-throughput capillary\nelectrophoresis data, we previously proposed a suite of efficient analysis\nsoftware named HiTRACE (High Throughput Robust Analysis of Capillary\nElectrophoresis). HiTRACE has been used extensively for quantitating data from\nRNA and DNA structure mapping experiments, including mutate-and-map contact\ninference, chromatin footprinting, the EteRNA RNA design project and other\nhigh-throughput applications. However, HiTRACE is based on a suite of\ncommand-line MATLAB scripts that requires nontrivial efforts to learn, use, and\nextend. Here we present HiTRACE-Web, an online version of HiTRACE that includes\nstandard features previously available in the command-line version as well as\nadditional features such as automated band annotation and flexible adjustment\nof annotations, all via a user-friendly environment. By making use of\nparallelization, the on-line workflow is also faster than software\nimplementations available to most users on their local computers. Free access:\nhttp://hitrace.org"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Flexible RNA design under structure and sequence constraints using\n  formal languages"}, {"role": "assistant", "content": "The problem of RNA secondary structure design (also called inverse folding)\nis the following: given a target secondary structure, one aims to create a\nsequence that folds into, or is compatible with, a given structure. In several\npractical applications in biology, additional constraints must be taken into\naccount, such as the presence/absence of regulatory motifs, either at a\nspecific location or anywhere in the sequence. In this study, we investigate\nthe design of RNA sequences from their targeted secondary structure, given\nthese additional sequence constraints. To this purpose, we develop a general\nframework based on concepts of language theory, namely context-free grammars\nand finite automata. We efficiently combine a comprehensive set of constraints\ninto a unifying context-free grammar of moderate size. From there, we use\ngeneric generic algorithms to perform a (weighted) random generation, or an\nexhaustive enumeration, of candidate sequences. The resulting method, whose\ncomplexity scales linearly with the length of the RNA, was implemented as a\nstandalone program. The resulting software was embedded into a publicly\navailable dedicated web server. The applicability demonstrated of the method on\na concrete case study dedicated to Exon Splicing Enhancers, in which our\napproach was successfully used in the design of \\emph{in vitro} experiments."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Variable-length haplotype construction for gene-gene interaction studies"}, {"role": "assistant", "content": "This paper presents a non-parametric classification technique for identifying\na candidate bi-allelic genetic marker set that best describes disease\nsusceptibility in gene-gene interaction studies. The developed technique\nfunctions by creating a mapping between inferred haplotypes and case/control\nstatus. The technique cycles through all possible marker combination models\ngenerated from the available marker set where the best interaction model is\ndetermined from prediction accuracy and two auxiliary criteria including\nlow-to-high order haplotype propagation capability and model parsimony. Since\nvariable-length haplotypes are created during the best model identification,\nthe developed technique is referred to as a variable-length haplotype\nconstruction for gene-gene interaction (VarHAP) technique. VarHAP has been\nbenchmarked against a multifactor dimensionality reduction (MDR) program and a\nhaplotype interaction technique embedded in a FAMHAP program in various\ntwo-locus interaction problems. The results reveal that VarHAP is suitable for\nall interaction situations with the presence of weak and strong linkage\ndisequilibrium among genetic markers."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Using structural and evolutionary information to detect and correct\n  pyrosequencing errors in non-coding RNAs"}, {"role": "assistant", "content": "Analysis of the sequence-structure relationship in RNA molecules are\nessential to evolutionary studies but also to concrete applications such as\nerror-correction methodologies in sequencing technologies. The prohibitive\nsizes of the mutational and conformational landscapes combined with the volume\nof data to proceed require efficient algorithms to compute sequence-structure\nproperties. More specifically, here we aim to calculate which mutations\nincrease the most the likelihood of a sequence to a given structure and RNA\nfamily. In this paper, we introduce RNApyro, an efficient linear-time and space\ninside-outside algorithm that computes exact mutational probabilities under\nsecondary structure and evolutionary constraints given as a multiple sequence\nalignment with a consensus structure. We develop a scoring scheme combining\nclassical stacking base pair energies to novel isostericity scales, and apply\nour techniques to correct point-wise errors in 5s and 16s rRNA sequences. Our\nresults suggest that RNApyro is a promising algorithm to complement existing\ntools in the NGS error-correction pipeline."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multi-cancer molecular signatures and their interrelationships"}, {"role": "assistant", "content": "Although cancer is known to be characterized by several unifying biological\nhallmarks, systems biology has had limited success in identifying molecular\nsignatures present in in all types of cancer. The current availability of rich\ndata sets from many different cancer types provides an opportunity for thorough\ncomputational data mining in search of such common patterns. Here we report the\nidentification of 18 \"pan-cancer\" molecular signatures resulting from analysis\nof data sets containing values from mRNA expression, microRNA expression, DNA\nmethylation, and protein activity, from twelve different cancer types. The\nmembership of many of these signatures points to particular biological\nmechanisms related to cancer progression, suggesting that they represent\nimportant attributes of cancer in need of being elucidated for potential\napplications in diagnostic, prognostic and therapeutic products applicable to\nmultiple cancer types."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Collective Correlations of Brodmann Areas fMRI Study with RMT-Denoising"}, {"role": "assistant", "content": "We study collective behavior of Brodmann regions of human cerebral cortex\nusing functional Magnetic Resonance Imaging (fMRI) and Random Matrix Theory\n(RMT). The raw fMRI data is mapped onto the cortex regions corresponding to the\nBrodmann areas with the aid of the Talairach coordinates. Principal Component\nAnalysis (PCA) of the Pearson correlation matrix for 41 different Brodmann\nregions is carried out to determine their collective activity in the idle state\nand in the active state stimulated by tapping. The collective brain activity is\nidentified through the statistical analysis of the eigenvectors to the largest\neigenvalues of the Pearson correlation matrix. The leading eigenvectors have a\nlarge participation ratio. This indicates that several Broadmann regions\ncollectively give rise to the brain activity associated with these\neigenvectors. We apply random matrix theory to interpret the underlying\nmultivariate data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Arabidopsis plants perform arithmetic division to prevent starvation at\n  night"}, {"role": "assistant", "content": "Photosynthetic starch reserves that accumulate in Arabidopsis leaves during\nthe day decrease approximately linearly with time at night to support\nmetabolism and growth. We find that the rate of decrease is adjusted to\naccommodate variation in the time of onset of darkness and starch content, such\nthat reserves last almost precisely until dawn. Generation of these dynamics\ntherefore requires an arithmetic division computation between the starch\ncontent and expected time to dawn. We introduce two novel chemical kinetic\nmodels capable of implementing analog arithmetic division. Predictions from the\nmodels are successfully tested in plants perturbed by a night-time light period\nor by mutations in starch degradation pathways. Our experiments indicate which\ncomponents of the starch degradation apparatus may be important for appropriate\narithmetic division. Our results are potentially relevant for any biological\nsystem dependent on a food reserve for survival over a predictable time period."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Dynamics of Boolean Networks"}, {"role": "assistant", "content": "Boolean networks are special types of finite state time-discrete dynamical\nsystems. A Boolean network can be described by a function from an n-dimensional\nvector space over the field of two elements to itself. A fundamental problem in\nstudying these dynamical systems is to link their long term behaviors to the\nstructures of the functions that define them. In this paper, a method for\nderiving a Boolean network's dynamical information via its disjunctive normal\nform is explained. For a given Boolean network, a matrix with entries 0 and 1\nis associated with the polynomial function that represents the network, then\nthe information on the fixed points and the limit cycles is derived by\nanalyzing the matrix. The described method provides an algorithm for the\ndetermination of the fixed points from the polynomial expression of a Boolean\nnetwork. The method can also be used to construct Boolean networks with\nprescribed limit cycles and fixed points. Examples are provided to explain the\nalgorithm."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Determining Structurally Identifiable Parameter Combinations Using\n  Subset Profiling"}, {"role": "assistant", "content": "Identifiability is a necessary condition for successful parameter estimation\nof dynamic system models. A major component of identifiability analysis is\ndetermining the identifiable parameter combinations, the functional forms for\nthe dependencies between unidentifiable parameters. Identifiable combinations\ncan help in model reparameterization and also in determining which parameters\nmay be experimentally measured to recover model identifiability. Several\nnumerical approaches to determining identifiability of differential equation\nmodels have been developed, however the question of determining identifiable\ncombinations remains incompletely addressed. In this paper, we present a new\napproach which uses parameter subset selection methods based on the Fisher\nInformation Matrix, together with the profile likelihood, to effectively\nestimate identifiable combinations. We demonstrate this approach on several\nexample models in pharmacokinetics, cellular biology, and physiology."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Combination prevention for the elimination of HIV"}, {"role": "assistant", "content": "The development of potent drugs for the control of viraemia in people living\nwith HIV means that infected people may live a normal, healthy life and offers\nthe prospect of eliminating HIV transmission in the short term and HIV\ninfection in the long term. Other interventions, including the use of condoms,\npre-exposure prophylaxis, treatment of sexually transmitted infections and\nbehaviour change programmes, may also be effective in reducing HIV transmission\nto varying degrees.\n  Here we examine recommendations for when to start treatment with\nanti-retroviral drugs, estimate the impact that treatment may have on HIV\ntransmission in the short and in the long term, and compare the impact and cost\nof treatment with that of other methods of control. We focus on generalized HIV\nepidemics in sub-Saharan Africa. We show that universal access to ART combined\nwith early treatment is the most effective and, in the long term, the most\ncost-effective intervention. Elimination will require effective coverage of\nabout 80% or more but treatment is effective and cost effective even at low\nlevels of coverage.\n  Other interventions may provide important support to a programme of early\ntreatment in particular groups. Condoms provide protection for both men and\nwomen and should be readily available whenever they are needed. Medical male\ncircumcision will provide a degree of immediate protection for men and\nmicrobicides will do the same for women. Behaviour change programmes in\nthemselves are unlikely to have a significant impact on overall transmission\nbut may play a critical role in supporting early treatment through helping to\navoid stigma and discrimination, ensuring the acceptability of testing and\nearly treatment as well as compliance."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Measuring ligand-receptor binding kinetics and dynamics using k-space\n  image correlation spectroscopy"}, {"role": "assistant", "content": "Accurate measurements of kinetic rate constants for interacting biomolecules\nis crucial for understanding the mechanisms underlying intracellular signalling\npathways. The magnitude of binding rates plays a very important molecular\nregulatory role which can lead to very different cellular physiological\nresponses under different conditions. Here, we extend the k-space image\ncorrelation spectroscopy (kICS) technique to study the kinetic binding rates of\nsystems wherein: (a) fluorescently labelled, free ligands in solution interact\nwith unlabelled, diffusing receptors in the plasma membrane and (b) systems\nwhere labelled, diffusing receptors are allowed to bind/unbind and interconvert\nbetween two different diffusing states on the plasma membrane. We develop the\nnecessary mathematical framework for the kICS analysis and demonstrate how to\nextract the elevant kinetic binding parameters of the underlying molecular\nsystem from fluorescence video-microscopy image time-series. Finally, by\nexamining real data for two model experimental systems, we demonstrate how kICS\ncan be a powerful tool to measure molecular transport coefficients and binding\nkinetics."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Towards Reliable Automatic Protein Structure Alignment"}, {"role": "assistant", "content": "A variety of methods have been proposed for structure similarity calculation,\nwhich are called structure alignment or superposition. One major shortcoming in\ncurrent structure alignment algorithms is in their inherent design, which is\nbased on local structure similarity. In this work, we propose a method to\nincorporate global information in obtaining optimal alignments and\nsuperpositions. Our method, when applied to optimizing the TM-score and the GDT\nscore, produces significantly better results than current state-of-the-art\nprotein structure alignment tools. Specifically, if the highest TM-score found\nby TMalign is lower than (0.6) and the highest TM-score found by one of the\ntested methods is higher than (0.5), there is a probability of (42%) that\nTMalign failed to find TM-scores higher than (0.5), while the same probability\nis reduced to (2%) if our method is used. This could significantly improve the\naccuracy of fold detection if the cutoff TM-score of (0.5) is used.\n  In addition, existing structure alignment algorithms focus on structure\nsimilarity alone and simply ignore other important similarities, such as\nsequence similarity. Our approach has the capacity to incorporate multiple\nsimilarities into the scoring function. Results show that sequence similarity\naids in finding high quality protein structure alignments that are more\nconsistent with eye-examined alignments in HOMSTRAD. Even when structure\nsimilarity itself fails to find alignments with any consistency with\neye-examined alignments, our method remains capable of finding alignments\nhighly similar to, or even identical to, eye-examined alignments."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Faster mass decomposition"}, {"role": "assistant", "content": "Metabolomics complements investigation of the genome, transcriptome, and\nproteome of an organism. Today, the vast majority of metabolites remain\nunknown, in particular for non-model organisms. Mass spectrometry is one of the\npredominant techniques for analyzing small molecules such as metabolites. A\nfundamental step for identifying a small molecule is to determine its molecular\nformula.\n  Here, we present and evaluate three algorithm engineering techniques that\nspeed up the molecular formula determination. For that, we modify an existing\nalgorithm for decomposing the monoisotopic mass of a molecule. These techniques\nlead to a four-fold reduction of running times, and reduce memory consumption\nby up to 94%. In comparison to the classical search tree algorithm, our\nalgorithm reaches a 1000-fold speedup."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: MSARC: Multiple Sequence Alignment by Residue Clustering"}, {"role": "assistant", "content": "Progressive methods offer efficient and reasonably good solutions to the\nmultiple sequence alignment problem. However, resulting alignments are biased\nby guide-trees, especially for relatively distant sequences.\n  We propose MSARC, a new graph-clustering based algorithm that aligns sequence\nsets without guide-trees. Experiments on the BAliBASE dataset show that MSARC\nachieves alignment quality similar to best progressive methods and\nsubstantially higher than the quality of other non-progressive algorithms.\nFurthermore, MSARC outperforms all other methods on sequence sets with the\nsimilarity structure hardly represented by a phylogenetic tree. Furthermore,\nMSARC outperforms all other methods on sequence sets whose evolutionary\ndistances are hardly representable by a phylogenetic tree. These datasets are\nmost exposed to the guide-tree bias of alignments.\n  MSARC is available at http://bioputer.mimuw.edu.pl/msarc"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Mutual Enrichment in Ranked Lists and the Statistical Assessment of\n  Position Weight Matrix Motifs"}, {"role": "assistant", "content": "Statistics in ranked lists is important in analyzing molecular biology\nmeasurement data, such as ChIP-seq, which yields ranked lists of genomic\nsequences. State of the art methods study fixed motifs in ranked lists. More\nflexible models such as position weight matrix (PWM) motifs are not addressed\nin this context. To assess the enrichment of a PWM motif in a ranked list we\nuse a PWM induced second ranking on the same set of elements. Possible orders\nof one ranked list relative to the other are modeled by permutations. Due to\nsample space complexity, it is difficult to characterize tail distributions in\nthe group of permutations. In this paper we develop tight upper bounds on tail\ndistributions of the size of the intersection of the top of two uniformly and\nindependently drawn permutations and demonstrate advantages of this approach\nusing our software implementation, mmHG-Finder, to study PWMs in several\ndatasets."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Modeling Intratumor Gene Copy Number Heterogeneity using Fluorescence in\n  Situ Hybridization data"}, {"role": "assistant", "content": "Tumorigenesis is an evolutionary process which involves a significant number\nof genomic rearrangements typically coupled with changes in the gene copy\nnumber profiles of numerous cells. Fluorescence in situ hybridization (FISH) is\na cytogenetic technique which allows counting copy numbers of genes in single\ncells. The study of cancer progression using FISH data has received\nconsiderably less attention compared to other types of cancer datasets.\n  In this work we focus on inferring likely tumor progression pathways using\npublicly available FISH data. We model the evolutionary process as a Markov\nchain in the positive integer cone Z_+^g where g is the number of genes\nexamined with FISH. Compared to existing work which oversimplifies reality by\nassuming independence of copy number changes, our model is able to capture\ndependencies. We model the probability distribution of a dataset with\nhierarchical log-linear models, a popular probabilistic model of count data.\nOur choice provides an attractive trade-off between parsimony and good data\nfit. We prove a theorem of independent interest which provides necessary and\nsufficient conditions for reconstructing oncogenetic trees. Using this theorem\nwe are able to capitalize on the wealth of inter-tumor phylogenetic methods. We\nshow how to produce tumor phylogenetic trees which capture the dynamics of\ncancer progression. We validate our proposed method on a breast tumor dataset."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Phylogenetic Analysis of Cell Types using Histone Modifications"}, {"role": "assistant", "content": "In cell differentiation, a cell of a less specialized type becomes one of a\nmore specialized type, even though all cells have the same genome.\nTranscription factors and epigenetic marks like histone modifications can play\na significant role in the differentiation process. In this paper, we present a\nsimple analysis of cell types and differentiation paths using phylogenetic\ninference based on ChIP-Seq histone modification data. We propose new data\nrepresentation techniques and new distance measures for ChIP-Seq data and use\nthese together with standard phylogenetic inference methods to build\nbiologically meaningful trees that indicate how diverse types of cells are\nrelated. We demonstrate our approach on H3K4me3 and H3K27me3 data for 37 and 13\ntypes of cells respectively, using the dataset to explore various issues\nsurrounding replicate data, variability between cells of the same type, and\nrobustness. The promising results we obtain point the way to a new approach to\nthe study of cell differentiation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: From Cellular Characteristics to Disease Diagnosis: Uncovering\n  Phenotypes with Supercells"}, {"role": "assistant", "content": "Cell heterogeneity and the inherent complexity due to the interplay of\nmultiple molecular processes within the cell pose difficult challenges for\ncurrent single-cell biology. We introduce an approach that identifies a disease\nphenotype from multiparameter single-cell measurements, which is based on the\nconcept of \"supercell statistics\", a single-cell-based averaging procedure\nfollowed by a machine learning classification scheme. We are able to assess the\noptimal tradeoff between the number of single cells averaged and the number of\nmeasurements needed to capture phenotypic differences between healthy and\ndiseased patients, as well as between different diseases that are difficult to\ndiagnose otherwise. We apply our approach to two kinds of single-cell datasets,\naddressing the diagnosis of a premature aging disorder using images of cell\nnuclei, as well as the phenotypes of two non-infectious uveitides (the ocular\nmanifestations of Beh\\c{c}et's disease and sarcoidosis) based on multicolor\nflow cytometry. In the former case, one nuclear shape measurement taken over a\ngroup of 30 cells is sufficient to classify samples as healthy or diseased, in\nagreement with usual laboratory practice. In the latter, our method is able to\nidentify a minimal set of 5 markers that accurately predict Beh\\c{c}et's\ndisease and sarcoidosis. This is the first time that a quantitative phenotypic\ndistinction between these two diseases has been achieved. To obtain this clear\nphenotypic signature, about one hundred CD8+ T cells need to be measured.\nBeyond these specific cases, the approach proposed here is applicable to\ndatasets generated by other kinds of state-of-the-art and forthcoming\nsingle-cell technologies, such as multidimensional mass cytometry, single-cell\ngene expression, and single-cell full genome sequencing techniques."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multi-study Integration of Brain Cancer Transcriptomes Reveals\n  Organ-Level Molecular Signatures"}, {"role": "assistant", "content": "We utilized abundant transcriptomic data for the primary classes of brain\ncancers to study the feasibility of separating all of these diseases\nsimultaneously based on molecular data alone. These signatures were based on a\nnew method reported herein that resulted in a brain cancer marker panel of 44\nunique genes. Many of these genes have established relevance to the brain\ncancers examined, with others having known roles in cancer biology. Analyses on\nlarge-scale data from multiple sources must deal with significant challenges\nassociated with heterogeneity between different published studies, for it was\nobserved that the variation among individual studies often had a larger effect\non the transcriptome than did phenotype differences, as is typical. We found\nthat learning signatures across multiple datasets greatly enhanced\nreproducibility and accuracy in predictive performance on truly independent\nvalidation sets, even when keeping the size of the training set the same. This\nwas most likely due to the meta-signature encompassing more of the\nheterogeneity across different sources and conditions, while amplifying signal\nfrom the repeated global characteristics of the phenotype. When molecular\nsignatures of brain cancers were constructed from all currently available\nmicroarray data, 90 percent phenotype prediction accuracy, or the accuracy of\nidentifying a particular brain cancer from the background of all phenotypes,\nwas found. Looking forward, we discuss our approach in the context of the\neventual development of organ-specific molecular signatures from peripheral\nfluids such as the blood."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Efficient Bayesian-based Multi-View Deconvolution"}, {"role": "assistant", "content": "Light sheet fluorescence microscopy is able to image large specimen with high\nresolution by imaging the sam- ples from multiple angles. Multi-view\ndeconvolution can significantly improve the resolution and contrast of the\nimages, but its application has been limited due to the large size of the\ndatasets. Here we present a Bayesian- based derivation of multi-view\ndeconvolution that drastically improves the convergence time and provide a fast\nimplementation utilizing graphics hardware."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Proceedings of the 13th Workshop on Algorithms in Bioinformatics\n  (WABI2013)"}, {"role": "assistant", "content": "These are the proceedings of the 13th Workshop on Algorithms in\nBioinformatics, WABI2013, which was held September 2-4 2013 in Sophia\nAntipolis, France. All manuscripts were peer reviewed by the WABI2013 program\ncommittee and external reviewers."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Disease universe: Visualisation of population-wide disease-wide\n  associations"}, {"role": "assistant", "content": "We apply a force-directed spring embedding graph layout approach to\nelectronic health records in order to visualise population-wide associations\nbetween human disorders as presented in an individual biological organism. The\nintroduced visualisation is implemented on the basis of the Google maps\nplatform and can be found at http://disease-map.net . We argue that the\nsuggested method of visualisation can both validate already known specifics of\nassociations between disorders and identify novel never noticed association\npatterns."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Dynamic Metrics of Heart Rate Variability"}, {"role": "assistant", "content": "Numerous metrics of heart rate variability (HRV) have been described,\nanalyzed, and compared in the literature. However, they rarely cover the actual\nmetrics used in a class of HRV data acquisition devices - those designed\nprimarily to produce real-time metrics. This paper characterizes a class of\nmetrics that we term dynamic metrics. We also report the results of a pilot\nstudy which compares one such dynamic metric, based on photoplethysmographic\ndata using a moving sampling window set to the length of an estimated breath\ncycle (EBC), with established HRV metrics. The results show high correlation\ncoefficients between the dynamic EBC metrics and the established static SDNN\nmetric (standard deviation of Normal-to-Normal) based on electrocardiography.\nThese results demonstrate the usefulness of data acquisition devices designed\nfor real-time metrics."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Growth and form of melanoma cell colonies"}, {"role": "assistant", "content": "We study the statistical properties of melanoma cell colonies grown in vitro\nby analyzing the results of crystal violet assays at different concentrations\nof initial plated cells and for different growth times. The distribution of\ncolony sizes is described well by a continuous time branching process. To\ncharacterize the shape fluctuations of the colonies, we compute the\ndistribution of eccentricities. The experimental results are compared with\nnumerical results for models of random division of elastic cells, showing that\nexperimental results are best reproduced by restricting cell division to the\nouter rim of the colony. Our results serve to illustrate the wealth of\ninformation that can be extracted by a standard experimental method such as the\ncrystal violet assay."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Biological Averaging in RNA-Seq"}, {"role": "assistant", "content": "RNA-seq has become a de facto standard for measuring gene expression.\nTraditionally, RNA-seq experiments are mathematically averaged -- they sequence\nthe mRNA of individuals from different treatment groups, hoping to correlate\nphenotype with differences in arithmetic read count averages at shared loci of\ninterest. Alternatively, the tissue from the same individuals may be pooled\nprior to sequencing in what we refer to as a biologically averaged design. As\nmathematical averaging sequences all individuals it controls for both\nbiological and technical variation; however, is the statistical resolution\ngained always worth the additional cost? To compare biological and mathematical\naveraging, we examined theoretical and empirical estimates of statistical\nefficiency and relative cost efficiency. Though less efficient at a fixed\nsample size, we found that biological averaging can be more cost efficient than\nmathematical averaging. With this motivation, we developed a differential\nexpression classifier, ICRBC, that can detect alternatively expressed genes\nbetween biologically averaged samples. In simulation studies, we found that\nbiological averaging and subsequent analysis with our classifier performed\ncomparably to existing methods, such as ASC, edgeR, and DESeq, especially when\nindividuals were pooled evenly and less than 20% of the regulome was expected\nto be differentially regulated. In two technically distinct mouse datasets and\none plant dataset, we found that our method was over 87% concordant with edgeR\nfor the 100 most significant features. We therefore conclude biological\naveraging may sufficiently control biological variation to a level that\ndifferences in gene expression may be detectable. In such situations, ICRBC can\nenable reliable exploratory analysis at a fraction of the cost, especially when\ninterest lies in the most differentially expressed loci."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Piggy-backing protein domains with Formal Concept Analysis"}, {"role": "assistant", "content": "Identifying reliable domain-domain interactions (DDIs) will increase our\nability to predict novel protein-protein interactions (PPIs), to unravel\ninteractions in protein complexes, and thus gain more information about the\nfunction and behavior of genes. One of the challenges of identifying reliable\nDDIs is domain promiscuity. Promiscuous domains are domains that can occur in\nmany domain architectures and are therefore found in many proteins. This\nbecomes a problem for a method where the score of a domain-pair is the ratio\nbetween observed and expected frequencies because the PPI network is sparse. As\nsuch, many protein-pairs will be non-interacting and domain-pairs with\npromiscuous domains will be penalized. This domain promiscuity challenge to the\nproblem of inferring reliable DDIs from PPIs has been recognized, and a number\nof work-arounds have been proposed. In this paper, we report an application of\nFormal Concept Analysis (FCA) to this problem. We find that the relationship\nbetween formal concepts provide a natural way for rare domains to elevate the\nrank of promiscuous domains, and enrich highly ranked domain-pairs with\nreliable DDIs. This piggy-backing of promiscuous domains onto rare domains is\npossible due to the domain architecture of proteins which mixes promiscuous\nwith rare domains."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Dual-target function validation of single-particle selection from\n  low-contrast cryo-electron micrographs"}, {"role": "assistant", "content": "Weak-signal detection and single-particle selection from low-contrast\nmicrographs of frozen hydrated biomolecules by cryo-electron microscopy\n(cryo-EM) presents a practical challenge. Cryo-EM image contrast degrades as\nthe size of biomolecules of structural interest decreases. When the image\ncontrast falls into a range where the location or presence of single particles\nbecomes ambiguous, a need arises for objective computational approaches to\ndetect weak signal and to select and verify particles from these low-contrast\nmicrographs. Here we propose an objective validation scheme for low-contrast\nparticle selection using a combination of two different target functions. In an\nimplementation of this dual-target function (DTF) validation, a first target\nfunction of fast local correlation was used to select particles through\ntemplate matching, followed by signal validation through a second target\nfunction of maximum likelihood. By a systematic study of simulated data, we\nfound that such an implementation of DTF validation is capable of selecting and\nverifying particles from cryo-EM micrographs with a signal-to-noise ratio as\nlow as 0.002. Importantly, we demonstrated that DTF validation can robustly\nevade over-fitting or reference bias from the particle-picking template,\nallowing true signal to emerge from amidst heavy noise in an objective fashion.\nThe DTF approach allows efficient assembly of a large number of single-particle\ncryo-EM images of smaller biomolecules or specimens containing\ncontrast-degrading agents like detergents in a semi-automatic manner."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A biomarker based on gene expression indicates plant water status in\n  controlled and natural environments"}, {"role": "assistant", "content": "Plant or soil water status are required in many scientific fields to\nunderstand plant responses to drought. Because the transcriptomic response to\nabiotic conditions, such as water deficit, reflects plant water status, genomic\ntools could be used to develop a new type of molecular biomarker. Using the\nsunflower (Helianthus annuus L.) as a model species to study the transcriptomic\nresponse to water deficit both in greenhouse and field conditions, we\nspecifically identified three genes that showed an expression pattern highly\ncorrelated to plant water status as estimated by the pre-dawn leaf water\npotential, fraction of transpirable soil water, soil water content or fraction\nof total soil water in controlled conditions. We developed a generalized linear\nmodel to estimate these classical water status indicators from the expression\nlevels of the three selected genes under controlled conditions. This estimation\nwas independent of the four tested genotypes and the stage (pre- or\npost-flowering) of the plant. We further validated this gene expression\nbiomarker under field conditions for four genotypes in three different trials,\nover a large range of water status, and we were able to correct their\nexpression values for a large diurnal sampling period."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Understanding uncertainty in temperature effects on vector-borne\n  disease: A Bayesian approach"}, {"role": "assistant", "content": "Extrinsic environmental factors influence the distribution and population\ndynamics of many organisms, including insects that are of concern for human\nhealth and agriculture. This is particularly true for vector-borne infectious\ndiseases, like malaria, which is a major source of morbidity and mortality in\nhumans. Understanding the mechanistic links between environment and population\nprocesses for these diseases is key to predicting the consequences of climate\nchange on transmission and for developing effective interventions. An important\nmeasure of the intensity of disease transmission is the reproductive number\n$R_0$. However, understanding the mechanisms linking $R_0$ and temperature, an\nenvironmental factor driving disease risk, can be challenging because the data\navailable for parameterization are often poor. To address this we show how a\nBayesian approach can help identify critical uncertainties in components of\n$R_0$ and how this uncertainty is propagated into the estimate of $R_0$. Most\nnotably, we find that different parameters dominate the uncertainty at\ndifferent temperature regimes: bite rate from 15-25$^\\circ$ C; fecundity across\nall temperatures, but especially $\\sim$25-32$^\\circ$ C; mortality from\n20-30$^\\circ$ C; parasite development rate at $\\sim$15-16$^\\circ$C and again at\n$\\sim$33-35$^\\circ$C. Focusing empirical studies on these parameters and\ncorresponding temperature ranges would be the most efficient way to improve\nestimates of $R_0$. While we focus on malaria, our methods apply to improving\nprocess-based models more generally, including epidemiological, physiological\nniche, and species distribution models."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Protein signatures using electrostatic molecular surfaces in harmonic\n  space"}, {"role": "assistant", "content": "We developed a novel method based on the Fourier analysis of protein\nmolecular surfaces to speed up the analysis of the vast structural data\ngenerated in the post-genomic era. This method computes the power spectrum of\nsurfaces of the molecular electrostatic potential, whose three-dimensional\ncoordinates have been either experimentally or theoretically determined. Thus\nwe achieve a reduction of the initial three-dimensional information on the\nmolecular surface to the one-dimensional information on pairs of points at a\nfixed scale apart. Consequently, the similarity search in our method is\ncomputationally less demanding and significantly faster than shape comparison\nmethods. As proof of principle, we applied our method to a training set of\nviral proteins that are involved in major diseases such as Hepatitis C, Dengue\nfever, Yellow fever, Bovine viral diarrhea and West Nile fever. The training\nset contains proteins of four different protein families, as well as a\nmammalian representative enzyme. We found that the power spectrum successfully\nassigns a unique signature to each protein included in our training set, thus\nproviding a direct probe of functional similarity among proteins. The results\nagree with established biological data from conventional structural\nbiochemistry analyses."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Cellular decision-making bias: the missing ingredient in cell functional\n  diversity"}, {"role": "assistant", "content": "Cell functional diversity is a significant determinant on how biological\nprocesses unfold. Most accounts of diversity involve a search for sequence or\nexpression differences. Perhaps there are more subtle mechanisms at work. Using\nthe metaphor of information processing and decision-making might provide a\nclearer view of these subtleties. Understanding adaptive and transformative\nprocesses (such as cellular reprogramming) as a series of simple decisions\nallows us to use a technique called cellular signal detection theory (cellular\nSDT) to detect potential bias in mechanisms that favor one outcome over\nanother. We can apply method of detecting cellular reprogramming bias to\ncellular reprogramming and other complex molecular processes. To demonstrate\nscope of this method, we will critically examine differences between cell\nphenotypes reprogrammed to muscle fiber and neuron phenotypes. In cases where\nthe signature of phenotypic bias is cryptic, signatures of genomic bias\n(pre-existing and induced) may provide an alternative. The examination of these\nalternates will be explored using data from a series of fibroblast cell lines\nbefore cellular reprogramming (pre-existing) and differences between fractions\nof cellular RNA for individual genes after drug treatment (induced). In\nconclusion, the usefulness and limitations of this method and associated\nanalogies will be discussed."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Dynamical coupling during collective animal motion"}, {"role": "assistant", "content": "The measurement of information flows within moving animal groups has recently\nbeen a topic of considerable interest, and it has become clear that the\nindividual(s) that drive collective movement may change over time, and that\nsuch individuals may not necessarily always lead from the front. However,\nmethods to quantify the influence of specific individuals on the behaviour of\nother group members and the direction of information flow in moving group, are\nlacking on the level of empirical studies and theoretical models. Using high\nspatio-temporal resolution GPS trajectories of foraging meerkats, Suricata\nsuricatta, we provide an information-theoretic framework to identify dynamical\ncoupling between animals independent of their relative spatial positions. Based\non this identification, we then compare designations of individuals as either\ndrivers or responders against designations provided by the relative spatial\nposition. We find that not only does coupling occur both from the frontal to\nthe trailing individuals and vice versa, but also that the coupling direction\nis a non-linear function of the relative position. This provides evidence for\n(i) intermittent fluctuation of the coupling strength and (ii) alternation in\nthe coupling direction within foraging meerkat pairs. The framework we\nintroduce allows for a detailed description of the dynamical patterns of mutual\ninfluence between all pairs of individuals within moving animal groups. We\nargue that applying an information-theoretic perspective to the study of\ncoordinated phenomena in animal groups will eventually help to understand cause\nand effect in collective behaviour."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Understanding Health and Disease with Multidimensional Single-Cell\n  Methods"}, {"role": "assistant", "content": "Current efforts in the biomedical sciences and related interdisciplinary\nfields are focused on gaining a molecular understanding of health and disease,\nwhich is a problem of daunting complexity that spans many orders of magnitude\nin characteristic length scales, from small molecules that regulate cell\nfunction to cell ensembles that form tissues and organs working together as an\norganism. In order to uncover the molecular nature of the emergent properties\nof a cell, it is essential to measure multiple cell components simultaneously\nin the same cell. In turn, cell heterogeneity requires multiple cells to be\nmeasured in order to understand health and disease in the organism. This review\nsummarizes current efforts towards a data-driven framework that leverages\nsingle-cell technologies to build robust signatures of healthy and diseased\nphenotypes. While some approaches focus on multicolor flow cytometry data and\nother methods are designed to analyze high-content image-based screens, we\nemphasize the so-called Supercell/SVM paradigm (recently developed by the\nauthors of this review and collaborators) as a unified framework that captures\nmesoscopic-scale emergence to build reliable phenotypes. Beyond their specific\ncontributions to basic and translational biomedical research, these efforts\nillustrate, from a larger perspective, the powerful synergy that might be\nachieved from bringing together methods and ideas from statistical physics,\ndata mining, and mathematics to solve the most pressing problems currently\nfacing the life sciences."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Ending AIDS in South Africa: How long will it take? How much will it\n  cost?"}, {"role": "assistant", "content": "South Africa has more people infected with HIV but, by providing access to\nanti-retroviral therapy (ART), has kept more people alive than any other\ncountry. The effectiveness, availability and affordability of potent\nanti-retroviral therapy (ART) make it possible to contemplate ending the\nepidemic of HIV/AIDS. We consider what would have happened without ART, the\nimpact of the current roll-out of ART, what might be possible if early\ntreatment becomes available to all, and what could have happened if ART had\nbeen provided much earlier in the epidemic. In 2013 the provision of ART has\nreduced the prevalence of HIV from an estimated 15% to 9% among adults not on\nART, the annual incidence from 2% to 0.9%, and the AIDS related deaths from\n0.9% to 0.3% p.a. saving 1.5 million lives and USD727M. Regular testing and\nuniversal access to ART could reduce the prevalence among adults not on ART in\n2023 to 0.06%, annual incidence to 0.05%, and eliminate AIDS deaths. Cumulative\ncosts between 2013 ands 2023 would increase by USD692M only 4% of the total\ncost of USD17Bn. If a universal testing and early treatment had started in 1998\nthe prevalence of HIV among adults not on ART in 2013 would have fallen to\n0.03%, annual incidence to 0.03%, and saved 2.5 million lives. The cost up to\n2013 would have increased by USD18Bn but this would have been cost effective at\nUS$7,200 per life saved. Future surveys of HIV among women attending ante-natal\nclinics should include testing women for the presence of anti-retroviral drugs,\nmeasuring their viral loads, and using appropriate assays for estimating HIV\nincidence. These data would make it possible to develop better and more\nreliable estimates of the current state of the epidemic, the success of the\ncurrent ART programme, levels of viral load suppression for those on ART and\nthe incidence of infection."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Overshoot in biological systems modeled by Markov chains: a\n  nonequilibrium dynamic phenomenon"}, {"role": "assistant", "content": "A number of biological systems can be modeled by Markov chains. Recently,\nthere has been an increasing concern about when biological systems modeled by\nMarkov chains will perform a dynamic phenomenon called overshoot. In this\narticle, we found that the steady-state behavior of the system will have a\ngreat effect on the occurrence of overshoot. We confirmed that overshoot in\ngeneral cannot occur in systems which will finally approach an equilibrium\nsteady state. We further classified overshoot into two types, named as simple\novershoot and oscillating overshoot. We showed that except for extreme cases,\noscillating overshoot will occur if the system is far from equilibrium. All\nthese results clearly show that overshoot is a nonequilibrium dynamic\nphenomenon with energy consumption. In addition, the main result in this\narticle is validated with real experimental data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Experimental Design for Dynamics Identification of Cellular Processes"}, {"role": "assistant", "content": "We address the problem of using nonlinear models to design experiments to\ncharacterize the dynamics of cellular processes by using the approach of the\nMaximally Informative Next Experiment (MINE), which was introduced in [W. Dong,\net al. Systems biology of the clock in neurospora crassa. {\\em PLoS ONE}, page\ne3105, 2008] and independently in [M. M. Donahue, et al. Experiment design\nthrough dynamical characterization of non-linear systems biology models\nutilising sparse grids. {\\em IET System Biology}, 4:249--262, 2010]. In this\napproach, existing data is used to define a probability distribution on the\nparameters; the next measurement point is the one that yields the largest model\noutput variance with this distribution. Building upon this approach, we\nintroduce the Expected Dynamics Estimator (EDE), which is the expected value\nusing this distribution of the output as a function of time. We prove the\nconsistency of this estimator (uniform convergence to true dynamics) even when\nthe chosen experiments cluster in a finite set of points. We extend this proof\nof consistency to various practical assumptions on noisy data and moderate\nlevels of model mismatch. Through the derivation and proof, we develop a\nrelaxed version of MINE that is more computationally tractable and robust than\nthe original formulation. The results are illustrated with numerical examples\non two nonlinear ordinary differential equation models of biomolecular and\ncellular processes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Improved design and screening of high bioactivity peptides for drug\n  discovery"}, {"role": "assistant", "content": "The discovery of peptides having high biological activity is very challenging\nmainly because there is an enormous diversity of compounds and only a minority\nhave the desired properties. To lower cost and reduce the time to obtain\npromising compounds, machine learning approaches can greatly assist in the\nprocess and even replace expensive laboratory experiments by learning a\npredictor with existing data. Unfortunately, selecting ligands having the\ngreatest predicted bioactivity requires a prohibitive amount of computational\ntime. For this combinatorial problem, heuristics and stochastic optimization\nmethods are not guaranteed to find adequate compounds.\n  We propose an efficient algorithm based on De Bruijn graphs, guaranteed to\nfind the peptides of maximal predicted bioactivity. We demonstrate how this\nalgorithm can be part of an iterative combinatorial chemistry procedure to\nspeed up the discovery and the validation of peptide leads. Moreover, the\nproposed approach does not require the use of known ligands for the target\nprotein since it can leverage recent multi-target machine learning predictors\nwhere ligands for similar targets can serve as initial training data. Finally,\nwe validated the proposed approach in vitro with the discovery of new cationic\nanti-microbial peptides.\n  Source code is freely available at\nhttp://graal.ift.ulaval.ca/peptide-design/."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A fast and scalable kymograph alignment algorithm for nanochannel-based\n  optical DNA mappings"}, {"role": "assistant", "content": "Optical mapping by direct visualization of individual DNA molecules,\nstretched in nanochannels with sequence-specific fluorescent labeling,\nrepresents a promising tool for disease diagnostics and genomics. An important\nchallenge for this technique is thermal motion of the DNA as it undergoes\nimaging; this blurs fluorescent patterns along the DNA and results in\ninformation loss. Correcting for this effect (a process referred to as\nkymograph alignment) is a common preprocessing step in nanochannel-based\noptical mapping workflows, and we present here a highly efficient algorithm to\naccomplish this via pattern recognition. We compare our method with the one\nprevious approach, and we find that our method is orders of magnitude faster\nwhile producing data of similar quality. We demonstrate proof of principle of\nour approach on experimental data consisting of melt mapped bacteriophage DNA."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Cellphone based Portable Bacteria Pre-Concentrating microfluidic Sensor\n  and Impedance Sensing System"}, {"role": "assistant", "content": "Portable low-cost sensors and sensing systems for the identification and\nquantitative measurement of bacteria in field water are critical in preventing\ndrinking water from being contaminated by bacteria. In this article, we\nreported the design, fabrication and testing of a low-cost, miniaturized and\nsensitive bacteria sensor based on electrical impedance spectroscopy method\nusing a smartphone as the platform. Our design of microfluidics enabled the\npre-concentration of the bacteria which lowered the detection limit to 10\nbacterial cells per milliliter. We envision that our demonstrated\nsmartphone-based sensing system will realize highly-sensitive and rapid\nin-field quantification of multiple species of bacteria and pathogens."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Discovery of Proteomics based on Machine learning"}, {"role": "assistant", "content": "The ultimate target of proteomics identification is to identify and quantify\nthe protein in the organism. Mass spectrometry (MS) based on label-free protein\nquantitation has mainly focused on analysis of peptide spectral counts and ion\npeak heights. Using several observed peptides (proteotypic) can identify the\norigin protein. However, each peptide's possibility to be detected was severely\ninfluenced by the peptide physicochemical properties, which confounded the\nresults of MS accounting. Using about a million peptide identification\ngenerated by four different kinds of proteomic platforms, we successfully\nidentified >16,000 proteotypic peptides. We used machine learning\nclassification to derive peptide detection probabilities that are used to\npredict the number of trypic peptides to be observed, which can serve to\nestimate the absolutely abundance of protein with highly accuracy. We used the\ndata of peptides (provides by CAS lab) to derive the best model from different\nkinds of methods. We first employed SVM and Random Forest classifier to\nidentify the proteotypic and unobserved peptides, and then searched the best\nparameter for better prediction results. Considering the excellent performance\nof our model, we can calculate the absolutely estimation of protein abundance."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The jigsaw puzzle of sequence phenotype inference: Piecing together\n  Shannon entropy, importance sampling, and Empirical Bayes"}, {"role": "assistant", "content": "A nucleotide sequence 35 base pairs long can take\n1,180,591,620,717,411,303,424 possible values. An example of systems biology\ndatasets, protein binding microarrays, contain activity data from about 40000\nsuch sequences. The discrepancy between the number of possible configurations\nand the available activities is enormous. Thus, albeit that systems biology\ndatasets are large in absolute terms, they oftentimes require methods developed\nfor rare events due to the combinatorial increase in the number of possible\nconfigurations of biological systems. A plethora of techniques for handling\nlarge datasets, such as Empirical Bayes, or rare events, such as importance\nsampling, have been developed in the literature, but these cannot always be\nsimultaneously utilized. Here we introduce a principled approach to Empirical\nBayes based on importance sampling, information theory, and theoretical physics\nin the general context of sequence phenotype model induction. We present the\nanalytical calculations that underlie our approach. We demonstrate the\ncomputational efficiency of the approach on concrete examples, and demonstrate\nits efficacy by applying the theory to publicly available protein binding\nmicroarray transcription factor datasets and to data on synthetic\ncAMP-regulated enhancer sequences. As further demonstrations, we find\ntranscription factor binding motifs, predict the activity of new sequences and\nextract the locations of transcription factor binding sites. In summary, we\npresent a novel method that is efficient (requiring minimal computational time\nand reasonable amounts of memory), has high predictive power that is comparable\nwith that of models with hundreds of parameters, and has a limited number of\noptimized parameters, proportional to the sequence length."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Tortuosity Entropy: a measure of spatial complexity of behavioral\n  changes in animal movement data"}, {"role": "assistant", "content": "The goal of animal movement analysis is to understand how organisms explore\nand exploit the complex and varying environment. Animals usually exhibit varied\nand complicated movements, from apparently deterministic behaviors to highly\nrandom ones. This is critical for assessing movement efficiency and strategies\nthat are used to quantify and analyze movement trajectories. Here we introduce\na tortuosity entropy (TorEn) based on comparison of parameters, e.g. heading,\nbearing, speed, of consecutive points in movement trajectory, which is a simple\nmeasure for quantifying the behavioral change in animal movement data in a fine\nscale. In our approach, the differences between pairwise successive track\npoints are transformed inot symbolic sequences, then we map these symbols into\na group of pattern vectors and calculate the information entropy of pattern\nvector. Tortuosity entropy can be easily applied to arbitrary real-world\ndata-deterministic or stochastic, stationary or non-stationary. We test the\nalgorithm on both simulated trajectories and real trajectories and show that\nboth mixed segments in synthetic data and different phases in real movement\ndata are identified accurately. The results show that the algorithm is\napplicable to various situations, indicating that our approach is a promising\ntool to reveal the behavioral pattern in movement data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The discriminant power of RNA features for pre-miRNA recognition"}, {"role": "assistant", "content": "Computational discovery of microRNAs (miRNA) is based on pre-determined sets\nof features from miRNA precursors (pre-miRNA). These feature sets used by\ncurrent tools for pre-miRNA recognition differ in construction and dimension.\nSome feature sets are composed of sequence-structure patterns commonly found in\npre-miRNAs, while others are a combination of more sophisticated RNA features.\nCurrent tools achieve similar predictive performance even though the feature\nsets used - and their computational cost - differ widely. In this work, we\nanalyze the discriminant power of seven feature sets, which are used in six\npre-miRNA prediction tools. The analysis is based on the classification\nperformance achieved with these feature sets for the training algorithms used\nin these tools. We also evaluate feature discrimination through the F-score and\nfeature importance in the induction of random forests. More diverse feature\nsets produce classifiers with significantly higher classification performance\ncompared to feature sets composed only of sequence-structure patterns. However,\nsmall or non-significant differences were found among the estimated\nclassification performances of classifiers induced using sets with\ndiversification of features, despite the wide differences in their dimension.\nBased on these results, we applied a feature selection method to reduce the\ncomputational cost of computing the feature set, while maintaining discriminant\npower. We obtained a lower-dimensional feature set, which achieved a\nsensitivity of 90% and a specificity of 95%. Our feature set achieves a\nsensitivity and specificity within 0.1% of the maximal values obtained with any\nfeature set while it is 34x faster to compute. Even compared to another feature\nset, which is the computationally least expensive feature set of those from the\nliterature which perform within 0.1% of the maximal values, it is 34x faster to\ncompute."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Detection of the melanoma biomarker TROY using silicon nanowire\n  field-effect transistors"}, {"role": "assistant", "content": "Antibody-functionalized silicon nanowire field-effect transistors have been\nshown to exhibit excellent analyte detection sensitivity enabling sensing of\nanalyte concentrations at levels not readily accessible by other methods. One\nexample where accurate measurement of small concentrations is necessary is\ndetection of serum biomarkers, such as the recently discovered tumor necrosis\nfactor receptor superfamily member TROY (TNFRSF19), which may serve as a\nbiomarker for melanoma. TROY is normally only present in brain but it is\naberrantly expressed in primary and metastatic melanoma cells and shed into the\nsurrounding environment. In this study, we show the detection of different\nconcentrations of TROY in buffer solution using top-down fabricated silicon\nnanowires. We demonstrate the selectivity of our sensors by comparing the\nsignal with that obtained from bovine serum albumin in buffer solution. Both\nthe signal size and the reaction kinetics serve to distinguish the two signals.\nUsing a fast-mixing two-compartment reaction model, we are able to extract the\nassociation and dissociation rate constants for the reaction of TROY with the\nantibody immobilized on the sensor surface."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Stochastic Model for Tumor Control Probability: Effects of Cell Cycle\n  and (A)symmetric Proliferation"}, {"role": "assistant", "content": "Estimating the required dose in radiotherapy is of crucial importance since\nthe administrated dose should be sufficient to eradicate the tumor and at the\nsame time should inflict minimal damage on normal cells. The probability that a\ngiven dose and schedule of ionizing radiation eradicates all the tumor cells in\na given tissue is called the tumor control probability (TCP), and is often used\nto compare various treatment strategies used in radiation therapy. In this\npaper, we aim to investigate the effects of including cell-cycle phase on the\nTCP by analyzing a stochastic model of a tumor comprised of actively dividing\ncells and quiescent cells with different radiation sensitivities. We derive an\nexact phase-diagram for the steady-state TCP of the model and show that at\nhigh, clinically-relevant doses of radiation, the distinction between active\nand quiescent tumor cells (i.e. accounting for cell-cycle effects) becomes of\nnegligible importance in terms of its effect on the TCP curve. However, for\nvery low doses of radiation, these proportions become significant determinants\nof the TCP. Moreover, we use a novel numerical approach based on the method of\ncharacteristics for partial differential equations, validated by the Gillespie\nalgorithm, to compute the TCP as a function of time. We observe that our\nresults differ from the results in the literature using similar existing\nmodels, even though similar parameters values are used, and the reasons for\nthis are discussed."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Covariance in protein multiple sequence alignments using groups of\n  columns"}, {"role": "assistant", "content": "Algorithms that detect covariance between pairs of columns in multiple\nsequence alignments are commonly employed to predict functionally important\nresidues and structural contacts. However, the assumption that co-variance only\noccurs between individual residues in the protein is more driven by\ncomputational convenience rather than fundamental protein architecture. Here we\ndevelop a novel algorithm that defines a covariance score across two groups of\ncolumns where each group represents a stretch of contiguous columns in the\nalignment. We define a test set that consists of secondary structure elements\n({\\alpha}-helixes and {\\beta}-strands) across more than 1,100 PFAM families.\nUsing these alignments to predict segments that are physically close in\nstructure, we show that our method substantially out-performs approaches that\naggregate the results of algorithms that operate on individual column pairs.\nOur approach demonstrates that considering units of proteins beyond pairs of\ncolumns can improve the power and utility of covariance algorithms."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Field Effect Transistor Nanosensor for Breast Cancer Diagnostics"}, {"role": "assistant", "content": "Silicon nanochannel field effect transistor (FET) biosensors are one of the\nmost promising technologies in the development of highly sensitive and\nlabel-free analyte detection for cancer diagnostics. With their exceptional\nelectrical properties and small dimensions, silicon nanochannels are ideally\nsuited for extraordinarily high sensitivity. In fact, the high\nsurface-to-volume ratios of these systems make single molecule detection\npossible. Further, FET biosensors offer the benefits of high speed, low cost,\nand high yield manufacturing, without sacrificing the sensitivity typical for\ntraditional optical methods in diagnostics. Top down manufacturing methods\nleverage advantages in Complementary Metal Oxide Semiconductor (CMOS)\ntechnologies, making richly multiplexed sensor arrays a reality. Here, we\ndiscuss the fabrication and use of silicon nanochannel FET devices as\nbiosensors for breast cancer diagnosis and monitoring."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Uncovering low-dimensional, miR-based signatures of acute myeloid and\n  lymphoblastic leukemias with a machine-learning-driven network approach"}, {"role": "assistant", "content": "Complex phenotypic differences among different acute leukemias cannot be\nfully captured by analyzing the expression levels of one single molecule, such\nas a miR, at a time, but requires systematic analysis of large sets of miRs.\nWhile a popular approach for analysis of such datasets is principal component\nanalysis (PCA), this method is not designed to optimally discriminate different\nphenotypes. Moreover, PCA and other low-dimensional representation methods\nyield linear or non-linear combinations of all measured miRs. Global human miR\nexpression was measured in AML, B-ALL, and T-ALL cell lines and patient RNA\nsamples. By systematically applying support vector machines to all measured\nmiRs taken in dyad and triad groups, we built miR networks using cell line data\nand validated our findings with primary patient samples. All the coordinately\ntranscribed members of the miR-23a cluster (which includes also miR-24 and\nmiR-27a), known to function as tumor suppressors of acute leukemias, appeared\nin the AML, B-ALL and T-ALL centric networks. Subsequent qRT-PCR analysis\nshowed that the most connected miR in the B-ALL-centric network, miR-708, is\nhighly and specifically expressed in B-ALLs, suggesting that miR-708 might\nserve as a biomarker for B-ALL. This approach is systematic, quantitative,\nscalable, and unbiased. Rather than a single signature, our approach yields a\nnetwork of signatures reflecting the redundant nature of biological signaling\npathways. The network representation allows for visual analysis of all\nsignatures by an expert and for future integration of additional information.\nFurthermore, each signature involves only small sets of miRs, such as dyads and\ntriads, which are well suited for in depth validation through laboratory\nexperiments such as loss- and gain-of-function assays designed to drive changes\nin leukemia cell survival, proliferation and differentiation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Combined therapies of antithrombotics and antioxidants delay in silico\n  brain tumor progression"}, {"role": "assistant", "content": "Glioblastoma multiforme, the most frequent type of primary brain tumor, is a\nrapidly evolving and spatially heterogeneous high-grade astrocytoma that\npresents areas of necrosis, hypercellularity and microvascular hyperplasia. The\naberrant vasculature leads to hypoxic areas and results in an increase of the\noxidative stress selecting for more invasive tumor cell phenotypes. In our\nstudy we assay in silico different therapeutic approaches which combine\nantithrombotics, antioxidants and standard radiotherapy. To do so, we have\ndeveloped a biocomputational model of glioblastoma multiforme that incorporates\nthe spatio-temporal interplay among two glioma cell phenotypes corresponding to\noxygenated and hypoxic cells, a necrotic core and the local vasculature whose\nresponse evolves with tumor progression. Our numerical simulations predict that\nsuitable combinations of antithrombotics and antioxidants may diminish, in a\nsynergetic way, oxidative stress and the subsequent hypoxic response. This\nnovel therapeutical strategy, with potentially low or no toxicity, might reduce\ntumor invasion and further sensitize glioblastoma multiforme to conventional\nradiotherapy or other cytotoxic agents, hopefully increasing median patient\noverall survival time."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Effective Particle Methods for Fisher-Kolmogorov Equations: Theory and\n  Applications to Brain Tumor Dynamics"}, {"role": "assistant", "content": "Extended systems governed by partial differential equations can, under\nsuitable conditions, be approximated by means of sets of ordinary differential\nequations for global quantities capturing the essential features of the systems\ndynamics. Here we obtain a small number of effective equations describing the\ndynamics of single-front and localized solutions of Fisher-Kolmogorov type\nequations. These solutions are parametrized by means of a minimal set of\ntime-dependent quantities for which ordinary differential equations ruling\ntheir dynamics are found. A comparison of the finite dimensional equations and\nthe dynamics of the full partial differential equation is made showing a very\ngood quantitative agreement with the dynamics of the partial differential\nequation. We also discuss some implications of our findings for the\nunderstanding of the growth progression of certain types of primary brain\ntumors and discuss possible extensions of our results to related equations\narising in different modelling scenarios."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Delay effects in the response of low grade gliomas to radiotherapy: A\n  mathematical model and its therapeutical implications"}, {"role": "assistant", "content": "Low grade gliomas (LGGs) are a group of primary brain tumors usually\nencountered in young patient populations. These tumors represent a difficult\nchallenge because many patients survive a decade or more and may be at a higher\nrisk for treatment-related complications. Specifically, radiation therapy is\nknown to have a relevant effect on survival but in many cases it can be\ndeferred to avoid side effects while maintaining its beneficial effect.\nHowever, a subset of low-grade gliomas manifests more aggressive clinical\nbehavior and requires earlier intervention. Moreover, the effectiveness of\nradiotherapy depends on the tumor characteristics. Recently Pallud et al.,\n[Neuro-oncology, 14(4):1-10, 2012], studied patients with LGGs treated with\nradiation therapy as a first line therapy. and found the counterintuitive\nresult that tumors with a fast response to the therapy had a worse prognosis\nthan those responding late. In this paper we construct a mathematical model\ndescribing the basic facts of glioma progression and response to radiotherapy.\nThe model provides also an explanation to the observations of Pallud et al.\nUsing the model we propose radiation fractionation schemes that might be\ntherapeutically useful by helping to evaluate the tumor malignancy while at the\nsame time reducing the toxicity associated to the treatment."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Numerical Solution of the Model for HIV Infection of Cd4+T Cells by\n  Using Multistage Differential Transform Method"}, {"role": "assistant", "content": "The Multistage Differential Transform Method (MDTM) is employed to solve the\nmodel for HIV infection of CD4+T cells. Comparing the numerical results to\nthose obtained by the classical fourth order Runge-Kutta method showed the\npreciseness and efficacy of the multistep differential transform method. The\nstudy shows that the method is a powerful and promising tool for solving\ncoupled systems of differential equations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Sparse Learning of Markovian Population Models in Random Environments"}, {"role": "assistant", "content": "Markovian population models are suitable abstractions to describe well-mixed\ninteracting particle systems in situation where stochastic fluctuations are\nsignificant due to the involvement of low copy particles. In molecular biology,\nmeasurements on the single-cell level attest to this stochasticity and one is\ntempted to interpret such measurements across an isogenic cell population as\ndifferent sample paths of one and the same Markov model. Over recent years\nevidence built up against this interpretation due to the presence of\ncell-to-cell variability stemming from factors other than intrinsic\nfluctuations. To account for this extrinsic variability, Markovian models in\nrandom environments need to be considered and a key emerging question is how to\nperform inference for such models. We model extrinsic variability by a random\nparametrization of all propensity functions. To detect which of those\npropensities have significant variability, we lay out a sparse learning\nprocedure captured by a hierarchical Bayesian model whose evidence function is\niteratively maximized using a variational Bayesian expectation-maximization\nalgorithm."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: An Exploration of Physiological Responses to the Native American Flute"}, {"role": "assistant", "content": "This pilot study explored physiological responses to playing and listening to\nthe Native American flute. Autonomic, electroencephalographic (EEG), and heart\nrate variability (HRV) metrics were recorded while participants (N = 15) played\nflutes and listened to several styles of music. Flute playing was accompanied\nby an 84% increase in HRV (p < .001). EEG theta (4-8 Hz) activity increased\nwhile playing flutes (p = .007) and alpha (8-12 Hz) increased while playing\nlower-pitched flutes (p = .009). Increase in alpha from baseline to the flute\nplaying conditions strongly correlated with experience playing Native American\nflutes (r = +.700). Wide-band beta (12-25 Hz) decreased from the silence\nconditions when listening to solo Native American flute music (p = .013). The\nfindings of increased HRV, increasing slow-wave rhythms, and decreased beta\nsupport the hypothesis that Native American flutes, particularly those with\nlower pitches, may have a role in music therapy contexts. We conclude that the\nNative American flute may merit a more prominent role in music therapy and that\na study of the effects of flute playing on clinical conditions, such as\npost-traumatic stress disorder (PTSD), asthma, chronic obstructive pulmonary\ndisease (COPD), hypertension, anxiety, and major depressive disorder, is\nwarranted."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Predicting the Next Maxima Incidents of the Seasonally Forced SEIR\n  Epidemic Model"}, {"role": "assistant", "content": "This paper aims at predicting the next maxima values of the state variables\nof the seasonal SEIR epidemic model and their in-between time intervals.\nLorenz's method of analogues is applied on the attractor formed by the maxima\nof the corresponding state variables. It is found that both quantities are\ncharacterized by a high degree of predictability in the case of the chaotic\nregime of the parameter space."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A generalized residual technique for analyzing complex movement models\n  using earth mover's distance"}, {"role": "assistant", "content": "1. Complex systems of moving and interacting objects are ubiquitous in the\nnatural and social sciences. Predicting their behavior often requires models\nthat mimic these systems with sufficient accuracy, while accounting for their\ninherent stochasticity. Though tools exist to determine which of a set of\ncandidate models is best relative to the others, there is currently no generic\ngoodness-of-fit framework for testing how close the best model is to the real\ncomplex stochastic system.\n  2. We propose such a framework, using a novel application of the Earth\nmover's distance, also known as the Wasserstein metric. It is applicable to any\nstochastic process where the probability of the model's state at time $t$ is a\nfunction of the state at previous times. It generalizes the concept of a\nresidual, often used to analyze 1D summary statistics, to situations where the\ncomplexity of the underlying model's probability distribution makes standard\nresidual analysis too imprecise for practical use.\n  3. We give a scheme for testing the hypothesis that a model is an accurate\ndescription of a data set. We demonstrate the tractability and usefulness of\nour approach by application to animal movement models in complex, heterogeneous\nenvironments. We detail methods for visualizing results and extracting a\nvariety of information on a given model's quality, such as whether there is any\ninherent bias in the model, or in which situations it is most accurate. We\ndemonstrate our techniques by application to data on multi-species flocks of\ninsectivore birds in the Amazon rainforest.\n  4. This work provides a usable toolkit to assess the quality of generic\nmovement models of complex systems, in an absolute rather than a relative\nsense."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Hypercomplex cross-correlation of DNA sequences"}, {"role": "assistant", "content": "A hypercomplex representation of DNA is proposed to facilitate comparing DNA\nsequences with fuzzy composition. With the hypercomplex number representation,\nthe conventional sequence analysis method, such as, dot matrix analysis,\ndynamic programming, and cross-correlation method have been extended and\nimproved to align DNA sequences with fuzzy composition. The hypercomplex dot\nmatrix analysis can provide more control over the degree of alignment desired.\nA new scoring system has been proposed to accommodate the hypercomplex number\nrepresentation of DNA and integrated with dynamic programming alignment method.\nBy using hypercomplex cross-correlation, the match and mismatch alignment\ninformation between two aligned DNA sequences are separately stored in the\nresultant real part and imaginary parts respectively. The mismatch alignment\ninformation is very useful to refine consensus sequence based motif scanning."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A statistical thin-tail test of predicting regulatory regions in the\n  Drosophila genome"}, {"role": "assistant", "content": "Background: The identification of transcription factor binding sites (TFBSs)\nand cis-regulatory modules (CRMs) is a crucial step in studying gene\nexpression, but the computational method attempting to distinguish CRMs from\nNCNRs still remains a challenging problem due to the limited knowledge of\nspecific interactions involved. Methods: The statistical properties of\ncis-regulatory modules (CRMs) are explored by estimating the similar-word set\ndistribution with overrepresentation (Z-score). It is observed that CRMs tend\nto have a thin-tail Z-score distribution. A new statistical thin-tail test with\ntwo thinness coefficients is proposed to distinguish CRMs from non-coding\nnon-regulatory regions (NCNRs). Results: As compared with the existing\nfluffy-tail test, the first thinness coefficient is designed to reduce\ncomputational time, making the novel thin-tail test very suitable for long\nsequences and large database analysis in the post-genome time and the second\none to improve the separation accuracy between CRMs and NCNRs. These two\nthinness coefficients may serve as valuable filtering indexes to predict CRMs\nexperimentally. Conclusions: The novel thin-tail test provides an efficient and\neffective means for distinguishing CRMs from NCNRs based on the specific\nstatistical properties of CRMs and can guide future experiments aimed at\nfinding new CRMs in the post-genome time."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Unsuspected implications arising from assumptions in simulations:\n  insights from recasting a forest growth model in system dynamics"}, {"role": "assistant", "content": "Familiarity with a simulation platform can seduce modellers into accepting\nuntested assumptions for convenience of implementation. These assumptions may\nhave consequences greater than commonly suspected, and it is important that\nmodellers remain mindful of assumptions and remain diligent with sensitivity\ntesting. Familiarity with a technique can lead to complacency, and alternative\napproaches and software can reveal untested assumptions. Visual modelling\nenvironments based on system dynamics may help to make critical assumptions\nmore evident by offering an accessible visual overview and empowering a focus\non representational rather than computational efficiency. This capacity is\nillustrated using a cohort-based forest growth model developed for mixed\nspecies forest. The alternative model implementation revealed that untested\nassumptions in the original model could have substantial influence on simulated\noutcomes. An important implication is that modellers should remain conscious of\nall assumptions, consider alternative implementations that reveal assumptions\nmore clearly, and conduct sensitivity tests to inform decisions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Stephenson et al.'s ecological fallacy"}, {"role": "assistant", "content": "After more than a century of research the typical growth pattern of a tree\nwas thought to be fairly well understood. Following germination height growth\naccelerates for some time, then increment peaks and the added height each year\nbecomes less and less. The cross sectional area (basal area) of the tree\nfollows a similar pattern, but the maximum basal area increment occurs at some\ntime after the maximum height increment. An increase in basal area in a tall\ntree will add more volume to the stem than the same increase in a short tree,\nso the increment in stem volume (or mass) peaks very late. Stephenson et al.\nchallenge this paradigm, and suggest that mass increment increases\ncontinuously. Their analysis methods however are a textbook example of the\necological fallacy, and their conclusions therefore unsupported."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Distinction between the Preneoplastic and Neoplastic State of Murine\n  Mammary Glands by spin-echo NMR"}, {"role": "assistant", "content": "We have, using spin-echo nuclear magnetic resonance spectroscopy, measured\nthe relaxation times and diffusion coefficient of water protons in primary\nmammary adenocarcinomas of mice. In our biological model, three morphological\nstages were defined: (a) mammary gland tissue from pregnant mice, (b)\npreneoplastic nodules, and (c) neoplastic tissue. It was found that neoplastic\ntissues could be distinguished from normal and prenoeplastic tissue. Spin-spin\nand spin-lattice relaxation times and the diffusion coefficient of water\nprotons are increased in the neoplastic tissue relative to mammary gland tissue\nfrom pregnant mice and preneoplastic nodule tissue. These results suggested\nthat one can use a pulsed NMR method to detect and even predict breast cancer."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Shape Optimization of Compliant Pressure Actuated Cellular Structures"}, {"role": "assistant", "content": "Biologically inspired pressure actuated cellular structures can alter their\nshape through pressure variations. Previous work introduced a computational\nframework for pressure actuated cellular structures which was limited to two\ncell rows and central cell corner hinges. This article rigorously extends these\nresults by taking into account an arbitrary number of cell rows, a more\ncomplicated cell kinematics that includes hinge eccentricities and varying side\nlengths as well as rotational and axial cell side springs. The nonlinear\neffects of arbitrary cell deformations are fully considered. Furthermore, the\noptimization is considerably improved by using a second-order approach. The\npresented framework enables the design of compliant pressure actuated cellular\nstructures that can change their form from one shape to another within a set of\none-dimensional C1 continuous functions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Principal component gene set enrichment (PCGSE)"}, {"role": "assistant", "content": "Motivation: Although principal component analysis (PCA) is widely used for\nthe dimensional reduction of biomedical data, interpretation of PCA results\nremains daunting. Most existing methods attempt to explain each principal\ncomponent (PC) in terms of a small number of variables by generating\napproximate PCs with few non-zero loadings. Although useful when just a few\nvariables dominate the population PCs, these methods are often inadequate for\ncharacterizing the PCs of high-dimensional genomic data. For genomic data,\nreproducible and biologically meaningful PC interpretation requires methods\nbased on the combined signal of functionally related sets of genes. While gene\nset testing methods have been widely used in supervised settings to quantify\nthe association of groups of genes with clinical outcomes, these methods have\nseen only limited application for testing the enrichment of gene sets relative\nto sample PCs. Results: We describe a novel approach, principal component gene\nset enrichment (PCGSE), for computing the statistical association between gene\nsets and the PCs of genomic data. The PCGSE method performs a two-stage\ncompetitive gene set test using the correlation between each gene and each PC\nas the gene-level test statistic with flexible choice of both the gene set test\nstatistic and the method used to compute the null distribution of the gene set\nstatistic. Using simulated data with simulated gene sets and real gene\nexpression data with curated gene sets, we demonstrate that biologically\nmeaningful and computationally efficient results can be obtained from a simple\nparametric version of the PCGSE method that performs a correlation-adjusted\ntwo-sample t-test between the gene-level test statistics for gene set members\nand genes not in the set. Availability:\nhttp://cran.r-project.org/web/packages/PCGSE/index.html Contact:\nrob.frost@dartmouth.edu or jason.h.moore@dartmouth.edu"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Ending AIDS in Gabon: How long will it take? How much will it cost?"}, {"role": "assistant", "content": "The prevalence of HIV in West Africa is lower than elsewhere in Africa but\nGabon has one of the highest rates of HIV in that region. Gabon has a small\npopulation and a high per capita gross domestic product making it an ideal\nplace to carry out a programme of early treatment for HIV. The effectiveness,\navailability and affordability of triple combination therapy make it possible\nto contemplate ending AIDS deaths and HIV transmission in the short term and\nHIV prevalence in the long term. Here we consider what would have happened in\nGabon without the development of potent anti-retroviral therapy (ART), the\nimpact that the current roll-out of ART has had on HIV, and what might be\npossible if early treatment with ART becomes available to all. We fit a dynamic\ntransmission model to trends in the adult prevalence of HIV and infer trends in\nincidence, mortality and the impact of ART. The availability of ART has reduced\nthe prevalence of HIV among adults not on ART from 4.2% to 2.9%, annual\nincidence from 0.43% to 0.27%, and the proportion of adults dying from AIDS\nillnesses each year from 0.36% to 0.13% saving the lives of 2.3 thousand people\nin 2013 alone. The provision of ART has been highly cost effective saving the\ncountry at least $18 million up to 2013."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Elimination of HIV in South Africa through expanded access to\n  antiretroviral therapy: Cautions, caveats and the importance of parsimony"}, {"role": "assistant", "content": "In a recent article Hontelez and colleagues investigate the prospects for\nelimination of HIV in South Africa through expanded access to antiretroviral\ntherapy (ART) using STDSIM, a micro-simulation model. One of the first\npublished models to suggest that expanded access to ART could lead to the\nelimination of HIV, referred to by the authors as the Granich Model, was\ndeveloped and implemented by the present author. The notion that expanded\naccess to ART could lead to the end of the AIDS epidemic gave rise to\nconsiderable interest and debate and remains contentious. In considering this\nnotion Hontelez et al. start by stripping down STDSIM to a simple model that is\nequivalent to the model developed by the present author3 but is a stochastic\nevent driven model. Hontelez and colleagues then reintroduce levels of\ncomplexity to explore ways in which the model structure affects the results. In\ncontrast to our earlier conclusions Hontelez and colleagues conclude that\nuniversal voluntary counselling and testing with immediate ART at 90% coverage\nshould result in the elimination of HIV but would take three times longer than\npredicted by the model developed by the present author. Hontelez et al. suggest\nthat the current scale-up of ART at CD4 cell counts less than 350 cells/microL\nwill lead to elimination of HIV in 30 years. I disagree with both claims and\nbelieve that their more complex models rely on unwarranted and unsubstantiated\nassumptions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: multiDimBio: An R Package for the Design, Analysis, and Visualization of\n  Systems Biology Experiments"}, {"role": "assistant", "content": "The past decade has witnessed a dramatic increase in the size and scope of\nbiological and behavioral experiments. These experiments are providing an\nunprecedented level of detail and depth of data. However, this increase in data\npresents substantial statistical and graphical hurdles to overcome, namely how\nto distinguish signal from noise and how to visualize multidimensional results.\nHere we present a series of tools designed to support a research project from\ninception to publication. We provide implementation of dimension reduction\ntechniques and visualizations that function well with the types of data often\nseen in animal behavior studies. This package is designed to be used with\nexperimental data but can also be used for experimental design and sample\njustification. The goal for this project is to create a package that will\nevolve over time, thereby remaining relevant and reflective of current methods\nand techniques."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Bayesian Approach to Optimizing Stem Cell Cryopreservation protocols"}, {"role": "assistant", "content": "Cryopreservation is beset with the challenge of protocol alignment across a\nwide range of cell types and process variables. By taking a cross-sectional\nassessment of previously published cryopreservation data (sample means and\nstandard errors) as preliminary meta-data, a decision tree learning analysis\n(DTLA) was performed to develop an understanding of target survival and\noptimized pruning methods based on different approaches. Briefly, a clear\ndirection on the decision process for selection of methods was developed with\nkey choices being the cooling rate, plunge temperature on the one hand and\nbiomaterial choice, use of composites (sugars and proteins), loading procedure\nand cell location in 3D scaffold on the other. Secondly, using machine learning\nand generalized approaches via the Na\\\"ive Bayes Classification (NBC) approach,\nthese metadata were used to develop posterior probabilities for combinatorial\napproaches that were implicitly recorded in the metadata. These latter results\nshowed that newer protocol choices developed using probability elicitation\ntechniques can unearth improved protocols consistent with multiple\nunidimensional optimized physical protocols. In conclusion, this article\nproposes the use of DTLA models and subsequently NBC for the improvement of\nmodern cryopreservation techniques through an integrative approach.\n  Keywords: 3D cryopreservation, decision-tree learning (DTL), sugars, mouse\nembryonic stem cells, meta-data, Na\\\"ive Bayes Classifier (NBC)"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Dealing with complexity of biological systems: from data to models"}, {"role": "assistant", "content": "Four chapters of the synthesis represent four major areas of my research\ninterests: 1) data analysis in molecular biology, 2) mathematical modeling of\nbiological networks, 3) genome evolution, and 4) cancer systems biology. The\nfirst chapter is devoted to my work in developing non-linear methods of\ndimension reduction (methods of elastic maps and principal trees) which extends\nthe classical method of principal components. Also I present application of\nmatrix factorization techniques to analysis of cancer data. The second chapter\nis devoted to the complexity of mathematical models in molecular biology. I\ndescribe the basic ideas of asymptotology of chemical reaction networks aiming\nat dissecting and simplifying complex chemical kinetics models. Two\napplications of this approach are presented: to modeling NFkB and apoptosis\npathways, and to modeling mechanisms of miRNA action on protein translation.\nThe third chapter briefly describes my investigations of the genome structure\nin different organisms (from microbes to human cancer genomes). Unsupervised\ndata analysis approaches are used to investigate the patterns in genomic\nsequences shaped by genome evolution and influenced by the basic properties of\nthe environment. The fourth chapter summarizes my experience in studying cancer\nby computational methods (through combining integrative data analysis and\nmathematical modeling approaches). In particular, I describe the on-going\nresearch projects such as mathematical modeling of cell fate decisions and\nsynthetic lethal interactions in DNA repair network. The synthesis is concluded\nby listing major challenges in computational systems biology, connected to the\ntopics of this text, i.e. dealing with complexity of biological systems."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A rapid molecular approach to determining the occurrence of pathogen\n  indicators in compost"}, {"role": "assistant", "content": "An accurate method for enumerating pathogen indicators, such as Escherichia\ncoli (E. coli), and Salmonella spp. is important for assessing the safety of\ncompost samples. This study aimed to determine the occurrence of pathogen\nindicators in compost samples by using a molecular approach known as Polymerase\nChain Reaction (PCR). The DNA sample was extracted from sewage sludge compost.\nThe specificity of the probes and primers at the species level were verified by\nperforming NCBI-BLAST2 (Basic Local Alignment Search Tool). Primers that target\nthe gadAB gene for E.coli and invA gene for Salmonella spp. were selected which\nproduce fragment lengths around 670bp and 285bp respectively. The primers were\ntested against bacterial cultures of both species and produced a strong signal\nband of the expected fragment length. It provided results within 6 hours which\nis relatively rapid compared to conventional culturing techniques. The other\nadvantages of PCR are shown to be its high sensitivity, and high specificity."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Enumeration of Salmonella in compost material by a non-culture based\n  method"}, {"role": "assistant", "content": "Accurate enumeration of Salmonella spp. is important for assessing whether\nthis pathogen has survived composting. Recent literature has reported that\nenumeration of Salmonella spp. using standard microbiological methods has a\nnumbers of disadvantages, particularly the time taken to obtain a result. This\nresearch is an attempt to develop a rapid, low-cost detection method that is\nquantitative, highly sensitive and target specific. This paper reports the\ndevelopment of a DNA fragment that can be used to quantify Salmonella spp. by\ncompetitive polymerase chain reaction (cPCR) targeted at the invA gene of\nSalmonella (PCR primers that target the invA gene are reported to have very\nhigh specificity for Salmonella strains). It is shown that cPCR, which could be\ncompleted in 5 hours, could quantify the number of copies of the Salmonella\ninvA gene in a sample solution."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The Process and Pathogen Behavior in Composting: A Review"}, {"role": "assistant", "content": "Composting is defined as the biological decomposition and stabilization of\norganic substrates under aerobic conditions to allow the development of\nthermophilic temperatures. This thermophilic temperature is a result of\nbiologically produced heat. Composting produces the final product which is\nsufficiently stable for storage and application to land without adverse\nenvironmental effects. There are many factors which affect the decomposition of\norganic matter in the composting process. Since the composting process is very\nintricate, it is not easy to estimate the effect of a single factor on the rate\nof organic matter decomposition. This paper looked at the main factors\naffecting the composting process. Problems regarding the controlling,\ninactivation and regrowth of pathogen in compost material are also discussed."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Survival of Salmonella spp. in Composting using Vial and Direct\n  Inoculums Technique"}, {"role": "assistant", "content": "The survival of Salmonella spp. as pathogen indicator in composting was\nstudied. The inoculums technique was used to gives the known amounts of\nSalmonella spp. involved in composting. The inoculums of Salmonella spp.\nsolution was added directly into the compost material. The direct inoculum was\ncompared with inoculums in vial technique. The Salmonella spp. solution placed\ninto a vial and inserted into the middle of compost material before starting\nthe composting process. The conventional method that is used for the\nenumeration of Salmonella spp. is serial dilution followed by standard membrane\nfiltration as recommended in the compost quality standard method PAS 100 and\nthe British Standard (BS EN ISO 6579:2002). This study was designed to\ninvestigate the relationship of temperature and contact material that may also\ninvolve in pathogen activation specifically to Salmonella spp. The exposure to\nan average temperature during composting of about 55-60{\\deg}C was kept for at\nleast 3 days as it was reported sufficiently kills the vast majority of enteric\npathogen (Deportes et al., 1995). The amount of Salmonella spp. and temperature\nfor both samples was set as indicator to determine the survival of Salmonella\nspp. in direct and non-direct inoculums. This study gives the figures of\ndie-off rate for Salmonella spp. during composting. The differentiation between\ndirect contact (Sample A) and non-contact of Salmonella spp. with compost\nmaterial (Sample B) during composting was also revealed. The results from\nlaboratory scale of composting study has been showed that after 8 days (which\nincluded at least at 66{\\deg}C) the numbers of Salmonella spp. in Sample A were\nbelow the limits in UK compost standard (known as PAS 100)(BSI, 2005) which\nrequired the compost to be free of Salmonella spp. Meanwhile, Sample B still\ngives high amount of Salmonella spp. in even after composting for 20 days."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: For principled model fitting in mathematical biology"}, {"role": "assistant", "content": "The mathematical models used to capture features of complex, biological\nsystems are typically non-linear, meaning that there are no generally valid\nsimple relationships between their outputs and the data that might be used to\nvalidate them. This invalidates the assumptions behind standard statistical\nmethods such as linear regression, and often the methods used to parameterise\nbiological models from data are ad hoc. In this perspective, I will argue for\nan approach to model fitting in mathematical biology that incorporates modern\nstatistical methodology without losing the insights gained through non-linear\ndynamic models, and will call such an approach principled model fitting.\nPrincipled model fitting therefore involves defining likelihoods of observing\nreal data on the basis of models that capture key biological mechanisms."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Tipping Elements in the Human Intestinal Ecosystem"}, {"role": "assistant", "content": "Recent studies show that the microbial communities inhabiting the human\nintestine can have profound impact on our well-being and health. However, we\nhave limited understanding of the mechanisms that control this complex\necosystem. Based on a deep phylogenetic analysis of the intestinal microbiota\nin a thousand western adults we identified groups of bacteria that tend to be\neither nearly absent, or abundant in most individuals. The abundances of these\nbimodally distributed bacteria vary independently, and their contrasting\nalternative states are associated with host factors such as ageing and\noverweight. We propose that such bimodal groups represent independent tipping\nelements of the intestinal microbiota. These reflect the overall state of the\nintestinal ecosystem whose critical transitions can have profound health\nimplications and diagnostic potential."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Estimating binding properties of transcription factors from genome-wide\n  binding profiles"}, {"role": "assistant", "content": "The binding of transcription factors (TFs) is essential for gene expression.\nOne important characteristic is the actual occupancy of a putative binding site\nin the genome. In this study, we propose an analytical model to predict genomic\noccupancy that incorporates the preferred target sequence of a TF in the form\nof a position weight matrix (PWM), DNA accessibility data (in case of\neukaryotes), the number of TF molecules expected to be bound specifically to\nthe DNA and a parameter that modulates the specificity of the TF. Given actual\noccupancy data in form of ChIP-seq profiles, we backwards inferred copy number\nand specificity for five Drosophila TFs during early embryonic development:\nBicoid, Caudal, Giant, Hunchback and Kruppel. Our results suggest that these\nTFs display thousands of molecules that are specifically bound to the DNA and\nthat, while Bicoid and Caudal display a higher specificity, the other three\ntranscription factors (Giant, Hunchback and Kruppel) display lower specificity\nin their binding (despite having PWMs with higher information content). This\nstudy gives further weight to earlier investigations into TF copy numbers that\nsuggest a significant proportion of molecules are not bound specifically to the\nDNA."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Application of signal processing techniques in the assessment of\n  clinical risks in preterm infants"}, {"role": "assistant", "content": "Preterm infants with very low birth weight suffer from a high risk of\nintra-ventricular hemorrhage(IVH) and other serious diseases. To improve the\nclinical risk assessment of preterm infants and develop potential clinically\nmakers for the adverse outcome, the first part of the paper develops the\nfrequency spectral analysis on the non-invasively measured heart rate\nvariability, blood pressure variability and cerebral near-infrared spectroscopy\nmeasures. Moderate and high correlations with the clinical risk index for\nbabies were identified from various spectral measures of arterial baroreflex\nand cerebral autoregulation functions. It was also observed that the\ncross-spectral transfer function analysis of cerebral NIRS and arterial blood\npressure was able to provide a number of parameters that were potentially\nuseful for distinguishing between preterm infants with or without IVH.\nFurthermore, the detrended fluctuation analysis that quantifies the fractal\ncorrelation properties of physiological signals has been examined, to determine\nwhether it could derive markers for the identification of preterm infants with\nIVH. Cardiac output(CO) and total peripheral resistance(TPR) are two important\nparameters of the cardiovascular system. Measurement of these two parameters\ncan provide valuable information for the assessment and management of patients\nneeding intensive care, including preterm infants in the neonatal intensive\ncare unit. To further assess the changes in CO and TPR in the preterm infants,\nthe multivariate regression model based on the useful features from ABP method\nwas used to improve the accuracy and robustness of the estimation. The\ncombination of signal analysis and multivariate regression model in estimation\nof CO has produced some outcomes, and in the future, more effort should be\ninvolved in this kind of research to improve the prediction of serious diseases\nin preterm infants."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A modular approach to adaptive structures"}, {"role": "assistant", "content": "A remarkable property of nastic, shape changing plants is their complete\nfusion between actuators and structure. This is achieved by combining a large\nnumber of cells whose geometry, internal pressures and material properties are\noptimized for a given set of target shapes and stiffness requirements. An\nadvantage of such a fusion is that cell walls are prestressed by cell pressures\nwhich increases, decreases the overall structural stiffness, weight. Inspired\nby the nastic movement of plants, Pagitz et al. 2012 Bioinspir. Biomim. 7\npublished a novel concept for pressure actuated cellular structures. This\narticle extends previous work by introducing a modular approach to adaptive\nstructures. An algorithm that breaks down any continuous target shapes into a\nsmall number of standardized modules is presented. Furthermore it is shown how\ncytoskeletons within each cell enhance the properties of adaptive modules. An\nadaptive passenger seat and an aircrafts leading, trailing edge is used to\ndemonstrate the potential of a modular approach."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multidimensional mutual information methods for the analysis of\n  covariation in multiple sequence alignments"}, {"role": "assistant", "content": "Several methods are available for the detection of covarying positions from a\nmultiple sequence alignment (MSA). If the MSA contains a large number of\nsequences, information about the proximities between residues derived from\ncovariation maps can be sufficient to predict a protein fold. If the structure\nis already known, information on the covarying positions can be valuable to\nunderstand the protein mechanism.\n  In this study we have sought to determine whether a multivariate extension of\ntraditional mutual information (MI) can be an additional tool to study\ncovariation. The performance of two multidimensional MI (mdMI) methods,\ndesigned to remove the effect of ternary/quaternary interdependencies, was\ntested with a set of 9 MSAs each containing <400 sequences, and was shown to be\ncomparable to that of methods based on maximum entropy/pseudolikelyhood\nstatistical models of protein sequences. However, while all the methods tested\ndetected a similar number of covarying pairs among the residues separated by <\n8 {\\AA} in the reference X-ray structures, there was on average less than 65%\noverlap between the top scoring pairs detected by methods that are based on\ndifferent principles.\n  We have also attempted to identify whether the difference in performance\namong methods is due to different efficiency in removing covariation\noriginating from chains of structural contacts. We found that the reason why\nmethods that derive partial correlation between the columns of a MSA provide a\nbetter recognition of close contacts is not because they remove chaining\neffects, but because they filter out the correlation between distant residues\nthat originates from general fitness constraints. In contrast we found that\ntrue chaining effects are expression of real physical perturbations that\npropagate inside proteins, and therefore are not removed by the derivation of\npartial correlation between variables."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Assessing T cell clonal size distribution: a non-parametric approach"}, {"role": "assistant", "content": "Clonal structure of the human peripheral T-cell repertoire is shaped by a\nnumber of homeostatic mechanisms, including antigen presentation, cytokine and\ncell regulation. Its accurate tuning leads to a remarkable ability to combat\npathogens in all their variety, while systemic failures may lead to severe\nconsequences like autoimmune diseases. Here we develop and make use of a\nnon-parametric statistical approach to assess T cell clonal size distributions\nfrom recent next generation sequencing data. For 41 healthy individuals and a\npatient with ankylosing spondylitis, who undergone treatment, we invariably\nfind power law scaling over several decades and for the first time calculate\nquantitatively meaningful values of decay exponent. It has proved to be much\nthe same among healthy donors, significantly different for an autoimmune\npatient before the therapy, and converging towards a typical value afterwards.\nWe discuss implications of the findings for theoretical understanding and\nmathematical modeling of adaptive immunity."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A note on the duality between interaction responses and mutual positions\n  in flocking and schooling"}, {"role": "assistant", "content": "Background: Recent research in animal behaviour has contributed to determine\nhow alignment, turning responses, and changes of speed mediate flocking and\nschooling interactions in different animal species. Here, we address\nspecifically the problem of what interaction responses support different\nnearest neighbour configurations in terms of mutual position and distance.\nResults: We find that the different interaction rules observed in different\nanimal species may be a simple consequence of the relative positions that\nindividuals assume when they move together, and of the noise inherent with the\nmovement of animals, or associated with tracking inaccuracy. Conclusions: The\nanisotropic positioning of individuals with respect to their neighbours, in\ncombination with noise, can explain several aspects of the movement responses\nobserved in real animal groups, and should be considered explicitly in future\nmodels of flocking and schooling. By making a distinction between interaction\nresponses involved in maintaining a preferred flock configuration, and\ninteraction responses directed at changing it, we provide a frame to\ndiscriminate movement interactions that signal directional conflict from those\nunderlying consensual group motion."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Waves of cells with an unstable phenotype accelerate the progression of\n  high-grade brain tumors"}, {"role": "assistant", "content": "In this paper we study a reduced continuous model describing the local\nevolution of high grade gliomas - a lethal type of primary brain tumor -\nthrough the interplay of different cellular phenotypes. We show how hypoxic\nevents, even sporadic and/or limited in space may have a crucial role on the\nacceleration of the growth speed of high grade gliomas. Our modeling approach\nis based on two cellular phenotypes one of them being more migratory and the\nsecond one more proliferative with transitions between them being driven by the\nlocal oxygen values, assumed in this simple model to be uniform. Surprisingly\neven acute hypoxia events (i.e. very localized in time) leading to the\nappearance of migratory populations have the potential of accelerating the\ninvasion speed of the proliferative phenotype up to speeds close to those of\nthe migratory phenotype. The high invasion speed of the tumor persists for\ntimes much longer than the lifetime of the hypoxic event and the phenomenon is\nobserved both when the migratory cells form a persistent wave of cells located\non the invasion front and when they form a evanecent wave dissapearing after a\nshort time by decay into the more proliferative phenotype.\n  Our findings are obtained through numerical simulations of the model\nequations. We also provide a deeper mathematical analysis of some aspects of\nthe problem such as the conditions for the existence of persistent waves of\ncells with a more migratory phenotype."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A two-phase two-layer model for transdermal drug delivery and\n  percutaneous absorption"}, {"role": "assistant", "content": "One of the promising frontiers of bioengineering is the controlled release of\na therapeuticdrug from a vehicle across the skin (transdermal drug delivery).\nIn order to study the complete process, a two-phase mathematical model\ndescribing the dynamics of a substance between two coupled media of different\nproperties and dimensions is presented. A system of partial differential\nequations describes the diffusion and the binding/unbinding processes in both\nlayers. Additional flux continuity at the interface and clearance conditions\ninto systemic circulation are imposed. An eigenvalue problem with discontinuous\ncoefficients is solved and an analytical solution is given in the form of an\ninfinite series expansion. The model points out the role of the diffusion and\nreaction parameters, which control the complex transfer mechanism and the drug\nkinetics across the two layers. Drug masses are given and their dependence on\nthe physical parameters is discussed."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Bayesian inference of time varying parameters in autoregressive\n  processes"}, {"role": "assistant", "content": "In the autoregressive process of first order AR(1), a homogeneous correlated\ntime series $u_t$ is recursively constructed as $u_t = q\\; u_{t-1} + \\sigma\n\\;\\epsilon_t$, using random Gaussian deviates $\\epsilon_t$ and fixed values for\nthe correlation coefficient $q$ and for the noise amplitude $\\sigma$. To model\ntemporally heterogeneous time series, the coefficients $q_t$ and $\\sigma_t$ can\nbe regarded as time-dependend variables by themselves, leading to the\ntime-varying autoregressive processes TVAR(1). We assume here that the time\nseries $u_t$ is known and attempt to infer the temporal evolution of the\n'superstatistical' parameters $q_t$ and $\\sigma_t$. We present a sequential\nBayesian method of inference, which is conceptually related to the Hidden\nMarkov model, but takes into account the direct statistical dependence of\nsuccessively measured variables $u_t$. The method requires almost no prior\nknowledge about the temporal dynamics of $q_t$ and $\\sigma_t$ and can handle\ngradual and abrupt changes of these superparameters simultaneously. We compare\nour method with a Maximum Likelihood estimate based on a sliding window and\nshow that it is superior for a wide range of window sizes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Interference of Binding Protein with Serum Growth Hormone Measurements"}, {"role": "assistant", "content": "Measurement of serum growth hormone by mass spectrometry is demonstrated to\nbe unaffected by interferences with growth hormone binding protein as\nfrequently encountered with antibody-based routine test methods and provides an\nalternative approach, therefore, to acquisition of accurate results."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Lab-in-a-phone: Smartphone-based Portable Fluorometer for pH Field\n  Measurements of Environmental Water"}, {"role": "assistant", "content": "A novel portable fluorometer combining the attributes of a smartphone with an\neasy fit, simple and compact sample chamber fabricated using 3D printing has\nbeen developed for pH measurements of environmental water in the field. The\nresults were then compared directly with those obtained using conventional\nelectrode based measurements."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Generalized sensitivity functions for size-structured population models"}, {"role": "assistant", "content": "Size-structured population models provide a popular means to mathematically\ndescribe phenomena such as bacterial aggregation, schooling fish, and\nplanetesimal evolution. For parameter estimation, generalized sensitivity\nfunctions (GSFs) provide a tool that quantifies the impact of data from\nspecific regions of the experimental domain. These functions help identify the\nmost relevant data subdomains, which enhances the optimization of experimental\ndesign. To our knowledge, GSFs have not been used in the partial differential\nequation (PDE) realm, so we provide a novel PDE extension of the discrete and\ncontinuous ordinary differential equation (ODE) concepts of Thomaseth and\nCobelli and Banks et al. respectively. We analyze the GSFs in the context of\nsize-structured population models, and specifically analyze the Smoluchowski\ncoagulation equation to determine the most relevant time and volume domains for\nthree, distinct aggregation kernels. Finally, we provide evidence that\nparameter estimation for the Smoluchowski coagulation equation does not require\npost-gelation data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Crystal Basis Model: Codon-Anticodon Interaction and Genetic Code\n  Evolution"}, {"role": "assistant", "content": "Imposing a minimum principle in the framework of the so called crystal basis\nmodel of the genetic code, we determine the structure of the minimum set of 22\nanticodons which allows the translational-transcription for animal\nmitochondrial code. The results are in very good agreement with the observed\nanticodons.\n  Then, we analyze the evolution of the genetic code, with 20 amino acids\nencoded from the beginning, from the viewpoint of codon-anticodon interaction.\nFollowing the same spirit as above, we determine the structure of the\nanticodons in the Ancient, Archetypal and Early Genetic codes. Most of our\nresults agree with the generally accepted scheme."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: EEG source localization using a sparsity prior based on Brodmann areas"}, {"role": "assistant", "content": "Localizing the sources of electrical activity in the brain from\nElectroencephalographic (EEG) data is an important tool for non-invasive study\nof brain dynamics. Generally, the source localization process involves a\nhigh-dimensional inverse problem that has an infinite number of solutions and\nthus requires additional constraints to be considered to have a unique\nsolution. In the context of EEG source localization, we propose a novel\napproach that is based on dividing the cerebral cortex of the brain into a\nfinite number of Functional Zones which correspond to unitary functional areas\nin the brain. In this paper we investigate the use of Brodmanns areas as the\nFunctional Zones. This approach allows us to apply a sparsity constraint to\nfind a unique solution for the inverse EEG problem. Compared to previously\npublished algorithms which use different sparsity constraints to solve this\nproblem, the proposed method is potentially more consistent with the known\nsparsity profile of the human brain activity and thus may be able to ensure\nbetter localization. Numerical experiments are conducted on a realistic head\nmodel obtained from segmentation of MRI images of the head and includes four\nmajor compartments namely scalp, skull, cerebrospinal fluid (CSF) and brain\nwith relative conductivity values. Three different electrode setups are tested\nin the numerical experiments."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Energy-based Analysis of Biochemical Cycles using Bond Graphs"}, {"role": "assistant", "content": "Thermodynamic aspects of chemical reactions have a long history in the\nPhysical Chemistry literature. In particular, biochemical cycles - the\nbuilding-blocks of biochemical systems - require a source of energy to\nfunction. However, although fundamental, the role of chemical potential and\nGibb's free energy in the analysis of biochemical systems is often overlooked\nleading to models which are physically impossible. The bond graph approach was\ndeveloped for modelling engineering systems where energy generation, storage\nand transmission are fundamental. The method focuses on how power flows between\ncomponents and how energy is stored, transmitted or dissipated within\ncomponents. Based on early ideas of network thermodynamics, we have applied\nthis approach to biochemical systems to generate models which automatically\nobey the laws of thermodynamics. We illustrate the method with examples of\nbiochemical cycles. We have found that thermodynamically compliant models of\nsimple biochemical cycles can easily be developed using this approach. In\nparticular, both stoichiometric information and simulation models can be\ndeveloped directly from the bond graph. Furthermore, model reduction and\napproximation while retaining structural and thermodynamic properties is\nfacilitated. Because the bond graph approach is also modular and scaleable, we\nbelieve that it provides a secure foundation for building thermodynamically\ncompliant models of large biochemical networks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Efficient inference of parsimonious phenomenological models of cellular\n  dynamics using S-systems and alternating regression"}, {"role": "assistant", "content": "The nonlinearity of dynamics in systems biology makes it hard to infer them\nfrom experimental data. Simple linear models are computationally efficient, but\ncannot incorporate these important nonlinearities. An adaptive method based on\nthe S-system formalism, which is a sensible representation of nonlinear\nmass-action kinetics typically found in cellular dynamics, maintains the\nefficiency of linear regression. We combine this approach with adaptive model\nselection to obtain efficient and parsimonious representations of cellular\ndynamics. The approach is tested by inferring the dynamics of yeast glycolysis\nfrom simulated data. With little computing time, it produces dynamical models\nwith high predictive power and with structural complexity adapted to the\ndifficulty of the inference problem."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Differentiating the L\\'evy walk from a composite correlated random walk"}, {"role": "assistant", "content": "1. Understanding how to find targets with very limited information is a topic\nof interest in many disciplines. In ecology, such research has often focused on\nthe development of two movement models: i) the L\\'evy walk and; ii) the\ncomposite correlated random walk and its associated area-restricted search\nbehaviour. Although the processes underlying these models differ, they can\nproduce similar movement patterns. Due to this similarity and because of their\ndisparate formulation, current methods cannot reliably differentiate between\nthese two models.\n  2. Here, we present a method that differentiates between the two models. It\nconsists of likelihood functions, including one for a hidden Markov model, and\nassociated statistical measures that assess the relative support for and\nabsolute fit of each model.\n  3. Using a simulation study, we show that our method can differentiate\nbetween the two search models over a range of parameter values. Using the\nmovement data of two polar bears (\\textit{Ursus maritimus}), we show that the\nmethod can be applied to complex, real-world movement paths.\n  4. By providing the means to differentiate between the two most prominent\nsearch models in the literature, and a framework that could be extended to\ninclude other models, we facilitate further research into the strategies\nanimals use to find resources."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Parametric Inference using Persistence Diagrams: A Case Study in\n  Population Genetics"}, {"role": "assistant", "content": "Persistent homology computes topological invariants from point cloud data.\nRecent work has focused on developing statistical methods for data analysis in\nthis framework. We show that, in certain models, parametric inference can be\nperformed using statistics defined on the computed invariants. We develop this\nidea with a model from population genetics, the coalescent with recombination.\nWe apply our model to an influenza dataset, identifying two scales of\ntopological structure which have a distinct biological interpretation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: On the Theory and Algorithm for rigorous discretization in applications\n  of Information Theory"}, {"role": "assistant", "content": "We identify fundamental issues with discretization when estimating\ninformation-theoretic quantities in the analysis of data. These difficulties\nare theoretical in nature and arise with discrete datasets carrying significant\nimplications for the corresponding claims and results. Here we describe the\norigins of the methodological problems, and provide a clear illustration of\ntheir impact with the example of biological network reconstruction. We propose\nan algorithm (shared information metric) that corrects for the biases and the\nresulting improved performance of the algorithm demonstrates the need to take\ndue consideration of this issue in different contexts."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: PhyloPythiaS+: A self-training method for the rapid reconstruction of\n  low-ranking taxonomic bins from metagenomes"}, {"role": "assistant", "content": "Metagenomics is an approach for characterizing environmental microbial\ncommunities in situ, it allows their functional and taxonomic characterization\nand to recover sequences from uncultured taxa. For communities of up to medium\ndiversity, e.g. excluding environments such as soil, this is often achieved by\na combination of sequence assembly and binning, where sequences are grouped\ninto 'bins' representing taxa of the underlying microbial community from which\nthey originate. Assignment to low-ranking taxonomic bins is an important\nchallenge for binning methods as is scalability to Gb-sized datasets generated\nwith deep sequencing techniques. One of the best available methods for the\nrecovery of species bins from an individual metagenome sample is the\nexpert-trained PhyloPythiaS package, where a human expert decides on the taxa\nto incorporate in a composition-based taxonomic metagenome classifier and\nidentifies the 'training' sequences using marker genes directly from the\nsample. Due to the manual effort involved, this approach does not scale to\nmultiple metagenome samples and requires substantial expertise, which\nresearchers who are new to the area may not have. With these challenges in\nmind, we have developed PhyloPythiaS+, a successor to our previously described\nmethod PhyloPythia(S). The newly developed + component performs the work\npreviously done by the human expert. PhyloPythiaS+ also includes a new k-mer\ncounting algorithm, which accelerated k-mer counting 100-fold and reduced the\noverall execution time of the software by a factor of three. Our software\nallows to analyze Gb-sized metagenomes with inexpensive hardware, and to\nrecover species or genera-level bins with low error rates in a fully automated\nfashion."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Mass Spectrometry-An Alternative in Growth Hormone Measurement"}, {"role": "assistant", "content": "Growth hormone (GH) constitutes a set of closely related protein isoforms. In\nclinical practice, the disagreement of test results between commercially\navailable ligand-binding assays is still an ongoing issue, and incomplete\nknowledge about the particular function of the different forms leaves an\nuncertainty of what should be the appropriate measurand. Mass spectrometry is\npromising to be a way forward. Not only is it capable of providing SI-traceable\nreference values for the calibration of current GH-tests, but it also offers an\nindependent approach to highly reliable mass-selective quantification of\nindividual GH-isoforms. This capability may add to reliability in doping\ncontrol too. The article points out why and how."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Bystander effects and their implications for clinical radiation therapy:\n  Insights from multiscale in silico experiments"}, {"role": "assistant", "content": "Radiotherapy is a commonly used treatment for cancer and is usually given in\nvarying doses. At low radiation doses relatively few cells die as a direct\nresponse to radiation but secondary radiation effects such as DNA mutation or\nbystander effects affect many cells. Consequently it is at low radiation levels\nwhere an understanding of bystander effects is essential in designing novel\ntherapies with superior clinical outcomes. In this article, we use a hybrid\nmultiscale mathematical model to study the direct effects of radiation as well\nas radiation-induced bystander effects on both tumour cells and normal cells.\nWe show that bystander responses may play a major role in mediating radiation\ndamage to cells at low-doses of radiotherapy, doing more damage than that due\nto direct radiation. The survival curves derived from our computational\nsimulations showed an area of hyper-radiosensitivity at low-doses that are not\nobtained using a traditional radiobiological model."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Extreme protraction for low grade gliomas: Theoretical proof of concept\n  of a novel therapeutical strategy"}, {"role": "assistant", "content": "Grade II gliomas are slowly growing primary brain tumors that affect mostly\nyoung patients and become fatal after a few years. Current clinical handling\nincludes surgery as first line treatment. Cytotoxic therapies (radiotherapy RT\nor chemotherapy QT) are used initially only for patients having a bad\nprognosis. Therapies are administered following the 'maximum dose in minimum\ntime' principle, what is the same schedule used for high grade brain tumors.\nUsing mathematical models describing the growth of these tumors in response to\nradiotherapy, we find that a extreme protraction therapeutical strategy, i.e.\nenlarging substantially the time interval between RT fractions, may lead to a\nbetter tumor control. Explicit formulas are found providing the optimal spacing\nbetween doses in a very good agreement with the simulations of the full\nthree-dimensional mathematical model approximating the tumor spatio-temporal\ndynamics. This idea, although breaking the well-stablished paradigm, has\nbiological meaning since in these slowly growing tumors it may be more\nfavourable to treat the tumor as the different tumor subpopulations move to\nmore sensitive phases of the cell cycle."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Effects of low-level deuterium enrichment on bacterial growth"}, {"role": "assistant", "content": "Using very precise (up to 0.05%) measurements of the growth parameters for\nbacteria E. coli grown on minimal media, we aimed to determine the lowest\ndeuterium concentration at which the adverse effects that are prominent at\nhigher enrichments start to become noticeable. Such a threshold was found at\n0.5% D, a surprisingly high value, while the ultralow deuterium concentrations\n(up to 0.25% D) showed signs of the opposite trend. Bacterial adaptation for\n400 generations in isotopically different environment confirmed preference for\nultralow (up to 0.25% D) enrichment. This effect appears to be similar to those\ndescribed in sporadic but multiple earlier reports. Possible explanations\ninclude hormesis and isotopic resonance phenomena, with the latter explanation\nbeing favored."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Shape mode analysis exposes movement patterns in biology: flagella and\n  flatworms as case studies"}, {"role": "assistant", "content": "We illustrate shape mode analysis as a simple, yet powerful technique to\nconcisely describe complex biological shapes and their dynamics. We\ncharacterize undulatory bending waves of beating flagella and reconstruct a\nlimit cycle of flagellar oscillations, paying particular attention to the\nperiodicity of angular data. As a second example, we analyze non-convex\nboundary outlines of gliding flatworms, which allows us to expose stereotypic\nbody postures that can be related to two different locomotion mechanisms.\nFurther, shape mode analysis based on principal component analysis allows to\ndiscriminate different flatworm species, despite large motion-associated shape\nvariability. Thus, complex shape dynamics is characterized by a small number of\nshape scores that change in time. We present this method using descriptive\nexamples, explaining abstract mathematics in a graphic way."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Mass spectrometry based protein identification with accurate statistical\n  significance assignment"}, {"role": "assistant", "content": "Motivation: Assigning statistical significance accurately has become\nincreasingly important as meta data of many types, often assembled in\nhierarchies, are constructed and combined for further biological analyses.\nStatistical inaccuracy of meta data at any level may propagate to downstream\nanalyses, undermining the validity of scientific conclusions thus drawn. From\nthe perspective of mass spectrometry based proteomics, even though accurate\nstatistics for peptide identification can now be achieved, accurate protein\nlevel statistics remain challenging.\n  Results: We have constructed a protein ID method that combines peptide\nevidences of a candidate protein based on a rigorous formula derived earlier;\nin this formula the database $P$-value of every peptide is weighted, prior to\nthe final combination, according to the number of proteins it maps to. We have\nalso shown that this protein ID method provides accurate protein level\n$E$-value, eliminating the need of using empirical post-processing methods for\ntype-I error control. Using a known protein mixture, we find that this protein\nID method, when combined with the Soric formula, yields accurate values for the\nproportion of false discoveries. In terms of retrieval efficacy, the results\nfrom our method are comparable with other methods tested.\n  Availability: The source code, implemented in C++ on a linux system, is\navailable for download at\nftp://ftp.ncbi.nlm.nih.gov/pub/qmbp/qmbp_ms/RAId/RAId_Linux_64Bit"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Tracking single C. elegans using a USB microscope on a motorized stage"}, {"role": "assistant", "content": "Locomotion and gross morphology have been important phenotypes for C. elegans\ngenetics since the inception of the field and remain relevant. In parallel with\ndevelopments in genome sequencing and editing, phenotyping methods have become\nmore automated and quantitative, making it possible to detect subtle\ndifferences between mutants and wild-type animals. In this chapter, we describe\nhow to calibrate a single worm tracker consisting of a USB microscope mounted\non a motorized stage and how to record and analyze movies of worms crawling on\nfood. The resulting quantitative phenotypic fingerprint can sensitively\nidentify differences between mutant and wild type worms."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Mapping physiological suitability limits of malaria in Africa under\n  climate change"}, {"role": "assistant", "content": "We mapped current and future temperature suitability for malaria transmission\nin Africa using a published model that incorporates nonlinear physiological\nresponses to temperature of the mosquito vector Anopheles gambiae and the\nmalaria parasite Plasmodium falciparum. We found that a larger area of Africa\ncurrently experiences the ideal temperature for transmission than previously\nsupposed. Under future climate projections, we predicted a modest increase in\nthe overall area suitable for malaria transmission, but a net decrease in the\nmost suitable area. Combined with population density projections, our maps\nsuggest that areas with temperatures suitable for year-round, highest risk\ntransmission will shift from coastal West Africa to the Albertine Rift between\nDemocratic Republic of Congo and Uganda, while areas with seasonal transmission\nsuitability will shift toward sub-Saharan coastal areas. Mapping temperature\nsuitability places important bounds on malaria transmissibility and, along with\nlocal level demographic, socioeconomic, and ecological factors, can indicate\nwhere resources may be best spent on malaria control."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Optimizing control of HIV in Kenya"}, {"role": "assistant", "content": "UNAIDS has embraced an ambitious global target for the implementation of\ntreatment for people living with HIV. This 90-90-90 target would mean that, by\n2020, 90% of all those living with HIV should know their status, 90% of these\nwould be on treatment and 90% of these would have fully suppressed plasma viral\nloads. To reach this target in the next five years presents a major logistical\nchallenge. However, the prevalence of HIV varies greatly by risk groups, age,\ngender, geography and social conditions. For reasons of effectiveness and\nimpact the focus must first be on those who are most likely to be infected with\nHIV and therefore most likely to infect others. In Kenya the prevalence of HIV\nin adults varies by two orders of magnitude among the counties. The effective\nimplementation of 90-90-90 will depend on first providing ART where the\nprevalence of infection is greatest, then to those that are most easily reached\nin large numbers and finally to the whole population. Here we use routine data\nfrom ante-natal clinics and national survey data to assess the variation of the\nprevalence of HIV among counties in Kenya; we suggest reasons for this\nvariation, and estimate the effectiveness of targeting the role out of ART. The\nhighest prevalence occurs in some of the counties bordering Lake Victoria and\nthese are most in need of ART. These districts in Nyanza Province, account for\n31% of all cases in Kenya but make up 10% of the population and cover 1.8% of\nthe land-area. The highest concentrations of HIV cases are in Nairobi and\nMombasa which account for a further 18% of all cases in Kenya but make up 12%\nof the population and cover 0.1% of the land-area. Providing ART in these two\ncities will be relatively straightforward given their small geographical area."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: From birds to bacteria: generalised velocity jump processes with resting\n  states"}, {"role": "assistant", "content": "There are various cases of animal movement where behaviour broadly switches\nbetween two modes of operation, corresponding to a long distance movement state\nand a resting or local movement state. Here a mathematical description of this\nprocess is formulated, adapted from Friedrich et. al. (2006). The approach\nallows the specification any running or waiting time distribution along with\nany angular and speed distributions. The resulting system of partial\nintegro-differential equations are tumultuous and therefore it is necessary to\nboth simplify and derive summary statistics. An expression for the mean squared\ndisplacement is derived which shows good agreement with experimental data from\nthe bacterium Escherichia coli and the gull Larus fuscus. Finally a large time\ndiffusive approximation is considered via a Cattaneo approximation (Hillen,\n2004). This leads to the novel result that the effective diffusion constant is\ndependent on the mean and variance of the running time distribution but only on\nthe mean of the waiting time distribution."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The spatial scan statistic: A new method for spatial aggregation of\n  categorical raster maps"}, {"role": "assistant", "content": "Multiple-scale and broad-scale assessments often require rescaling the\noriginal data to a consistent grain size for analysis. Rescaling categorical\nraster data by spatial aggregation is common in large area ecological\nassessments. However, distortion and loss of information are associated with\naggregation. Using a majority rule generally results in dominant classes\nbecoming more pronounced and rare classes becoming less pronounced. Using\nnearest neighbor techniques generally maintains the global proportion of each\ncategory in the original map but can lead to disaggregation. In this paper we\nimplement the spatial scan statistic for spatial aggregation of categorical\nraster maps and describe the behavior of the technique at the local level\n(aggregation unit) and global level (map). We also contrast the spatial scan\nstatistic technique with the majority rule and nearest neighbor approaches. In\ngeneral, the scan statistic technique behaved inverse the majority rule\napproach in that rare classes rather than abundant classes were preserved. We\nsuggest the scan statistic techniques should be used for spatial aggregation of\ncategorical maps when preserving heterogeneity and information from rare\nclasses are important goals of the study or assessment."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Network Filtration Protocol for Elucidating Relationships between\n  Families in a Protein Similarity Network"}, {"role": "assistant", "content": "Motivation: The study of diverse enzyme superfamilies can provide important\ninsight into the relationships between protein sequence, structure and\nfunction. It is often challenging, however, to discover these relationships\nacross a large and diverse superfamily. Contemporary similarity network\nvisualization techniques allow researchers to aggregate sequence similarity\ninformation into a single global view. Network visualization provides a\nqualitative estimate of functional diversity within a superfamily, but is\nunable to quantitate explicit boundaries, when present, between neighboring\nfamilies in sequence space. This limits the potential of existing\nsequence-based algorithms to generate functional predictions from superfamily\ndatasets.\n  Results: By building on current network analysis tools, we have developed a\nnew algorithm for elucidating pairs of homologous families within a sequence\ndataset. Our algorithm is able to filter through a dense similarity network in\norder to estimate both the boundaries of individual families and also how the\nfamilies neighbor one another. Globally, these neighboring families define a\ntopology across the entire superfamily. The topology is simple to interpret by\nvisualizing the network output generated by our filtration protocol. We have\ncompared the network topology within the kinase superfamily against available\nphylogenetic data. Our results suggest that neighbors within the filtered\nkinase network are more likely to share structural and functional properties\nthan more distant network clusters."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Numerical modeling of inhomogeneous DNA replication kinetics"}, {"role": "assistant", "content": "We present a calculation technique for modeling inhomogeneous DNA replication\nkinetics, where replication factors such as initiation rates or fork speeds can\nchange with both position and time. We can use our model to simulate data sets\nobtained by molecular combing, a widely used experimental technique for probing\nreplication. We can also infer information about the replication program by\nfitting our model to experimental data sets and also test the efficacy of\nplanned experiments by fitting our model to simulated data sets. We consider\nasynchronous data sets and illustrate how a lack of synchrony affects\nreplication profiles. In addition to combing data, our technique is\nwell-adapted to microarray-based studies of replication."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Optimizing Metabonomic Spectral Replacement"}, {"role": "assistant", "content": "Metabonomics, the measure of the fingerprint of biochemical perturbations\ncaused by disease, drugs or toxins, recently has become a major focus of\nresearch in various areas especially indications of drug toxicity. Two types of\ntechnology (known by the initials NMR and MS) are employed and both produce\nmassive data in form of spectra. Sophisticated statistical models, known as\npattern recognition techniques, are commonly applied for summarizing and\nanalyzing these multidimensional data. However, strong signals from compounds\nthat are administered during toxicological trials interfere with these models.\nSo called 'spectral replacement' is a method to eliminate these signals by\nreplacing them with the signals in their corresponding regions in control\nspectrum. The replaced regions are subsequently scaled. However, this scaling\nis not accurately measured and often results in overestimation of integrated\nintensity of the replaced signals. Here, a novel protocol is proposed which\nprovides an accurate estimation of the replaced regions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Diagnostics for assessing the linear noise and moment closure\n  approximations"}, {"role": "assistant", "content": "Solving the chemical master equation exactly is typically not possible, so\ninstead we must rely on simulation based methods. Unfortunately, drawing exact\nrealisations, results in simulating every reaction that occurs. This will\npreclude the use of exact simulators for models of any realistic size and so\napproximate algorithms become important. In this paper we describe a general\nframework for assessing the accuracy of the linear noise and two moment\napproximations. By constructing an efficient space filling design over the\nparameter region of interest, we present a number of useful diagnostic tools\nthat aids modellers in assessing whether the approximation is suitable. In\nparticular, we leverage the normality assumption of the linear noise and moment\nclosure approximations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Managing HIV/AIDS in Malawi"}, {"role": "assistant", "content": "The epidemic of HIV in Malawi started early and at its peak 15% of all adults\nwere infected with HIV. Malawi is a low-income country and the cost of putting\nall HIV-positive people in Malawi onto ART, expressed as a percentage of the\ngross domestic product, is the highest in the world. Nevertheless, Malawi has\nmade great progress and the greatly reduced cost of potent anti-retroviral\ntherapy (ART) makes it possible to contemplate ending the epidemic of HIV/AIDS.\nHere we consider what would have happened without ART, the No ART\ncounterfactual, the impact if the current level of roll-out of ART is\nmaintained, the Current Programme, and the likely impact if treatment is made\navailable to everyone who is eligible under the 2013 guidelines of the World\nHealth Organization reaching full coverage by 2020, the Expanded Programme.\n  The Current Programme has substantially reduced the epidemic of HIV and the\nnumber of people dying of AIDS. The Expanded Programme has the potential to\navert more infections, save more lives and end the epidemic. The annual cost of\nmanaging HIV will increase from about US$132 million in 2014 to about US$155\nmillion in 2020 but will fall after that. If the Expanded Programme is\nimplemented several key areas must be addressed. Testing services will need to\nbe expanded and supported by mass testing campaigns, so as to diagnose people\nwith HIV and enrol them in treatment and care as early as possible. A regular\nand uninterrupted supply of drugs will have to be assured. The quantity and\nquality of existing health staff will need to be strengthened. Community health\nworkers will need to be mobilized and trained to encourage people to be tested\nand accept treatment, to monitor progress and to support people on treatment;\nthis in turn will help to reduce stigma and discrimination, loss to follow up\nof people diagnosed with HIV, and improve adherence for those on treatment."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Unified Mathematical Language for Medicine and Science"}, {"role": "assistant", "content": "A unified mathematical language for medicine and science will be presented.\nUsing this language, models for DNA replication, protein synthesis, chemical\nreactions, neurons and a cardiac cycle of a heart have been built. Models for\nTuring machines, cellular automaton, fractals and physical systems are also\nrepresented with the use of this language. Interestingly, the language comes\nwith a way to represent probability theory concepts and also programming\nstatements. With this language, questions and processes in medicine can be\nrepresented as systems of equations; and solutions to these equations are\nviewed as treatments or previously unknown processes. This language can serve\nas the framework for the creation of a large interactive open-access scientific\ndatabase that allows extensive mathematical medicine computations. It can also\nserve as a basis for exploring ideas related to what could be called\nmetascience."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Water Stability and Nutrient Leaching of Different Levels of Maltose\n  Formulated Fish Pellets"}, {"role": "assistant", "content": "The effects of different levels of maltose on feed pellet water stability and\nnutrient leaching were studied. Five treatments, including control with three\nreplicates with setup (0.0, 20, 25, 30 and 35%). Pellet leaching rates were\nused to indicate pellet water stability. The results show that the presence of\nmaltose in the diets significantly improved pellet water stability (p<0.05),\nbut the leaching rates of the feed (35% maltose) observed higher than other\nfeeds. Increased maltose resulted in the corresponding decrease in pellet\nstability. The protein leaching rate of control feed and feed (20% maltose) was\nsignificantly (p < 0.05) lower than the rates of other diets The lipid leaching\nrate of control feed was lower than the rates of other diets, while the feed\n(35% maltose) was more leaching rate. It improved feeds water stability is one\nimportant reason why maltose enhances fish growth."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The Hurst exponents of Nitzschia sp. diatom trajectories observed by\n  light microscopy"}, {"role": "assistant", "content": "We present the results of an experiment with light microscopy performed to\ncapture the trajectories of live Nitzschia sp. diatoms. The time series\ncorresponding to the motility of this kind of cells along ninety-five\ncircular-like trajectories have been obtained and analyzed with the scaling\nstatistical method of detrended fluctuation analysis optimized via a wavelet\ntransform. In this way, we determined the Hurst parameters, in two orthogonal\ndirections, which characterize the nature of the motion of live diatoms in\nlight microscopy experiments. We have found mean values of these directional\nHurst parameters between 0.70 and 0.63 with overall standard errors below 0.15.\nThese numerical values give evidence that the motion of Nitzschia sp. diatoms\nis of persistent type and suggest an active cell motility with a kind of memory\nassociated with long-range correlations on the path of their trajectories. For\nthe collected statistics, we also find that the values of the Hurst exponents\ndepend on the number of abrupt turns that occur in the diatom trajectory and on\nthe type of wavelet, although their mean values do not change much"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Extracting Hidden Hierarchies in 3D Distribution Networks"}, {"role": "assistant", "content": "Natural and man-made transport webs are frequently dominated by dense sets of\nnested cycles. The architecture of these networks, as defined by the topology\nand edge weights, determines how efficiently the networks perform their\nfunction. Yet, the set of tools that can characterize such a weighted\ncycle-rich architecture in a physically relevant, mathematically compact way is\nsparse. In order to fill this void, we have developed a new algorithm that\nrests on an abstraction of the physical `tiling' in the case of a two\ndimensional network to an effective tiling of an abstract surface in space that\nthe network may be thought to sit in. Generically these abstract surfaces are\nricher than the flat plane and as a result there are now two families of\nfundamental units that may aggregate upon cutting weakest links -- the\nplaquettes of the tiling and the longer `topological' cycles associated with\nthe abstract surface itself. Upon sequential removal of the weakest links, as\ndetermined by the edge weight, neighboring plaquettes merge and a tree\ncharacterizing this merging process results. The properties of this\ncharacteristic tree can provide the physical and topological data required to\ndescribe the architecture of the network and to build physical models. The new\nalgorithm can be used for automated phenotypic characterization of any weighted\nnetwork whose structure is dominated by cycles, such as mammalian vasculature\nin the organs, the root networks of clonal colonies like quaking aspen, or the\nforce networks in jammed granular matter."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Integrated multimodal network approach to PET and MRI based on\n  multidimensional persistent homology"}, {"role": "assistant", "content": "Finding the underlying relationships among multiple imaging modalities in a\ncoherent fashion is one of challenging problems in the multimodal analysis. In\nthis study, we propose a novel multimodal network approach based on multidi-\nmensional persistent homology. In this extension of the previous threshold-free\nmethod of persistent homology, we visualize and discriminate the topological\nchange of integrated brain networks by varying not only threshold but also\nmixing ratios between two different imaging modalities. Moreover, we also pro-\npose an integration method for multimodal networks, called one-dimensional\nprojection, with a specific mixing ratio between modalities. We applied the\nproposed methods to PET and MRI data from 21 autism spectrum disorder (ASD)\nchildren and 10 pediatric control subjects. From the results, we found that the\nbrain networks of ASD children and controls differ significantly, with ASD\nshowing asymmetrical changes of connected structures between PET and MRI. The\nintegrated MRI and PET networks showed that ASD children had weaker connections\nthan controls within the visual cortex, between dorsal and ventral parts of the\ntemporal pole, between frontal and parietal regions, and between the left\nperisylvian and other brain regions. These results provide a multidimensional\nhomological understanding of disease-related PET and MRI networks that\ndiscloses the network association with ASD."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Bag-of-calls analysis reveals group-specific vocal repertoire in\n  long-finned pilot whales"}, {"role": "assistant", "content": "Besides humans, several marine mammal species exhibit prerequisites to evolve\nlanguage: high cognitive abilities, flexibility in vocal production and\nadvanced social interactions. Here, we describe and analyse the vocal\nrepertoire of long-finned pilot whales (Globicephalus melas) recorded in\nnorthern Norway. Observer based analysis reveals a complex vocal repertoire\nwith 140 different call types, call sequences, call repetitions and\ngroup-specific differences in the usage of call types. Developing and applying\na new automated analysis method, the bag-of-calls approach, we find that groups\nof pilot whales can be distinguished purely by statistical properties of their\nvocalisations. Comparing inter-and intra-group differences of ensembles of\ncalls allows to identify and quantify group-specificity. Consequently, the\nbag-of-calls approach is a valid method to specify difference and concordance\nin acoustic communication in the absence of exact knowledge about signalers,\nwhich is common observing marine mammals under natural conditions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Modeling-based determination of physiological parameters of systemic\n  VOCs by breath gas analysis: a pilot study"}, {"role": "assistant", "content": "In this paper we develop a simple two compartment model which extends the\nFarhi equation to the case when the inhaled concentration of a volatile organic\ncompound (VOC) is not zero. The model connects the exhaled breath concentration\nof systemic VOCs with physiological parameters such as endogenous production\nrates and metabolic rates. Its validity is tested with data obtained for\nisoprene and inhaled deuterated isoprene-D5."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Simulating Stochastic Reaction-Diffusion Systems on and within Moving\n  Boundaries"}, {"role": "assistant", "content": "Chemical reactions inside cells are generally considered to happen within\nfixed-size compartments. Needless to say, cells and their compartments are\nhighly dynamic. Thus, such stringent assumptions may not reflect biochemical\nreality, and can highly bias conclusions from simulation studies. In this work,\nwe present an intuitive algorithm for particle-based diffusion in and on moving\nboundaries, for both point particles and spherical particles. We first\nbenchmark in appropriate scenarios our proposed stochastic method against\nsolutions of partial differential equations, and further demonstrate that\nmoving boundaries can give rise to super diffusive motion as well as\ntime-inhomogeneous reaction rates. Finally, we conduct a numerical experiment\nrepresenting photobleaching of diffusing fluorescent proteins in dividing\nSaccharomyces cerevisiae cells to demonstrate that moving boundaries might\ncause important effects neglected in previously published studies."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Real-time PCR (qPCR) assay for Rhizoctonia solani anastomoses group\n  AG2-2IIIb"}, {"role": "assistant", "content": "Rhizoctonia solani anastomosis group AG2-2 IIIB is a severe sugar beet and\nmaize pathogen. It causes crown and root rot disease which leads to yield\nlosses world-wide. The soil-borne pathogen is difficult to detect and quantify\nby conventional methods. We developed a real-time PCR (qPCR) assay for the\nquantification of genomic DNA of Rhizoctonia solani AG2-2 IIIB based on the ITS\nregion of rDNA genes. The limit of quantification of the assay is 1.8 pg\ngenomic DNA. The amplification efficiency was 96.4. The assay will be helpful\nin the diagnoses of Rhizoctonia solani infection of sugar beet and maize roots\nand in the quantification of R. solani AG2-2 IIIB inoculum in plant debris and\nsoil."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Conversion of cDNA differential display results (DDRT-PCR) into\n  quantitative transcription profiles"}, {"role": "assistant", "content": "Background: Gene expression studies on non-model organisms require open-end\nstrategies for transcription profiling. Gel-based analysis of cDNA fragments\nallows to detect alterations in gene expression for genes which have neither\nbeen sequenced yet nor are available in cDNA libraries. Commonly used protocols\nare cDNA Differential Display (DDRT-PCR) and cDNA-AFLP. Both methods have been\nused merely as qualitative gene discovery tools so far. Results: We developed\nprocedures for the conversion of DDRT-PCR data into quantitative transcription\nprofiles. Amplified cDNA fragments are separated on a DNA sequencer. Data\nprocessing consists of four steps: (i) cDNA bands in lanes corresponding to\nsamples treated with the same primer combination are matched in order to\nidentify fragments originating from the same transcript, (ii) intensity of\nbands is determined by densitometry, (iii) densitometric values are normalized,\nand (iv) intensity ratio is calculated for each pair of corresponding bands.\nTranscription profiles are represented by sets of intensity ratios (control vs.\ntreatment) for cDNA fragments defined by primer combination and DNA mobility.\nWe demonstrated the procedure by analyzing DDRT-PCR data on the effect of\nsecondary metabolites of oilseed rape Brassica napus on the transcriptome of\nthe pathogenic fungus Leptosphaeria maculans. Conclusion: We developed a data\nprocessing procedure for quantitative analysis of amplified cDNA fragments. The\nsystem utilizes common software and provides an open-end alternative to\nmicroarray analysis. The processing is expected to work equally well with\nDDRT-PCR and cDNA-AFLP data and be useful in research on organisms for which\nmicroarray analysis is not available or economical."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Analysis of the human diseasome reveals phenotype modules across common,\n  genetic, and infectious diseases"}, {"role": "assistant", "content": "Phenotypes are the observable characteristics of an organism arising from its\nresponse to the environment. Phenotypes associated with engineered and natural\ngenetic variation are widely recorded using phenotype ontologies in model\norganisms, as are signs and symptoms of human Mendelian diseases in databases\nsuch as OMIM and Orphanet. Exploiting these resources, several computational\nmethods have been developed for integration and analysis of phenotype data to\nidentify the genetic etiology of diseases or suggest plausible interventions. A\nsimilar resource would be highly useful not only for rare and Mendelian\ndiseases, but also for common, complex and infectious diseases. We apply a\nsemantic text- mining approach to identify the phenotypes (signs and symptoms)\nassociated with over 8,000 diseases. We demonstrate that our method generates\nphenotypes that correctly identify known disease-associated genes in mice and\nhumans with high accuracy. Using a phenotypic similarity measure, we generate a\nhuman disease network in which diseases that share signs and symptoms cluster\ntogether, and we use this network to identify phenotypic disease modules."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Evaluating the accuracy of diffusion MRI models in white matter"}, {"role": "assistant", "content": "Models of diffusion MRI within a voxel are useful for making inferences about\nthe properties of the tissue and inferring fiber orientation distribution used\nby tractography algorithms. A useful model must fit the data accurately.\nHowever, evaluations of model-accuracy of some of the models that are commonly\nused in analyzing human white matter have not been published before. Here, we\nevaluate model-accuracy of the two main classes of diffusion MRI models. The\ndiffusion tensor model (DTM) summarizes diffusion as a 3-dimensional Gaussian\ndistribution. Sparse fascicle models (SFM) summarize the signal as a linear sum\nof signals originating from a collection of fascicles oriented in different\ndirections. We use cross-validation to assess model-accuracy at different\ngradient amplitudes (b-values) throughout the white matter. Specifically, we\nfit each model to all the white matter voxels in one data set and then use the\nmodel to predict a second, independent data set. This is the first evaluation\nof model-accuracy of these models. In most of the white matter the DTM predicts\nthe data more accurately than test-retest reliability; SFM model-accuracy is\nhigher than test-retest reliability and also higher than the DTM, particularly\nfor measurements with (a) a b-value above 1000 in locations containing fiber\ncrossings, and (b) in the regions of the brain surrounding the optic\nradiations. The SFM also has better parameter-validity: it more accurately\nestimates the fiber orientation distribution function (fODF) in each voxel,\nwhich is useful for fiber tracking."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A stochastic model of the production of multiple proteins in cells"}, {"role": "assistant", "content": "The production processes of proteins in prokaryotic cells are investigated.\nMost of the mathematical models in the literature study the production of {\\em\none} fixed type of proteins. When several classes of proteins are considered,\nan important additional aspect has to be taken into account, the limited common\nresources of the cell (polymerases and ribosomes) used by the production\nprocess. Understanding the impact of this limitation is a key issue in this\ndomain. In this paper we focus on the allocation of ribosomes in the case of\nthe production of multiple proteins. The cytoplasm of the cell being a\ndisorganized medium subject to thermal noise, the protein production process\nhas an important stochastic component. For this reason, a Markovian model of\nthis process is introduced. Asymptotic results of the equilibrium are obtained\nunder a scaling procedure and a realistic biological assumption of saturation\nof the ribosomes available in the cell. It is shown in particular that, in the\nlimit, the number of non-allocated ribosomes at equilibrium converges in\ndistribution to a Poisson distribution whose parameter satisfies a fixed point\nequation. It is also shown that the production process of different types of\nproteins can be seen as independent production processes but with modified\nparameters."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Single Channel Cutaneous Electrogastrography on Local White Rabbit\n  (Oryctolagus cuniculus) and Its Electrogastrogram Classification Algorithm"}, {"role": "assistant", "content": "It has been a common practice to place electrodes based on external\nlandmarks, rather than locating the appropriate organ first by imaging\ntechnuiqes such as CT scan, ultrasound, etc. Therefore, aside from abiding the\ncutaneous EGG (electrogastrography) electrodes placement rule, identification\nof its waveform should be performed to ease the validation of one's EGG\nrecording method. This research focused on the assembly of EGG instrument, its\nperformance testing, and its usage on local white rabbit (O. cuniculus). A\ntotal of 72 recordings obtained and processed. Data procession implies EGG\nparameterization based on segmentation and time domain analysis. Therefore this\nresearch gives an insight of an EGG recording method that could be applied on\nanother preclinical, veterinary, and even for clinical examination."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Learning microbial interaction networks from metagenomic count data"}, {"role": "assistant", "content": "Many microbes associate with higher eukaryotes and impact their vitality. In\norder to engineer microbiomes for host benefit, we must understand the rules of\ncommunity assembly and maintenence, which in large part, demands an\nunderstanding of the direct interactions between community members. Toward this\nend, we've developed a Poisson-multivariate normal hierarchical model to learn\ndirect interactions from the count-based output of standard metagenomics\nsequencing experiments. Our model controls for confounding predictors at the\nPoisson layer, and captures direct taxon-taxon interactions at the multivariate\nnormal layer using an $\\ell_1$ penalized precision matrix. We show in a\nsynthetic experiment that our method handily outperforms state-of-the-art\nmethods such as SparCC and the graphical lasso (glasso). In a real, in planta\nperturbation experiment of a nine member bacterial community, we show our\nmodel, but not SparCC or glasso, correctly resolves a direct interaction\nstructure among three community members that associate with Arabidopsis\nthaliana roots. We conclude that our method provides a structured, accurate,\nand distributionally reasonable way of modeling correlated count based random\nvariables and capturing direct interactions among them."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Single Channel Cutaneous Electrogastrography Parameters from Local White\n  Rabbit (Oryctolagus cuniculus)"}, {"role": "assistant", "content": "EGG recordings performed on 13 local white rabbits (O. cuniculus) which\ndivided into 3 groups; acetosal 35 mg/kgBM receiver, reserpine 37.5 mg/kgBM\nreceiver, and control group. A total of 72 EGG recordings obtained from them,\nwhich divided furthermore into 9 datasets based on prepandrial state,\npostpandrial state, and post 1 hour drug administration state. EGG parameters\nsuch as the number of cycle per minute ($cpm$), average voltage of action\npotential segment ($\\bar{V_a}$), root mean square voltage of action potential\nsegment ($A_{rms}$), root mean square voltage of all EGG segment ($V_{rms}$),\naverage period of action potential segment ($\\bar{T_a}$), average period of\nresting plateau ($\\bar{T_i}$), average period difference among action potential\nsegment and resting plateau ($\\bar{T_a - T_i}$), and dominant frequency ($f_d$)\nare obtained. Insignificant difference of $f_d$ ($P$ = 0.9112993) and cpm ($P$\n= 0.9382463) among 9 EGG datasets were found. These findings contrasted the\ncommon practice of EGG assessment, which $f_d$ and $cpm$ are the main\nparameters for diagnosis base. In other hand, significant difference between 9\nEGG datasets found for $\\bar{V_a}$, $A_{rms}$, and $V_{rms}$ parameter with $P$\n= 0.0007346, 0.0039191, and 0.0000559 respectively. In conclusion, EGG\nparameterization should not be limited to $f_d$ and $cpm$ only."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Individual discrimination of freely swimming pulse-type electric fish\n  from electrode array recordings"}, {"role": "assistant", "content": "Pulse-type weakly electric fishes communicate through electrical discharges\nwith a stereotyped waveform, varying solely the interval between pulses\naccording to the information being transmitted. This simple codification\nmechanism is similar to the one found in various known neuronal circuits, which\nrenders these animals as good models for the study of natural communication\nsystems, allowing experiments involving behavioral and neuroethological\naspects. Performing analysis of data collected from more than one freely\nswimming fish is a challenge since the detected electric organ discharge (EOD)\npatterns are dependent on each animal's position and orientation relative to\nthe electrodes. However, since each fish emits a characteristic EOD waveform,\ncomputational tools can be employed to match each EOD to the respective fish.\nIn this paper we describe a computational method able to recognize fish EODs\nfrom dyads using normalized feature vectors obtained by applying Fourier and\ndual-tree complex wavelet packet transforms. We employ support vector machines\nas classifiers, and a continuity constraint algorithm allows us to solve issues\ncaused by overlapping EODs and signal saturation. Extensive validation\nprocedures with Gymnotus sp. showed that EODs can be assigned correctly to each\nfish with only two errors per million discharges."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Coverage Criterion for Spaced Seeds and its Applications to Support\n  Vector Machine String Kernels and k-Mer Distances"}, {"role": "assistant", "content": "Spaced seeds have been recently shown to not only detect more alignments, but\nalso to give a more accurate measure of phylogenetic distances (Boden et al.,\n2013, Horwege et al., 2014, Leimeister et al., 2014), and to provide a lower\nmisclassification rate when used with Support Vector Machines (SVMs) (On-odera\nand Shibuya, 2013), We confirm by independent experiments these two results,\nand propose in this article to use a coverage criterion (Benson and Mak, 2008,\nMartin, 2013, Martin and No{\\'e}, 2014), to measure the seed efficiency in both\ncases in order to design better seed patterns. We show first how this coverage\ncriterion can be directly measured by a full automaton-based approach. We then\nillustrate how this criterion performs when compared with two other criteria\nfrequently used, namely the single-hit and multiple-hit criteria, through\ncorrelation coefficients with the correct classification/the true distance. At\nthe end, for alignment-free distances, we propose an extension by adopting the\ncoverage criterion, show how it performs, and indicate how it can be\nefficiently computed."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: In-vitro iontophoresis of pinneal Sus scrofa skin and its transport flux\n  modelling as influenced by time and current density"}, {"role": "assistant", "content": "The purpose of this study was to enhance the existing time dependent flux\nmodel for the transdermal iontophoretic transport of drugs. This study\nevaluated the flux data as influenced by time and current density. In vitro\niontophoresis performed on the piglet (Sus scrofa) necropsy-taken medial scapha\npinneal skin that mounted in the U shaped sink chamber. Iontophoresis of\natenolol with a constant dose of 1000 ppm was implemented for 3 hours with\nacceptor phase sampling every 30 minutes. Data were analised based on\nexponential fitting of each current density value to produce a current density\ndependent flux model. This model then combined with the time differential model\nof flux to produce a flux model that takes account of both current density and\ntime."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Fitting and projecting HIV epidemics: Data, structure and parsimony"}, {"role": "assistant", "content": "Understanding historical trends in the epidemic of HIV is important for\nassessing current and projecting future trends in prevalence, incidence and\nmortality and for evaluating the impact and cost-effectiveness of control\nmeasures. In generalized epidemics the available data are of variable quality\namong countries and limited mainly to trends in the prevalence of HIV among\nwomen attending ante-natal clinics. In concentrated epidemics one needs, at the\nvery least, time trends in the prevalence of HIV among different risk groups,\nincluding intravenous drug users, men-who-have-sex-with-men, and commercial sex\nworkers as well as the size of each group and the degree of overlap between\nthem. Here we focus on the comparatively straight forward problems presented by\ngeneralized epidemics. We fit data from Kenya to a susceptible-infected model\nand then successively add structure to the model, drawing on our knowledge of\nthe natural history of HIV, to explore the effect that different structural\naspects of the model have on the fits and the projections.\n  Both heterogeneity in risk and changes in behaviour over time are important\nbut easily confounded. Using a Weibull rather than exponential survival\nfunction for people infected with HIV, in the absence of treatment, makes a\nsignificant difference to the estimated trends in incidence and mortality and\nto the projected trends. Allowing for population growth has a small effect on\nthe fits and the projections but is easy to include. Including details of the\ndemography adds substantially to the complexity of the model, increases the run\ntime by several orders of magnitude, but changes the fits and projections only\nslightly and to an extent that is less than the uncertainty inherent in the\ndata. We make specific recommendations for the kind of model that would be\nsuitable for understanding and managing HIV epidemics in east and southern\nAfrica."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Dynamical System Modeling Of Immune Reconstitution Following Allogeneic\n  Stem Cell Transplantation Identifies Patients At Risk For Adverse Outcomes"}, {"role": "assistant", "content": "Systems that evolve over time and follow mathematical laws as they do so, are\ncalled dynamical systems. Lymphocyte recovery and clinical outcomes in 41\nallograft recipients conditioned using anti-thymocyte globulin (ATG) and 4.5\nGray total-body-irradiation were studied to determine if immune reconstitution\ncould be described as a dynamical system. Survival, relapse, and graft vs. host\ndisease (GVHD) were not significantly different in two cohorts of patients\nreceiving different doses of ATG. However, donor-derived CD3+ (ddCD3) cell\nreconstitution was superior in the lower ATG dose cohort, and there were fewer\ninstances of donor lymphocyte infusion (DLI). Lymphoid recovery was plotted in\neach individual over time and demonstrated one of three sigmoid growth\npatterns; Pattern A (n=15), had rapid growth with high lymphocyte counts,\npattern B (n=14), slower growth with intermediate recovery and pattern C, poor\nlymphocyte reconstitution (n=10). There was a significant association between\nlymphocyte recovery patterns and both the rate of change of ddCD3 at day 30\npost-SCT and the clinical outcomes. GVHD was observed more frequently with\npattern A; relapse and DLI more so with pattern C, with a consequent survival\nadvantage in patients with patterns A and B. We conclude that evaluating immune\nreconstitution following SCT as a dynamical system may differentiate patients\nat risk of adverse outcomes and allow early intervention to modulate that risk."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Novel model for wine fermentation including the yeast dying phase"}, {"role": "assistant", "content": "This paper presents a novel model for wine fermentation including a death\nphase for yeast and the influence of oxygen on the process. A model for the\ninclusion of the yeast dying phase is derived and compared to a model taken\nfrom the literature. The modeling ability of the several models is analyzed by\ncomparing their simulation results."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Alignment of metabolic trajectories with application to metabonomic\n  toxicology"}, {"role": "assistant", "content": "Geometry of the metabolic trajectories is characteristic of the biological\nresponse (Keun, Ebbels et al. 2004). Yet, due to unavoidable inter-individual\nvariations, the exact trajectories characterising the biological responses\ndiffer. We examined whether the differences seen between metabolic trajectories\nof a specific treatment, correspond to the variations seen in the other\nbiological manifestations of the same treatment. Differences in trajectories\nwere measured via alignment procedures which introduced and implemented in this\nstudy. Our study revealed strong correlation between the scales of the aligned\ntrajectories of metabolic responses and the severity of the hepatocelluar\nlesions induced after administration of hydrazine. Thus the results confirm\nthat aligned trajectories are characteristic of a specific treatment. They then\ncan be used for comparison with other treatment specific or unknown metabolic\ntrajectories and can have many metabonomic applications such as preclinical\ntoxicological screening"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A New Characterization of Fine Scale Diffusion on the Cell Membrane"}, {"role": "assistant", "content": "We use a large single particle tracking data set to analyze the short time\nand small spatial scale motion of quantum dots labeling proteins in cell\nmembranes. Our analysis focuses on the jumps which are the changes in the\nposition of the quantum dots between frames in a movie of their motion.\nPreviously we have shown that the directions of the jumps are uniformly\ndistributed and the jump lengths can be characterized by a double power law\ndistribution.\n  Here we show that the jumps over a small number of time steps can be\ndescribed by scalings of a {\\em single} double power law distribution. This\nprovides additional strong evidence that the double power law provides an\naccurate description of the fine scale motion. This more extensive analysis\nprovides strong evidence that the double power law is a novel stable\ndistribution for the motion. This analysis provides strong evidence that an\nearlier result that the motion can be modeled as diffusion in a space of\nfractional dimension roughly 3/2 is correct. The form of the power law\ndistribution quantifies the excess of short jumps in the data and provides an\naccurate characterization of the fine scale diffusion and, in fact, this\ndistribution gives an accurate description of the jump lengths up to a few\nhundred nanometers. Our results complement of the usual mean squared\ndisplacement analysis used to study diffusion at larger scales where the\nproteins are more likely to strongly interact with larger membrane structures."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Caracteriza\\c{c}\\~ao de circuitos pecu\\'arios com base em redes de\n  movimenta\\c{c}\\~ao de animais"}, {"role": "assistant", "content": "A network is a set of nodes that are linked together by a set of edges.\nNetworks can represent any set of objects that have relations among themselves.\nCommunities are sets of nodes that are related in an important way, probably\nsharing common properties and/or playing similar roles within a network. When\nnetwork analysis is applied to study the livestock movement patterns, the\nepidemiological units of interest (farm premises, counties, states, countries,\netc.) are represented as nodes, and animal movements between the nodes are\nrepresented as the edges of a network. Unraveling a network structure, and\nhence the trade preferences and pathways, could be very useful to a researcher\nor a decision-maker. We implemented a community detection algorithm to find\nlivestock communities that is consistent with the definition of a livestock\nproduction zone, assuming that a community is a group of farm premises in which\nan animal is more likely to stay during its life time than expected by chance.\nWe applied this algorithm to the network of within animal movements made inside\nthe State of Mato Grosso, for the year of 2007. This database holds information\nabout 87,899 premises and 521,431 movements throughout the year, totalizing\n15,844,779 animals moved. The community detection algorithm achieved a network\npartition that shows a clear geographical and commercial pattern, two crucial\nfeatures to preventive veterinary medicine applications, and also has a\nmeaningful interpretation in trade networks where links emerge from the choice\nof trader nodes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Electronic health record phenotyping improves detection and screening of\n  type 2 diabetes in the general United States population: A cross-sectional,\n  unselected, retrospective study"}, {"role": "assistant", "content": "Objectives: In the United States, 25% of people with type 2 diabetes are\nundiagnosed. Conventional screening models use limited demographic information\nto assess risk. We evaluated whether electronic health record (EHR) phenotyping\ncould improve diabetes screening, even when records are incomplete and data are\nnot recorded systematically across patients and practice locations. Methods: In\nthis cross-sectional, retrospective study, data from 9,948 US patients between\n2009 and 2012 were used to develop a pre-screening tool to predict current type\n2 diabetes, using multivariate logistic regression. We compared (1) a full EHR\nmodel containing prescribed medications, diagnoses, and traditional predictive\ninformation, (2) a restricted EHR model where medication information was\nremoved, and (3) a conventional model containing only traditional predictive\ninformation (BMI, age, gender, hypertensive and smoking status). We\nadditionally used a random-forests classification model to judge whether\nincluding additional EHR information could increase the ability to detect\npatients with Type 2 diabetes on new patient samples. Results: Using a\npatient's full or restricted EHR to detect diabetes was superior to using basic\ncovariates alone (p<0.001). The random forests model replicated on out-of-bag\ndata. Migraines and cardiac dysrhythmias were negatively associated with type 2\ndiabetes, while acute bronchitis and herpes zoster were positively associated,\namong other factors. Conclusions: EHR phenotyping resulted in markedly superior\ndetection of type 2 diabetes in a general US population, could increase the\nefficiency and accuracy of disease screening, and are capable of picking up\nsignals in real-world records."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The pseudo-compartment method for coupling PDE and compartment-based\n  models of diffusion"}, {"role": "assistant", "content": "Spatial reaction-diffusion models have been employed to describe many\nemergent phenomena in biological systems. The modelling technique most commonly\nadopted in the literature implements systems of partial differential equations\n(PDEs), which assumes there are sufficient densities of particles that a\ncontinuum approximation is valid. However, due to recent advances in\ncomputational power, the simulation, and therefore postulation, of\ncomputationally intensive individual-based models has become a popular way to\ninvestigate the effects of noise in reaction-diffusion systems in which regions\nof low copy numbers exist.\n  The stochastic models with which we shall be concerned in this manuscript are\nreferred to as `compartment-based'. These models are characterised by a\ndiscretisation of the computational domain into a grid/lattice of\n`compartments'. Within each compartment particles are assumed to be well-mixed\nand are permitted to react with other particles within their compartment or to\ntransfer between neighbouring compartments.\n  We develop two hybrid algorithms in which a PDE is coupled to a\ncompartment-based model. Rather than attempting to balance average fluxes, our\nalgorithms answer a more fundamental question: `how are individual particles\ntransported between the vastly different model descriptions?' First, we present\nan algorithm derived by carefully re-defining the continuous PDE concentration\nas a probability distribution. Whilst this first algorithm shows strong\nconvergence to analytic solutions of test problems, it can be cumbersome to\nsimulate. Our second algorithm is a simplified and more efficient\nimplementation of the first, it is derived in the continuum limit over the PDE\nregion alone. We test our hybrid methods for functionality and accuracy in a\nvariety of different scenarios by comparing the averaged simulations to\nanalytic solutions of PDEs for mean concentrations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: On a chain of fragmentation equations for duplication-mutation dynamics\n  in DNA sequences"}, {"role": "assistant", "content": "Recent studies have revealed that for the majority of species the length\ndistributions of duplicated sequences in natural DNA follow a power-law tail.\nWe study duplication-mutation models for processes in natural DNA sequences and\nthe length distributions of exact matches computed from both synthetic and\nnatural sequences. Here we present a hierarchy of equations for various number\nof exact matches for these models. The reduction of these equations to one\nequation for pairs of exact repeats is found. Quantitative correspondence of\nsolutions of the equation to simulations is demonstrated."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Revisiting resource selection probability functions and single-visit\n  methods: Clarification and extensions"}, {"role": "assistant", "content": "Models accounting for imperfect detection are important. Single-visit methods\nhave been proposed as an alternative to multiple-visits methods to relax the\nassumption of closed population. Knape and Korner-Nievergelt (2015) showed that\nunder certain models of probability of detection single-visit methods are\nstatistically non-identifiable leading to biased population estimates. There is\na close relationship between estimation of the resource selection probability\nfunction (RSPF) using weighted distributions and single-visit methods for\noccupancy and abundance estimation. We explain the precise mathematical\nconditions needed for RSPF estimation as stated in Lele and Keim (2006). The\nidentical conditions, that remained unstated in our papers on single-visit\nmethodology, are needed for single-visit methodology to work. We show that the\nclass of admissible models is quite broad and does not excessively restrict the\napplication of the RSPF or the single-visit methodology. To complement the work\nby Knape and Korner-Nievergelt, we study the performance of multiple-visit\nmethods under the scaled logistic detection function and a much wider set of\nsituations. In general, under the scaled logistic detection function\nmultiple-visits methods also lead to biased estimates. As a solution to this\nproblem, we extend the single-visit methodology to a class of models that\nallows use of scaled probability function. We propose a Multinomial extension\nof single visit methodology that can be used to check whether the detection\nfunction satisfies the RSPF condition or not. Furthermore, we show that if the\nscaling factor depends on covariates, then it can also be estimated."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Valid auto-models for spatially autocorrelated occupancy and abundance\n  data"}, {"role": "assistant", "content": "Auto-logistic and related auto-models, implemented approximately as\nautocovariate regression, provide simple and direct modelling of spatial\ndependence. The autologistic model has been widely applied in ecology since\nAugustin, Mugglestone and Buckland (J. Appl. Ecol., 1996, 33, 339) analysed red\ndeer census data using a hybrid estimation approach, combining maximum\npseudo-likelihood estimation with Gibbs sampling of missing data. However\nDormann (Ecol. Model., 2007, 207, 234) questioned the validity of auto-logistic\nregression, giving examples of apparent underestimation of covariate parameters\nin analysis of simulated \"snouter\" data. Dormann et al. (Ecography, 2007, 30,\n609) extended this analysis to auto-Poisson and auto-normal models, reporting\nsimilar anomalies. All the above studies employ neighbourhood weighting schemes\ninconsistent with conditions (Besag, J. R. Stat. Soc., Ser. B, 1974, 36, 192)\nrequired for auto-model validity; furthermore the auto-Poisson analysis fails\nto exclude cooperative interactions. We show that all \"snouter\" anomalies are\nresolved by correct auto-model implementation. Re-analysis of the red deer data\nshows that invalid neighbourhood weightings generate only small estimation\nerrors for the full dataset, but larger errors occur on geographic subsamples.\nA substantial fraction of papers applying auto-logistic regression to\necological data use these invalid weightings, which are default options in the\nwidely used \"spdep\" spatial dependence package for R. Auto-logistic analyses\nusing invalid neighbourhood weightings will be erroneous to an extent that can\nvary widely. These analyses can easily be corrected by using valid\nneighbourhood weightings available in \"spdep\". The hybrid estimation approach\nfor missing data is readily adapted for valid neighbourhood weighting schemes\nand is implemented here in R for application to sparse presence-absence data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A maximum likelihood estimate of natural mortality for brown tiger prawn\n  (Penaeus esculentus) in Moreton Bay (Australia)"}, {"role": "assistant", "content": "The delay difference model was implemented to fit 21 years of brown tiger\nprawn (Penaeus esculentus) catch in Moreton Bay by maximum likelihood to assess\nthe status of this stock. Monte Carlo simulations testing of the stock\nassessment software coded in C++ showed that the model could estimate\nsimultaneously natural mortality in addition to catchability, recruitment and\ninitial biomasses. Applied to logbooks data collected from 1990 to 2010, this\nimplementation of the delay difference provided for the first time an estimate\nof natural mortality for brown tiger prawn in Moreton Bay, equal to $0.031 \\pm\n0.002$ week$^{-1}$. This estimate is approximately 30\\% lower than the value of\nnatural mortality (0.045 week$^{-1}$) used in previous stock assessments of\nthis species."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Pigeons trade efficiency for stability in response to level of challenge\n  during confined flight"}, {"role": "assistant", "content": "Individuals traversing challenging obstacles are faced with a decision: they\ncan adopt traversal strategies that minimally disrupt their normal locomotion\npatterns or they can adopt strategies that substantially alter their gait,\nconferring new advantages and disadvantages. We flew pigeons (Columba livia)\nthrough an array of vertical obstacles in a flight arena, presenting them with\nthis choice. The pigeons selected either a strategy involving only a slight\npause in the normal wingbeat cycle, or a wings folded posture granting reduced\nefficiency but greater stability should a misjudgment lead to collision. The\nmore stable but less efficient flight strategy was not employed to traverse\neasy obstacles with wide gaps for passage, but came to dominate the postures\nused as obstacle challenge increased with narrower gaps and there was a greater\nchance of a collision. These results indicate that birds weigh potential\nobstacle negotiation strategies and estimate task difficulty during locomotor\npattern selection."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Generalization of Carey's Equality and a Theorem on Stationary\n  Population"}, {"role": "assistant", "content": "Carey's Equality pertaining to stationary models is well known. In this\npaper, we have stated and proved a fundamental theorem related to the formation\nof this Equality. This theorem will provide an in-depth understanding of the\nrole of each captive subject, and their corresponding follow-up duration in a\nstationary population. We have demonstrated a numerical example of a captive\ncohort and the survival pattern of medfly populations. These results can be\nadopted to understand age-structure and aging process in stationary and\nnon-stationary population population models. Key words: Captive cohort, life\nexpectancy, symmetric patterns."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Whether relative respiration in trees can be constant: a discussion of a\n  scaling hypothesis"}, {"role": "assistant", "content": "Respiration measurements of whole tree plants have been reported that give\nevidence that the relative per volume/mass unit respiration decreases with\nincrease of tree body size. In this study, based on the available data\npublished a question was explored if the relative per area unit respiration in\ntrees can be a constant, independent of the surface area size. There is a\ndefinite gap in the published data when the allometric studies of tree body\nstructure do not intercept with studies on trees respiration. Thus the question\nwas studied with the help of indirect comparison between various data. The\ncomparison showed that the scaling exponents, volume vs. surface area and\nrespiration vs. stem volume, are slightly larger than they should be for the\nhypothesis of the relative respiration constancy to hold. The data studied give\nevidence that the relative per area unit respiration slightly increases with\nthe increase in tree surface area. Possible explanations of the relationship\ninclude a different distribution of metabolically active parts of stem and\nhigher nitrogen content in larger trees. Also, the published datasets might\ninclude large fast growing trees, which imply that larger trees grow faster and\nhence have higher per unit surface area growth respiration. A crucial\nexperiment is required in which the respiration measurements were performed for\nthe same data as the measurements of scaling between stem volume and surface\narea."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Data management to support reproducible research"}, {"role": "assistant", "content": "We describe the current state and future plans for a set of tools for\nscientific data management (SDM) designed to support scientific transparency\nand reproducible research. SDM has been in active use at our MRI Center for\nmore than two years. We designed the system to be used from the beginning of a\nresearch project, which contrasts with conventional end-state databases that\naccept data as a project concludes. A number of benefits accrue from using\nscientific data management tools early and throughout the project, including\ndata integrity as well as reuse of the data and of computational methods."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Behavioral modulation of the coexistence between Apis melifera and\n  Varroa destructor: A defense against colony colapse disorder?"}, {"role": "assistant", "content": "Colony Collapse Disorder has become a global problem for beekeepers and for\nthe crops which depend on bee polination. Multiple factors are known to\nincrease the risk of colony colapse, and the ectoparasitic mite Varroa\ndestructor that parasitizes honey bees is among the main threats to colony\nhealth. Although this mite is unlikely to, by itself, cause the collapse of\nhives, it plays an important role as it is a vector for many viral diseases.\nSuch diseases are among the likely causes for Colony Collapse Disorder.\n  The effects of V. destructor infestation are disparate in different parts of\nthe world. Greater morbidity - in the form of colony losses - has been reported\nin colonies of European honey bees (EHB) in Europe, Asia and North America.\nHowever, this mite has been present in Brasil for many years and yet there are\nno reports of Africanized honey bee (AHB) colonies losses.\n  Studies carried out in Mexico showed that some resistance behaviors to the\nmite - especially grooming and hygienic behavior - appear to be different in\neach subspecies. Could those difference in behaviors explain why the AHB are\nless susceptible to Colony Collapse Disorder?\n  In order to answer this question, we propose a mathematical model of the\ncoexistence dynamics of these two species, the bee and the mite, to analyze the\nrole of resistance behaviors in the overall health of the colony, and, as a\nconsequence, its ability to face epidemiological challenges."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Escape path complexity and its context dependency in Pacific blue-eyes\n  (Pseudomugil signifer)"}, {"role": "assistant", "content": "The escape trajectories animals take following a predatory attack appear to\nshow high degrees of apparent 'randomness' - a property that has been described\nas 'protean behaviour'. Here we present a method of quantifying the escape\ntrajectories of individual animals using a path complexity approach. When fish\n(Pseudomugil signifer) were attacked either on their own or in groups, we find\nthat an individual's path rapidly increases in entropy (our measure of\ncomplexity) following the attack. For individuals on their own, this entropy\nremains elevated (indicating a more random path) for a sustained period (10\nseconds) after the attack, whilst it falls more quickly for individuals in\ngroups. The entropy of the path is context dependent. When attacks towards\nsingle fish come from greater distances, a fish's path shows less complexity\ncompared to attacks that come from short range. This context dependency effect\ndid not exist, however, when individuals were in groups. Nor did the path\ncomplexity of individuals in groups depend on a fish's local density of\nneighbours. We separate out the components of speed and direction changes to\ndetermine which of these components contributes to the overall increase in path\ncomplexity following an attack. We found that both speed and direction measures\ncontribute similarly to an individual's path's complexity in absolute terms.\nOur work highlights the adaptive behavioural tactics that animals use to avoid\npredators and also provides a novel method for quantifying the escape\ntrajectories of animals."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Study of N-Acetyl aspartic acid/Creatine Ratio in the White Matter of\n  HIV Positive Patients and Its Application"}, {"role": "assistant", "content": "A total of 50 patients were enrolled in the study, and MRI brain with MR\nspectroscopy was done. Tuberculosis was the most common neurologic disease\nfound in the HIV positive group, consisting of 9 patients. Seven of these\npatients had tuberculous meningitis amongst which a further 2 had vasculitic\ninfarcts.PML was seen in 6 patients. NAA to Cr ratio was found to be reduced in\nall the patients, and in fact the value was further reduced compared to the HIV\npositive group as a whole. Raised choline and myoInositol peaks were also found\nin all the patients. MR Spectroscopy showed lipid lactate peaks confirming the\ndiagnosis. 2 patients had HIV encephalopathy on the imaging study. Their\nspectra also revealed lowered NAA peaks along with raised choline peaks. 2\npatients with cryptococcosis showed characteristic imaging finding of enlarged\nVirchow Robin (perivascular) spaces. They revealed elevated choline peaks in\naddition to reduced NAA. The values of NAA to Cr ratio were determined after\nduly processing the spectroscopic data from both cases and controls. Each group\n(Cases and controls) were divided on the basis of age into two age groups:\nLesser than or equal to 40 years, and greater than 40 years. In all three\ngroups the values of the mean NAA to Cr ratio ratio was significantly (p-value\nless than 0.05) reduced in comparison to controls. An ancillary finding was the\nreduction of NAA to Cr ratio further in cases of PML. Combined use of both the\nconventional and advanced MRI sequences is advisable as spectroscopy helps in\nconfirming the diagnosis of opportunistic infection of the CNS in HIV positive\npatients. NAA to Cr ratio ratio is reduced in HIV positive patients and is a\nmarker for HIV infection of the brain even in the absence of imaging findings\nof HIV encephalopathy or when the patient is symptomatic due to neurological\ndisease of other etiologies."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Breast Cancer Data Analytics With Missing Values: A study on Ethnic, Age\n  and Income Groups"}, {"role": "assistant", "content": "An analysis of breast cancer incidences in women and the relationship between\nethnicity and survival rate has been an ongoing study with recorded incidences\nof missing values in the secondary data. In this paper, we study and report the\nresults of breast cancer survival rate by ethnicity, age and income groups from\nthe dataset collected for 53593 patients in South East England between the\nyears 1998 and 2003. In addition to this, we also predict the missing values\nfor the ethnic groups in the dataset. The principle findings in our study\nsuggest that: 1) women of white ethnicity in South East England have a highest\npercentage of survival rate when compared to the black ethnicity, 2) High\nincome groups have higher survival rates to that of lower income groups and 3)\nAge groups between 80-95 have lower percentage of survival rate."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Expectation-Maximization Binary Clustering for Behavioural Annotation"}, {"role": "assistant", "content": "We present a variant of the well sounded Expectation-Maximization Clustering\nalgorithm that is constrained to generate partitions of the input space into\nhigh and low values. The motivation of splitting input variables into high and\nlow values is to favour the semantic interpretation of the final clustering.\nThe Expectation-Maximization binary Clustering is specially useful when a\nbimodal conditional distribution of the variables is expected or at least when\na binary discretization of the input space is deemed meaningful. Furthermore,\nthe algorithm deals with the reliability of the input data such that the larger\ntheir uncertainty the less their role in the final clustering. We show here its\nsuitability for behavioural annotation of movement trajectories. However, it\ncan be considered as a general purpose algorithm for the clustering or\nsegmentation of multivariate data or temporal series."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Nonlinear Mixed-Effect Models for Prostate-Specific Antigen Kinetics and\n  Link with Survival in the Context of Metastatic Prostate Cancer: a Comparison\n  by Simulation of Two-Stage and Joint Approaches"}, {"role": "assistant", "content": "In metastatic castration-resistant prostate cancer (mCRPC) clinical trials,\nthe assessment of treatment efficacy essentially relies on the time-to-death\nand the kinetics of prostate-specific antigen (PSA). Joint modelling has been\nincreasingly used to characterize the relationship between a time-to-event and\na biomarker kinetics but numerical difficulties often limit this approach to\nlinear models. Here we evaluated by simulation the capability of a new feature\nof the Stochastic Approximation Expectation-Maximization algorithm in Monolix\nto estimate the parameters of a joint model where PSA kinetics was defined by a\nmechanistic nonlinear mixed-effect model. The design of the study and the\nparameter values were inspired from one arm of a clinical trial. Increasingly\nhigh levels of association between PSA and survival were considered and results\nwere compared with those found using two simplified alternatives to joint\nmodel, a two-stage and a joint sequential model. We found that joint model\nallowed for a precise estimation of all longitudinal and survival parameters.\nIn particular the effect of PSA kinetics on survival could be precisely\nestimated, regardless of the strength of the association. In contrast, both\nsimplified approaches led to bias on longitudinal parameters and two-stage\nmodel systematically underestimated the effect of PSA kinetics on survival. In\nsummary we showed that joint model can be used to characterize the relationship\nbetween a nonlinear kinetics and survival. This opens the way for the use of\nmore complex and physiological models to improve treatment evaluation and\nprediction in oncology."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Outcome prediction in mathematical models of immune response to\n  infection"}, {"role": "assistant", "content": "Clinicians need to predict patient outcomes with high accuracy as early as\npossible after disease inception. In this manuscript, we show that\npatient-to-patient variability sets a fundamental limit on outcome prediction\naccuracy for a general class of mathematical models for the immune response to\ninfection. However, accuracy can be increased at the expense of delayed\nprognosis. We investigate several systems of ordinary differential equations\n(ODEs) that model the host immune response to a pathogen load. Advantages of\nsystems of ODEs for investigating the immune response to infection include the\nability to collect data on large numbers of `virtual patients', each with a\ngiven set of model parameters, and obtain many time points during the course of\nthe infection. We implement patient-to-patient variability $v$ in the ODE\nmodels by randomly selecting the model parameters from Gaussian distributions\nwith variance $v$ that are centered on physiological values. We use logistic\nregression with one-versus-all classification to predict the discrete\nsteady-state outcomes of the system. We find that the prediction algorithm\nachieves near $100\\%$ accuracy for $v=0$, and the accuracy decreases with\nincreasing $v$ for all ODE models studied. The fact that multiple steady-state\noutcomes can be obtained for a given initial condition, i.e. the basins of\nattraction overlap in the space of initial conditions, limits the prediction\naccuracy for $v>0$. Increasing the elapsed time of the variables used to train\nand test the classifier, increases the prediction accuracy, while adding\nexplicit external noise to the ODE models decreases the prediction accuracy.\nOur results quantify the competition between early prognosis and high\nprediction accuracy that is frequently encountered by clinicians."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Probabilistic modeling of occurring substitutions in PAR-CLIP data"}, {"role": "assistant", "content": "Photoactivatable ribonucleoside-enhanced cross-linking and\nimmunoprecipitation (PAR-CLIP) is an experimental method based on\nnext-generation sequencing for identifying the RNA interaction sites of a given\nprotein. The method deliberately inserts T-to-C substitutions at the\nRNA-protein interaction sites, which provides a second layer of evidence\ncompared to other CLIP methods. However, the experiment includes several\nsources of noise which cause both low-frequency errors and spurious\nhigh-frequency alterations. Therefore, rigorous statistical analysis is\nrequired in order to separate true T-to-C base changes, following\ncross-linking, from noise. So far, most of the existing PAR-CLIP data analysis\nmethods focus on discarding the low-frequency errors and rely on high-frequency\nsubstitutions to report binding sites, not taking into account the possibility\nof high-frequency false positive substitutions. Here, we introduce BMix, a new\nprobabilistic method which explicitly accounts for the sources of noise in PAR-\nCLIP data and distinguishes cross-link induced T-to-C substitutions from low\nand high-frequency erroneous alterations. We demonstrate the superior speed and\naccuracy of our method compared to existing approaches on both simulated and\nreal, publicly available human datasets. The model is implemented in the Matlab\ntoolbox BMix, freely available at www.cbg.bsse.ethz.ch/software/BMix."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Path Similarity Analysis: a Method for Quantifying Macromolecular\n  Pathways"}, {"role": "assistant", "content": "Diverse classes of proteins function through large-scale conformational\nchanges; sophisticated enhanced sampling methods have been proposed to generate\nthese macromolecular transition paths. As such paths are curves in a\nhigh-dimensional space, they have been difficult to compare quantitatively, a\nprerequisite to, for instance, assess the quality of different sampling\nalgorithms. The Path Similarity Analysis (PSA) approach alleviates these\ndifficulties by utilizing the full information in 3N-dimensional trajectories\nin configuration space. PSA employs the Hausdorff or Fr\\'echet path\nmetrics---adopted from computational geometry---enabling us to quantify path\n(dis)similarity, while the new concept of a Hausdorff-pair map permits the\nextraction of atomic-scale determinants responsible for path differences.\nCombined with clustering techniques, PSA facilitates the comparison of many\npaths, including collections of transition ensembles. We use the closed-to-open\ntransition of the enzyme adenylate kinase (AdK)---a commonly used testbed for\nthe assessment enhanced sampling algorithms---to examine multiple microsecond\nequilibrium molecular dynamics (MD) transitions of AdK in its substrate-free\nform alongside transition ensembles from the MD-based dynamic importance\nsampling (DIMS-MD) and targeted MD (TMD) methods, and a geometrical targeting\nalgorithm (FRODA). A Hausdorff pairs analysis of these ensembles revealed, for\ninstance, that differences in DIMS-MD and FRODA paths were mediated by a set of\nconserved salt bridges whose charge-charge interactions are fully modeled in\nDIMS-MD but not in FRODA. We also demonstrate how existing trajectory analysis\nmethods relying on pre-defined collective variables, such as native contacts or\ngeometric quantities, can be used synergistically with PSA, as well as the\napplication of PSA to more complex systems such as membrane transporter\nproteins."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A branching network model for T cell dissemination in adaptive immune\n  response"}, {"role": "assistant", "content": "In this paper we consider a model based on branching process theory for the\nproliferation and the dissemination network of T cells in the adaptive immune\nresponse. A multi-type Galton Watson branching process is assumed as the basic\nproliferation mechanism, associated to the migration of T cells of the\ndifferent generations from the draining lymph node to the spleen and other\nlymphoid organs. Time recursion equations for the mean values and the\ncovariance matrices of the the cell population counts are derived in all the\ncompartments of the network model. Moreover, a normal approximation of the\nlog-likelihood function of the cell relative frequencies is derived, which\nallows one to obtain estimates of both the probability parameters of the\nbranching process and the migration rates in the various compartments of the\nnetwork."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Information and long term memory in calcium signals"}, {"role": "assistant", "content": "Unicellular organisms are open metabolic systems that need to process\ninformation about their external environment in order to survive. In most types\nof tissues and organisms, cells use calcium signaling to carry information from\nthe extracellular side of the plasma membrane to the different metabolic\ntargets of their internal medium. This information might be encoded in the\namplitude, frequency, duration, waveform or timing of the calcium oscillations.\nThus, specific information coming from extracellular stimuli can be encoded in\nthe calcium signal and decoded again later in different locations within the\ncell. Despite its cellular importance, little is known about the quantitative\ninformative properties of the calcium concentration dynamics inside the cell.\nIn order to understand some of these informational properties, we have studied\nexperimental Ca2+ series of Xenopus laevis oocytes under different external pH\nstimulus. The data has been analyzed by means of information-theoretic\napproaches such as Conditional Entropy, Information Retention, and other\nnon-linear dynamics tools such as the power spectra, the Largest Lyapunov\nexponent and the bridge detrended Scaled Window Variance analysis. We have\nquantified the biomolecular information flows of the experimental data in bits,\nand essential aspects of the information contained in the experimental calcium\nfluxes have been exhaustively analyzed. Our main result shows that inside all\nthe studied intracellular Ca2+ flows a highly organized informational structure\nemerge, which exhibit deterministic chaotic behavior, long term memory and\ncomplex oscillations of the uncertainty reduction based on past values. The\nunderstanding of the informational properties of calcium signals is one of the\nkey elements to elucidate the physiological functional coupling of the cell and\nthe integrative dynamics of cellular life."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: RNeXML: a package for reading and writing richly annotated phylogenetic,\n  character, and trait data in R"}, {"role": "assistant", "content": "NeXML is a powerful and extensible exchange standard recently proposed to\nbetter meet the expanding needs for phylogenetic data and metadata sharing.\nHere we present the RNeXML package, which provides users of the R programming\nlanguage with easy-to-use tools for reading and writing NeXML documents,\nincluding rich metadata, in a way that interfaces seamlessly with the extensive\nlibrary of phylogenetic tools already available in the R ecosystem."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Probabilistic Approach for Evaluating Metabolite Sample Integrity"}, {"role": "assistant", "content": "The success of metabolomics studies depends upon the \"fitness\" of each\nbiological sample used for analysis: it is critical that metabolite levels\nreported for a biological sample represent an accurate snapshot of the studied\norganism's metabolite profile at time of sample collection. Numerous factors\nmay compromise metabolite sample fitness, including chemical and biological\nfactors which intervene during sample collection, handling, storage, and\npreparation for analysis. We propose a probabilistic model for the quantitative\nassessment of metabolite sample fitness. Collection and processing of nuclear\nmagnetic resonance (NMR) and ultra-performance liquid chromatography (UPLC-MS)\nmetabolomics data is discussed. Feature selection methods utilized for\nmultivariate data analysis are briefly reviewed, including feature clustering\nand computation of latent vectors using spectral methods. We propose that the\ntime-course of metabolite changes in samples stored at different temperatures\nmay be utilized to identify changing-metabolite-to-stable-metabolite ratios as\nmarkers of sample fitness. Tolerance intervals may be computed to characterize\nthese ratios among fresh samples. In order to discover additional structure in\nthe data relevant to sample fitness, we propose using data labeled according to\nthese ratios to train a Dirichlet process mixture model (DPMM) for assessing\nsample fitness. DPMMs are highly intuitive since they model the metabolite\nlevels in a sample as arising from a combination of processes including, e.g.,\nnormal biological processes and degradation- or contamination-inducing\nprocesses. The outputs of a DPMM are probabilities that a sample is associated\nwith a given process, and these probabilities may be incorporated into a final\nclassifier for sample fitness."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Cell-cycle-synchronized, oscillatory expression of a negatively\n  autoregulated gene in E. coli"}, {"role": "assistant", "content": "Engineering genetic networks to be both predictable and robust is a key\nchallenge in synthetic biology. Synthetic circuits must reliably function in\ndynamic, stochastic and heterogeneous environments, and simple circuits can be\nstudied to refine complex gene-regulation models. Although robust behaviours\nsuch as genetic oscillators have been designed and implemented in prokaryotic\nand eukaryotic organisms, a priori genetic engineering of even simple networks\nremains difficult, and many aspects of cell and molecular biology critical to\nengineering robust networks are still inadequately characterized. Particularly,\nperiodic processes such as gene doubling and cell division are rarely\nconsidered in gene regulatory models, which may become more important as\nsynthetic biologists utilize new tools for chromosome integration. We studied a\nchromosome-integrated, negative-feedback circuit based upon the bacteriophage\n{\\lambda} transcriptional repressor Cro and observed strong, feedback-dependent\noscillations in single-cell time traces. This finding was surprising due to a\nlack of cooperativity, long delays or fast protein degradation. We further show\nthat oscillations are synchronized to the cell cycle by gene duplication, with\nphase shifts predictably correlating with estimated gene doubling times.\nFurthermore, we characterized the influence of negative feedback on the\nmagnitude and dynamics of noise in gene expression. Our results show that\ncell-cycle effects must be accounted for in accurate, predictive models for\neven simple gene circuits. Cell-cycle-periodic expression of {\\lambda} Cro also\nsuggests an explanation for cell-size dependence in lysis probability and an\nevolutionary basis for site-specific {\\lambda} integration."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Cancer risk is not (just) bad luck"}, {"role": "assistant", "content": "Tomasetti and Vogelstein recently proposed that the majority of variation in\ncancer risk among tissues is due to \"bad luck,\" that is, random mutations\narising during DNA replication in normal noncancerous stem cells. They\ngeneralize this finding to cancer overall, claiming that \"the stochastic\neffects of DNA replication appear to be the major contributor to cancer in\nhumans.\" We show that this conclusion results from a logical fallacy based on\nignoring the influence of population heterogeneity in correlations exhibited at\nthe level of the whole population. Because environmental and genetic factors\ncannot explain the huge differences in cancer rates between different organs,\nit is wrong to conclude that these factors play a minor role in cancer rates.\nIn contrast, we show that one can indeed measure huge differences in cancer\nrates between different organs and, at the same time, observe a strong effect\nof environmental and genetic factors in cancer rates."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Reconciling transport models across scales: the role of volume exclusion"}, {"role": "assistant", "content": "Diffusive transport is a universal phenomenon, throughout both biological and\nphysical sciences, and models of diffusion are routinely used to interrogate\ndiffusion-driven processes. However, most models neglect to take into account\nthe role of volume exclusion, which can significantly alter diffusive\ntransport, particularly within biological systems where the diffusing particles\nmight occupy a significant fraction of the available space. In this work we use\na random walk approach to provide a means to reconcile models that incorporate\ncrowding effects on different spatial scales. Our work demonstrates that\ncoarse-grained models incorporating simplified descriptions of excluded volume\ncan be used in many circumstances, but that care must be taken in pushing the\ncoarse-graining process too far."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: img2net: Automated network-based analysis of imaged phenotypes"}, {"role": "assistant", "content": "Automated analysis of imaged phenotypes enables fast and reproducible\nquantification of biologically relevant features. Despite recent developments,\nrecordings of complex, networked structures, such as: leaf venation patterns,\ncytoskeletal structures, or traffic networks, remain challenging to analyze.\nHere we illustrate the applicability of img2net to automatedly analyze such\nstructures by reconstructing the underlying network, computing relevant network\nproperties, and statistically comparing networks of different types or under\ndifferent conditions. The software can be readily used for analyzing image data\nof arbitrary 2D and 3D network-like structures. img2net is open-source software\nunder the GPL and can be downloaded from\nhttp://mathbiol.mpimp-golm.mpg.de/img2net/, where supplementary information and\ndata sets for testing are provided."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Topological phenotypes constitute a new dimension in the phenotypic\n  space of leaf venation networks"}, {"role": "assistant", "content": "The leaves of angiosperms contain highly complex venation networks consisting\nof recursively nested, hierarchically organized loops. We describe a new\nphenotypic trait of reticulate vascular networks based on the topology of the\nnested loops. This phenotypic trait encodes information orthogonal to widely\nused geometric phenotypic traits, and thus constitutes a new dimension in the\nleaf venation phenotypic space. We apply our metric to a database of 186 leaves\nand leaflets representing 137 species, predominantly from the Burseraceae\nfamily, revealing diverse topological network traits even within this single\nfamily. We show that topological information significantly improves\nidentification of leaves from fragments by calculating a \"leaf venation\nfingerprint\" from topology and geometry. Further, we present a phenomenological\nmodel suggesting that the topological traits can be explained by noise effects\nunique to specimen during development of each leaf which leave their imprint on\nthe final network. This work opens the path to new quantitative identification\ntechniques for leaves which go beyond simple geometric traits such as vein\ndensity and is directly applicable to other planar or sub-planar networks such\nas blood vessels in the brain."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Flow similarity, stochastic branching, and quarter power scaling in\n  plants"}, {"role": "assistant", "content": "The origin of allometric scaling patterns that are multiples of 1/4 has long\nfascinated biologists. While not universal, scaling relationships with\nexponents that are close to multiples of 1/4 are common and have been described\nin all major clades. Foremost among these relationships is the 3/4 scaling of\nmetabolism with mass which underpins the 1/4 power dependence of biological\nrates and times. Several models have been advanced to explain the underlying\nmechanistic drivers of such patterns, but questions regarding a disconnect\nbetween model structures and empirical data have limited their widespread\nacceptance. Notable among these is a fractal branching model which predicts\npower law scaling of both metabolism and physical dimensions. While a power law\nis a useful first approximation to many datasets, non-linearity in some large\ndata compilations suggest the possibility of more complex or alternative\nmechanisms. Here, we first show that quarter power scaling can be derived using\nonly the preservation of volume flow rate and velocity as model constraints.\nApplying our model to the specific case of land plants, we show that\nincorporating biomechanical principles and allowing different parts of plant\nbranching networks to be optimized to serve different functions predicts\nnon-linearity in allometric relationships, and helps explain why interspecific\nscaling exponents covary along a fractal continuum. We also demonstrate that\nwhile branching may be a stochastic process, due to the conservation of volume,\ndata may still be consistent with the expectations for a fractal network when\none examines subtrees within a tree. Data from numerous sources at the level of\nplant shoots, stems, petioles, and leaves show strong agreement with our model\npredictions. This novel theoretical framework provides an easily testable\nalternative to current general models of plant metabolic allometry."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: An automated workflow for parallel processing of large multiview SPIM\n  recordings"}, {"role": "assistant", "content": "Multiview light sheet fluorescence microscopy (LSFM) allows to image\ndeveloping organisms in 3D at unprecedented temporal resolution over long\nperiods of time. The resulting massive amounts of raw image data requires\nextensive processing interactively via dedicated graphical user interface (GUI)\napplications. The consecutive processing steps can be easily automated and the\nindividual time points can be processed independently, which lends itself to\ntrivial parallelization on a high performance cluster (HPC). Here we introduce\nan automated workflow for processing large multiview, multi-channel,\nmulti-illumination time-lapse LSFM data on a single workstation or in parallel\non a HPC. The pipeline relies on snakemake to resolve dependencies among\nconsecutive processing steps and can be easily adapted to any cluster\nenvironment for processing LSFM data in a fraction of the time required to\ncollect it."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: pyBioSig: optimizing group discrimination using genetic algorithms for\n  biosignature discovery"}, {"role": "assistant", "content": "In medical sciences, a biomarker is \"a characteristic that is objectively\nmeasured and evaluated as an indicator of normal biological processes,\npathogenic processes, or pharmacologic responses to a therapeutic\nintervention\". Molecular experiments are providing rapid and systematic\napproaches to search for biomarkers, but because single-molecule biomarkers\nhave shown a disappointing lack of robustness for clinical diagnosis,\nresearchers have begun searching for distinctive sets of molecules, called\n\"biosignatures\". However, the most popular statistics are not appropriate for\ntheir identification, and the number of possible biosignatures to be tested is\nfrequently intractable. In the present work, we developed a \"multivariate\nfilter\" using genetic algorithms (GA) as a feature (gene) selector to optimize\na measure of intra-group cohesion and inter-group dispersion. This method was\nimplemented using Python and R (pyBioSig, available at\nhttps://github.com/fredgca/pybiosig under LGPL) and can be manipulated via\ngraphical interface or Python scripts. Using it, we were able to identify\nputative biosignatures composed by just a few genes and capable of recovering\nmultiple groups simultaneously in a hierarchical clustering, even ones that\nwere not recovered using the whole transcriptome, within a feasible length of\ntime using a personal computer. Our results allowed us to conclude that using\nGA to optimize our new intra-group cohesion and inter-group dispersion measure\nis a clear, effective, and computationally feasible strategy for the\nidentification of putative \"omical\" biosignatures that could support\ndiscrimination among multiple groups simultaneously."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Group Size Effect on the Success of Wolves Hunting"}, {"role": "assistant", "content": "Social foraging shows unexpected features such as the existence of a group\nsize threshold to accomplish a successful hunt. Above this threshold,\nadditional individuals do not increase the probability of capturing the prey.\nRecent direct observations of wolves in Yellowstone Park show that the group\nsize threshold when hunting its most formidable prey, bison, is nearly three\ntimes greater than when hunting elk, a prey that is considerably less\nchallenging to capture than bison. These observations provide empirical support\nto a computational particle model of group hunting which was previously shown\nto be effective in explaining why hunting success peaks at apparently small\npack sizes when hunting elk. The model is based on considering two critical\ndistances between wolves and prey: the minimal safe distance at which wolves\nstand from the prey, and the avoidance distance at which wolves move away from\neach other when they approach the prey. The minimal safe distance is longer\nwhen the prey is more dangerous to hunt. We show that the model explains\neffectively that the group size threshold is greater when the minimal safe\ndistance is longer. Although both distances are longer when the prey is more\ndangerous, they contribute oppositely to the value of the group size threshold:\nthe group size threshold is smaller when the avoidance distance is longer. This\nunexpected mechanism gives rise to a global increase of the group size\nthreshold when considering bison with respect to elk, but other prey more\ndangerous than elk can lead to specific critical distances that can give rise\nto the same group size threshold. Our results show that the computational model\ncan guide further research on group size effects, suggesting that more\nexperimental observations should be obtained for other kind of prey as e.g.\nmoose."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: CCA Fuzzy Land Cover: a new method for classifying vegetation types and\n  coverages and its implications for deforestation analysis"}, {"role": "assistant", "content": "Land cover has been evaluated and classified on the basis of general features\nusing reflectance or digital levels of photographic or satellite data. One of\nthe most common methodologies based on CORINE land cover (Coordination of\nInformation on the Environment) data, which classifies natural cover according\nto a small number of categories. This method produces generalizations about the\ninventoried areas, resulting in the loss of important floristic and structural\ninformation about vegetation types present (such as palm groves, tall dense\nmangroves, and dense forests). This classification forfeits relevant\ninformation on sites with high heterogeneity and diversity. Especially in the\ntropics, simplification of coverage types reaches its maximum level with the\nuse of deforestation analysis, particularly when it is reduced to the two\nclasses of forests and nonforests. As this paper demonstrates, these results\nhave considerable consequences for political efforts to conserve the\nbiodiversity of megadiverse countries. We designed a new methodological\napproach that incorporates biological distinctiveness combined with\nphytosociological classification of vegetation and its relation to physical\nfeatures. This approach is based on parameters obtained through canonical\ncorrespondence analysis on a fuzzy logic model, which are used to construct\nmultiple coverage maps. This tool is useful for monitoring and analyzing\nvegetation dynamics, since it maintains the typological integrity of a\ncartographic series. The methodology creates cartographic series congruent in\ntime and scale, can be applied to multiple and varied satellite inputs, and\nalways evaluates the same model parameters. We tested this new method in the\nsouthwestern Colombian Caribbean region and compared our results with those\nfrom what we believe are outdated tools used in other analyses of deforestation\naround the world."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A solution for reducing high bias in estimates of stored carbon in\n  tropical forests (aboveground biomass)"}, {"role": "assistant", "content": "A nondestructive method for estimating the amount of carbon stored by\nindividuals, communities, vegetation types, and coverages, as well as their\nvolume and aboveground biomass, is presented. This methodology is based on\ninformation on carbon stocks obtained through three-dimensional analysis of\ntree architecture and artificial neural networks. This technique accurately\nincorporates the diversity of plant forms measured in plots, transects, and\nrelev\\'es. Stored carbon in any vegetation type is usually calculated as half\nthe biomass of sampled individuals, estimated with allometric formulas. The\nmost complete of these formulas incorporate diameter, height, and specific\ngravity of wood but do not consider the variation in carbon stored in different\norgans or different species, nor do they include information on the wide array\nof architectures present in different plant communities. To develop these\nallometric models, many individuals of different species must be sacrificed to\nidentify and validate samples and to minimize error. It is common to find\ncutting-edge studies that encourage logging to improve estimates of carbon. In\nour approach we replace this destructive methodology with a new technique for\nquantifying global aboveground carbon. We demonstrate that carbon content in\nforest aboveground biomass in the pantropics could rise to 723.97 Pg C. This\nstudy shows that a reevaluation of climatic and ecological models is needed to\nmove toward a better understanding of the adverse effects of climate change,\ndeforestation, and degradation of tropical vegetation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Ribosome Flow Model on a Ring"}, {"role": "assistant", "content": "The asymmetric simple exclusion process (ASEP) is an important model from\nstatistical physics describing particles that hop randomly from one site to the\nnext along an ordered lattice of sites, but only if the next site is empty.\nASEP has been used to model and analyze numerous multiagent systems with local\ninteractions including the flow of ribosomes along the mRNA strand.\n  In ASEP with periodic boundary conditions a particle that hops from the last\nsite returns to the first one. The mean field approximation of this model is\nreferred to as the ribosome flow model on a ring (RFMR). The RFMR may be used\nto model both synthetic and endogenous gene expression regimes.\n  We analyze the RFMR using the theory of monotone dynamical systems. We show\nthat it admits a continuum of equilibrium points and that every trajectory\nconverges to an equilibrium point. Furthermore, we show that it entrains to\nperiodic transition rates between the sites. We describe the implications of\nthe analysis results to understanding and engineering cyclic mRNA translation\nin-vitro and in-vivo."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Modeling, Simulating, and Parameter Fitting of Biochemical Kinetic\n  Experiments"}, {"role": "assistant", "content": "In many chemical and biological applications, systems of differential\nequations containing unknown parameters are used to explain empirical\nobservations and experimental data. The DEs are typically nonlinear and\ndifficult to analyze, requiring numerical methods to approximate the solutions.\nCompounding this difficulty are the unknown parameters in the DE system, which\nmust be given specific numerical values in order for simulations to be run.\n  Estrogen receptor protein dimerization is used as an example to demonstrate\nmodel construction, reduction, simulation, and parameter estimation.\nMathematical, computational, and statistical methods are applied to empirical\ndata to deduce kinetic parameter estimates and guide decisions regarding future\nexperiments and modeling. The process demonstrated serves as a pedagogical\nexample of quantitative methods being used to extract parameter values from\nbiochemical data models."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Large-scale EM Analysis of the Drosophila Antennal Lobe with\n  Automatically Computed Synapse Point Clouds"}, {"role": "assistant", "content": "The promise of extracting connectomes and performing useful analysis on large\nelectron microscopy (EM) datasets has been an elusive dream for many years.\nTracing in even the smallest portions of neuropil requires copious human\nannotation, the rate-limiting step for generating a connectome. While a\ncombination of improved imaging and automatic segmentation will lead to the\nanalysis of increasingly large volumes, machines still fail to reach the\nquality of human tracers. Unfortunately, small errors in image segmentation can\nlead to catastrophic distortions of the connectome.\n  In this paper, to analyze very large datasets, we explore different\nmechanisms that are less sensitive to errors in automation. Namely, we advocate\nand deploy extensive synapse detection on the entire antennal lobe (AL)\nneuropil in the brain of the fruit fly Drosophila, a region much larger than\nany densely annotated to date. The resulting synapse point cloud produced is\ninvaluable for determining compartment boundaries in the AL and choosing\nspecific regions for subsequent analysis. We introduce our methodology in this\npaper for region selection and show both manual and automatic synapse\nannotation results. Finally, we note the correspondence between image datasets\nobtained using the synaptic marker, antibody nc82, and our datasets enabling\nregistration between light and EM image modalities."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Analyse lexicale outill{\\'e}e de la parole transcrite de patients\n  schizophr{\\`e}nes"}, {"role": "assistant", "content": "This article details the results of analyses we conducted on the discourse of\nschizophrenic patients, at the oral production (disfluences) and lexical\n(part-of-speech and lemmas) levels. This study is part of a larger project,\nwhich includes other levels of analyses (syntax and discourse). The obtained\nresults should help us rebut or identify new linguistic evidence participating\nin the manifestation of a dysfunction at these different levels. The corpus\ncontains more than 375,000 words, its analysis therefore required that we use\nNatural Language Processing (NLP) and lexicometric tools. In particular, we\nprocessed disfluencies and parts-of-speech separately, which allowed us to\ndemonstrate that if schizophrenic patients do produce more disfluencies than\ncontrol, their lexical richness is not significatively different."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Autoantibody recognition mechanisms of p53 epitopes"}, {"role": "assistant", "content": "There is an urgent need for economical blood based, noninvasive molecular\nbiomarkers to assist in the detection and diagnosis of cancers in a cost\neffective manner at an early stage, when curative interventions are still\npossible. Serum autoantibodies are attractive biomarkers for early cancer\ndetection, but their development has been hindered by the punctuated genetic\nnature of the ten million known cancer mutations. A recent study of 50,000\npatients (Pedersen et al., 2013) showed p53 15mer epitopes are much more\nsensitive colon cancer biomarkers than p53, which in turn is a more sensitive\ncancer biomarker than any other protein. The function of p53 as a nearly\nuniversal tumor suppressor is well established, because of its strong\nimmunogenicity in terms of not only antibody recruitment, but also stimulation\nof autoantibodies. Here we examine bioinformatic fractal scaling analysis for\nidentifying sensitive epitopes from the p53 amino acid sequence, and show how\nit could be used for early cancer detection (ECD). We trim 15mers to 7mers, and\nidentify specific 7mers from other species that could be more sensitive to\naggressive human cancers, such as liver cancer."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Integrated probability of coronary heart disease subject to the -308\n  tumor necrosis factor-alpha SNP: a Bayesian meta-analysis"}, {"role": "assistant", "content": "We present a meta-analysis of independent studies on the potential\nimplication in the occurrence of coronary heart disease (CHD) of the\nsingle-nucleotide polymorphism (SNP) at the -308 position of the tumor necrosis\nfactor alpha (TNF-alpha) gene. We use Bayesian analysis to integrate\nindependent data sets and to infer statistically robust measurements of\ncorrelation. Bayesian hypothesis testing indicates that there is no preference\nfor the hypothesis that the -308 TNF-alpha SNP is related to the occurrence of\nCHD, in the Caucasian or in the Asian population, over the null hypothesis. As\na measure of correlation, we use the probability of occurrence of CHD\nconditional on the presence of the SNP, derived as the posterior probability of\nthe Bayesian meta-analysis. The conditional probability indicates that CHD is\nnot more likely to occur when the SNP is present, which suggests that the -308\nTNF-alpha SNP is not implicated in the occurrence of CHD."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A pharmacokinetic -- viral kinetic model describes the effect of\n  alisporivir monotherapy or in combination with peg-IFN on 2 hepatitis C\n  virologic response"}, {"role": "assistant", "content": "Alisporivir is a cyclophilin inhibitor with demonstrated in vitro and in vivo\nactivity against hepatitis C 11 virus (HCV). We estimated antiviral\neffectiveness of alisporivir alone or in combination with 12\npegylated-Inteferon (peg-IFN) in 88 patients infected with different HCV\ngenotypes treated for four 13 weeks. The pharmacokinetics of both drugs were\nmodeled and used as driving functions for the viral 14 kinetic model. Genotype\nwas found to significantly affect pegylated-Inteferon effectiveness\n($\\epsilon$= 86.3% 15 and 99.1% in genotype-1/4 and genotype-2/3, respectively,\np\\textless{}10 -7) and infected cells loss rate ($\\delta$= 16 0.22 vs 0.39 day\n-1 in genotype-1/4 and genotype-2/3, respectively, p\\textless{}10 -6).\nAlisporivir effectiveness 17 was not significantly different across genotype\nand was high for doses $\\ge$600 mg QD. We simulated 18 virologic responses with\nother alisporivir dosing regimens in HCV genotype-2/3 patients using the 19\nmodel. Our predictions consistently matched the observed responses,\ndemonstrating that this model 20 could be a useful tool for anticipating\nvirologic response and optimize alisporivir-based therapies."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Modeling of breath methane concentration profiles during exercise on an\n  ergometer"}, {"role": "assistant", "content": "We develop a simple three compartment model based on mass balance equations\nwhich quantitatively describes the dynamics of breath methane concentration\nprofiles during exercise on an ergometer. With the help of this model it is\npossible to estimate the endogenous production rate of methane in the large\nintestine by measuring breath gas concentrations of methane."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Exact propagation without analytical solutions"}, {"role": "assistant", "content": "We present a simulation algorithm that accurately propagates a molecule pair\nusing large time steps without the need to invoke the full exact analytical\nsolutions of the Smoluchowski diffusion equation. Because the proposed method\nonly uses uniform and Gaussian random numbers, it allows for position updates\nthat are two to three orders of magnitude faster than those of a corresponding\nscheme based on full solutions, while mantaining the same degree of accuracy.\nNeither simplifying nor ad hoc assumptions that are foreign to the underlying\nSmoluchowski theory are employed, instead, the algorithm faithfully\nincorporates the individual elements of the theoretical model. The method is\nflexible and applicable in 1, 2 and 3 dimensions, suggesting that it may find\nbroad usage in various stochastic simulation algorithms. We demonstrate the\nalgorithm for the case of a non-reactive, irreversible and reversible reacting\nmolecule pair."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: On the parameters affecting dual-target-function evaluation of\n  single-particle selection from cryo-electron micrographs"}, {"role": "assistant", "content": "In the analysis of frozen hydrated biomolecules by single-particle\ncryo-electron microscopy, template-based particle picking by a target function\ncalled fast local correlation (FLC) allows a large number of particle images to\nbe automatically picked from micrographs. A second, independent target function\nbased on maximum likelihood (ML) can be used to align the images and verify the\npresence of signal in the picked particles. Although the paradigm of this\ndual-target-function (DTF) evaluation of single-particle selection has been\npracticed in recent years, it remains unclear how the performance of this DTF\napproach is affected by the signal-to-noise ratio of the images and by the\nchoice of references for FLC and ML. Here we examine this problem through a\nsystematic study of simulated data, followed by experimental substantiation. We\nquantitatively pinpoint the critical signal-to-noise ratio (SNR), at which the\nDTF approach starts losing its ability to select and verify particles from\ncryo-EM micrographs. A Gaussian model is shown to be as effective in picking\nparticles as a single projection view of the imaged molecule in the tested\ncases. For both simulated micrographs and real cryo-EM data of the 173-kDa\nglucose isomerase complex, we found that the use of a Gaussian model to\ninitialize the target functions suppressed the detrimental effect of reference\nbias in template-based particle selection. Given a sufficient signal-to-noise\nratio in the images and the appropriate choice of references, the DTF approach\ncan expedite the automated assembly of single-particle data sets."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: On the Principled Description of Human Movements"}, {"role": "assistant", "content": "While the use of technology to provide accurate and objective measurements of\nhuman movement performance is presently an area of great interest, efforts to\nquantify the performance of movement are hampered by the lack of a principled\nmodel that describes how a subject goes about making a movement. We put forward\na principled mathematical formalism that describes human movements using an\noptimal control model in which the subject controls the jerk of the movement.\nWe construct the formalism by assuming that the movement a subject chooses to\nmake is better than the alternatives. We quantify the relative quality of\nmovements mathematically by specifying a cost functional that assigns a\nnumerical value to every possible movement; the subject makes the movement that\nminimizes the cost functional. We develop the mathematical structure of\nmovements that minimize a cost functional, and observe that this development\nparallels the development of analytical mechanics from the Principle of Least\nAction. We derive a constant of the motion for human movements that plays a\nrole that is analogous to the role that the energy plays in classical\nmechanics. We apply the formalism to the description of two movements: (1)\nrapid, targeted movements of a computer mouse, and (2) finger-tapping, and show\nthat the constant of the motion that we have derived provides a useful value\nwith which we can characterize the performance of the movements. In the case of\nrapid, targeted movements of a computer mouse, we show how the model of human\nmovement that we have developed can be made to agree with Fitts' law, and we\nshow how Fitts' law is related to the constant of the motion that we have\nderived. We finally show that solutions exist within the model of human\nmovements that exhibit an oscillatory character reminiscent of tremor."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Prediction of Metabolic Pathways Involvement in Prokaryotic UniProtKB\n  Data by Association Rule Mining"}, {"role": "assistant", "content": "The widening gap between known proteins and their functions has encouraged\nthe development of methods to automatically infer annotations. Automatic\nfunctional annotation of proteins is expected to meet the conflicting\nrequirements of maximizing annotation coverage, while minimizing erroneous\nfunctional assignments. This trade-off imposes a great challenge in designing\nintelligent systems to tackle the problem of automatic protein annotation. In\nthis work, we present a system that utilizes rule mining techniques to predict\nmetabolic pathways in prokaryotes. The resulting knowledge represents\npredictive models that assign pathway involvement to UniProtKB entries. We\ncarried out an evaluation study of our system performance using\ncross-validation technique. We found that it achieved very promising results in\npathway identification with an F1-measure of 0.982 and an AUC of 0.987. Our\nprediction models were then successfully applied to 6.2 million\nUniProtKB/TrEMBL reference proteome entries of prokaryotes. As a result,\n663,724 entries were covered, where 436,510 of them lacked any previous pathway\nannotations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Technical Report: Modelling Multiple Cell Types with Partial\n  Differential Equations"}, {"role": "assistant", "content": "Partial differential equations are a convenient way to describe reaction-\nadvection-diffusion processes of signalling models. If only one cell type is\npresent, and tissue dynamics can be neglected, the equations can be solved\ndirectly. However, in case of multiple cell types it is not always straight\nforward to integrate a continuous description of the tissue dynamics. Here, we\ndiscuss (delayed) differentiation of cells into different cell types and\nhypertrophic cell volume change upon differentiation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Bioinformatic Scaling of Allosteric Interactions in Biomedical Isozymes"}, {"role": "assistant", "content": "Allosteric (long-range) interactions can be surprisingly strong in proteins\nof biomedical interest. Here we use bioinformatic scaling to connect prior\nresults on nonsteroidal anti-inflammatory drugs to promising new drugs that\ninhibit cancer cell metabolism. Many parallel features are apparent, which\nexplain how even one amino acid mutation, remote from active sites, can alter\nmedical results. The enzyme twins involved are cyclooxygenase (aspirin) and\nisocitrate dehydrogenase (IDH). The IDH results are accurate to 1% and are\noverdetermined by adjusting a single bioinformatic scaling parameter. It\nappears that the final stage in optimizing protein functionality may involve\nleveling of the hydrophobic cutoffs of the arms of conformational hydrophilic\nhinges."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Detection of contamination in noninvasive prenatal fetal gender test"}, {"role": "assistant", "content": "The risk of false positive results in noninvasive prenatal diagnosis focused\non fetal gender and RhD status determination could be a problem in clinical\nroutine. This is because these tests are based on detection of presence of DNA\nsequences with high population frequency and so there is the risk of sample\ncontamination during sample collection and processing. In our study the\ndifferent fragmentation of fetal and maternal DNA molecules present in maternal\ncirculation was utilized in identification of contaminated samples.\nAmplification of Y-chromosome specific assays different in size was tested on\ncirculating DNA samples.\n  Of the four tested assays two shorter (84 and 177 bp) showed expected qPCR\nefficiency and have comparable amplification profiles. The difference in Ct\nvalues between these two assays was found to be statistically significant in\ncomparison of fetal male and normal male samples (p<0.0001) as well as in\nblinded pilot study performed on 10 artificially contaminated and 10\nnon-contaminated samples (F=34.4, p<0.0001) that were all identified correctly.\n  Our results showed that differently sized assays performed well in detection\nof external contamination of samples in noninvasive prenatal fetal gender test\nand could be of help in clinical laboratories to minimize the risk of false\npositive results."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Urban vegetation change after a hundred years in a tropical city (San\n  Jos\\'e de Costa Rica)"}, {"role": "assistant", "content": "Urban vegetation is of key importance because a large proportion of the human\npopulation lives in cities. Nevertheless, urban vegetation is understudied\noutside central Europe and particularly, little is known about the flora of\ntropical Asian, African and Latin American cities. We present an estimate of\nhow the vegetation has changed in the city of San Jos\\'e, Costa Rica, after\nabout one century, with the repeat photography technique (based on a collection\nof 19th and early 20th century photographs by Jos\\'e Fidel Trist\\'an and\nothers) and with data from the Costa Rican National Herbarium. We found little\nvegetation change in the landscape of San Jos\\'e during the 20th century, where\na total of 95 families and 458 species were collected in the late 19th and\nearly 20th century. The families with most species were Asteraceae, Fabaceae,\nPoaceae, Lamiaceae, Euphorbiaceae, Solanaceae, Cyperaceae, Acanthaceae,\nMalvaceae, Piperaceae and Verbenaceae. Similar results have been found in\nEurope, where the number of plant species often is stable for long periods even\nwhen the individual species vary."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Air pollution in a tropical city: the relationship between wind\n  direction and lichen bio-indicators in San Jos\\'e, Costa Rica"}, {"role": "assistant", "content": "Lichens are good bio-indicators of air pollution, but in most tropical\ncountries there are few studies on the subject; however, in the city of San\nJos\\'e, Costa Rica, the relationship between air pollution and lichens has been\nstudied for decades. In this article we evaluate the hypothesis that air\npollution is lower where the wind enters the urban area (Northeast) and higher\nwhere it exits San Jos\\'e (Southwest). We identified the urban parks with a\nminimum area of approximately 5 000m2 and randomly selected a sample of 40\nparks located along the passage of wind through the city. To measure lichen\ncoverage, we applied a previously validated 10 x 20cm template with 50 random\npoints to five trees per park (1.5m above ground, to the side with most\nlichens). Our results (years 2008 and 2009) fully agree with the generally\naccepted view that lichens reflect air pollution carried by circulating air\nmasses. The practical implication is that the air enters the city relatively\nclean by the semi-rural and economically middle class area of Coronado, and\nleaves through the developed neighborhoods of Escaz\\'u and Santa Ana with a\nsignificant amount of pollutants. In the dry season, the live lichen coverage\nof this tropical city was lower than in the May to December rainy season, a\npattern that contrasts with temperate habitats; but regardless of the season,\npollution follows the pattern of wind movement through the city."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Electrical Structure of Biological Cells and Tissues: impedance\n  spectroscopy, stereology, and singular perturbation theory"}, {"role": "assistant", "content": "Impedance Spectroscopy resolves electrical properties into uncorrelated\nvariables, as a function of frequency, with exquisite resolution. Separation is\nrobust and most useful when the system is linear. Impedance spectroscopy\ncombined with appropriate structural knowledge provides insight into pathways\nfor current flow, with more success than other methods. Biological applications\nof impedance spectroscopy are often not useful since so much of biology is\nstrongly nonlinear in its essential features, and impedance spectroscopy is\nfundamentally a linear analysis. All cells and tissues have cell membranes and\nits capacitance is both linear and important to cell function. Measurements\nproved straightforward in skeletal muscle, cardiac muscle, and lens of the eye.\nIn skeletal muscle, measurements provided the best estimates of the predominant\n(cell) membrane system that dominates electrical properties. In cardiac muscle,\nmeasurements showed definitively that classical microelectrode voltage clamp\ncould not control the potential of the predominant membranes, that were in the\ntubular system separated from the extracellular space by substantial\ndistributed resistance. In the lens of the eye, impedance spectroscopy changed\nthe basis of all recording and interpretation of electrical measurements and\nlaid the basis for Rae and Mathias extensive later experimental work. Many\ntissues are riddled with extracellular space as clefts and tubules, for\nexample, cardiac muscle, the lens of the eye, most epithelia, and of course\nfrog muscle. These tissues are best analyzed with a bidomain theory that arose\nfrom the work on electrical structure described here. There has been a great\ndeal of work since then on the bi-domain and this represents the most important\ncontribution to biology of the analysis of electrical structure in my view."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantifying Reticulation in Phylogenetic Complexes Using Homology"}, {"role": "assistant", "content": "Reticulate evolutionary processes result in phylogenetic histories that\ncannot be modeled using a tree topology. Here, we apply methods from\ntopological data analysis to molecular sequence data with reticulations. Using\na simple example, we demonstrate the correspondence between nontrivial higher\nhomology and reticulate evolution. We discuss the sensitivity of the standard\nfiltration and show cases where reticulate evolution can fail to be detected.\nWe introduce an extension of the standard framework and define the median\ncomplex as a construction to recover signal of the frequency and scale of\nreticulate evolution by inferring and imputing putative ancestral states.\nFinally, we apply our methods to two datasets from phylogenetics. Our work\nexpands on earlier ideas of using topology to extract important evolutionary\nfeatures from genomic data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Evidence for Magnetoreception in Red Drum (Sciaenops ocellatus), Black\n  Drum (Pogonias cromis), and Sea Catfish (Ariopsis felis)"}, {"role": "assistant", "content": "Over the past few decades, magnetoreception has been discovered in several\nspecies of teleost and elasmobranch fishes by employing varied experimental\nmethods including conditioning experiments, observations of alignment with\nexternal fields, and experiments with magnetic deterrents. Biogenic magnetite\nhas been confirmed to be an important receptor mechanism in some species, but\nthere is ongoing debate regarding whether other mechanisms are at work. This\npaper presents evidence for magnetoreception in three additional species, red\ndrum (Sciaenops ocellatus), black drum (Pogonias cromis), and sea catfish\n(Ariopsis felis), by employing experiments to test whether fish respond\ndifferently to bait on a magnetic hook than on a control. In red drum, the\ncontrol hook outcaught the magnetic hook by 32 - 18 for chi-squared = 3.92 and\na P-value of 0.048. Black drum showed a significant attraction for the magnetic\nhook, which prevailed over the control hook by 11 - 3 for chi-squared = 4.57\nand a P-value of 0.033. Gafftopsail catfish (Bagre marinus) showed no\npreference with a 31 - 35 split between magnetic hook and control for\nchi-squared = 0.242 and a P-value of 0.623. In a sample of 100 sea catfish in\nan analogous experiment using smaller hooks, the control hook was preferred\n62-38 for chi-squared = 5.76 and a P-value of < 0.001. Such a simple method for\nidentifying magnetoreceptive species may quickly expand the number of known\nmagnetoreceptive species and allow for easier access to magnetoreceptive\nspecies and thus facilitate testing of magnetoreceptive hypotheses."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Infomap Bioregions: Interactive mapping of biogeographical regions from\n  species distributions"}, {"role": "assistant", "content": "Biogeographical regions (bioregions) reveal how different sets of species are\nspatially grouped and therefore are important units for conservation,\nhistorical biogeography, ecology and evolution. Several methods have been\ndeveloped to identify bioregions based on species distribution data rather than\nexpert opinion. One approach successfully applies network theory to simplify\nand highlight the underlying structure in species distributions. However, this\nmethod lacks tools for simple and efficient analysis. Here we present Infomap\nBioregions, an interactive web application that inputs species distribution\ndata and generates bioregion maps. Species distributions may be provided as\ngeoreferenced point occurrences or range maps, and can be of local, regional or\nglobal scale. The application uses a novel adaptive resolution method to make\nbest use of often incomplete species distribution data. The results can be\ndownloaded as vector graphics, shapefiles or in table format. We validate the\ntool by processing large datasets of publicly available species distribution\ndata of the world's amphibians using species ranges, and mammals using point\noccurrences. We then calculate the fit between the inferred bioregions and WWF\necoregions. As examples of applications, researchers can reconstruct ancestral\nranges in historical biogeography or identify indicator species for targeted\nconservation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: De novo visual proteomics in single cells through pattern mining"}, {"role": "assistant", "content": "Cryo-electron tomography enables 3D visualization of cells in a near native\nstate at molecular resolution. The produced cellular tomograms contain detailed\ninformation about all macromolecular complexes, their structures, their\nabundances and their specific spatial locations in the cell. However,\nextracting this information is very challenging and current methods usually\nrely on templates of known structure. Here, we formulate a template-free visual\nproteomics analysis as a de novo pattern mining problem and propose a new\nframework called \"Multi Pattern Pursuit\" for supporting proteome-scale de novo\ndiscovery of macromolecular complexes in cellular tomograms without using\ntemplates of known structures. Our tests on simulated and experimental\ntomograms show that our method is a promising tool for template-free visual\nproteomics analysis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Brighter than the sun: Powerscape visualizations illustrate power needs\n  in neuroscience and psychology"}, {"role": "assistant", "content": "Participant needs to achieve a given power are frequently underestimated.\nThis is particularly problematic when effect sizes are small, such as is common\nin neuroscience and psychology. We provide tools to make these demands\nimmediately obvious in the form of a powerscape visualization."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Limits to causal inference with state-space reconstruction for\n  infectious disease"}, {"role": "assistant", "content": "Infectious diseases are notorious for their complex dynamics, which make it\ndifficult to fit models to test hypotheses. Methods based on state-space\nreconstruction have been proposed to infer causal interactions in noisy,\nnonlinear dynamical systems. These \"model-free\" methods are collectively known\nas convergent cross-mapping (CCM). Although CCM has theoretical support,\nnatural systems routinely violate its assumptions. To identify the practical\nlimits of causal inference under CCM, we simulated the dynamics of two pathogen\nstrains with varying interaction strengths. The original method of CCM is\nextremely sensitive to periodic fluctuations, inferring interactions between\nindependent strains that oscillate with similar frequencies. This sensitivity\nvanishes with alternative criteria for inferring causality. However, CCM\nremains sensitive to high levels of process noise and changes to the\ndeterministic attractor. This sensitivity is problematic because it remains\nchallenging to gauge noise and dynamical changes in natural systems, including\nthe quality of reconstructed attractors that underlie cross-mapping. We\nillustrate these challenges by analyzing time series of reportable childhood\ninfections in New York City and Chicago during the pre-vaccine era. We comment\non the statistical and conceptual challenges that currently limit the use of\nstate-space reconstruction in causal inference."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Probabilistic Nearest Neighbor Estimation of Diffusion Constants from\n  Single Molecular Measurement without Explicit Tracking"}, {"role": "assistant", "content": "Time course measurement of single molecules on a cell surface provides\ndetailed information on the dynamics of the molecules, which is otherwise\ninaccessible. To extract the quantitative information, single particle tracking\n(SPT) is typically performed. However, trajectories extracted by SPT inevitably\nhave linking errors when the diffusion speed of single molecules is high\ncompared to the scale of the particle density. To circumvent this problem we\ndeveloped an algorithm to estimate diffusion constants without relying on SPT.\nWe demonstrated that the proposed algorithm provides reasonable estimation of\ndiffusion constants even when other methods fail due to high particle density\nor inhomogeneous particle distribution. In addition, our algorithm can be used\nfor visualization of time course data from single molecular measurements."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: An expanded evaluation of protein function prediction methods shows an\n  improvement in accuracy"}, {"role": "assistant", "content": "Background: The increasing volume and variety of genotypic and phenotypic\ndata is a major defining characteristic of modern biomedical sciences. At the\nsame time, the limitations in technology for generating data and the inherently\nstochastic nature of biomolecular events have led to the discrepancy between\nthe volume of data and the amount of knowledge gleaned from it. A major\nbottleneck in our ability to understand the molecular underpinnings of life is\nthe assignment of function to biological macromolecules, especially proteins.\nWhile molecular experiments provide the most reliable annotation of proteins,\ntheir relatively low throughput and restricted purview have led to an\nincreasing role for computational function prediction. However, accurately\nassessing methods for protein function prediction and tracking progress in the\nfield remain challenging. Methodology: We have conducted the second Critical\nAssessment of Functional Annotation (CAFA), a timed challenge to assess\ncomputational methods that automatically assign protein function. One hundred\ntwenty-six methods from 56 research groups were evaluated for their ability to\npredict biological functions using the Gene Ontology and gene-disease\nassociations using the Human Phenotype Ontology on a set of 3,681 proteins from\n18 species. CAFA2 featured significantly expanded analysis compared with CAFA1,\nwith regards to data set size, variety, and assessment metrics. To review\nprogress in the field, the analysis also compared the best methods\nparticipating in CAFA1 to those of CAFA2. Conclusions: The top performing\nmethods in CAFA2 outperformed the best methods from CAFA1, demonstrating that\ncomputational function prediction is improving. This increased accuracy can be\nattributed to the combined effect of the growing number of experimental\nannotations and improved methods for function prediction."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Community-Wide Evaluation of Computational Function Prediction"}, {"role": "assistant", "content": "A biological experiment is the most reliable way of assigning function to a\nprotein. However, in the era of high-throughput sequencing, scientists are\nunable to carry out experiments to determine the function of every single gene\nproduct. Therefore, to gain insights into the activity of these molecules and\nguide experiments, we must rely on computational means to functionally annotate\nthe majority of sequence data. To understand how well these algorithms perform,\nwe have established a challenge involving a broad scientific community in which\nwe evaluate different annotation methods according to their ability to predict\nthe associations between previously unannotated protein sequences and Gene\nOntology terms. Here we discuss the rationale, benefits and issues associated\nwith evaluating computational methods in an ongoing community-wide challenge."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Patterns of mast fruiting - a stochastic approach"}, {"role": "assistant", "content": "Mast fruiting represents a synchronous population behaviour which can spread\non large landscape areas. This reproductive pattern is generally perceived as a\nsynchronous periodic production of large seed crops and has a significant\npractical importance to forest natural regeneration in order to synchronize\ncuttings. The mechanisms of masting are still argued and models of this\nphenomenon are uncommon, so a stochastic approach can cast significant light on\nsome particular aspects. Trees manage to get synchronized and coordinate their\nreproductive routines. But is it possible that trees get synchronized by\nchance, absolutely random? Using a Monte Carlo simulation of seeding years and\na theoretical masting pattern, a stochastic analysis is performed in order to\nassess the chance of random mast fruiting. Two populations of 100 trees, with\ndifferent fruiting periodicity of 2-3 years and 4-6 years, were set and the\nfruition dynamic was simulated for 100 years. The results show that periodicity\nitself cannot induce by chance the masting effect, but periodicity\nmathematically influences the reproductive pattern."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A dynamical network model for age-related health deficits and mortality"}, {"role": "assistant", "content": "How long people live depends on their health, and how it changes with age.\nIndividual health can be tracked by the accumulation of age-related health\ndeficits. The fraction of age-related deficits is a simple quantitative measure\nof human aging. This quantitative frailty index (F) is as good as chronological\nage in predicting mortality. In this paper, we use a dynamical network model of\ndeficits to explore the effects of interactions between deficits, deficit\ndamage and repair processes, and the connection between the F and mortality.\nWith our model, we qualitatively reproduce Gompertz's law of increasing human\nmortality with age, the broadening of the F distribution with age, the\ncharacteristic non-linear increase of the F with age, and the increased\nmortality of high-frailty individuals. No explicit time-dependence in damage or\nrepair rates is needed in our model. Instead, implicit time-dependence arises\nthrough deficit interactions -- so that the average deficit damage rates\nincreases, and deficit repair rates decreases, with age . We use a simple\nmortality criterion, where mortality occurs when the most connected node is\ndamaged."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Physical and mathematical modeling in experimental papers: achieving\n  robustness of mathematical modeling studies"}, {"role": "assistant", "content": "Development of several alternative mathematical models for the biological\nsystem in question and discrimination between such models using experimental\ndata is the best way to robust conclusions. Models which challenge existing\ntheories are more valuable than models which support such theories."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Identifying differences in the rules of interaction between individuals\n  in moving animal groups"}, {"role": "assistant", "content": "Collective movement can be achieved when individuals respond to the local\nmovements and positions of their neighbours. Some individuals may\ndisproportionately influence group movement if they occupy particular spatial\npositions in the group, for example, positions at the front of the group. We\nasked, therefore, what led individuals in moving pairs of fish (Gambusia\nholbrooki) to occupy a position in front of their partner. Individuals adjusted\ntheir speed and direction differently in response to their partner's position,\nresulting in individuals occupying different positions in the group.\nIndividuals that were found most often at the front of the pair had greater\nmean changes in speed than their partner, and were less likely to turn towards\ntheir partner, compared to those individuals most often found at the back of\nthe pair. The pair moved faster when led by the individual that was usually at\nthe front. Our results highlight how differences in the social responsiveness\nbetween individuals can give rise to leadership in free moving groups. They\nalso demonstrate how the movement characteristics of groups depend on the\nspatial configuration of individuals within them."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Inferring the perturbation time from biological time course data"}, {"role": "assistant", "content": "Time course data are often used to study the changes to a biological process\nafter perturbation. Statistical methods have been developed to determine\nwhether such a perturbation induces changes over time, e.g. comparing a\nperturbed and unperturbed time course dataset to uncover differences. However,\nexisting methods do not provide a principled statistical approach to identify\nthe specific time when the two time course datasets first begin to diverge\nafter a perturbation; we call this the perturbation time. Estimation of the\nperturbation time for different variables in a biological process allows us to\nidentify the sequence of events following a perturbation and therefore provides\nvaluable insights into likely causal relationships.\n  In this paper, we propose a Bayesian method to infer the perturbation time\ngiven time course data from a wild-type and perturbed system. We use a\nnon-parametric approach based on Gaussian Process regression. We derive a\nprobabilistic model of noise-corrupted and replicated time course data coming\nfrom the same profile before the perturbation time and diverging after the\nperturbation time. The likelihood function can be worked out exactly for this\nmodel and the posterior distribution of the perturbation time is obtained by a\nsimple histogram approach, without recourse to complex approximate inference\nalgorithms. We validate the method on simulated data and apply it to study the\ntranscriptional change occurring in Arabidopsis following inoculation with P.\nsyringae pv. tomato DC3000 versus the disarmed strain DC3000hrpA.\n  An R package, DEtime, implementing the method is available at\nhttps://github.com/ManchesterBioinference/DEtime along with the data and code\nrequired to reproduce all the results."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Stochastic modeling of cell growth with symmetric or asymmetric division"}, {"role": "assistant", "content": "We consider a class of biologically-motivated stochastic processes in which a\nunicellular organism divides its resources (volume or damaged proteins, in\nparticular) symmetrically or asymmetrically between its progeny. Assuming the\nfinal amount of the resource is controlled by a growth policy and subject to\nadditive and multiplicative noise, we derive the \"master equation\" describing\nhow the resource distribution evolves over subsequent generations and use it to\nstudy the properties of stable resource distributions. We find conditions under\nwhich a unique stable resource distribution exists and calculate its moments\nfor the class of affine linear growth policies. Moreover, we apply an\nasymptotic analysis to elucidate the conditions under which the stable\ndistribution (when it exists) has a power-law tail. Finally, we use the results\nof this asymptotic analysis along with the moment equations to draw a stability\nphase diagram for the system that reveals the counterintuitive result that\nasymmetry serves to increase stability while at the same time widening the\nstable distribution. We also briefly discuss how cells can divide damaged\nproteins asymmetrically between their progeny as a form of damage control. In\nthe appendix, motivated by the asymmetric division of cell volume in\nSaccharomyces cerevisiae, we extend our results to the case wherein mother and\ndaughter cells follow different growth policies."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A tool for computing diversity and consideration on differences between\n  diversity indices"}, {"role": "assistant", "content": "Diversity represents a key concept in ecology, and there are various methods\nof assessing it. The multitude of diversity indices are quite puzzling and\nsometimes difficult to compute for a large volume of data. This paper promotes\na computational tool used to assess the diversity of different entities. The\nBIODIV software is a user-friendly tool, developed using Microsoft Visual\nBasic. It is capable to compute several diversity indices such as: Shannon,\nSimpson, Pielou, Brillouin, Berger-Parker, McIntosh, Margalef, Menhinick and\nGleason. The software tool was tested using real data sets and the results were\nanalysed in order to make assumption on the indices behaviour. The results\nshowed a clear segregation of indices in two major groups with similar\nexpressivity."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The limitations of model-based experimental design and parameter\n  estimation in sloppy systems"}, {"role": "assistant", "content": "We explore the relationship among model fidelity, experimental design, and\nparameter estimation in sloppy models. We show that the approximate nature of\nmathematical models poses challenges for experimental design in sloppy models.\nIn many models of complex biological processes it is unknown what are the\nrelevant physics that must be included to explain collective behaviors. As a\nconsequence, models are often overly complex, with many practically\nunidentifiable parameters. Furthermore, which details are relevant/irrelevant\nvary among potential experiments. By selecting complementary experiments,\nexperimental design may inadvertently make details that were ommitted from the\nmodel become relevant. When this occurs, the model will fail to give a good fit\nto the data. We use a simple hyper-model of model error to quantify a model's\ninadequacy and apply it to two models of complex biological processes (EGFR\nsignaling and DNA repair) with optimally selected experiments. We find that\nalthough parameters may be accurately estimated, the error in the model renders\nit less predictive than it was in the sloppy regime where model error is small.\nWe introduce the concept of a \\emph{sloppy system}--a sequence of models of\nincreasing complexity that become sloppy in the limit of microscopic accuracy.\nWe explore the limits of accurate parameter estimation in sloppy systems and\nargue that system identification better approached by considering a hierarchy\nof models of varying detail rather than focusing parameter estimation in a\nsingle model."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Analysis of animal accelerometer data using hidden Markov models"}, {"role": "assistant", "content": "Use of accelerometers is now widespread within animal biotelemetry as they\nprovide a means of measuring an animal's activity in a meaningful and\nquantitative way where direct observation is not possible. In sequential\nacceleration data there is a natural dependence between observations of\nmovement or behaviour, a fact that has been largely ignored in most analyses.\nAnalyses of acceleration data where serial dependence has been explicitly\nmodelled have largely relied on hidden Markov models (HMMs). Depending on the\naim of an analysis, either a supervised or an unsupervised learning approach\ncan be applied. Under a supervised context, an HMM is trained to classify\nunlabelled acceleration data into a finite set of pre-specified categories,\nwhereas we will demonstrate how an unsupervised learning approach can be used\nto infer new aspects of animal behaviour. We will provide the details necessary\nto implement and assess an HMM in both the supervised and unsupervised context,\nand discuss the data requirements of each case. We outline two applications to\nmarine and aerial systems (sharks and eagles) taking the unsupervised approach,\nwhich is more readily applicable to animal activity measured in the field. HMMs\nwere used to infer the effects of temporal, atmospheric and tidal inputs on\nanimal behaviour. Animal accelerometer data allow ecologists to identify\nimportant correlates and drivers of animal activity (and hence behaviour). The\nHMM framework is well suited to deal with the main features commonly observed\nin accelerometer data. The ability to combine direct observations of animals\nactivity and combine it with statistical models which account for the features\nof accelerometer data offer a new way to quantify animal behaviour, energetic\nexpenditure and deepen our insights into individual behaviour as a constituent\nof populations and ecosystems."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: 3D-Printing for Analytical Ultracentrifugation"}, {"role": "assistant", "content": "Analytical ultracentrifugation (AUC) is a classical technique of physical\nbiochemistry providing information on size, shape, and interactions of\nmacromolecules from the analysis of their migration in centrifugal fields while\nfree in solution. A key mechanical element in AUC is the centerpiece, a\ncomponent of the sample cell assembly that is mounted between the optical\nwindows to allow imaging and to seal the sample solution column against high\nvacuum while exposed to gravitational forces in excess of 300,000 g. For\nsedimentation velocity it needs to be precisely sector-shaped to allow\nunimpeded radial macromolecular migration. During the history of AUC a great\nvariety of centerpiece designs have been developed for different types of\nexperiments. Here, we report that centerpieces can now be readily fabricated by\n3D printing at low cost, from a variety of materials, and with customized\ndesigns. The new centerpieces can exhibit sufficient mechanical stability to\nwithstand the gravitational forces at the highest rotor speeds and be\nsufficiently precise for sedimentation equilibrium and sedimentation velocity\nexperiments. Sedimentation velocity experiments with bovine serum albumin as a\nreference molecule in 3D printed centerpieces with standard double-sector\ndesign result in sedimentation boundaries virtually indistinguishable from\nthose in commercial double-sector epoxy centerpieces, with sedimentation\ncoefficients well within the range of published values. The statistical error\nof the measurement is slightly above that obtained with commercial epoxy, but\nstill below 1%. Facilitated by modern open-source design and fabrication\nparadigms, we believe 3D printed centerpieces and AUC accessories can spawn a\nvariety of improvements in AUC experimental design, efficiency and resource\nallocation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Methods used by WHO to estimate the Global burden of TB disease"}, {"role": "assistant", "content": "This paper describes methodological details used by WHO in 2015 to estimate\nTB incidence, prevalence and mortality. Incidence and mortality are\ndisaggregated by HIV status, age and sex. Methods to derive MDR-TB burden\nindicators are detailed. Four main methods were used to derive incidence: (i)\ncase notification data combined with expert opinion about case detection gaps\n(120 countries representing 51% of global incidence); (ii) results from\nnational TB prevalence surveys (19 countries, 46% of global incidence); (iii)\nnotifications in high-income countries adjusted by a standard factor to account\nfor under-reporting and underdiagnosis (73 countries, 3% of global incidence)\nand (iv) capture-recapture modelling (5 countries, 0.5% of global incidence).\nPrevalence was obtained from results of national prevalence surveys in 21\ncountries, representing 69% of global prevalence). In other countries,\nprevalence was estimated from incidence and disease duration. Mortality was\nobtained from national vital registration systems of mortality surveys in 129\ncountries (43% of global HIV-negative TB mortality). In other countries,\nmortality was derived indirectly from incidence and case fatality ratio."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Coupling volume-excluding compartment-based models of diffusion at\n  different scales: Voronoi and pseudo-compartment approaches"}, {"role": "assistant", "content": "Numerous processes across both the physical and biological sciences are\ndriven by diffusion. Partial differential equations (PDEs) are a popular tool\nfor modelling such phenomena deterministically, but it is often necessary to\nuse stochastic models to accurately capture the behaviour of a system,\nespecially when the number of diffusing particles is low. The stochastic models\nwe consider in this paper are `compartment-based': the domain is discretized\ninto compartments, and particles can jump between these compartments.\nVolume-excluding effects (crowding) can be incorporated by blocking movement\nwith some probability.\n  Recent work has established the connection between fine-grained models and\ncoarse-grained models incorporating volume exclusion, but only for uniform\nlattices. In this paper we consider non-uniform, hybrid lattices that\nincorporate both fine- and coarse-grained regions, and present two different\napproaches to describing the interface of the regions. We test both techniques\nin a range of scenarios to establish their accuracy, benchmarking against\nfine-grained models, and show that the hybrid models developed in this paper\ncan be significantly faster to simulate than the fine-grained models in certain\nsituations, and are at least as fast otherwise."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Initial validation for the estimation of resting-state fMRI effective\n  connectivity by a generalization of the correlation approach"}, {"role": "assistant", "content": "Resting-state functional MRI (rs-fMRI) is widely used to noninvasively study\nhuman brain networks. Network functional connectivity is often estimated by\ncalculating the timeseries correlation between blood-oxygen-level dependent\n(BOLD) signal from different regions of interest. However, standard correlation\ncannot characterize the direction of information flow between regions. In this\npaper, we introduce and test a new concept, prediction correlation, to estimate\neffective connectivity in functional brain networks from rs-fMRI. In this\napproach, the correlation between two BOLD signals is replaced by a correlation\nbetween one BOLD signal and a prediction of this signal via a causal system\ndriven by another BOLD signal. Three validations are described: (1) Prediction\ncorrelation performed well on simulated data where the ground truth was known,\nand outperformed four other methods. (2) On simulated data designed to display\nthe \"common driver\" problem, prediction correlation did not introduce false\nconnections between non-interacting driven ROIs. (3) On experimental data,\nprediction correlation recovered the previously identified network organization\nof human brain. Prediction correlation scales well to work with hundreds of\nROIs, enabling it to assess whole brain interregional connectivity at the\nsingle subject level. These results provide an initial validation that\nprediction correlation can capture the direction of information flow and\nestimate the duration of extended temporal delays in information flow between\nregions of interest based on BOLD signal. This approach not only maintains the\nhigh sensitivity to network connectivity provided by the correlation analysis,\nbut also performs well in the estimation of causal information flow in the\nbrain."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Understanding the spatiotemporal pattern of grazing cattle movement"}, {"role": "assistant", "content": "In this study, we analyse a high-frequency movement dataset for a group of\ngrazing cattle and investigate their spatiotemporal patterns using a simple\ntwo-state `stop-and-move' mobility model. We find that the dispersal kernel in\nthe moving state is best described by a mixture exponential distribution,\nindicating the hierarchical nature of the movement. On the other hand, the\nwaiting time appears to be scale-invariant below a certain cut-off and is best\ndescribed by a truncated power-law distribution, suggesting heterogenous\ndynamics in the non-moving state. We explore possible explanations for the\nobserved phenomena, covering factors that can play a role in the generation of\nmobility patterns, such as the context of grazing environment, the intrinsic\ndecision-making mechanism or the energy status of different activities. In\nparticular, we propose a new hypothesis that the underlying movement pattern\ncan be attributed to the most probable observable energy status under the\nmaximum entropy configuration. These results are not only valuable for\nmodelling cattle movement but also provide new insights for understanding the\nunderlying biological basis of grazing behaviour."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Finding Mutated Subnetworks Associated with Survival in Cancer"}, {"role": "assistant", "content": "Next-generation sequencing technologies allow the measurement of somatic\nmutations in a large number of patients from the same cancer type. One of the\nmain goals in analyzing these mutations is the identification of mutations\nassociated with clinical parameters, such as survival time. This goal is\nhindered by the genetic heterogeneity of mutations in cancer, due to the fact\nthat genes and mutations act in the context of pathways. To identify mutations\nassociated with survival time it is therefore crucial to study mutations in the\ncontext of interaction networks.\n  In this work we study the problem of identifying subnetworks of a large\ngene-gene interaction network that have mutations associated with survival. We\nformally define the associated computational problem by using a score for\nsubnetworks based on the test statistic of the log-rank test, a widely used\nstatistical test for comparing the survival of two populations. We show that\nthe computational problem is NP-hard and we propose a novel algorithm, called\nNetwork of Mutations Associated with Survival (NoMAS), to solve it. NoMAS is\nbased on the color-coding technique, that has been previously used in other\napplications to find the highest scoring subnetwork with high probability when\nthe subnetwork score is additive. In our case the score is not additive;\nnonetheless, we prove that under a reasonable model for mutations in cancer\nNoMAS does identify the optimal solution with high probability. We test NoMAS\non simulated and cancer data, comparing it to approaches based on single gene\ntests and to various greedy approaches. We show that our method does indeed\nfind the optimal solution and performs better than the other approaches.\nMoreover, on two cancer datasets our method identifies subnetworks with\nsignificant association to survival when none of the genes has significant\nassociation with survival when considered in isolation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Robust Individual Circadian Parameter Estimation for Biosignal-based\n  Personalisation of Cancer Chronotherapy"}, {"role": "assistant", "content": "In cancer treatment, chemotherapy is administered according a constant\nschedule. The chronotherapy approach, considering chronobiological drug\ndelivery, adapts the chemotherapy profile to the circadian rhythms of the human\norganism. This reduces toxicity effects and at the same time enhances\nefficiency of chemotherapy. To personalize cancer treatment, chemotherapy\nprofiles have to be further adapted to individual patients. Therefore, we\npresent a new model to represent cycle phenomena in circadian rhythms. The\nmodel enables a more precise modelling of the underlying circadian rhythms. In\ncomparison with the standard model, our model delivers better results in all\ndefined quality indices. The new model can be used to adapt the chemotherapy\nprofile efficiently to individual patients. The adaption to individual patients\ncontributes to the aim of personalizing cancer therapy."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Distributed Gradient Descent in Bacterial Food Search"}, {"role": "assistant", "content": "Communication and coordination play a major role in the ability of bacterial\ncells to adapt to ever changing environments and conditions. Recent work has\nshown that such coordination underlies several aspects of bacterial responses\nincluding their ability to develop antibiotic resistance. Here we develop a new\ndistributed gradient descent method that helps explain how bacterial cells\ncollectively search for food in harsh environments using extremely limited\ncommunication and computational complexity. This method can also be used for\ncomputational tasks when agents are facing similarly restricted conditions. We\nformalize the communication and computation assumptions required for successful\ncoordination and prove that the method we propose leads to convergence even\nwhen using a dynamically changing interaction network. The proposed method\nimproves upon prior models suggested for bacterial foraging despite making\nfewer assumptions. Simulation studies and analysis of experimental data\nillustrate the ability of the method to explain and further predict several\naspects of bacterial swarm food search."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multi-level methods and approximating distribution functions"}, {"role": "assistant", "content": "Biochemical reaction networks are often modelled using discrete-state,\ncontinuous-time Markov chains. System statistics of these Markov chains usually\ncannot be calculated analytically and therefore estimates must be generated via\nsimulation techniques. There is a well documented class of simulation\ntechniques known as exact stochastic simulation algorithms, an example of which\nis Gillespie's direct method. These algorithms often come with high\ncomputational costs, therefore approximate stochastic simulation algorithms\nsuch as the tau-leap method are used. However, in order to minimise the bias in\nthe estimates generated using them, a relatively small value of tau is needed,\nrendering the computational costs comparable to Gillespie's direct method.\n  The multi-level Monte Carlo method (Anderson and Higham, Multiscale Model.\nSimul. 10:146-179, 2012) provides a reduction in computational costs whilst\nminimising or even eliminating the bias in the estimates of system statistics.\nThis is achieved by first crudely approximating required statistics with many\nsample paths of low accuracy. Then correction terms are added until a required\nlevel of accuracy is reached. Recent literature has primarily focussed on\nimplementing the multi-level method efficiently to estimate a single system\nstatistic. However, it is clearly also of interest to be able to approximate\nentire probability distributions of species counts. We present two novel\nmethods that combine known techniques for distribution reconstruction with the\nmulti-level method. We demonstrate the potential of our methods using a number\nof examples."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Understanding the Systems Biology of Pathogen Virulence Using Semantic\n  Methodologies"}, {"role": "assistant", "content": "Systems biology approaches to the integrative study of cells, organs and\norganisms offer the best means of understanding in a holistic manner the\ndiversity of molecular assays that can be now be implemented in a high\nthroughput manner. Such assays can sample the genome, epigenome, proteome,\nmetabolome and microbiome contemporaneously, allowing us for the first time to\nperform a complete analysis of physiological activity. The central problem\nremains empowering the scientific community to actually implement such an\nintegration, across seemingly diverse data types and measurements. One\npromising solution is to apply semantic techniques on a self-consistent and\nimplicitly correct ontological representation of these data types. In this\npaper we describe how we have applied one such solution, based around the\nInterMine data warehouse platform which uses as its basis the Sequence\nOntology, to facilitate a systems biology analysis of virulence in the\napicomplexan pathogen $Toxoplasma~gondii$, a common parasite that infects up to\nhalf the worlds population, with acute pathogenic risks for immuno-compromised\nindividuals or pregnant mothers. Our solution, which we named `toxoMine', has\nprovided both a platform for our collaborators to perform such integrative\nanalyses and also opportunities for such cyberinfrastructure to be further\ndeveloped, particularly to take advantage of possible semantic similarities of\nvalue to knowledge discovery in the Omics enterprise. We discuss these\nopportunities in the context of further enhancing the capabilities of this\npowerful integrative platform."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Towards a fully predictive model of flight paths in pigeons navigating\n  in the familiar area: prediction across differing individuals"}, {"role": "assistant", "content": "This paper will detail the basis of our previously developed predictive model\nfor pigeon flight paths based on observations of the specific individual being\npredicted. We will then describe how this model can be adapted to predict the\nflight of a new, unobserved bird, based on observations of other individuals\nfrom the same release site. We will test the accuracy of these predictions\nrelative to naive models with no previous flight information and those trained\non the focal bird's own previous flights, and discuss the implications of these\nresults for the nature of navigational cue use in the familiar area. Finally we\nwill discuss how visual cues may be explicitly encoded in the model in future\nwork."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: PyPanda: a Python Package for Gene Regulatory Network Reconstruction"}, {"role": "assistant", "content": "PANDA (Passing Attributes between Networks for Data Assimilation) is a gene\nregulatory network inference method that uses message-passing to integrate\nmultiple sources of 'omics data. PANDA was originally coded in C++. In this\napplication note we describe PyPanda, the Python version of PANDA. PyPanda runs\nconsiderably faster than the C++ version and includes additional features for\nnetwork analysis. Availability: The open source PyPanda Python package is\nfreely available at https://github.com/davidvi/pypanda. Contact: d.g.p.van\nijzendoorn@lumc.nl"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A hybrid algorithm for coupling PDE and compartment-based dynamics"}, {"role": "assistant", "content": "Stochastic simulation methods can be applied successfully to model exact\nspatio-temporally resolved reaction-diffusion systems. However, in many cases,\nthese methods can quickly become extremely computationally intensive with\nincreasing particle numbers. An alternative description of many of these\nsystems can be derived in the diffusive limit as a deterministic, continuum\nsystem of partial differential equations. Although the numerical solution of\nsuch partial differential equations is, in general, much more efficient than\nthe full stochastic simulation, the deterministic continuum description is\ngenerally not valid when copy numbers are low and stochastic effects dominate.\nTherefore, to take advantage of the benefits of both of these types of models,\neach of which may be appropriate in different parts of a spatial domain, we\nhave developed an algorithm that can be used to couple these two types of model\ntogether. This hybrid coupling algorithm uses an overlap region between the two\nmodelling regimes. By coupling fluxes at one end of the interface and using a\nconcentration-matching condition at the other end, we ensure that mass is\nappropriately transferred between PDE- and compartment-based regimes. Our\nmethodology gives notable reductions in simulation time in comparison with\nusing a fully stochastic model, whilst maintaining the important stochastic\nfeatures of the system and providing detail in appropriate areas of the domain.\nWe test our hybrid methodology robustly by applying it to several biologically\nmotivated problems including diffusion and morphogen gradient formation. Our\nanalysis shows that the resulting error is small, unbiased and does not grow\nover time."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: eQTL mapping and inherited risk enrichment analysis : a systems biology\n  approach for coronary artery disease"}, {"role": "assistant", "content": "Despite extensive research during the last decades, coronary artery disease\n(CAD) remains the number one cause of death, responsible for near 50% of global\nmortality. A main reason for this is that CAD has a complex inheritance and\netiology that unlike rare single gene disorders cannot fully be understood from\nstudies of of genes one-by-one.In parallel, studies that simultaneously assess\nmultiple, functionally associated genes are warranted. For this reason we\nundertook the Stockholm Atherosclerosis Gene Expression (STAGE) study that\nbesides careful clinical characterization and genome-wide DNA genotyping also\nassessed the global gene expression profiles from seven CAD-relevant vascular\nand metabolic tissues. In this thesis report we show that by integrating GWAS\nwith genetics of gene expression studies like STAGE, we can advance our\nunderstanding from the perspective of multiple genes and gene variants acting\nin conjunction to cause CAD in the form of regulatory gene networks. This is\ndone through developing new bioinformatics tools and applying them to\ndisease-specific, genetics of global gene expression studies like STAGE. These\ntools are necessary to go beyond our current limited single-gene understanding\nof complex traits, like CAD."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: pSpatiocyte: A Parallel Stochastic Method for Particle\n  Reaction-Diffusion Systems"}, {"role": "assistant", "content": "Computational systems biology has provided plenty of insights into cell\nbiology. Early on, the focus was on reaction networks between molecular\nspecies. Spatial distribution only began to be considered mostly within the\nlast decade. However, calculations were restricted to small systems because of\ntremendously high computational workloads. To date, application to the cell of\ntypical size with molecular resolution is still far from realization. In this\narticle, we present a new parallel stochastic method for particle\nreaction-diffusion systems. The program called pSpatiocyte was created bearing\nin mind reaction networks in biological cells operating in crowded\nintracellular environments as the primary simulation target. pSpatiocyte\nemploys unique discretization and parallelization algorithms based on a\nhexagonal close-packed lattice for efficient execution particularly on large\ndistributed memory parallel computers. For two-level parallelization, we\nintroduced isolated subdomain and tri-stage lockstep communication for\nprocess-level, and voxel-locking techniques for thread-level. We performed a\nseries of parallel runs on RIKEN's K computer. For a fine lattice that had\nrelatively low occupancy, pSpatiocyte achieved 7686 times speedup with 663552\ncores relative to 64 cores from the viewpoint of strong scaling and exhibited\n74\\% parallel efficiency. As for weak scaling, efficiencies at least 60% were\nobserved up to 663552 cores. In addition to computational performance,\ndiffusion and reaction rates were validated by theory and another\nwell-validated program and had good agreement. Lastly, as a preliminary example\nof real-world applications, we present a calculation of the MAPK model, a\ntypical reaction network motif in cell signaling pathways."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Bayesian approach to parameter identification with an application to\n  Turing systems"}, {"role": "assistant", "content": "We present a Bayesian methodology for infinite as well as finite dimensional\nparameter identification for partial differential equation models. The Bayesian\nframework provides a rigorous mathematical framework for incorporating prior\nknowledge on uncertainty in the observations and the parameters themselves,\nresulting in an approximation of the full probability distribution for the\nparameters, given the data. Although the numerical approximation of the full\nprobability distribution is computationally expensive, parallelised algorithms\ncan make many practically relevant problems computationally feasible. The\nprobability distribution not only provides estimates for the values of the\nparameters, but also provides information about the inferability of parameters\nand the sensitivity of the model. This information is crucial when a\nmathematical model is used to study the outcome of real-world experiments.\nKeeping in mind the applicability of our approach to tackle real-world\npractical problems with data from experiments, in this initial proof of concept\nwork, we apply this theoretical and computational framework to parameter\nidentification for a well studied semilinear reaction-diffusion system with\nactivator-depleted reaction kinetics, posed on evolving and stationary domains."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Parameter inference method for stochastic single-cell dynamics from\n  tree-structured data"}, {"role": "assistant", "content": "With the advance of experimental techniques such as time-lapse fluorescence\nmicroscopy, the availability of single-cell trajectory data has vastly\nincreased, and so has the demand for computational methods suitable for\nparameter inference with this type of data. However, most of the currently\navailable methods treat single-cell trajectories independently, ignoring the\nmother-daughter relationships and the information provided by population\nstructure. This information is however essential if a process of interest\nhappens at cell division, or if it evolves slowly compared to the duration of\nthe cell cycle. In this work, we highlight the importance of tracking cell\nlineage trees and propose a Bayesian framework for parameter inference on\ntree-structured data. Our method relies on a combination of Sequential Monte\nCarlo for likelihood approximation and Markov Chain Monte Carlo for parameter\nsampling. We demonstrate the capabilities of our inference framework on two\nsimple examples in which the lineage tree information is necessary: one in\nwhich the cell phenotype can only switch at cell division and another where the\ncell type fluctuates randomly over timescales that extend well beyond the\nlifetime of a single cell."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Analysis of differential splicing suggests different modes of short-term\n  splicing regulation"}, {"role": "assistant", "content": "Motivation: Alternative splicing is an important mechanism in which the\nregions of pre-mRNAs are differentially joined in order to form different\ntranscript isoforms. Alternative splicing is involved in the regulation of\nnormal physiological functions but also linked to the development of diseases\nsuch as cancer. We analyse differential expression and splicing using RNA-seq\ntime series in three different settings: overall gene expression levels,\nabsolute transcript expression levels and relative transcript expression\nlevels.\n  Results: Using estrogen receptor $\\alpha$ signalling response as a model\nsystem, our Gaussian process (GP)-based test identifies genes with differential\nsplicing and/or differentially expressed transcripts. We discover genes with\nconsistent changes in alternative splicing independent of changes in absolute\nexpression and genes where some transcripts change while others stay constant\nin absolute level. The results suggest classes of genes with different modes of\nalternative splicing regulation during the experiment.\n  Availability: R and Matlab codes implementing the method are available at\nhttps://github.com/PROBIC/diffsplicing . An interactive browser for viewing all\nmodel fits is available at http://users.ics.aalto.fi/hande/splicingGP/ ."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Measuring cellular traction forces on non-planar substrates"}, {"role": "assistant", "content": "Animal cells use traction forces to sense the mechanics and geometry of their\nenvironment. Measuring these traction forces requires a workflow combining cell\nexperiments, image processing and force reconstruction based on elasticity\ntheory. Such procedures have been established before mainly for planar\nsubstrates, in which case one can use the Green's function formalism. Here we\nintroduce a worksflow to measure traction forces of cardiac myofibroblasts on\nnon-planar elastic substrates. Soft elastic substrates with a wave-like\ntopology were micromolded from polydimethylsiloxane (PDMS) and fluorescent\nmarker beads were distributed homogeneously in the substrate. Using feature\nvector based tracking of these marker beads, we first constructed a hexahedral\nmesh for the substrate. We then solved the direct elastic boundary volume\nproblem on this mesh using the finite element method (FEM). Using data\nsimulations, we show that the traction forces can be reconstructed from the\nsubstrate deformations by solving the corresponding inverse problem with a\nL1-norm for the residue and a L2-norm for 0th order Tikhonov regularization.\nApplying this procedure to the experimental data, we find that cardiac\nmyofibroblast cells tend to align both their shapes and their forces with the\nlong axis of the deformable wavy substrate."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: DNA-to-go: A portable smartphone-enabled PCR assay platform"}, {"role": "assistant", "content": "We address the need for affordable, rapid, and easy to use diagnostic\ntechnologies by coupling an innovative thermocycling system that harnesses\nnatural convection to perform rapid DNA amplification via the polymerase chain\nreaction (PCR) with smartphone-based detection. Our approach offers an\ninherently simple design that enables PCR to be completed in 10-20 minutes.\nElectrical power requirements are dramatically reduced by harnessing natural\nconvection to actuate the reaction, allowing the entire system to be operated\nfrom a standard USB connection (5 V) via solar battery packs. Instantaneous\ndetection and analysis are enabled using an ordinary smartphone camera and\ndedicated app interface."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Identifying statistically significant patterns in gene expression data"}, {"role": "assistant", "content": "Motivation: Clustering techniques are routinely applied to identify patterns\nof co-expression in gene expression data. Co-regulation, and involvement of\ngenes in similar cellular function, is subsequently inferred from the clusters\nwhich are obtained. Increasingly sophisticated algorithms have been applied to\nmicroarray data, however, less attention has been given to the statistical\nsignificance of the results of clustering studies. We present a technique for\nthe analysis of commonly used hierarchical linkage-based clustering called\nSignificance Analysis of Linkage Trees (SALT).\n  Results: The statistical significance of pairwise similarity levels between\ngene expression profiles, a measure of co-expression, is established using a\nsurrogate data analysis method. We find that a modified version of the standard\nlinkage technique, complete-linkage, must be used to generate hierarchical\nlinkage trees with the appropriate properties. The approach is illustrated\nusing synthetic data generated from a novel model of gene expression profiles\nand is then applied to previously analysed microarray data on the\ntranscriptional response of human fibroblasts to serum stimulation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Formal Modeling and Analysis of Pancreatic Cancer Microenvironment"}, {"role": "assistant", "content": "The focus of pancreatic cancer research has been shifted from pancreatic\ncancer cells towards their microenvironment, involving pancreatic stellate\ncells that interact with cancer cells and influence tumor progression. To\nquantitatively understand the pancreatic cancer microenvironment, we construct\na computational model for intracellular signaling networks of cancer cells and\nstellate cells as well as their intercellular communication. We extend the\nrule-based BioNetGen language to depict intra- and inter-cellular dynamics\nusing discrete and continuous variables respectively. Our framework also\nenables a statistical model checking procedure for analyzing the system\nbehavior in response to various perturbations. The results demonstrate the\npredictive power of our model by identifying important system properties that\nare consistent with existing experimental observations. We also obtain\ninteresting insights into the development of novel therapeutic strategies for\npancreatic cancer."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A parallelizable sampling method for parameter inference of large\n  biochemical reaction models"}, {"role": "assistant", "content": "The development of mechanistic models of biological systems is a central part\nof Systems Biology. One major task in developing these models is the inference\nof the correct model parameters. Due to the size of most realistic models and\ntheir possibly complex dynamical behaviour one must usually rely on sample\nbased methods. In this paper we present a novel algorithm that reliably\nestimates model parameters for deterministic as well as stochastic models from\ntrajectory data. Our algorithm samples iteratively independent particles from\nthe level sets of the likelihood and recovers the posterior from these level\nsets. The presented approach is easily parallelizable and, by utilizing density\nestimation through Dirichlet Process Gaussian Mixture Models, can deal with\nhigh dimensional parameter spaces. We illustrate that our algorithm is\napplicable to large, realistic deterministic and stochastic models and succeeds\nin inferring the correct posterior from a given number of observed\ntrajectories. This algorithm presents a novel, computationally feasible\napproach to identify parameters of large biochemical reaction models based on\nsample path data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Automated pulse discrimination of two freely-swimming weakly electric\n  fish and analysis of their electrical behavior during a dominance contest"}, {"role": "assistant", "content": "Electric fishes modulate their electric organ discharges with a remarkable\nvariability. Some patterns can be easily identified, such as pulse rate\nchanges, offs and chirps, which are often associated with important behavioral\ncontexts, including aggression, hiding and mating. However, these behaviors are\nonly observed when at least two fish are freely interacting. Although their\nelectrical pulses can be easily recorded by non-invasive techniques,\ndiscriminating the emitter of each pulse is challenging when physically similar\nfish are allowed to freely move and interact. Here we optimized a custom-made\nsoftware recently designed to identify the emitter of pulses by using automated\nchirp detection, adaptive threshold for pulse detection and slightly changing\nhow the recorded signals are integrated. With these optimizations, we performed\na quantitative analysis of the statistical changes throughout the dominance\ncontest with respect to Inter Pulse Intervals, Chirps and Offs dyads of freely\nmoving Gymnotus carapo. In all dyads, chirps were signatures of subsequent\nsubmission, even when they occurred early in the contest. Although offs were\nobserved in both dominant and submissive fish, they were substantially more\nfrequent in submissive individuals, in agreement with the idea from previous\nstudies that offs are electric cues of submission. In general, after the\ndominance is established the submissive fish significantly changes its average\npulse rate, while the pulse rate of the dominant remained unchanged.\nAdditionally, no chirps or offs were observed when two fish were manually kept\nin direct physical contact, suggesting that these electric behaviors are not\nautomatic responses to physical contact."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Developing and Testing a Bayesian Analysis of Fluorescence Lifetime\n  Measurements"}, {"role": "assistant", "content": "FRET measurements can provide dynamic spatial information on length scales\nsmaller than the diffraction limit of light. Several methods exist to measure\nFRET between fluorophores, including Fluorescence Lifetime Imaging Microscopy\n(FLIM), which relies on the reduction of fluorescence lifetime when a\nfluorophore is undergoing FRET. FLIM measurements take the form of histograms\nof photon arrival times, containing contributions from a mixed population of\nfluorophores both undergoing and not undergoing FRET, with the measured\ndistribution being a mixture of exponentials of different lifetimes. Here, we\npresent an analysis method based on Bayesian inference that rigorously takes\ninto account several experimental complications. We test the precision and\naccuracy of our analysis on controlled experimental data and verify that we can\nfaithfully extract model parameters, both in the low-photon and low-fraction\nregimes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Protein single-model quality assessment by feature-based probability\n  density functions"}, {"role": "assistant", "content": "Protein quality assessment (QA) has played an important role in protein\nstructure prediction. We developed a novel single-model quality assessment\nmethod - Qprob. Qprob calculates the absolute error for each protein feature\nvalue against the true quality scores (i.e. GDT-TS scores) of protein\nstructural models, and uses them to estimate its probability density\ndistribution for quality assessment. Qprob has been blindly tested on the 11th\nCritical Assessment of Techniques for Protein Structure Prediction (CASP11) as\nMULTICOM-NOVEL server. The official CASP result shows that Qprob ranks as one\nof the top single-model QA methods. In addition, Qprob makes contributions to\nour protein tertiary structure predictor MULTICOM, which is officially ranked\n3rd out of 143 predictors. The good performance shows that Qprob is good at\nassessing the quality of models of hard targets. These results demonstrate that\nthis new probability density distribution based method is effective for protein\nsingle-model quality assessment and is useful for protein structure prediction.\nThe webserver and software packages of Qprob are available at:\nhttp://calla.rnet.missouri.edu/qprob/."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Characterization and reduction of variability in selection based on\n  effect-size using association measures in cohort study of heterogeneous\n  diseases"}, {"role": "assistant", "content": "Cohort studies employ pairwise measures of association to quantify\ndependencies among conditions and exposures. To reliably use these measures to\ndraw conclusions about the underlying association strengths requires that the\nmeasures be robust and unbiased. These considerations assume greater\nsignificance when applied to disease networks, where associations among\nheterogeneous pairs of diseases are ranked. Using disease diagnoses data from a\nlarge cohort of 5.5 million individuals, we develop a comprehensive methodology\nto characterize the bias of standard association measures like relative risk\nand $\\phi$ correlation. To overcome these biases, we devise a novel measure\nbased on a stochastic model for disease development. The new measure is\ndemonstrated to have the least overall bias and hence would be most suitable\nfor application to heterogeneous disease cohorts."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Lecture notes on stochastic models in systems biology"}, {"role": "assistant", "content": "These notes provide a short, focused introduction to modelling stochastic\ngene expression, including a derivation of the master equation, the recovery of\ndeterministic dynamics, birth-and-death processes, and Langevin theory. The\nnotes were last updated around 2010 and written for lectures given at summer\nschools held at McGill University's Centre for Non-linear Dynamics in 2004,\n2006, and 2008."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Caveat on the Boltzmann distribution function use in biology"}, {"role": "assistant", "content": "Sigmoid semilogarithmic functions with shape of Boltzmann equations, have\nbecome extremely popular to describe diverse biological situations. Part of the\npopularity is due to the easy avail- ability of software which fits Boltzmann\nfunctions to data, without much knowledge of the fitting procedure or the\nstatistical properties of the parameters derived from the procedure. The\npurpose of this paper is to explore the plasticity of the Boltzmann function to\nfit data, some aspects of the optimization procedure to fit the function to\ndata and how to use this plastic function to differentiate the effect of\ntreatment on data and to attest the statistical significance of treatment\neffect on the data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Patterns of Selection of Human Movements I: Movement Utility, Metabolic\n  Energy, and Normal Walking Gaits"}, {"role": "assistant", "content": "The biomechanics of the human body allow humans a range of possible ways of\nexecuting movements to attain specific goals. Nevertheless, humans exhibit\nsignificant patterns in how they execute movements. We propose that the\nobserved patterns of human movement arise because subjects select those ways to\nexecute movements that are, in a rigorous sense, optimal. In this project, we\nshow how this proposition can guide the development of computational models of\nmovement selection and thereby account for human movement patterns. We proceed\nby first developing a movement utility formalism that operationalizes the\nconcept of a best or optimal way of executing a movement using a utility\nfunction so that the problem of movement selection becomes the problem of\nfinding the movement that maximizes the utility function. Since the movement\nutility formalism includes a contribution of the metabolic energy of the\nmovement (maximum utility movements try to minimize metabolic energy), we also\ndevelop a metabolic energy formalism that we can use to construct estimators of\nthe metabolic energies of particular movements. We then show how we can\nconstruct an estimator for the metabolic energies of normal walking gaits and\nwe use that estimator to construct a movement utility model of the selection of\nnormal walking gaits and show that the relationship between avg. walking speed\nand avg. step length predicted by this model agrees with observation. We\nconclude by proposing a physical mechanism that a subject might use to estimate\nthe metabolic energy of a movement in practice."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Boosting Docking-based Virtual Screening with Deep Learning"}, {"role": "assistant", "content": "In this work, we propose a deep learning approach to improve docking-based\nvirtual screening. The introduced deep neural network, DeepVS, uses the output\nof a docking program and learns how to extract relevant features from basic\ndata such as atom and residues types obtained from protein-ligand complexes.\nOur approach introduces the use of atom and amino acid embeddings and\nimplements an effective way of creating distributed vector representations of\nprotein-ligand complexes by modeling the compound as a set of atom contexts\nthat is further processed by a convolutional layer. One of the main advantages\nof the proposed method is that it does not require feature engineering. We\nevaluate DeepVS on the Directory of Useful Decoys (DUD), using the output of\ntwo docking programs: AutodockVina1.1.2 and Dock6.6. Using a strict evaluation\nwith leave-one-out cross-validation, DeepVS outperforms the docking programs in\nboth AUC ROC and enrichment factor. Moreover, using the output of\nAutodockVina1.1.2, DeepVS achieves an AUC ROC of 0.81, which, to the best of\nour knowledge, is the best AUC reported so far for virtual screening using the\n40 receptors from DUD."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Full Computational Reproducibility in Biological Science: Methods,\n  Software and a Case Study in Protein Biology"}, {"role": "assistant", "content": "Independent computational reproducibility of scientific results is rapidly\nbecoming of pivotal importance in scientific progress as computation itself\nplays a more and more central role in so many branches of science.\nHistorically, reproducibility has followed the familiar Popperian [38] model\nwhereby theory cannot be verified by scientific testing, it can only be\nfalsified. Ultimately, this implies that if an experiment cannot be reproduced\nindependently to some satisfactory level of precision, its value is essentially\nunquantifiable; put brutally, it is impossible to determine its scientific\nvalue. The burgeoning presence of software in most scientific work adds a new\nand particularly opaque layer of complexity [29]. In spite of much recent\ninterest in many scientific areas, emphasis remains more on procedures,\nstrictures and discussion [12, 14, 16, 29, 30, 37, 41], reflecting the\ninexperience of most scientific journals when it comes to software, rather than\nthe details of how computational reproducibility is actually achieved, for\nwhich there appear to be relatively few guiding examples [6, 10, 17]. After\nconsidering basic principles, here we show how full computational\nreproducibility can be achieved in practice at every stage using a case study\nof a multi-gigabyte protein study on the open SwissProt protein database, from\ndata download all the way to individual figure by figure reproduction as an\nexemplar for general scientific computation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: matLeap: A fast adaptive Matlab-ready tau-leaping implementation\n  suitable for Bayesian inference"}, {"role": "assistant", "content": "Background: Species abundance distributions in chemical reaction network\nmodels cannot usually be computed analytically. Instead, stochas- tic\nsimulation algorithms allow sample from the the system configuration. Although\nmany algorithms have been described, no fast implementation has been provided\nfor {\\tau}-leaping which i) is Matlab-compatible, ii) adap- tively alternates\nbetween SSA, implicit and explicit {\\tau}-leaping, and iii) provides summary\nstatistics necessary for Bayesian inference. Results: We provide a\nMatlab-compatible implementation of the adap- tive explicit-implicit\n{\\tau}-leaping algorithm to address the above-mentioned deficits. matLeap\nprovides equal or substantially faster results compared to two widely used\nsimulation packages while maintaining accuracy. Lastly, matLeap yields summary\nstatistics of the stochastic process unavailable with other methods, which are\nindispensable for Bayesian inference. Conclusions: matLeap addresses\nshortcomings in existing Matlab-compatible stochastic simulation software,\nproviding significant speedups and sum- mary statistics that are especially\nuseful for researchers utilizing particle- filter based methods for Bayesian\ninference. Code is available for download at\nhttps://github.com/claassengroup/matLeap. Contact:\njustin.feigelman@imsb.biol.ethz.ch"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Efficient parameter sensitivity computation for spatially-extended\n  reaction networks"}, {"role": "assistant", "content": "Reaction-diffusion models are widely used to study spatially-extended\nchemical reaction systems. In order to understand how the dynamics of a\nreaction-diffusion model are affected by changes in its input parameters,\nefficient methods for computing parametric sensitivities are required. In this\nwork, we focus on stochastic models of spatially-extended chemical reaction\nsystems that involve partitioning the computational domain into voxels.\nParametric sensitivities are often calculated using Monte Carlo techniques that\nare typically computationally expensive; however, variance reduction techniques\ncan decrease the number of Monte Carlo simulations required. By exploiting the\ncharacteristic dynamics of spatially-extended reaction networks, we are able to\nadapt existing finite difference schemes to robustly estimate parametric\nsensitivities in a spatially-extended network. We show that algorithmic\nperformance depends on the dynamics of the given network and the choice of\nsummary statistics. We then describe a hybrid technique that dynamically\nchooses the most appropriate simulation method for the network of interest. Our\nmethod is tested for functionality and accuracy in a range of different\nscenarios."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Classification of syncope through data analytics"}, {"role": "assistant", "content": "Objective: Syncope is a sudden loss of consciousness with loss of postural\ntone and spontaneous recovery; it is a common condition, albeit one that is\nchallenging to accurately diagnose. Uncertainties about the triggering\nmechanisms and their underlying pathophysiology have led to various\nclassifications of patients exhibiting this symptom. This study presents a new\nway to classify syncope types using machine learning. Method: we hypothesize\nthat syncope types can be characterized by analyzing blood pressure and heart\nrate time series data obtained from the head-up tilt test procedure. By\noptimizing classification rates, we identify a small number of determining\nmarkers which enable data clustering. Results: We apply the proposed method to\nclinical data from 157 subjects; each subject was identified by an expert as\nbeing either healthy or suffering from one of three conditions:\ncardioinhibitory syncope, vasodepressor syncope and postural orthostatic\ntachycardia. Clustering confirms the three disease groups and identifies two\ndistinct subgroups within the healthy controls. Conclusion: The proposed method\nprovides evidence to question current syncope classifications; it also offers\nmeans to refine them. Significance: Current syncope classifications are not\nbased on pathophysiology and have not led to significant improvements in\npatient care. It is expected that a more faithful classification will\nfacilitate our understanding of the autonomic system for healthy subjects,\nwhich is essential in analyzing pathophysiology of the disease groups."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Unsupervised cryo-EM data clustering through adaptively constrained\n  K-means algorithm"}, {"role": "assistant", "content": "In single-particle cryo-electron microscopy (cryo-EM), K-means clustering\nalgorithm is widely used in unsupervised 2D classification of projection images\nof biological macromolecules. 3D ab initio reconstruction requires accurate\nunsupervised classification in order to separate molecular projections of\ndistinct orientations. Due to background noise in single-particle images and\nuncertainty of molecular orientations, traditional K-means clustering algorithm\nmay classify images into wrong classes and produce classes with a large\nvariation in membership. Overcoming these limitations requires further\ndevelopment on clustering algorithms for cryo-EM data analysis. We propose a\nnovel unsupervised data clustering method building upon the traditional K-means\nalgorithm. By introducing an adaptive constraint term in the objective\nfunction, our algorithm not only avoids a large variation in class sizes but\nalso produces more accurate data clustering. Applications of this approach to\nboth simulated and experimental cryo-EM data demonstrate that our algorithm is\na significantly improved alterative to the traditional K-means algorithm in\nsingle-particle cryo-EM analysis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Mathematical Imaging Methods for Mitosis Analysis in Live-Cell Phase\n  Contrast Microscopy"}, {"role": "assistant", "content": "In this paper we propose a workflow to detect and track mitotic cells in\ntime-lapse microscopy image sequences. In order to avoid the requirement for\ncell lines expressing fluorescent markers and the associated phototoxicity,\nphase contrast microscopy is often preferred over fluorescence microscopy in\nlive-cell imaging. However, common specific image characteristics complicate\nimage processing and impede use of standard methods. Nevertheless, automated\nanalysis is desirable due to manual analysis being subjective, biased and\nextremely time-consuming for large data sets. Here, we present the following\nworkflow based on mathematical imaging methods. In the first step, mitosis\ndetection is performed by means of the circular Hough transform. The obtained\ncircular contour subsequently serves as an initialisation for the tracking\nalgorithm based on variational methods. It is sub-divided into two parts: in\norder to determine the beginning of the whole mitosis cycle, a backwards\ntracking procedure is performed. After that, the cell is tracked forwards in\ntime until the end of mitosis. As a result, the average of mitosis duration and\nratios of different cell fates (cell death, no division, division into two or\nmore daughter cells) can be measured and statistics on cell morphologies can be\nobtained. All of the tools are featured in the user-friendly\nMATLAB$^{\\circledR}$ Graphical User Interface MitosisAnalyser."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Growth and proline content in NaCl stressed plants of annual medic\n  species"}, {"role": "assistant", "content": "Wild populations of Medicago ciliaris and Medicago polymorpha were subjected\nto four salt treatments 0, 50, 100 and 150 mM NaCl, plant growth and proline\nconcentration in leaves were assessed. The analyzed data revealed significant\nvariability in salt response within and between the two species, depending on\nthe salinity level. It was found that high NaCl concentrations affected all the\ngrowth parameters. However, the reduction was more important at higher NaCl\nconcentrations and the highest reduction was obtained for the populations of\nMedicago polymorpha where it reached around 90% in root length at 150 mM NaCl\nfor Pmar. The Tunisian population of Medicago ciliaris, prospected on soils\naffected by salinity, was the best tolerant in all ecotypes studied in this\nwork. This population, exhibits a particular adaptability to salt environment\nat both germination and seedling stage. Furthermore, the correlation among the\nstudied plants sensitivity and leaf proline concentration showed that high\nproline contents were related to their reactivity to salt. Consequently, it\nappeared that proline biosynthesis occurred presumably as a consequence of\ndisturbance in cell homoeostasis and reflected poor performance and greater\ndamage in response to salt stress. These findings indicated that this osmolytes\ncontent may be used as another useful criterion to differentiate salt-tolerant\nfrom salt sensitive plant in annual medics."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Patterns of Selection of Human Movements II: Movement Limits, Mechanical\n  Energy, and Very Slow Walking Gaits"}, {"role": "assistant", "content": "The biomechanics of the human body allow humans a range of possible ways of\nexecuting movements to attain specific goals. This range of movement is limited\nby a number of mechanical, biomechanical, or cognitive constraints. Shifts in\nthese limits result in changes available possible movements from which a\nsubject can select and can affect which movements a subject selects. Therefore\nby understanding the limits on the range of movement we can come to a better\nunderstanding of declines in movement performance due to disease or aging. In\nthis project, we look at how models for the limits on the range of movement can\nbe derived in a principled manner from a model of the movement. Using the\nexample of normal walking gaits, we develop a lower limit on the avg. walking\nspeed by examining the process by which the body restores mechanical energy\nlost during walking, and we develop an upper limit on the avg. step length by\nexamining the forces the body can exert doing external mechanical work, in this\ncase, pulling a cart. Making slight changes to the model for normal walking\ngaits, we develop a model of very slow walking gaits with avg. walking speeds\nbelow the lower limit on normal walking gaits but that also has a lower limit\non the avg. walking speed. We note that the lowest avg. walking speeds observed\nclinically fall into the range of very slow walking gaits so defined, and argue\nthat forms of bipedal locomotion with still lower speeds should be considered\ndistinct from walking gaits."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Sources of false positives and false negatives in the STATCHECK\n  algorithm: Reply to Nuijten et al. (2016)"}, {"role": "assistant", "content": "STATCHECK is an R algorithm designed to scan papers automatically for\ninconsistencies between test statistics and their associated p values (Nuijten\net al., 2016). The goal of this comment is to point out an important and\nwell-documented flaw in this busily applied algorithm: It cannot handle\ncorrected p values. As a result, statistical tests applying appropriate\ncorrections to the p value (e.g., for multiple tests, post-hoc tests,\nviolations of assumptions, etc.) are likely to be flagged as reporting\ninconsistent statistics, whereas papers omitting necessary corrections are\ncertified as correct. The STATCHECK algorithm is thus valid for only a subset\nof scientific papers, and conclusions about the quality or integrity of\nstatistical reports should never be based solely on this program."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Efficient estimation of the maximum metabolic productivity of batch\n  systems"}, {"role": "assistant", "content": "Production of chemicals from engineered organisms in a batch culture involves\nan inherent trade-off between productivity, yield, and titer. Existing\nstrategies for strain design typically focus on designing mutations that\nachieve the highest yield possible while maintaining growth viability. While\nthese methods are computationally tractable, an optimum productivity could be\nachieved by a dynamic strategy in which the intracellular division of resources\nis permitted to change with time. New methods for the design and implementation\nof dynamic microbial processes, both computational and experimental, have\ntherefore been explored to maximize productivity. However, solving for the\noptimal metabolic behavior under the assumption that all fluxes in the cell are\nfree to vary is a challenging numerical task. This work presents an efficient\nmethod for the calculation of a maximum theoretical productivity of a batch\nculture system using a dynamic optimization framework. This metric is analogous\nto the maximum theoretical yield, a measure that is well established in the\nmetabolic engineering literature and whose use helps guide strain and pathway\nselection. The proposed method follows traditional assumptions of dynamic flux\nbalance analysis: (1) that internal metabolite fluxes are governed by a\npseudo-steady state, and (2) that external metabolite fluxes are dynamically\nbounded. The optimization is achieved via collocation on finite elements, and\naccounts explicitly for an arbitrary number of flux changes. The method can be\nfurther extended to explicitly solve for the trade-off curve between maximum\nproductivity and yield. We demonstrate the method on succinate production in\ntwo common microbial hosts, Escherichia coli and Actinobacillus succinogenes,\nrevealing that nearly optimal yields and productivities can be achieved with\nonly two discrete flux stages."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Mechanism for long-acting chimeras based on fusion with the\n  carboxyl-terminal peptide (CTP) of human chorionic gonadotropin beta-subunit\n  3"}, {"role": "assistant", "content": "Thermodynamic scaling explains the dramatic successes of CTP fused human\ngrowth proteins as regards lifetime in vivo and enhanced functionality compared\nto their wild-type analogues, like Biogen. The theory is semi-quantitative and\ncontains no adjustable parameters. It shows how hydrophilic terminal spheres\norient fused proteins in the neighborhood of a membrane surface, extending\nlifetimes and improving functionality."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Towards a HPC-oriented parallel implementation of a learning algorithm\n  for bioinformatics applications"}, {"role": "assistant", "content": "Background: The huge quantity of data produced in Biomedical research needs\nsophisticated algorithmic methodologies for its storage, analysis, and\nprocessing. High Performance Computing (HPC) appears as a magic bullet in this\nchallenge. However, several hard to solve parallelization and load balancing\nproblems arise in this context. Here we discuss the HPC-oriented implementation\nof a general purpose learning algorithm, originally conceived for DNA analysis\nand recently extended to treat uncertainty on data (U BRAIN). The U-BRAIN\nalgorithm is a learning algorithm that finds a Boolean formula in disjunctive\nnormal form (DNF), of approximately minimum complexity, that is consistent with\na set of data (instances) which may have missing bits. The conjunctive terms of\nthe formula are computed in an iterative way by identifying, from the given\ndata, a family of sets of conditions that must be satisfied by all the positive\ninstances and violated by all the negative ones; such conditions allow the\ncomputation of a set of coefficients (relevances) for each attribute (literal),\nthat form a probability distribution, allowing the selection of the term\nliterals. The great versatility that characterizes it, makes U-BRAIN applicable\nin many of the fields in which there are data to be analyzed. However the\nmemory and the execution time required by the running are of O(n3) and of O(n5)\norder, respectively, and so, the algorithm is unaffordable for huge data sets."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Science In the Cloud (SIC): A use case in MRI Connectomics"}, {"role": "assistant", "content": "Modern technologies are enabling scientists to collect extraordinary amounts\nof complex and sophisticated data across a huge range of scales like never\nbefore. With this onslaught of data, we can allow the focal point to shift\ntowards answering the question of how we can analyze and understand the massive\namounts of data in front of us. Unfortunately, lack of standardized sharing\nmechanisms and practices often make reproducing or extending scientific results\nvery difficult. With the creation of data organization structures and tools\nwhich drastically improve code portability, we now have the opportunity to\ndesign such a framework for communicating extensible scientific discoveries.\nOur proposed solution leverages these existing technologies and standards, and\nprovides an accessible and extensible model for reproducible research, called\n\"science in the cloud\" (sic). Exploiting scientific containers, cloud computing\nand cloud data services, we show the capability to launch a computer in the\ncloud and run a web service which enables intimate interaction with the tools\nand data presented. We hope this model will inspire the community to produce\nreproducible and, importantly, extensible results which will enable us to\ncollectively accelerate the rate at which scientific breakthroughs are\ndiscovered, replicated, and extended."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Machine Learning Model Interpretability for Precision Medicine"}, {"role": "assistant", "content": "Interpretability of machine learning models is critical for data-driven\nprecision medicine efforts. However, highly predictive models are generally\ncomplex and are difficult to interpret. Here using Model-Agnostic Explanations\nalgorithm, we show that complex models such as random forest can be made\ninterpretable. Using MIMIC-II dataset, we successfully predicted ICU mortality\nwith 80% balanced accuracy and were also were able to interpret the relative\neffect of the features on prediction at individual level."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Preliminary quantification of freely exploring Atta insularis"}, {"role": "assistant", "content": "In this paper, we study the \"free exploration\" of individual ants of the\nspecies Atta insularis, i.e., their motion on a featureless flat, horizontal\nsurface. Two basic preliminary results emerge from our work (a) the free\nexploration is super-diffusive and (b) ants tend to turn more frequently to the\nleft than to the right -so we call them \"let-handed\"-. More statistics is\nneeded, however, to confirm those findings."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Impact of germline susceptibility variants in cancer genetic studies"}, {"role": "assistant", "content": "Although somatic mutations are the main contributor to cancer, underlying\ngermline alterations may increase the risk of cancer, mold the somatic\nalteration landscape and cooperate with acquired mutations to promote the tumor\nonset and/or maintenance. Therefore, both tumor genome and germline sequence\ndata have to be analyzed to have a more complete picture of the overall genetic\nfoundation of the disease. To reinforce such notion we quantitatively assess\nthe bias of restricting the analysis to somatic mutation data using mutational\ndata from well-known cancer genes which displays both types of alterations,\ninherited and somatically acquired mutations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Analysis of Metagenome Composition by the Method of Random Primers"}, {"role": "assistant", "content": "Metagenome, a mixture of different genomes (as a rule, bacterial), represents\na pattern, and the analysis of its composition is, currently, one of the\nchallenging problems of bioinformatics. In the present study, the possibility\nof evaluating metagenome composition by DNA-marker methods is investigated.\nThese methods are based on using primers, short nucleic acid fragments. Each\nprimer picks out of the tested genome the fragment set specific just for this\ngenome, which is called its spectrum (for the given primer) and is used for\nidentifying the genome. The DNA-marker method, applied to a metagenome, also\ngives its spectrum, which, obviously, represents the union of the spectra of\nall genomes belonging to the metagenome. Thus each primer provides a projection\nof the genomes and of the metagenome onto the corresponding spectra set. Here\nwe propose to apply the random projection (random primer) approach for\nanalyzing metagenome composition and present some estimates of the method\neffectiveness for the case of Random Amplified Polymorphic DNA (RAPD)\ntechnology."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantification of heparin in complex matrices (including urine) using a\n  mix-and-read fluorescence assay"}, {"role": "assistant", "content": "Heparin is an important anticoagulant drug, about one billion doses are\nproduced annually. It is a polydisperse sulfated polysaccharide, and the\ninherent heterogeneity makes the analysis of heparin difficult. The global\ncrisis resulting from adulterated heparin in 2008 has drawn renewed attention\nto the challenges that are associated with the quality control and\ncharacterization of this complex biological medicine from natural sources. The\npresent study addresses the need for simple and user-friendly analytical\nmethods for the fast and accurate quantification of heparin in complex\nmatrices. Direct quantification of heparin in the low microgram per mL range\nwas accomplished using a specific commercially available assay based on the\nfluorescent molecular probe Heparin Red, simply by mixing the heparin\ncontaining sample and a reagent solution in a 96-well microplate followed by\nfluorescence readout. A screening of typical impurities in raw heparin\n(selected other glycosaminoglycans, residual nucleic acids and proteins),\nrelated to the extraction from animal tissues, as well as of components of the\nurine matrix (inorganic salts, amino acids, trace proteins) revealed that these\ncompounds even in large excess have no or very little effect on the accuracy of\nheparin determination. Heparin spike detection in urine, a biological\nmulticomponent matrix, also showed good accuracy. We envision applications of\nthis mix-and-read assay in the process and quality control in heparin\nmanufacturing, but also in pharmacokinetic studies as a convenient tool for\nmeasuring of the urinary excretion of heparins."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Patterns of Selection of Human Movements III: Energy Efficiency,\n  Mechanical Advantage, and Walking Gait"}, {"role": "assistant", "content": "Human movements are physical processes combining the classical mechanics of\nthe human body moving in space and the biomechanics of the muscles generating\nthe forces acting on the body under sophisticated sensory-motor control. One\nway to characterize movement performance is through measures of energy\nefficiency that relate the mechanical energy of the body and metabolic energy\nexpended by the muscles. We expect the practical utility of such measures to be\ngreater when human subjects execute movements that maximize energy efficiency.\nWe therefore seek to understand if and when subjects select movements with that\nmaximizing energy efficiency. We proceed using a model-based approach to\ndescribe movements which perform a task requiring the body to add or remove\nexternal mechanical work to or from an object. We use the specific example of\nwalking gaits doing external mechanical work by pulling a cart, and estimate\nthe relationship between the avg. walking speed and avg. step length. In the\nlimit where no external work is done, we find that the estimated maximum energy\nefficiency walking gait is much slower than the walking gaits healthy adults\ntypically select. We then modify the situation of the walking gait by\nintroducing an idealized mechanical device that creates an adjustable\nmechanical advantage. The walking gaits that maximize the energy efficiency\nusing the optimal mechanical advantage are again much slower than the walking\ngaits healthy adults typically select. We finally modify the situation so that\nthe avg. walking speed is fixed and derive the pattern of the avg. step length\nand mechanical advantage that maximize energy efficiency."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: EMDUnifrac: Exact Linear Time Computation of the Unifrac Metric and\n  Identification of Differentially Abundant Organisms"}, {"role": "assistant", "content": "Both the weighted and unweighted Unifrac distances have been very\nsuccessfully employed to assess if two communities differ, but do not give any\ninformation about how two communities differ. We take advantage of recent\nobservations that the Unifrac metric is equivalent to the so-called earth\nmover's distance (also known as the Kantorovich-Rubinstein metric) to develop\nan algorithm that not only computes the Unifrac distance in linear time and\nspace, but also simultaneously finds which operational taxonomic units are\nresponsible for the observed differences between samples. This allows the\nalgorithm, called EMDUnifrac, to determine why given samples are different, not\njust if they are different, and with no added computational burden. EMDUnifrac\ncan be utilized on any distribution on a tree, and so is particularly suitable\nto analyzing both operational taxonomic units derived from amplicon sequencing,\nas well as community profiles resulting from classifying whole genome shotgun\nmetagenomes. The EMDUnifrac source code (written in python) is freely available\nat: https://github.com/dkoslicki/EMDUnifrac."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: DistributedFBA.jl: High-level, high-performance flux balance analysis in\n  Julia"}, {"role": "assistant", "content": "Motivation:\n  Flux balance analysis, and its variants, are widely used methods for\npredicting steady-state reaction rates in biochemical reaction networks. The\nexploration of high dimensional networks with such methods is currently\nhampered by software performance limitations.\n  Results:\n  DistributedFBA.jl is a high-level, high-performance, open-source\nimplementation of flux balance analysis in Julia. It is tailored to solve\nmultiple flux balance analyses on a subset or all the reactions of large and\nhuge-scale networks, on any number of threads or nodes.\n  Availability:\n  The code and benchmark data are freely available on\nhttp://github.com/opencobra/COBRA.jl. The documentation can be found at\nhttp://opencobra.github.io/COBRA.jl"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: RADAR: A Novel Fast-Screening Method for Reading Difficulties with\n  Special Focus on Dyslexia"}, {"role": "assistant", "content": "Dyslexia is a developmental learning disorder of single word reading accuracy\nand/or fluency, with compelling research directed towards understanding the\ncontributions of the visual system. While dyslexia is not an oculomotor\ndisease, readers with dyslexia have shown different eye movements than\ntypically developing students during text reading. Readers with dyslexia\nexhibit longer and more frequent fixations, shorter saccade lengths, more\nbackward refixations than typical readers. Furthermore, readers with dyslexia\nare known to have difficulty in reading long words, lower skipping rate of\nshort words, and high gaze duration on many words. It is an open question\nwhether it is possible to harness these distinctive oculomotor scanning\npatterns observed during reading in order to develop a screening tool that can\nreliably identify struggling readers, who may be candidates for dyslexia. Here,\nwe introduce a novel, fast, objective, non-invasive method, named Rapid\nAssessment of Difficulties and Abnormalities in Reading (RADAR) that screens\nfor features associated with the aberrant visual scanning of reading text seen\nin dyslexia. Eye tracking parameter measurements that are stable under retest\nand have high discriminative power, as indicated by their ROC curves, were\nobtained during silent text reading. These parameters were combined to derive a\ntotal reading score (TRS) that can reliably separate readers with dyslexia from\ntypical readers. We tested TRS in a group of school-age children ranging from\n8.5 to 12.5 years of age. TRS achieved 94.2% correct classification of children\ntested. Specifically, 35 out of 37 control (specificity 94.6%) and 30 out of 32\nreaders with dyslexia (sensitivity 93.8%) were classified correctly using\nRADAR, under a circular validation condition where the individual evaluated was\nnot included in the test construction group."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Burkholderia genome mining for nonribosomal peptide synthetases reveals\n  a great potential for novel siderophores and lipopeptides synthesis"}, {"role": "assistant", "content": "Burkholderia is an important genus encompassing a variety of species,\nincluding pathogenic strains as well as strains that promote plant growth. We\nhave carried out a global strategy, which combined two complementary\napproaches. The first one is genome guided with deep analysis of genome\nsequences and the second one is assay guided with experiments to support the\npredictions obtained in silico. This efficient screening for new secondary\nmetabolites, performed on 48 gapless genomes of Burkholderia species, revealed\na total of 161 clusters containing nonribosomal peptide synthetases (NRPSs),\nwith the potential to synthesize at least 11 novel products. Most of them are\nsiderophores or lipopeptides, two classes of products with potential\napplication in biocontrol. The strategy led to the identification, for the\nfirst time, of the cluster for cepaciachelin biosynthesis in the genome of\nBurkholderia ambifaria AMMD and a cluster corresponding to a new\nmalleobactin-like siderophore, called phymabactin, was identified in\nBurkholderia phymatum STM815 genome. In both cases, the siderophore was\nproduced when the strain was grown in iron-limited conditions. Elsewhere, the\ncluster for the antifungal burkholdin was detected in the genome of B.\nambifaria AMMD and also Burkholderia sp. KJ006. Burkholderia pseudomallei\nstrains harbor the genetic potential to produce a novel lipopeptide called\nburkhomycin, containing a peptidyl moiety of 12 monomers. A mixture of\nlipopeptides produced by Burkholderia rhizoxinica lowered the surface tension\nof the supernatant from 70 to 27 mN/m. The production of nonribosomal secondary\nmetabolites seems related to the three phylogenetic groups obtained from 16S\nrRNA sequences. Moreover, the genome-mining approach gave new insights into the\nnonribosomal synthesis exemplified by the identification of dual C/E domains in\nlipopeptide NRPSs, up to now essentially found in Pseudomonas strains."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: diagno-syst: a tool for accurate inventories in metabarcoding"}, {"role": "assistant", "content": "Metabarcoding on amplicons is rapidly expanding as a method to produce\nmolecular based inventories of microbial communities. Here, we work on\nfreshwater diatoms, which are microalgae possibly inventoried both on a\nmorphological and a molecular basis. We have developed an algorithm, in a\nprogram called diagno-syst, based a the notion of informative read, which\ncarries out supervised clustering of reads by mapping them exactly one by one\non all reads of a well curated and taxonomically annotated reference database.\nThis program has been run on a HPC (and HTC) infrastructure to address\ncomputation load. We compare optical and molecular based inventories on 10\nsamples from L\\'eman lake, and 30 from Swedish rivers. We track all\npossibilities of mismatches between both approaches, and compare the results\nwith standard pipelines (with heuristics) like Mothur. We find that the\ncomparison with optics is more accurate when using exact calculations, at the\nprice of a heavier computation load. It is crucial when studying the long tail\nof biodiversity, which may be overestimated by pipelines or algorithms using\nheuristics instead (more false positive). This work supports the analysis that\nthese methods will benefit from progress in, first, building an agreement\nbetween molecular based and morphological based systematics and, second, having\nas complete as possible publicly available reference databases."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantitative Comparison of Abundance Structures of Generalized\n  Communities: From B-Cell Receptor Repertoires to Microbiomes"}, {"role": "assistant", "content": "The \\emph{community}, the assemblage of organisms co-existing in a given\nspace and time, has the potential to become one of the unifying concepts of\nbiology, especially with the advent of high-throughput sequencing experiments\nthat reveal genetic diversity exhaustively. In this spirit we show that a tool\nfrom community ecology, the Rank Abundance Distribution (RAD), can be turned by\nthe new MaxRank normalization method into a generic, expressive descriptor for\nquantitative comparison of communities in many areas of biology. To illustrate\nthe versatility of the method, we analyze RADs from various \\emph{generalized\ncommunities}, i.e.\\ assemblages of genetically diverse cells or organisms,\nincluding human B cells, gut microbiomes under antibiotic treatment and of\ndifferent ages and countries of origin, and other human and environmental\nmicrobial communities. We show that normalized RADs enable novel quantitative\napproaches that help to understand structures and dynamics of complex\ngeneralize communities."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Validation of gait characteristics extracted from raw accelerometry\n  during walking against measures of physical function, mobility, fatigability,\n  and fitness"}, {"role": "assistant", "content": "Background. Wearable accelerometry devices allow collection of high-density\nactivity data in large epidemiological studies both in-the-lab as well as\nin-the-wild (free-living). Such data can be used to detect and identify periods\nof sustained harmonic walking. This report aims to establish whether the micro-\nand macro-features of walking identified in the laboratory and free-living\nenvironments are associated with measures of physical function, mobility,\nfatigability, and fitness.\n  Methods. Fifty-one older adults (median age 77.5) enrolled in the\nDevelopmental Epidemiologic Cohort Study in Pittsburgh, Pennsylvania were\nincluded in the analyses. The study included an in-the-lab component as well as\n7 days of monitoring in-the-wild. Participants were equipped with hip-worn\nActigraph GT3X+ activity monitors, which collect high-density raw accelerometry\ndata. We applied a walking identification algorithm to the data and defined\nfeatures of walking, such as participant-specific walking acceleration and\ncadence. The association between these walking features and physical function,\nmobility, fatigability, and fitness was quantified using linear regression\nanalysis.\n  Results. Micro-scale features of walking (acceleration and cadence) estimated\nfrom in-the-lab and in-the-wild data were associated with measures of physical\nfunction, mobility, fatigability, and fitness. In-the-lab median walking\nacceleration was strongly inversely associated with physical function,\nmobility, fatigability and fitness. Additionally, in-the-wild daily walking\ntime was inversely associated with usual- and fast-paced 400m walking time.\n  Conclusions. The proposed accelerometry-derived walking features are\nsignificantly associated with measures of physical function, mobility,\nfatigability, and fitness, which provides evidence of convergent validity."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Hidden Markov Movement Model for rapidly identifying behavioral states\n  from animal tracks"}, {"role": "assistant", "content": "1. Electronic telemetry is frequently used to document animal movement\nthrough time. Methods that can identify underlying behaviors driving specific\nmovement patterns can help us understand how and why animals use available\nspace, thereby aiding conservation and management efforts. For aquatic animal\ntracking data with significant measurement error, a Bayesian state-space model\ncalled the first-Difference Correlated Random Walk with Switching (DCRWS) has\noften been used for this purpose. However, for aquatic animals, highly accurate\ntracking data of animal movement are now becoming more common.\n  2. We developed a new Hidden Markov Model (HMM) for identifying behavioral\nstates from animal tracks with negligible error, which we called the Hidden\nMarkov Movement Model (HMMM). We implemented as the basis for the HMMM the\nprocess equation of the DCRWS, but we used the method of maximum likelihood and\nthe R package TMB for rapid model fitting.\n  3. We compared the HMMM to a modified version of the DCRWS for highly\naccurate tracks, the DCRWSnome, and to a common HMM for animal tracks fitted\nwith the R package moveHMM. We show that the HMMM is both accurate and suitable\nfor multiple species by fitting it to real tracks from a grey seal, lake trout,\nand blue shark, as well as to simulated data.\n  4. The HMMM is a fast and reliable tool for making meaningful inference from\nanimal movement data that is ideally suited for ecologists who want to use the\npopular DCRWS implementation for highly accurate tracking data. It additionally\nprovides a groundwork for development of more complex modelling of animal\nmovement with TMB. To facilitate its uptake, we make it available through the R\npackage swim."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Method for Massively Parallel Analysis of Time Series"}, {"role": "assistant", "content": "Quantification of system-wide perturbations from time series -omic data (i.e.\na large number of variables with multiple measures in time) provides the basis\nfor many downstream hypothesis generating tools. Here we propose a method,\nMassively Parallel Analysis of Time Series (MPATS) that can be applied to\nquantify transcriptome-wide perturbations. The proposed method characterizes\neach individual time series through its $\\ell_1$ distance to every other time\nseries. Application of MPATS to compare biological conditions produces a ranked\nlist of time series based on their magnitude of differences in their $\\ell_1$\nrepresentation, which then can be further interpreted through enrichment\nanalysis. The performance of MPATS was validated through its application to a\nstudy of IFN$\\alpha$ dendritic cell responses to viral and bacterial infection.\nIn conjunction with Gene Set Enrichment Analysis (GSEA), MPATS produced\nconsistently identified signature gene sets of anti-bacterial and anti-viral\nresponse. Traditional methods such as EDGE and GSEA Time Series (GSEA-TS)\nfailed to identify the relevant signature gene sets. Furthermore, the results\nof MPATS highlighted the crucial functional difference between STAT1/STAT2\nduring anti-viral and anti-bacterial response. In our simulation study, MPATS\nexhibited acceptable performance with small group size (n = 3), when the\nappropriate effect size is considered. This method can be easily adopted for\nother -omic data types."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The impact of Gene Ontology evolution on GO-Term Information Content"}, {"role": "assistant", "content": "The Gene Ontology (GO) is a major bioinformatics ontology that provides\nstructured controlled vocabularies to classify gene and proteins function and\nrole. The GO and its annotations to gene products are now an integral part of\nfunctional analysis. Recently, the evaluation of similarity among gene products\nstarting from their annotations (also referred to as semantic similarities) has\nbecome an increasing area in bioinformatics. While many research on updates to\nthe structure of GO and on the annotation corpora have been made, the impact of\nGO evolution on semantic similarities is quite unobserved. Here we extensively\nanalyze how GO changes that should be carefully considered by all users of\nsemantic similarities. GO changes in particular have a big impact on\ninformation content (IC) of GO terms. Since many semantic similarities rely on\ncalculation of IC it is obvious that the study of these changes should be\ndeeply investigated. Here we consider GO versions from 2005 to 2014 and we\ncalculate IC of all GO Terms considering five different formulation. Then we\ncompare these results. Analysis confirm that there exists a statistically\nsignificant difference among different calculation on the same version of the\nontology (and this is quite obvious) and there exists a statistically\ndifference among the results obtained with different GO version on the same IC\nformula. Results evidence there exist a remarkable bias due to the GO evolution\nthat has not been considered so far. Possible future works should keep into\naccount this consideration."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Bounds on stationary moments in stochastic chemical kinetics"}, {"role": "assistant", "content": "In the stochastic formulation of chemical kinetics, the stationary moments of\nthe population count of species can be described via a set of linear equations.\nHowever, except for some specific cases such as systems with linear reaction\npropensities, the moment equations are underdetermined as a lower order moment\nmight depend upon a higher order moment. Here, we propose a method to find\nlower, and upper bounds on stationary moments of molecular counts in a chemical\nreaction system. The method exploits the fact that statistical moments of any\npositive-valued random variable must satisfy some constraints. Such constraints\ncan be expressed as nonlinear inequalities on moments in terms of their lower\norder moments, and solving them in conjugation with the stationary moment\nequations results in bounds on the moments. Using two examples of biochemical\nsystems, we illustrate that not only one obtains upper and lower bounds on a\ngiven stationary moment, but these bounds also improve as one uses more moment\nequations and utilizes the inequalities for the corresponding higher order\nmoments. Our results provide avenues for development of moment approximations\nthat provide explicit bounds on moment dynamics for systems whose dynamics are\notherwise intractable."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A model-based approach to assist variety evaluation in sunflower crop"}, {"role": "assistant", "content": "Assessing the performance and the characteristics (e.g. yield, quality,\ndisease resistance, abiotic stress tolerance) of new varieties is a key\ncomponent of crop performance improvement. However, the variety testing process\nis presently exclusively based on experimental field approaches which\ninherently reduces the number and the diversity of experienced combinations of\nvarieties x environmental conditions in regard of the multiplicity of growing\nconditions within the cultivation area. Our aim is to make a greater and faster\nuse of the information issuing from these trials using crop modeling and\nsimulation to amplify the environmental and agronomic conditions in which the\nnew varieties are tested.\n  In this study, we present a model-based approach to assist variety testing\nand implement this approach on sunflower crop, using the SUNFLO simulation\nmodel and a subset of 80 trials from a large multi-environment trial (MET)\nconducted each year by agricultural extension services to compare newly\nreleased sunflower hybrids. After estimating parameter values (using plant\nphenotyping) to account for new genetic material, we independently evaluated\nthe model prediction capacity on the MET (model accuracy was 54.4 %) and its\ncapacity to rank commercial hybrids for performance level (Kendall's $\\tau$ =\n0.41, P < 0.01). We then designed a numerical experiment by combining the\npreviously tested genetic and new cropping conditions (2100 virtual trials) to\ndetermine the best varieties and related management in representative French\nproduction regions.\n  We suggest that this approach could find operational outcomes to recommend\nvarieties according to environment types. Such spatial management of genetic\nresources could potentially improve crop performance by reducing the\ngenotype-phenotype mismatch in farming environments."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Group-wise 3D registration based templates to study the evolution of ant\n  worker neuroanatomy"}, {"role": "assistant", "content": "The evolutionary success of ants and other social insects is considered to be\nintrinsically linked to division of labor and emergent collective intelligence.\nThe role of the brains of individual ants in generating these processes,\nhowever, is poorly understood. One genus of ant of special interest is\nPheidole, which includes more than a thousand species, most of which are\ndimorphic, i.e. their colonies contain two subcastes of workers: minors and\nmajors. Using confocal imaging and manual annotations, it has been demonstrated\nthat minor and major workers of different ages of three species of Pheidole\nhave distinct patterns of brain size and subregion scaling. However, these\nstudies require laborious effort to quantify brain region volumes and are\nsubject to potential bias. To address these issues, we propose a group-wise 3D\nregistration approach to build for the first time bias-free brain atlases of\nintra- and inter-subcaste individuals and automatize the segmentation of new\nindividuals."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A novel entropy-based hierarchical clustering framework for ultrafast\n  protein structure search and alignment"}, {"role": "assistant", "content": "Identification and alignment of three-dimensional folding of proteins may\nyield useful information about relationships too remote to be detected by\nconventional methods, such as sequence comparison, and may potentially lead to\nprediction of patterns and motifs in mutual structural fragments. With the\nexponential increase of structural proteomics data, the methods that scale with\nthe rate of increase of data lose efficiency. Hence, new methods that reduce\nthe computational expense of this problem should be developed. We present a\nnovel framework through which we are able to find and align protein structure\nneighbors via hierarchical clustering and entropy-based query search, and\npresent a web-based protein database search and alignment tool to demonstrate\nthe applicability of our approach. The resulting method replicates the results\nof the current gold standard with a minimal loss in sensitivity in a\nsignificantly shorter amount of time, while ameliorating the existing web\nworkspace of protein structure comparison with a customized and dynamic\nweb-based environment. Our tool serves as both a functional industrial means of\nprotein structure comparison and a valid demonstration of heuristics in\nproteomics."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Synthesis of Methotrexate loaded Cerium fluoride nanoparticles with pH\n  sensitive extended release coupled with Hyaluronic acid receptor with\n  plausible theranostic capabilities for preclinical safety studies"}, {"role": "assistant", "content": "A key challenge in drug delivery systems is the real time monitoring of\ndelivered drug and subsequent response. Recent advancement in nanotechnology\nhas enabled the design and preclinical implementation of novel drug delivery\nsystems (DDS) with theranostic abilities. Herein, fluorescent cerium fluoride\n(CeF3) nanoparticles (nps) were synthesized and their surface modified with a\ncoat of polyethylenimine (PEI). Thereafter, Methotrexate was conjugated upon it\nthrough glutaraldehyde crosslinking for a pH-sensitive release. This was\nfollowed by the addition of a Hyaluronic acid (HA) receptor via\n1-Ethyl-3-(3-dimethylaminopropyl)-carbodiimide and N-hydroxysuccinimide\n(EDC-NHS) chemistry to achieve a possible active drug targeting system. The\nobtained drug delivery nano-agent retains and exhibits unique photo-luminescent\nproperties attributed to the nps while exhibiting potential theranostic\ncapabilities."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Using efficient parallelization in Graphic Processing Units to\n  parameterize stochastic fire propagation models"}, {"role": "assistant", "content": "Fire propagation is a major concern in the world in general and in\nArgentinian northwestern Patagonia in particular where every year hundreds of\nhectares are affected by both natural and anthropogenic forest fires. We\ndeveloped an efficient cellular automata model in Graphic Processing Units\n(GPUs) to simulate fire propagation. The graphical advantages of GPUs were\nexploded by overlapping wind direction maps, as well as vegetation, slope and\naspect maps, taking into account relevant landscape characteristics for fire\npropagation. Stochastic propagation was performed with a probability model that\ndepends on aspect, slope, wind direction and vegetation type. Implementing a\ngenetic algorithm search strategy we show, using simulated fires, that we\nrecover the five parameter values that characterize fire propagation. The\nefficiency of the fire simulation procedure allowed us to also estimate the\nfire ignition point when it is unknown as well as its associated uncertainty,\nmaking this approach suitable for the analysis of fire spread based on maps of\nburned areas without knowing the point of origin of the fires or how they\nspread."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Topological Distances between Networks and Its Application to Brain\n  Imaging"}, {"role": "assistant", "content": "This paper surveys various distance measures for networks and graphs that\nwere introduced in persistent homology. The scope of the paper is limited to\nnetwork distances that were actually used in brain networks but the methods can\nbe easily adapted to any weighted graph in other fields. The network version of\nGromov-Hausdorff, bottleneck, kernel distances are introduced. We also\nintroduce a recently developed KS-test like distance based on monotonic\ntopology features such as the zeroth Betti number. Numerous toy examples and\nthe result of applying many different distances to the brain networks of\ndifferent clinical status and populations are given."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Convolutional Neural Networks for Automated Annotation of Cellular\n  Cryo-Electron Tomograms"}, {"role": "assistant", "content": "Cellular Electron Cryotomography (CryoET) offers the ability to look inside\ncells and observe macromolecules frozen in action. A primary challenge for this\ntechnique is identifying and extracting the molecular components within the\ncrowded cellular environment. We introduce a method using neural networks to\ndramatically reduce the time and human effort required for subcellular\nannotation and feature extraction. Subsequent subtomogram classification and\naveraging yields in-situ structures of molecular components of interest."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Early monsoon drought and mid-summer vapor pressure deficit induce\n  growth cessation of lower margin Picea crassifolia"}, {"role": "assistant", "content": "Extreme climatic events have been shown to be strong drivers of tree growth,\nforest dynamics, and range contraction. Here we study the climatic drivers of\nPicea crassifolia Kom., an endemic to northwest China where climate has\nsignificantly warmed. Picea crassifolia was sampled from its lower\ndistributional margin to its upper distributional margin on the Helan Mountains\nto test the hypothesis that 1) growth at the upper limit is limited by cool\ntemperatures and 2) is limited by drought at its lower limit. We found that\ntrees at the lower distributional margin have experienced a higher rate of\nstem-growth cessation events since 2001 compared to trees at other elevations.\nWhile all populations have a similar climatic sensitivity, stem-growth\ncessation events in trees at lower distributional margin appear to be driven by\nlow precipitation in June as the monsoon begins to deliver moisture to the\nregion. Evidence indicates that mid-summer (July) vapor pressure deficit (VPD)\nexacerbates the frequency of these events. These data and our analysis makes it\nevident that an increase in severity and frequency of drought early in the\nmonsoon season could increase the frequency and severity of stem-growth\ncessation in Picea crassifolia trees at lower elevations. Increases in VPD and\nwarming would likely exacerbate the growth stress of this species on Helan\nMountain. Hypothetically, if the combinations of low moisture and increased VPD\nstress becomes more common, the mortality rate of lower distributional margin\ntrees could increase, especially of those that are already experiencing events\nof temporary growth cessation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Natural and fishing mortalities affecting eastern sea garfish,\n  Hyporhamphus australis, inferred from age-frequency data using hazard\n  functions"}, {"role": "assistant", "content": "Estimates of age-specific natural (M) and fishing (F) mortalities among\neconomically important stocks are required to determine sustainable yields and,\nultimately, facilitate effective resource management. Here we used hazard\nfunctions to estimate mortality rates for eastern sea garfish, Hyporhamphus\naustralis, a pelagic species that forms the basis of an Australian commercial\nlampara-net fishery. Data describing annual (2004 to 2015) age frequencies (0-1\nto 5-6 years), yield, effort (boat-days), and average weights at age were used\nto fit various stochastic models to estimate mortality rates by maximum\nlikelihood. The model best supported by the data implied: (i) the escape of\nfish aged 0-1 years increased from approximately 90 to 97% as a result of a\nmandated increase in stretched mesh opening from 25 to 28 mm; (ii) full\nselectivity among older age groups; (iii) a constant M of 0.52 +- 0.06 per\nyear; and (iv) a decline in F between 2004 and 2015. Recruitment and biomass\nwere estimated to vary, but increased during the sampled period. The results\nreiterate the utility of hazard functions to estimate and partition mortality\nrates, and support traditional input controls designed to reduce both accounted\nand unaccounted F."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Deep learning based subdivision approach for large scale macromolecules\n  structure recovery from electron cryo tomograms"}, {"role": "assistant", "content": "Motivation: Cellular Electron CryoTomography (CECT) enables 3D visualization\nof cellular organization at near-native state and in sub-molecular resolution,\nmaking it a powerful tool for analyzing structures of macromolecular complexes\nand their spatial organizations inside single cells. However, high degree of\nstructural complexity together with practical imaging limitations make the\nsystematic de novo discovery of structures within cells challenging. It would\nlikely require averaging and classifying millions of subtomograms potentially\ncontaining hundreds of highly heterogeneous structural classes. Although it is\nno longer difficult to acquire CECT data containing such amount of subtomograms\ndue to advances in data acquisition automation, existing computational\napproaches have very limited scalability or discrimination ability, making them\nincapable of processing such amount of data.\n  Results: To complement existing approaches, in this paper we propose a new\napproach for subdividing subtomograms into smaller but relatively homogeneous\nsubsets. The structures in these subsets can then be separately recovered using\nexisting computation intensive methods. Our approach is based on supervised\nstructural feature extraction using deep learning, in combination with\nunsupervised clustering and reference-free classification. Our experiments show\nthat, compared to existing unsupervised rotation invariant feature and\npose-normalization based approaches, our new approach achieves significant\nimprovements in both discrimination ability and scalability. More importantly,\nour new approach is able to discover new structural classes and recover\nstructures that do not exist in training data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Patterns of Selection of Human Movements IV: Energy Efficiency,\n  Mechanical Advantage, and Asynchronous Arm-Cranking"}, {"role": "assistant", "content": "Human movements are physical processes combining the classical mechanics of\nthe human body moving in space and the biomechanics of the muscles generating\nthe forces acting on the body under sophisticated sensory-motor control. The\ncharacterization of the performance of human movements is a problem with\nimportant applications in clinical and sports research. One way to characterize\nmovement performance is through measures of energy efficiency that relate the\nmechanical energy of the body and metabolic energy expended by the muscles.\nSuch a characterization provides information about the performance of a\nmovement insofar as subjects select movements with the aim of maximizing the\nenergy efficiency. We examine the case of the energy efficiency of asynchronous\narm-cranking doing external mechanical work, that is, using the arms to turn an\nasynchronous arm-crank that performs external mechanical work. We construct a\nmetabolic energy model and use it estimate how cranking may be performed with\nmaximum energy efficiency, and recover the intuitive result that for larger\nexternal forces the crank-handles should be placed as far from the center of\nthe crank as is comfortable for the subject to turn. We further examine\nmechanical advantage in asynchronous arm-cranking by constructing an idealized\nsystem that is driven by a crank and which involves an adjustable mechanical\nadvantage, and analyze the case in which the avg. frequency is fixed and derive\nthe mechanical advantages that maximize energy efficiency."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Instant determination of the potential biomarker heparan sulfate in\n  human plasma by a mix-and-read fluorescence assay"}, {"role": "assistant", "content": "Heparan sulfate (HS) is a linear, polydisperse sulfated polysaccharide\nbelonging to the glycosaminoglycan family. HS proteoglycans are ubiquitously\nfound at the cell surface and extracellular matrix in animal species. HS is\ninvolved in the interaction with a wide variety of proteins and the regulation\nof many biological activities. In certain pathologic conditions, expression and\nshedding of HS proteoglycans is overregulated, or enzymatic degradation of HS\nin lysosomes is deficient, both leading to excess circulating free HS chains in\nblood plasma. HS has therefore been suggested as a biomarker for various severe\ndisease states. The structural heterogeneity makes the quantification of\nheparan sulfate in complex matrices such as human plasma challenging. HS plasma\nlevels are usually quantified by either disaccharide analysis or enzyme linked\nimmunosorbent assay(ELISA). Both methods require time-consuming\nmultistep-protocols. We describe here the instant detection of heparan sulfate\nin spiked plasma samples by the Heparin Red Kit, a commercial mix-and-read\nfluorescence microplate assay. The method enables HS quantification in the low\nmicrogram per mL range without sample pretreatment. Heparin Red appears to be\nsufficiently sensitive for the detection of highly elevated HS levels as\nreported for mucopolysaccharidosis, graft versus host disease after\ntransplantation, dengue infection or septic shock. This study is a significant\nstep toward the development of a convenient and fast method for the\nquantification of HS in human plasma, with the potential to simplify the\ndetection and advance the acceptance of HS as a biomarker."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A mathematical model of low grade gliomas treated with temozolomide and\n  its therapeutical implications"}, {"role": "assistant", "content": "Low grade gliomas (LGGs) are infiltrative and incurable primary brain tumours\nwith typically slow evolution. These tumours usually occur in young and\notherwise healthy patients, bringing controversies in treatment planning since\naggressive treatment may lead to undesirable side effects. Thus, for management\ndecisions it would be valuable to obtain early estimates of LGG growth\npotential. Here we propose a simple mathematical model of LGG growth and its\nresponse to chemotherapy which allows the growth of LGGs to be described in\nreal patients. The model predicts, and our clinical data confirms, that the\nspeed of response to chemotherapy is related to tumour aggressiveness.\nMoreover, we provide a formula for the time to radiological progression, which\ncan be possibly used as a measure of tumour aggressiveness. Finally, we suggest\nthat the response to a few chemotherapy cycles upon diagnosis might be used to\npredict tumour growth and to guide therapeutical actions on the basis of the\nfindings."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantitative Prediction of Linear B-Cell Epitopes"}, {"role": "assistant", "content": "In scientific literature, there are many programs that predict linear B-cell\nepitopes from a protein sequence. Each program generates multiple B-cell\nepitopes that can be individually studied. This paper defines a function called\n<C> that combines results from five different prediction programs concerning\nthe linear B-cell epitopes (ie., BebiPred, EPMLR, BCPred, ABCPred and Emini\nPrediction) for selecting the best B-cell epitopes. We obtained 17 potential\nlinear B cells consensus epitopes from Glycoprotein E from serotype IV of the\ndengue virus for exploring new possibilities in vaccine development. The direct\nimplication of the results obtained is to open the way to experimentally\nvalidate more epitopes to increase the efficiency of the available treatments\nagainst dengue and to explore the methodology in other diseases."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multi-scale analysis and clustering of co-expression networks"}, {"role": "assistant", "content": "The increasing capacity of high-throughput genomic technologies for\ngenerating time-course data has stimulated a rich debate on the most\nappropriate methods to highlight crucial aspects of data structure. In this\nwork, we address the problem of sparse co-expression network representation of\nseveral time-course stress responses in {\\it Saccharomyces cerevisiae}. We\nquantify the information preserved from the original datasets under a\ngraph-theoretical framework and evaluate how cross-stress features can be\nidentified. This is performed both from a node and a network community\norganization point of view. Cluster analysis, here viewed as a problem of\nnetwork partitioning, is achieved under state-of-the-art algorithms relying on\nthe properties of stochastic processes on the constructed graphs. Relative\nperformance with respect to a metric-free Bayesian clustering analysis is\nevaluated and possible extensions are discussed. We further cluster the\nstress-induced co-expression networks generated independently by using their\ncommunity organization at multiple scales. This type of protocol allows for an\nintegration of multiple datasets that may not be immediately comparable, either\ndue to diverse experimental variations or because they represent different\ntypes of information about the same genes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Domain Boundary Detection in Hi-C Maps: A Probabilistic Graphical Model\n  Approach"}, {"role": "assistant", "content": "To understand the nature of a cell, one needs to understand the structure of\nits genome. For this purpose, experimental techniques such as Hi-C detecting\nchromosomal contacts are used to probe the three-dimensional genomic structure.\nThese experiments yield topological information, consistently showing a\nhierarchical subdivision of the genome into self-interacting domains across\nmany organisms. Current methods for detecting these domains using the Hi-C\ncontact matrix, i.e. a doubly-stochastic matrix, are mostly based on the\nassumption that the domains are distinct, thus non-overlapping. For overcoming\nthis simplification and for being able to unravel a possible nested domain\nstructure, we developed a probabilistic graphical model that makes no a priori\nassumptions on the domain structure. Within this approach, the Hi-C contact\nmatrix is analyzed using an Ising like probabilistic graphical model whose\ncoupling constant is proportional to each lattice point (entry in the contact\nmatrix). The results show clear boundaries between identified domains and the\nbackground. These domain boundaries are dependent on the coupling constant, so\nthat one matrix yields several clusters of different sizes, which show the\nself-interaction of the genome on different scales."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Changing measurements or changing movements? Sampling scale and movement\n  model identifiability across generations of biologging technology"}, {"role": "assistant", "content": "1. Animal movement patterns contribute to our understanding of variation in\nbreeding success and survival of individuals, and the implications for\npopulation dynamics. 2. Over time, sensor technology for measuring movement\npatterns has improved. Although older technologies may be rendered obsolete,\nthe existing data are still valuable, especially if new and old data can be\ncompared to test whether a behaviour has changed over time. 3. We used\nsimulated data to assess the ability to quantify and correctly identify\npatterns of seabird flight lengths under observational regimes used in\nsuccessive generations of tracking technology. 4. Care must be taken when\ncomparing data collected at differing time-scales, even when using inference\nprocedures that incorporate the observational process, as model selection and\nparameter estimation may be biased. In practice, comparisons may only be valid\nwhen degrading all data to match the lowest resolution in a set. 5. Changes in\ntracking technology that lead to aggregation of measurements at different\ntemporal scales make comparisons challenging. We therefore urge ecologists to\nuse synthetic data to assess whether accurate parameter estimation is possible\nfor models comparing disparate data sets before conducting analyses such as\nresponses to environmental changes or the assessment of management actions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Big-data approach in abundance estimation of non-identifiable animals\n  with camera-traps at the spots of attraction"}, {"role": "assistant", "content": "Camera-traps is a relatively new but already popular instrument in the\nestimation of abundance of non-identifiable animals. Although camera-traps are\nconvenient in application, there remain both theoretical complications such as\nspatial autocorrelation or false negative problem and practical difficulties,\nfor example, laborious random sampling. In the article we propose an\nalternative way to bypass the mentioned problems.\n  In the proposed approach, the raw video information collected from the\ncamera-traps situated at the spots of natural attraction is turned into the\nfrequency of visits, and the latter is transformed into the desired abundance\nestimate. The key for such a transformation is the application of the\ncorrection coefficients, computed for each particular observation environment\nusing the Bayesian approach and the massive database (DB) of observations under\nvarious conditions.\n  The main result of the article is a new method of census based on video-data\nfrom camera-traps at the spots of natural attraction and information from a\nspecial community-driven database.\n  The proposed method is based on automated video-capturing at a moderate\nnumber of easy to reach spots, so in the long term many laborious census works\nmay be conducted easier, cheaper and cause less disturbance for the wild life.\nInformation post-processing is strictly formalized, which leaves little chance\nfor subjective alterations. However, the method heavily relies on the volume\nand quality of the DB, which in its turn heavily relies on the efforts of the\ncommunity. There is realistic hope that the community of zoologists and\nenvironment specialists could create and maintain a DB similar to the proposed\none. Such a rich DB of visits might benefit not only censuses, but also many\nbehavioral studies."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Scale-invariant biomarker discovery in urine and plasma metabolite\n  fingerprints"}, {"role": "assistant", "content": "Motivation: Metabolomics data is typically scaled to a common reference like\na constant volume of body fluid, a constant creatinine level, or a constant\narea under the spectrum. Such normalization of the data, however, may affect\nthe selection of biomarkers and the biological interpretation of results in\nunforeseen ways.\n  Results: First, we study how the outcome of hypothesis tests for differential\nmetabolite concentration is affected by the choice of scale. Furthermore, we\nobserve this interdependence also for different classification approaches.\nSecond, to overcome this problem and establish a scale-invariant biomarker\ndiscovery algorithm, we extend linear zero-sum regression to the logistic\nregression framework and show in two applications to ${}^1$H NMR-based\nmetabolomics data how this approach overcomes the scaling problem.\n  Availability: Logistic zero-sum regression is available as an R package as\nwell as a high-performance computing implementation that can be downloaded at\nhttps://github.com/rehbergT/zeroSum"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: BIISQ: Bayesian nonparametric discovery of Isoforms and Individual\n  Specific Quantification"}, {"role": "assistant", "content": "Most human protein-coding genes can be transcribed into multiple possible\ndistinct mRNA isoforms. These alternative splicing patterns encourage molecular\ndiversity and dysregulation of isoform expression plays an important role in\ndisease etiology. However, isoforms are difficult to characterize from\nshort-read RNA-seq data because they share identical subsequences and exist in\ntissue- and sample-specific frequencies. Here, we develop BIISQ, a Bayesian\nnonparametric model to discover Isoforms and Individual Specific Quantification\nfrom RNA-seq data. BIISQ does not require known isoform reference sequences but\ninstead estimates isoform composition directly with an isoform catalog shared\nacross samples. We develop a stochastic variational inference approach for\nefficient and robust posterior inference and demonstrate superior precision and\nrecall for short read RNA-seq simulations and simulated short read data from\nPacBio long read sequencing when compared to state-of-the-art isoform\nreconstruction methods. BIISQ achieves the most significant gains for longer\n(in terms of exons) isoforms and isoforms that are lowly expressed (over 500%\nmore transcripts correctly inferred at low coverage in simulations). Finally,\nwe estimate isoforms in the GEUVADIS RNA-seq data, identify genetic variants\nthat regulate transcript ratios, and demonstrate variant enrichment in\nfunctional elements related to mRNA splicing regulation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Advances in Microfluidics and Lab-on-a-Chip Technologies"}, {"role": "assistant", "content": "Advances in molecular biology are enabling rapid and efficient analyses for\neffective intervention in domains such as biology research, infectious disease\nmanagement, food safety, and biodefense. The emergence of microfluidics and\nnanotechnologies has enabled both new capabilities and instrument sizes\npractical for point-of-care. It has also introduced new functionality, enhanced\nsensitivity, and reduced the time and cost involved in conventional molecular\ndiagnostic techniques. This chapter reviews the application of microfluidics\nfor molecular diagnostics methods such as nucleic acid amplification,\nnext-generation sequencing, high resolution melting analysis, cytogenetics,\nprotein detection and analysis, and cell sorting. We also review microfluidic\nsample preparation platforms applied to molecular diagnostics and targeted to\nsample-in, answer-out capabilities."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Walking behavior in a circular arena modified by pulsed light\n  stimulation in Drosophila melanogaster w1118 line"}, {"role": "assistant", "content": "The Drosophila melanogaster white-eyed w1118 line serves as a blank control,\nallowing genetic recombination of any gene of interest along with a readily\nrecognizable marker. w1118 flies display behavioral susceptibility to\nenvironmental stimulation such as light. It is of great importance to\ncharacterize the behavioral performance of w1118 flies because this would\nprovide a baseline from which the effect of the gene of interest could be\ndifferentiated. Little work has been performed to characterize the walking\nbehavior in adult w1118 flies. Here we show that pulsed light stimulation\nincreased the regularity of walking trajectories of w1118 flies in circular\narenas. We statistically modeled the distribution of distances to center and\nextracted the walking structures of w1118 flies. Pulsed light stimulation\nredistributed the time proportions for individual walking structures.\nSpecifically, pulsed light stimulation reduced the episodes of crossing over\nthe central region of the arena. An addition of four genomic copies of\nmini-white, a common marker gene for eye color, mimicked the effect of pulsed\nlight stimulation in reducing crossing in a circular arena. The reducing effect\nof mini-white was copy-number-dependent. These findings highlight the rhythmic\nlight stimulation-evoked modifications of walking behavior in w1118 flies and\nan unexpected behavioral consequence of mini-white in transgenic flies carrying\nw1118 isogenic background."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Analysis and prediction of protein folding energy changes upon mutation\n  by element specific persistent homology"}, {"role": "assistant", "content": "Motivation: Site directed mutagenesis is widely used to understand the\nstructure and function of biomolecules. Computational prediction of protein\nmutation impacts offers a fast, economical and potentially accurate alternative\nto laboratory mutagenesis. Most existing methods rely on geometric\ndescriptions, this work introduces a topology based approach to provide an\nentirely new representation of protein mutation impacts that could not be\nobtained from conventional techniques. Results: Topology based mutation\npredictor (T-MP) is introduced to dramatically reduce the geometric complexity\nand number of degrees of freedom of proteins, while element specific persistent\nhomology is proposed to retain essential biological information. The present\napproach is found to outperform other existing methods in globular protein\nmutation impact predictions. A Pearson correlation coefficient of 0.82 with an\nRMSE of 0.92 kcal/mol is obtained on a test set of 350 mutation samples. For\nthe prediction of membrane protein stability changes upon mutation, the\nproposed topological approach has a 84% higher Pearson correlation coefficient\nthan the current state-of-the-art empirical methods, achieving a Pearson\ncorrelation of 0.57 and an RMSE of 1.09 kcal/mol in a 5-fold cross validation\non a set of 223 membrane protein mutation samples."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The relation between alignment covariance and background-averaged\n  epistasis"}, {"role": "assistant", "content": "Epistasis, or the context-dependence of the effects of mutations, limits our\nability to predict the functional impact of combinations of mutations, and\nultimately our ability to predict evolutionary trajectories. Information about\nthe context-dependence of mutations can essentially be obtained in two ways:\nFirst, by experimental measurement the functional effects of combinations of\nmutations and calculating the epistatic contributions directly, and second, by\nstatistical analysis of the frequencies and co-occurrences of protein residues\nin a multiple sequence alignment of protein homologs. In this manuscript, we\nderive the mathematical relationship between epistasis calculated on the basis\nof functional measurements, and the covariance calculated from a multiple\nsequence alignment. There is no one-to-one mapping between covariance and\nepistatic terms: covariance implies epistasis, but epistasis does not\nnecessarily lead to covariance, indicating that covariance in itself is not the\ndirectly relevant quantity for functional prediction. Having calculated\nepistatic contributions from the alignment, we can directly obtain a functional\nprediction from the alignment statistics by applying a Walsh-Hadamard\ntransform, fully analogous to the transformation that reconstructs functional\ndata from measured epistatic contributions. This embedding into the Hadamard\nframework is directly relevant for solidifying our theoretical understanding of\nstatistical methods that predict function and three-dimensional structure from\nnatural alignments."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: TopologyNet: Topology based deep convolutional neural networks for\n  biomolecular property predictions"}, {"role": "assistant", "content": "Although deep learning approaches have had tremendous success in image, video\nand audio processing, computer vision, and speech recognition, their\napplications to three-dimensional (3D) biomolecular structural data sets have\nbeen hindered by the entangled geometric complexity and biological complexity.\nWe introduce topology, i.e., element specific persistent homology (ESPH), to\nuntangle geometric complexity and biological complexity. ESPH represents 3D\ncomplex geometry by one-dimensional (1D) topological invariants and retains\ncrucial biological information via a multichannel image representation. It is\nable to reveal hidden structure-function relationships in biomolecules. We\nfurther integrate ESPH and convolutional neural networks to construct a\nmultichannel topological neural network (TopologyNet) for the predictions of\nprotein-ligand binding affinities and protein stability changes upon mutation.\nTo overcome the limitations to deep learning arising from small and noisy\ntraining sets, we present a multitask topological convolutional neural network\n(MT-TCNN). We demonstrate that the present TopologyNet architectures outperform\nother state-of-the-art methods in the predictions of protein-ligand binding\naffinities, globular protein mutation impacts, and membrane protein mutation\nimpacts."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Convolutional neural networks automate detection for tracking of\n  submicron scale particles in 2D and 3D"}, {"role": "assistant", "content": "Particle tracking is a powerful biophysical tool that requires conversion of\nlarge video files into position time series, i.e. traces of the species of\ninterest for data analysis. Current tracking methods, based on a limited set of\ninput parameters to identify bright objects, are ill-equipped to handle the\nspectrum of spatiotemporal heterogeneity and poor signal-to-noise ratios\ntypically presented by submicron species in complex biological environments.\nExtensive user involvement is frequently necessary to optimize and execute\ntracking methods, which is not only inefficient but introduces user bias. To\ndevelop a fully automated tracking method, we developed a convolutional neural\nnetwork for particle localization from image data, comprised of over 6,000\nparameters, and employed machine learning techniques to train the network on a\ndiverse portfolio of video conditions. The neural network tracker provides\nunprecedented automation and accuracy, with exceptionally low false positive\nand false negative rates on both 2D and 3D simulated videos and 2D experimental\nvideos of difficult-to-track species."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Computational Approaches for Disease Gene Identification"}, {"role": "assistant", "content": "Identifying disease genes from human genome is an important and fundamental\nproblem in biomedical research. Despite many publications of machine learning\nmethods applied to discover new disease genes, it still remains a challenge\nbecause of the pleiotropy of genes, the limited number of confirmed disease\ngenes among whole genome and the genetic heterogeneity of diseases. Recent\napproaches have applied the concept of 'guilty by association' to investigate\nthe association between a disease phenotype and its causative genes, which\nmeans that candidate genes with similar characteristics as known disease genes\nare more likely to be associated with diseases. However, due to the imbalance\nissues (few genes are experimentally confirmed as disease related genes within\nhuman genome) in disease gene identification, semi-supervised approaches, like\nlabel propagation approaches and positive-unlabeled learning, are used to\nidentify candidate disease genes via making use of unknown genes for training -\ntypically in the scenario of a small amount of confirmed disease genes (labeled\ndata) with a large amount of unknown genome (unlabeled data). The performance\nof Disease gene prediction models are limited by potential bias of single\nlearning models and incompleteness and noise of single biological data sources,\ntherefore ensemble learning models are applied via combining multiple diverse\nbiological sources and learning models to obtain better predictive performance.\nIn this thesis, we propose three computational models for identifying candidate\ndisease genes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multivariate Multiscale Dispersion Entropy of Biomedical Times Series"}, {"role": "assistant", "content": "Objective: Due to the non-linearity of numerous biomedical signals,\nnon-linear analysis of multi-channel time series, notably multivariate\nmultiscale entropy (mvMSE), has been extensively used in biomedical signal\nprocessing. However, mvMSE has three drawbacks: 1) mvMSE values are either\nundefined or unreliable for short signals; 2) mvMSE is not fast enough for\nreal-time applications; and 3) the computation of mvMSE for signals with a\nlarge number of channels requires the storage of a huge number of elements.\nMethods: To deal with these problems and improve the stability of mvMSE, we\nintroduce multivariate multiscale dispersion entropy (MDE - mvMDE) as an\nextension of our recently developed MDE, to quantify the complexity of\nmultivariate time series. Results: We assess mvMDE, in comparison with mvMSE\nand multivariate multiscale fuzzy entropy (mvMFE), on correlated and\nuncorrelated multi-channel noise signals, bivariate autoregressive processes,\nand three biomedical datasets. The results show that mvMDE takes into account\ndependencies in patterns across both the time and spatial domains. The mvMDE,\nmvMSE, and mvMFE methods are consistent in that they lead to similar\nconclusions about the underlying physiological conditions. However, the\nproposed mvMDE discriminates various physiological states of the biomedical\nrecordings better than mvMSE and mvMFE. In addition, for both the short and\nlong time series, the mvMDE-based results are noticeably more stable than the\nmvMSE- and mvMFE-based ones. Conclusion: For short multivariate time series,\nmvMDE, unlike mvMSE, does not result in undefined values. Furthermore, mvMDE is\nnoticeably faster than mvMFE and mvMSE and also needs to store a considerably\nsmaller number of elements. Significance: Due to its ability to detect\ndifferent kinds of dynamics of multivariate signals, mvMDE has great potential\nto analyse various physiological signals."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: BIBI: Bayesian Inference of Breed Composition"}, {"role": "assistant", "content": "The aim of this paper was to develop statistical models to estimate\nindividual breed composition based on the previously proposed idea of\nregressing discrete random variables corresponding to counts of reference\nalleles of biallelic molecular markers located across the genome on the allele\nfrequencies of each marker in the pure (base) breeds. Some of the existing\nregression-based methods do not guarantee that estimators of breed composition\nwill lie in the appropriate parameter space and none of them account for\nuncertainty about allele frequencies in the pure breeds, that is, uncertainty\nabout the design matrix. In order to overcome these limitations, we proposed\ntwo Bayesian generalized linear models. For each individual, both models assume\nthat the counts of the reference allele at each marker locus follow independent\nBinomial distributions, use the logit link, and pose a Dirichlet prior over the\nvector of regression coefficients (which corresponds to breed composition).\nThis prior guarantees that point estimators of breed composition like the\nposterior mean pertain to the appropriate space. The difference between these\nmodels is that model termed BIBI does not account for uncertainty about the\ndesign matrix, while model termed BIBI2 accounts for such an uncertainty by\nassigning independent Beta priors to the entries of this matrix. We implemented\nthese models in a multibreed Angus-Brahman population. Posterior means were\nused as point estimators of breed composition. In addition, the ordinary least\nsquares estimator proposed by Kuehn et al. (2011) (OLSK) was also computed.\nBIBI and BIBI2 estimated breed composition more accurately than OLSK, and BIBI2\nhad an 8.3% improvement in accuracy as compared to BIBI."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Overcoming the ill-posedness through discretization in vector\n  tomography: Reconstruction of irrotational vector fields"}, {"role": "assistant", "content": "Vector tomography methods intend to reconstruct and visualize vector fields\nin restricted domains by measuring line integrals of projections of these\nvector fields. Here, we deal with the reconstruction of irrotational vector\nfunctions from boundary measurements. As the majority of inverse problems,\nvector field recovery is an ill posed in the continuous domain and therefore\nfurther assumptions, measurements and constraints should be imposed for the\nfull vector field estimation. The reconstruction idea in the discrete domain\nrelies on solving a numerical system of linear equations which derives from the\napproximation of the line integrals along lines which trace the bounded domain.\nThis work presents an extensive description of a vector field recovery, the\nfundamental assumptions and the ill conditioning of this inverse problem. More\nimportantly we show that this inverse problem is regularized via the domain\ndiscretization, i.e. we show that the recovery of an irrotational vector field\nwithin a discrete grid employing a finite set of longitudinal line integrals,\nleads to a consistent linear system which has bounded solution errors. We\nelaborate on the estimation of the solution's error and we prove that this\nrelative error is finite and therefore a stable vector field reconstruction is\nensured. Such theoretical aspects are critical for future implementations of\nvector tomography in practical applications like the inverse bioelectric field\nproblem. We validate our theoretical results by performing simulations that\nreconstruct smooth irrotational fields based solely on a finite number of\nboundary measurements and without the need of any additional or prior\ninformation (e.g. transversal line integrals or source free assumption)."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Estimating and interpreting secondary attack risk: Binomial considered\n  harmful"}, {"role": "assistant", "content": "The household secondary attack risk (SAR), often called the secondary attack\nrate or secondary infection risk, is the probability of infectious contact from\nan infectious household member A to a given household member B, where we define\ninfectious contact to be a contact sufficient to infect B if he or she is\nsusceptible. Estimation of the SAR is an important part of understanding and\ncontrolling the transmission of infectious diseases. In practice, it is most\noften estimated using binomial models such as logistic regression, which\nimplicitly attribute all secondary infections in a household to the primary\ncase. In the simplest case, the number of secondary infections in a household\nwith m susceptibles and a single primary case is modeled as a binomial(m, p)\nrandom variable where p is the SAR. Although it has long been understood that\ntransmission within households is not binomial, it is thought that multiple\ngenerations of transmission can be safely neglected when p is small. We use\nprobability generating functions and simulations to show that this is a\nmistake. The proportion of susceptible household members infected can be\nsubstantially larger than the SAR even when p is small. As a result, binomial\nestimates of the SAR are biased upward and their confidence intervals have poor\ncoverage probabilities even if adjusted for clustering. Accurate point and\ninterval estimates of the SAR can be obtained using longitudinal chain binomial\nmodels or pairwise survival analysis, which account for multiple generations of\ntransmission within households, the ongoing risk of infection from outside the\nhousehold, and incomplete follow-up. We illustrate the practical implications\nof these results in an analysis of household surveillance data collected by the\nLos Angeles County Department of Public Health during the 2009 influenza A\n(H1N1) pandemic."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Improving Nanopore Reads Raw Signal Alignment"}, {"role": "assistant", "content": "We investigate usage of dynamic time warping (DTW) algorithm for aligning raw\nsignal data from MinION sequencer. DTW is mostly using for fast alignment for\nselective sequencing to quickly determine whether a read comes from sequence of\ninterest.\n  We show that standard usage of DTW has low discriminative power mainly due to\nproblem with accurate estimation of scaling parameters. We propose a simple\nvariation of DTW algorithm, which does not suffer from scaling problems and has\nmuch higher discriminative power."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Concussion classification via deep learning using whole-brain white\n  matter fiber strains"}, {"role": "assistant", "content": "Developing an accurate and reliable injury predictor is central to the\nbiomechanical studies of traumatic brain injury. State-of-the-art efforts\ncontinue to rely on empirical, scalar metrics based on kinematics or\nmodel-estimated tissue responses explicitly pre-defined in a specific brain\nregion of interest. They could suffer from loss of information. A single\ntraining dataset has also been used to evaluate performance but without\ncross-validation. In this study, we developed a deep learning approach for\nconcussion classification using implicit features of the entire voxel-wise\nwhite matter fiber strains. Using reconstructed American National Football\nLeague (NFL) injury cases, leave-one-out cross-validation was employed to\nobjectively compare injury prediction performances against two baseline machine\nlearning classifiers (support vector machine (SVM) and random forest (RF)) and\nfour scalar metrics via univariate logistic regression (Brain Injury Criterion\n(BrIC), cumulative strain damage measure of the whole brain (CSDM-WB) and the\ncorpus callosum (CSDM-CC), and peak fiber strain in the CC). Feature-based deep\nlearning and machine learning classifiers consistently outperformed all scalar\ninjury metrics across all performance categories in cross-validation (e.g.,\naverage accuracy of 0.844 vs. 0.746, and average area under the receiver\noperating curve (AUC) of 0.873 vs. 0.769, respectively, based on the testing\ndataset). Nevertheless, deep learning achieved the best cross-validation\naccuracy, sensitivity, and AUC (e.g., accuracy of 0.862 vs. 0.828 and 0.842 for\nSVM and RF, respectively). These findings demonstrate the superior performances\nof deep learning in concussion prediction, and suggest its promise for future\napplications in biomechanical investigations of traumatic brain injury."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multi-task Deep Neural Networks in Automated Protein Function Prediction"}, {"role": "assistant", "content": "In recent years, deep learning algorithms have outperformed the state-of-the\nart methods in several areas thanks to the efficient methods for training and\nfor preventing overfitting, advancement in computer hardware, the availability\nof vast amount data. The high performance of multi-task deep neural networks in\ndrug discovery has attracted the attention to deep learning algorithms in\nbioinformatics area. Here, we proposed a hierarchical multi-task deep neural\nnetwork architecture based on Gene Ontology (GO) terms as a solution to protein\nfunction prediction problem and investigated various aspects of the proposed\narchitecture by performing several experiments. First, we showed that there is\na positive correlation between performance of the system and the size of\ntraining datasets. Second, we investigated whether the level of GO terms on GO\nhierarchy related to their performance. We showed that there is no relation\nbetween the depth of GO terms on GO hierarchy and their performance. In\naddition, we included all annotations to the training of a set of GO terms to\ninvestigate whether including noisy data to the training datasets change the\nperformance of the system. The results showed that including less reliable\nannotations in training of deep neural networks increased the performance of\nthe low performed GO terms, significantly. We evaluated the performance of the\nsystem using hierarchical evaluation method. Mathews correlation coefficient\nwas calculated as 0.75, 0.49 and 0.63 for molecular function, biological\nprocess and cellular component categories, respectively. We showed that deep\nlearning algorithms have a great potential in protein function prediction area.\nWe plan to further improve the DEEPred by including other types of annotations\nfrom various biological data sources. We plan to construct DEEPred as an open\naccess online tool."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Increased blood pressure variability upon standing up improves\n  reproducibility of cerebral autoregulation indices"}, {"role": "assistant", "content": "Dynamic cerebral autoregulation, that is the transient response of cerebral\nblood flow to changes in arterial blood pressure, is currently assessed using a\nvariety of different time series methods and data collection protocols. In the\ncontinuing absence of a gold standard for the study of cerebral autoregulation\nit is unclear to what extent does the assessment depend on the choice of a\ncomputational method and protocol. We use continuous measurements of blood\npressure and cerebral blood flow velocity in the middle cerebral artery from\nthe cohorts of 18 normotensive subjects performing sit-to-stand manoeuvre. We\nestimate cerebral autoregulation using a wide variety of black-box approaches\n(ARI, Mx, Sx, Dx, FIR and ARX) and compare them in the context of\nreproducibility and variability. For all autoregulation indices, considered\nhere, the ICC was greater during the standing protocol, however, it was\nsignificantly greater (Fisher's Z-test) for Mx (p < 0.03), Sx (p<0.003)$ and Dx\n(p<0.03). In the specific case of the sit-to-stand manoeuvre, measurements\ntaken immediately after standing up greatly improve the reproducibility of the\nautoregulation coefficients. This is generally coupled with an increase of the\nwithin-group spread of the estimates."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: DeepRT: deep learning for peptide retention time prediction in\n  proteomics"}, {"role": "assistant", "content": "Accurate predictions of peptide retention times (RT) in liquid chromatography\nhave many applications in mass spectrometry-based proteomics. Herein, we\npresent DeepRT, a deep learning based software for peptide retention time\nprediction. DeepRT automatically learns features directly from the peptide\nsequences using the deep convolutional Neural Network (CNN) and Recurrent\nNeural Network (RNN) model, which eliminates the need to use hand-crafted\nfeatures or rules. After the feature learning, principal component analysis\n(PCA) was used for dimensionality reduction, then three conventional machine\nlearning methods were utilized to perform modeling. Two published datasets were\nused to evaluate the performance of DeepRT and we demonstrate that DeepRT\ngreatly outperforms previous state-of-the-art approaches ELUDE and GPTime."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Dimensionality reduction, and function approximation of\n  poly(lactic-co-glycolic acid) micro- and nanoparticle dissolution rate"}, {"role": "assistant", "content": "Prediction of poly(lactic co glycolic acid) (PLGA) micro- and nanoparticles'\ndissolution rates plays a significant role in pharmaceutical and medical\nindustries. The prediction of PLGA dissolution rate is crucial for drug\nmanufacturing. Therefore, a model that predicts the PLGA dissolution rate could\nbe beneficial. PLGA dissolution is influenced by numerous factors (features),\nand counting the known features leads to a dataset with 300 features. This\nlarge number of features and high redundancy within the dataset makes the\nprediction task very difficult and inaccurate. In this study, dimensionality\nreduction techniques were applied in order to simplify the task and eliminate\nirrelevant and redundant features. A heterogeneous pool of several regression\nalgorithms were independently tested and evaluated. In addition, several\nensemble methods were tested in order to improve the accuracy of prediction.\nThe empirical results revealed that the proposed evolutionary weighted ensemble\nmethod offered the lowest margin of error and significantly outperformed the\nindividual algorithms and the other ensemble techniques."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Fast and Accurate Semi-Automatic Segmentation Tool for Brain Tumor MRIs"}, {"role": "assistant", "content": "Segmentation, the process of delineating tumor apart from healthy tissue, is\na vital part of both the clinical assessment and the quantitative analysis of\nbrain cancers. Here, we provide an open-source algorithm (MITKats), built on\nthe Medical Imaging Interaction Toolkit, to provide user-friendly and expedient\ntools for semi-automatic segmentation. To evaluate its performance against\ncompeting algorithms, we applied MITKats to 38 high-grade glioma cases from\npublicly available benchmarks. The similarity of the segmentations to\nexpert-delineated ground truths approached the discrepancies among different\nmanual raters, the theoretically maximal precision. The average time spent on\neach segmentation was 5 minutes, making MITKats between 4 and 11 times faster\nthan competing semi-automatic algorithms, while retaining similar accuracy."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A regional model for estimating the aboveground carbon density of\n  Borneo's tropical forests from airborne laser scanning"}, {"role": "assistant", "content": "Borneo contains some of the world's most biodiverse and carbon dense tropical\nforest, but this 750,000-km2 island has lost 62% of its old-growth forests\nwithin the last 40 years. Efforts to protect and restore the remaining forests\nof Borneo hinge on recognising the ecosystem services they provide, including\ntheir ability to store and sequester carbon. Airborne Laser Scanning (ALS) is a\nremote sensing technology that allows forest structural properties to be\ncaptured in great detail across vast geographic areas. In recent years ALS has\nbeen integrated into state-wide assessment of forest carbon in Neotropical and\nAfrican regions, but not yet in Asia. For this to happen new regional models\nneed to be developed for estimating carbon stocks from ALS in tropical Asia, as\nthe forests of this region are structurally and compositionally distinct from\nthose found elsewhere in the tropics. By combining ALS imagery with data from\n173 permanent forest plots spanning the lowland rain forests of Sabah, on the\nisland of Borneo, we develop a simple-yet-general model for estimating forest\ncarbon stocks using ALS-derived canopy height and canopy cover as input\nmetrics. An advanced feature of this new model is the propagation of\nuncertainty in both ALS- and ground-based data, allowing uncertainty in\nhectare-scale estimates of carbon stocks to be quantified robustly. We show\nthat the model effectively captures variation in aboveground carbons stocks\nacross extreme disturbance gradients spanning tall dipterocarp forests and\nheavily logged regions, and clearly outperforms existing ALS-based models\ncalibrated for the tropics, as well as currently available satellite-derived\nproducts. Our model provides a simple, generalised and effective approach for\nmapping forest carbon stocks in Borneo, providing a key tool to support the\nprotection and restoration of its tropical forests."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A multi-stage representation of cell proliferation as a Markov process"}, {"role": "assistant", "content": "The stochastic simulation algorithm commonly known as Gillespie's algorithm\nis now used ubiquitously in the modelling of biological processes in which\nstochastic effects play an important role. In well-mixed scenarios at the\nsub-cellular level it is often reasonable to assume that times between\nsuccessive reaction/interaction events are exponentially distributed and can be\nappropriately modelled as a Markov process and hence simulated by the Gillespie\nalgorithm. However, Gillespie's algorithm is routinely applied to model\nbiological systems for which it was never intended. In particular, processes in\nwhich cell proliferation is important should not be simulated naively using the\nGillespie algorithm since the history-dependent nature of the cell cycle breaks\nthe Markov process. The variance in experimentally measured cell cycle times is\nfar less than in an exponential cell cycle time distribution with the same\nmean.\n  Here we suggest a method of modelling the cell cycle that restores the\nmemoryless property to the system and is therefore consistent with simulation\nvia the Gillespie algorithm. By breaking the cell cycle into a number of\nindependent exponentially distributed stages we can restore the Markov property\nat the same time as more accurately approximating the appropriate cell cycle\ntime distributions. The consequences of our revised mathematical model are\nexplored analytically. We demonstrate the importance of employing the correct\ncell cycle time distribution by considering two models incorporating cellular\nproliferation (one spatial and one non-spatial) and demonstrating that changing\nthe cell cycle time distribution makes quantitative and qualitative differences\nto their outcomes. Our adaptation will allow modellers and experimentalists\nalike to appropriately represent cellular proliferation, whilst still being\nable to take advantage of the Gillespie algorithm."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Asymptotic scaling properties of the posterior mean and variance in the\n  Gaussian scale mixture model"}, {"role": "assistant", "content": "The Gaussian scale mixture model (GSM) is a simple yet powerful probabilistic\ngenerative model of natural image patches. In line with the well-established\nidea that sensory processing is adapted to the statistics of the natural\nenvironment, the GSM has also been considered a model of the early visual\nsystem, as a reasonable \"first-order\" approximation of the internal model that\nthe primary visual cortex (V1) implements. According to this view, neural\nactivities in V1 represent the posterior distribution under the GSM given a\nparticular visual stimulus. Indeed, (approximate) inference under the GSM has\nsuccessfully accounted for various nonlinearities in the mean (trial-average)\nresponses of V1 neurons, as well as the dependence of (across-trial) response\nvariability with stimulus contrast found in V1 recordings. However, previous\nwork almost exclusively relied on numerical simulations to obtain these\nresults. Thus, for a deeper insight into the realm of possible behaviours the\nGSM can (and cannot) exhibit and predict, here we present analytical\nderivations for the limiting behaviour of the mean and (co)variance of the GSM\nposterior at very low and very high contrast levels. These results should guide\nfuture work exploring neural circuit dynamics appropriate for implementing\ninference under the GSM."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Statistical abstraction for multi-scale spatio-temporal systems"}, {"role": "assistant", "content": "Spatio-temporal systems exhibiting multi-scale behaviour are common in\napplications ranging from cyber-physical systems to systems biology, yet they\npresent formidable challenges for computational modelling and analysis. Here we\nconsider a prototypic scenario where spatially distributed agents decide their\nmovement based on external inputs and a fast-equilibrating internal\ncomputation. We propose a generally applicable strategy based on statistically\nabstracting the internal system using Gaussian Processes, a powerful class of\nnon-parametric regression techniques from Bayesian Machine Learning. We show on\na running example of bacterial chemotaxis that this approach leads to accurate\nand much faster simulations in a variety of scenarios."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Vision for Health Informatics: Introducing the SKED Framework.An\n  Extensible Architecture for Scientific Knowledge Extraction from Data"}, {"role": "assistant", "content": "The goals of the Triple Aim of health care and the goals of P4 medicine\noutline objectives that require a significant health informatics component.\nHowever, the goals do not provide specifications about how all of the new\nindividual patient data will be combined in meaningful ways and with data from\nother sources, like epidemiological data, to promote the health of individuals\nand society. We seem to have more data than ever before but few resources and\nmeans to use it efficiently. We need a general, extensible solution that\nintegrates and homogenizes data of disparate origin, incompatible formats, and\nmultiple spatial and temporal scales. To address this problem, we introduce the\nScientific Knowledge Extraction from Data (SKED) architecture, as a\ntechnology-agnostic framework to minimize the overhead of data integration,\npermit reuse of analytical pipelines, and guarantee reproducible quantitative\nresults. The SKED architecture consists of a Resource Allocation Service to\nlocate resources, and the definition of data primitives to simplify and\nharmonize data. SKED allows automated knowledge discovery and provides a\nplatform for the realization of the major goals of modern health care."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Introducing Data Primitives: Data Formats for the SKED Framework"}, {"role": "assistant", "content": "Background: The past few years have seen a tremendous increase in the size\nand complexity of datasets. Scientific and clinical studies must to incorporate\ndatasets that cross multiple spatial and temporal scales to describe a\nparticular phenomenon. The storage and accessibility of these heterogeneous\ndatasets in a way that is useful to researchers and yet extensible to new data\ntypes is a major challenge.\n  Methods: In order to overcome these obstacles, we propose the use of data\nprimitives as a common currency between analytical methods. The four data\nprimitives we have identified are time series, text, annotated graph and\ntriangulated mesh, with associated metadata. Using only data primitives to\nstore data and as algorithm input, output, and intermediate results, promotes\ninteroperability, scalability, and reproducibility in scientific studies.\n  Results: Data primitives were used in a multi-omic, multi-scale systems\nbiology study of malaria infection in non-human primates to perform many types\nof integrative analysis quickly and efficiently.\n  Conclusions: Using data primitives as a common currency for both data storage\nand for cross talk between analytical methods enables the analysis of complex\nmulti-omic, multi-scale datasets in a reproducible modular fashion."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Queueing Analysis of a Chagas Disease Control Campaign"}, {"role": "assistant", "content": "A critical component of preventing the spread of vector borne diseases such\nas Chagas disease are door-to-door campaigns by public health officials that\nimplement insecticide application in order to eradicate the vector infestation\nof households. The success of such campaigns depends on adequate household\nparticipation during the active phase as well as on sufficient follow-up during\nthe surveillance phase when newly infested houses or infested houses that had\nnot participated in the active phase will receive treatment. Queueing models\nwhich are widely used in operations management give us a mathematical\nrepresentation of the operational efforts needed to contain the spread of\ninfestation. By modeling the queue as consisting of all infested houses in a\ngiven locality, we capture the dynamics of the insect population due to\nprevalence of infestation and to the additional growth of infestation by\nredispersion, i.e. by the spread of infestation to previously uninfested houses\nduring the wait time for treatment. In contrast to traditional queueing models,\nhouses waiting for treatment are not known but must be identified through a\nsearch process by public health workers. Thus, both the arrival rate of houses\nto the queue as well as the removal rate from the queue depend on the current\nlevel of infestation. We incorporate these dependencies through a load\ndependent queueing model which allows us to estimate the long run average rate\nof removing houses from the queue and therefore the cost associated with a\ngiven surveillance program. The model is motivated by and applied to an ongoing\nChagas disease control campaign in Arequipa, Peru."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Erg(r)odicity: Hidden Bias and the Growthrate Gain"}, {"role": "assistant", "content": "Many single-cell observables are highly heterogeneous. A part of this\nheterogeneity stems from age-related phenomena: the fact that there is a\nnonuniform distribution of cells with different ages. This has led to a renewed\ninterest in analytic methodologies including use of the \"von Foerster equation\"\nfor predicting population growth and cell age distributions. Here we discuss\nhow some of the most popular implementations of this machinery assume a strong\ncondition on the ergodicity of the cell cycle duration ensemble. We show that\none common definition for the term ergodicity, \"a single individual observed\nover many generations recapitulates the behavior of the entire ensemble\" is\nimplied by the other, \"the probability of observing any state is conserved\nacross time and over all individuals\" in an ensemble with a fixed number of\nindividuals but that this is not true when the ensemble is growing. We further\nexplore the impact of generational correlations between cell cycle durations on\nthe population growth rate. Finally, we explore the \"growth rate gain\" - the\nphenomenon that variations in the cell cycle duration lead to an improved\npopulation-level growth rate - in this context. We highlight that,\nfundamentally, this effect is due to asymmetric division."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Gene expression rearrangements denoting changes in the biological state"}, {"role": "assistant", "content": "In many situations, the gene expression signature is a unique marker of the\nbiological state. We study the modification of the gene expression distribution\nfunction when the biological state of a system experiences a change. This\nchange may be the result of a selective pressure, as in the Long Term Evolution\nExperiment with E. Coli populations, or the progression to Alzheimer disease in\naged brains, or the progression from a normal tissue to the cancer state. The\nfirst two cases seem to belong to a class of transitions, where the initial and\nfinal states are relatively close to each other, and the distribution function\nfor the differential expressions is short ranged, with a tail of only a few\ndozens of strongly varying genes. In the latter case, cancer, the initial and\nfinal states are far apart and separated by a low-fitness barrier. The\ndistribution function shows a very heavy tail, with thousands of silenced and\nover-expressed genes. We characterize the biological states by means of their\nprincipal component representations, and the expression distribution functions\nby their maximal and minimal differential expression values and the exponents\nof the Pareto laws describing the tails."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Sunflower yield and oil quality interactions and variability: analysis\n  through a simple simulation model"}, {"role": "assistant", "content": "Sunflower (Helianthus annuus L.) grain and oil quality are defined by grain\nweight and oil percentage, oil fatty acid composition and the amount of\nantioxidants. The aim of this work was to establish and validate a simple\nmodel, based on published relationships, which can estimate not only yield and\nits components, but also grain and oil quality aspects which are of relevance\nfor industrial processes or human health. The model we developed provided good\nestimations of grain yield (similar to those of a more complex model) and oil\nquality from independent experiments. It explained known differences in\npotential yield and grain and oil quality between locations, in terms of\ndifferences in incident radiation, mean or minimum temperature. Simulations\nshowed that recent climatic changes could have caused a decrease in sunflower\nyield and changes in oil quality. Our results suggest that at locations at\nlower latitudes, sunflower oil with high nutritious value and oxidative\nstability could compensate for relatively low yields, while at higher\nlatitudes, high-linoleic acid oil production should be compatible with high\nyield potentials. Our model could facilitate the selection of the best\nlocation, sowing date or density for the production of sunflower oil with\nspecific quality characteristics."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Sequence-based Multiscale Model (SeqMM) for High-throughput chromosome\n  conformation capture (Hi-C) data analysis"}, {"role": "assistant", "content": "In this paper, I introduce a Sequence-based Multiscale Model (SeqMM) for the\nbiomolecular data analysis. With the combination of spectral graph method, I\nreveal the essential difference between the global scale models and local scale\nones in structure clustering, i.e., different optimization on Euclidean (or\nspatial) distances and sequential (or genomic) distances. More specifically,\nclusters from global scale models optimize Euclidean distance relations. Local\nscale models, on the other hand, result in clusters that optimize the genomic\ndistance relations. For a biomolecular data, Euclidean distances and sequential\ndistances are two independent variables, which can never be optimized\nsimultaneously in data clustering. However, sequence scale in my SeqMM can work\nas a tuning parameter that balances these two variables and deliver different\nclusterings based on my purposes. Further, my SeqMM is used to explore the\nhierarchical structures of chromosomes. I find that in global scale, the\nFiedler vector from my SeqMM bears a great similarity with the principal vector\nfrom principal component analysis, and can be used to study genomic\ncompartments. In TAD analysis, I find that TADs evaluated from different scales\nare not consistent and vary a lot. Particularly when the sequence scale is\nsmall, the calculated TAD boundaries are dramatically different. Even for\nregions with high contact frequencies, TAD regions show no obvious consistence.\nHowever, when the scale value increases further, although TADs are still quite\ndifferent, TAD boundaries in these high contact frequency regions become more\nand more consistent. Finally, I find that for a fixed local scale, my method\ncan deliver very robust TAD boundaries in different cluster numbers."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Improved deep learning based macromolecules structure classification\n  from electron cryo tomograms"}, {"role": "assistant", "content": "Cellular processes are governed by macromolecular complexes inside the cell.\nStudy of the native structures of macromolecular complexes has been extremely\ndifficult due to lack of data. With recent breakthroughs in Cellular electron\ncryo tomography (CECT) 3D imaging technology, it is now possible for\nresearchers to gain accesses to fully study and understand the macromolecular\nstructures single cells. However, systematic recovery of macromolecular\nstructures from CECT is very difficult due to high degree of structural\ncomplexity and practical imaging limitations. Specifically, we proposed a deep\nlearning based image classification approach for large-scale systematic\nmacromolecular structure separation from CECT data. However, our previous work\nwas only a very initial step towards exploration of the full potential of deep\nlearning based macromolecule separation. In this paper, we focus on improving\nclassification performance by proposing three newly designed individual CNN\nmodels: an extended version of (Deep Small Receptive Field) DSRF3D, donated as\nDSRF3D-v2, a 3D residual block based neural network, named as RB3D and a\nconvolutional 3D(C3D) based model, CB3D. We compare them with our previously\ndeveloped model (DSRF3D) on 12 datasets with different SNRs and tilt angle\nranges. The experiments show that our new models achieved significantly higher\nclassification accuracies. The accuracies are not only higher than 0.9 on\nnormal datasets, but also demonstrate potentials to operate on datasets with\nhigh levels of noises and missing wedge effects presented."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A guide to performing systematic literature reviews in bioinformatics"}, {"role": "assistant", "content": "Bioinformatics research depends on high-quality databases to provide accurate\nresults. In silico experiments, correctly performed, may prospect novel\ndiscoveries and elucidates pathways for biological experiments through data\nanalysis in large scale. However, most biological databases have presented\nmistakes, such as data incorrectly classified or incomplete information. Also,\nsometimes, data mining algorithms cannot treat these errors, leading to serious\nproblems for the in silico analysis. Manual curation of data extracted from\nliterature is a possible solution for this problem. Systematic Literature\nReview (SLR), or Systematic Review, is a method to identify, evaluate and\nsummarize the state-of-the-art of a specific theme. Moreover, SLR allows the\ncollection from databases restrictively, which allows an analysis with lower\nbias than traditional reviews. The SRL approaches have been widely used for\ndecision-making in medical and environmental studies. However, other research\nareas, such as bioinformatics, do not have a specific step-by-step to guide\nresearchers undertaking the procedures of an SLR. In this study, we propose a\nguideline, called BiSRL, to perform SLR in bioinformatics. Our procedures cover\nthe most traditional guides to produce SLRs adapted to bioinformatics. To\nevaluate our method, we propose a case study to detect and summarize SLRs\ndeveloped for bioinformatics data. We used two databases: PubMed and\nScienceDirect. A total of 207 papers were screened in four steps: title,\nabstract, diagonal and full-text reading. Four evaluators performed the SLR\nindependently to reduce bias risk. A total of 8 papers was included in the SLR\ncase study. The case study demonstrates how to implement the methods of BiSLR\nto procedure SLR for bioinformatics. BiSLR may guide bioinformaticians to\nperform systematic reviews reproducible to collect accurate data for higher\nquality analysis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Machine Learning for Large-Scale Quality Control of 3D Shape Models in\n  Neuroimaging"}, {"role": "assistant", "content": "As very large studies of complex neuroimaging phenotypes become more common,\nhuman quality assessment of MRI-derived data remains one of the last major\nbottlenecks. Few attempts have so far been made to address this issue with\nmachine learning. In this work, we optimize predictive models of quality for\nmeshes representing deep brain structure shapes. We use standard vertex-wise\nand global shape features computed homologously across 19 cohorts and over 7500\nhuman-rated subjects, training kernelized Support Vector Machine and Gradient\nBoosted Decision Trees classifiers to detect meshes of failing quality. Our\nmodels generalize across datasets and diseases, reducing human workload by\n30-70\\%, or equivalently hundreds of human rater hours for datasets of\ncomparable size, with recall rates approaching inter-rater reliability."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Estimating Kinetic Rate Constants and Plug Concentration Profiles from\n  Simulated KCE Electropherogram Signals"}, {"role": "assistant", "content": "Kinetic rate constants fundamentally characterize the dynamics of the\nchemical interaction of macromolecules, and thus their study sets a major\ndirection in experimental biochemistry. The estimation of such constants is\noften challenging, partly due to the noisiness of data, and partly due to the\ntheoretical framework. Novel and qualitatively reasonable methods are presented\nfor the estimation of the rate constants of complex formation and dissociation\nin Kinetic Capillary Electrophoresis (KCE). This also serves the broader effort\nto resolve the inverse problem of KCE, where these estimates pose as initial\nstarting points in the non-linear optimization space, along with the asymmetric\nGaussian parameters describing the injected plug concentration profiles, which\nis also hereby estimated. This rate constant estimation method is also compared\nto an earlier one."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Computational Resolution of the Inverse Problem of Kinetic Capillary\n  Electrophoresis (KCE)"}, {"role": "assistant", "content": "Determining kinetic rate constants is a highly relevant problem in\nbiochemistry, so various methods have been designed to extract them from\nexperimental data. Such methods have two main components: the experimental\napparatus and the subsequent analysis, the latter often dependent on\nmathematical theory. Thus the theoretical approach taken influences the\neffectiveness of constant determination. A computational inverse problem\napproach is hereby presented, which does not merely give a single rough\napproximation of the sought constants, but is inherently capable of determining\nthem from exact signals to arbitrary accuracy. This approach is thus not merely\nnovel, but opens a whole new category of solution approaches in the field,\nenabled primarily by an efficient direct solver."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Accurate Chemical Master Equation Solution Using Multi-Finite Buffers"}, {"role": "assistant", "content": "The discrete chemical master equation (dCME) provides a fundamental framework\nfor studying stochasticity in mesoscopic networks. Because of the multi-scale\nnature of many networks where reaction rates have large disparity, directly\nsolving dCMEs is intractable due to the exploding size of the state space. It\nis important to truncate the state space effectively with quantified errors, so\naccurate solutions can be computed. It is also important to know if all major\nprobabilistic peaks have been computed. Here we introduce the Accurate CME\n(ACME) algorithm for obtaining direct solutions to dCMEs. With multi-finite\nbuffers for reducing the state space by O(n!), exact steady-state and\ntime-evolving network probability landscapes can be computed. We further\ndescribe a theoretical framework of aggregating microstates into a smaller\nnumber of macrostates by decomposing a network into independent aggregated\nbirth and death processes, and give an a priori method for rapidly determining\nsteady-state truncation errors. The maximal sizes of the finite buffers for a\ngiven error tolerance can also be pre-computed without costly trial solutions\nof dCMEs. We show exactly computed probability landscapes of three multi-scale\nnetworks, namely, a 6-node toggle switch, 11-node phage-lambda epigenetic\ncircuit, and 16-node MAPK cascade network, the latter two with no known\nsolutions. We also show how probabilities of rare events can be computed from\nfirst-passage times, another class of unsolved problems challenging for\nsimulation-based techniques due to large separations in time scales. Overall,\nthe ACME method enables accurate and efficient solutions of the dCME for a\nlarge class of networks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: State space truncation with quantified errors for accurate solutions to\n  discrete Chemical Master Equation"}, {"role": "assistant", "content": "The discrete chemical master equation (dCME) provides a general framework for\nstudying stochasticity in mesoscopic reaction networks. Since its direct\nsolution rapidly becomes intractable due to the increasing size of the state\nspace, truncation of the state space is necessary for solving most dCMEs. It is\ntherefore important to assess the consequences of state space truncations so\nerrors can be quantified and minimized. Here we describe a novel method for\nstate space truncation. By partitioning a reaction network into multiple\nmolecular equivalence groups (MEG), we truncate the state space by limiting the\ntotal molecular copy numbers in each MEG. We further describe a theoretical\nframework for analysis of the truncation error in the steady state probability\nlandscape using reflecting boundaries. By aggregating the state space based on\nthe usage of a MEG and constructing an aggregated Markov process, we show that\nthe truncation error of a MEG can be asymptotically bounded by the probability\nof states on the reflecting boundary of the MEG. Furthermore, truncating states\nof an arbitrary MEG will not undermine the estimated error of truncating any\nother MEGs. We then provide an error estimate for networks with multiple MEGs.\nTo rapidly determine the appropriate size of an arbitrary MEG, we introduce an\na priori method to estimate the upper bound of its truncation error, which can\nbe rapidly computed from reaction rates, without costly trial solutions of the\ndCME. We show results of applying our methods to four stochastic networks. We\ndemonstrate how truncation errors and steady state probability landscapes can\nbe computed using different sizes of the MEG(s) and how the results validate\nout theories. Overall, the novel state space truncation and error analysis\nmethods developed here can be used to ensure accurate direct solutions to the\ndCME for a large class of stochastic networks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: NMR microscopy for in vivo metabolomics, digitally twinned by\n  computational systems biology, needs a sensitivity boost"}, {"role": "assistant", "content": "The metabolism of an organism is regulated at the cellular level, yet is\nstrongly influenced by its environment. The precise metabolomic study of living\norganisms is currently hampered by measurement sensitivity: most metabolomic\nmeasurement techniques involve some compromise, in that averaging is performed\nover a volume significantly larger than a single cell, or require invasion of\nthe organism, or arrest the state of the organism. NMR is an inherently\nnon-invasive chemometric and imaging method, and hence in principle suitable\nfor metabolomic measurements. The digital twin of metabolomics is computational\nsystems biology, so that NMR microscopy is potentially a viable approach with\nwhich to join the theoretical and experimental exploration of the metabolomic\nand behavioural response of organisms. This prospect paper considers the\nchallenge of performing in vivo NMR-based metabolomics on the small organism C.\nelegans, points the way towards possible solutions created using MEMS\ntechniques, and highlights currently insurmountable challenges."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Robustly simulating biochemical reaction kinetics using multi-level\n  Monte Carlo approaches"}, {"role": "assistant", "content": "In this work, we consider the problem of estimating summary statistics to\ncharacterise biochemical reaction networks of interest. Such networks are often\ndescribed using the framework of the Chemical Master Equation (CME). For\nphysically-realistic models, the CME is widely considered to be analytically\nintractable. A variety of Monte Carlo algorithms have therefore been developed\nto explore the dynamics of such networks empirically. Amongst them is the\nmulti-level method, which uses estimates from multiple ensembles of sample\npaths of different accuracies to estimate a summary statistic of interest. {In\nthis work, we develop the multi-level method in two directions: (1) to increase\nthe robustness, reliability and performance of the multi-level method, we\nimplement an improved variance reduction method for generating the sample paths\nof each ensemble; and (2) to improve computational performance, we demonstrate\nthe successful use of a different mechanism for choosing which ensembles should\nbe included in the multi-level algorithm."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: PoMSA: An Efficient and Precise Position-based Multiple Sequence\n  Alignment Technique"}, {"role": "assistant", "content": "Analyzing the relation between a set of biological sequences can help to\nidentify and understand the evolutionary history of these sequences and the\nfunctional relations among them. Multiple Sequence Alignment (MSA) is the main\nobstacle to proper design and develop homology and evolutionary modeling\napplications since these kinds of applications require an effective MSA\ntechnique with high accuracy. This work proposes a novel Position-based\nMultiple Sequence Alignment (PoMSA) technique -- which depends on generating a\nposition matrix for a given set of biological sequences. This position matrix\ncan be used to reconstruct the given set of sequences in more aligned format.\nOn the contrary of existing techniques, PoMSA uses position matrix instead of\ndistance matrix to correctly adding gaps in sequences which improve the\nefficiency of the alignment operation. We have evaluated the proposed technique\nwith different datasets benchmarks such as BAliBASE, OXBench, and SMART. The\nexperiments show that PoMSA technique satisfies higher alignment score compared\nto existing state-of-art algorithms: Clustal-Omega, MAFTT, and MUSCLE."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The impact of temporal sampling resolution on parameter inference for\n  biological transport models"}, {"role": "assistant", "content": "Imaging data has become widely available to study biological systems at\nvarious scales, for example the motile behaviour of bacteria or the transport\nof mRNA, and it has the potential to transform our understanding of key\ntransport mechanisms. Often these imaging studies require us to compare\nbiological species or mutants, and to do this we need to quantitatively\ncharacterise their behaviour. Mathematical models offer a quantitative\ndescription of a system that enables us to perform this comparison, but to\nrelate these mechanistic mathematical models to imaging data, we need to\nestimate the parameters of the models. In this work, we study the impact of\ncollecting data at different temporal resolutions on parameter inference for\nbiological transport models by performing exact inference for simple velocity\njump process models in a Bayesian framework. This issue is prominent in a host\nof studies because the majority of imaging technologies place constraints on\nthe frequency with which images can be collected, and the discrete nature of\nobservations can introduce errors into parameter estimates. In this work, we\navoid such errors by formulating the velocity jump process model within a\nhidden states framework. This allows us to obtain estimates of the\nreorientation rate and noise amplitude for noisy observations of a simple\nvelocity jump process. We demonstrate the sensitivity of these estimates to\ntemporal variations in the sampling resolution and extent of measurement noise.\nWe use our methodology to provide experimental guidelines for researchers\naiming to characterise motile behaviour that can be described by a velocity\njump process. In particular, we consider how experimental constraints resulting\nin a trade-off between temporal sampling resolution and observation noise may\naffect parameter estimates."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Create, run, share, publish, and reference your LC-MS, FIA-MS, GC-MS,\n  and NMR data analysis workflows with the Workflow4Metabolomics 3.0 Galaxy\n  online infrastructure for metabolomics"}, {"role": "assistant", "content": "Metabolomics is a key approach in modern functional genomics and systems\nbiology. Due to the complexity of metabolomics data, the variety of\nexperimental designs, and the variety of existing bioinformatics tools,\nproviding experimenters with a simple and efficient resource to conduct\ncomprehensive and rigorous analysis of their data is of utmost importance. In\n2014, we launched the Workflow4Metabolomics (W4M,\nhttp://workflow4metabolomics.org) online infrastructure for metabolomics built\non the Galaxy environment, which offers user-friendly features to build and run\ndata analysis workflows including preprocessing, statistical analysis, and\nannotation steps. Here we present the new W4M 3.0 release, which contains twice\nas many tools as the first version, and provides two features which are, to our\nknowledge, unique among online resources. First, data from the four major\nmetabolomics technologies (i.e., LC-MS, FIA-MS, GC-MS, and NMR) can be analyzed\non a single platform. By using three studies in human physiology, alga\nevolution, and animal toxicology, we demonstrate how the 40 available tools can\nbe easily combined to address biological issues. Second, the full analysis\n(including the workflow, the parameter values, the input data and output\nresults) can be referenced with a permanent digital object identifier (DOI).\nPublication of data analyses is of major importance for robust and reproducible\nscience. Furthermore, the publicly shared workflows are of high-value for\ne-learning and training. The Workflow4Metabolomics 3.0 e-infrastructure thus\nnot only offers a unique online environment for analysis of data from the main\nmetabolomics technologies, but it is also the first reference repository for\nmetabolomics workflows."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: proFIA: A data preprocessing workflow for Flow Injection Analysis\n  coupled to High-Resolution Mass Spectrometry"}, {"role": "assistant", "content": "Motivation: Flow Injection Analysis coupled to High-Resolution Mass\nSpectrometry (FIA-HRMS) is a promising approach for high-throughput\nmetabolomics. FIA-HRMS data, however, cannot be preprocessed with current\nsoftware tools which rely on liquid chromatography separation, or handle low\nresolution data only. Results: We thus developed the proFIA package, which\nimplements a suite of innovative algorithms to preprocess FIA-HRMS raw files,\nand generates the table of peak intensities. The workflow consists of 3 steps:\ni) noise estimation, peak detection and quantification, ii) peak grouping\nacross samples, and iii) missing value imputation. In addition, we have\nimplemented a new indicator to quantify the potential alteration of the feature\npeak shape due to matrix effect. The preprocessing is fast (less than 15 s per\nfile), and the value of the main parameters (ppm and dmz) can be easily\ninferred from the mass resolution of the instrument. Application to two\nmetabolomics datasets (including spiked serum samples) showed high precision\n(96%) and recall (98%) compared with manual integration. These results\ndemonstrate that proFIA achieves very efficient and robust detection and\nquantification of FIA-HRMS data, and opens new opportunities for\nhigh-throughput phenotyping. Availability: The proFIA software (as well as the\nplasFIA data set) is available as an R package on the Bioconductor repository\n(http://bioconductor.org/packages/proFIA), and as a Galaxy module on the Main\nToolshed (https://toolshed.g2.bx.psu.edu/) and on the Workflow4Metabolomics\nonline infrastructure (http://workflow4metabolomics.org). Contacts:\nalexis.delabriere@cea.fr and etienne.thevenot@cea.fr."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The auxiliary region method: A hybrid method for coupling PDE- and\n  Brownian-based dynamics for reaction-diffusion systems"}, {"role": "assistant", "content": "Reaction-diffusion systems are used to represent many biological and physical\nphenomena. They model the random motion of particles (diffusion) and\ninteractions between them (reactions). Such systems can be modelled at multiple\nscales with varying degrees of accuracy and computational efficiency. When\nrepresenting genuinely multiscale phenomena, fine-scale models can be\nprohibitively expensive, whereas coarser models, although cheaper, often lack\nsufficient detail to accurately represent the phenomenon at hand. Spatial\nhybrid methods couple two or more of these representations in order to improve\nefficiency without compromising accuracy.\n  In this paper, we present a novel spatial hybrid method, which we call the\nauxiliary region method (ARM), which couples PDE and Brownian-based\nrepresentations of reaction-diffusion systems. Numerical PDE solutions on one\nside of an interface are coupled to Brownian-based dynamics on the other side\nusing compartment-based \"auxiliary regions\". We demonstrate that the hybrid\nmethod is able to simulate reaction-diffusion dynamics for a number of\ndifferent test problems with high accuracy. Further, we undertake error\nanalysis on the ARM which demonstrates that it is robust to changes in the free\nparameters in the model, where previous coupling algorithms are not. In\nparticular, we envisage that the method will be applicable for a wide range of\nspatial multi-scales problems including, filopodial dynamics, intracellular\nsignalling, embryogenesis and travelling wave phenomena."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Map-based cloning of the gene Pm21 that confers broad spectrum\n  resistance to wheat powdery mildew"}, {"role": "assistant", "content": "Common wheat (Triticum aestivum L.) is one of the most important cereal\ncrops. Wheat powdery mildew caused by Blumeria graminis f. sp. tritici (Bgt) is\na continuing threat to wheat production. The Pm21 gene, originating from\nDasypyrum villosum, confers high resistance to all known Bgt races and has been\nwidely applied in wheat breeding in China. In this research, we identify Pm21\nas a typical coiled-coil, nucleotide-binding site, leucine-rich repeat gene by\nan integrated strategy of resistance gene analog (RGA)-based cloning via\ncomparative genomics, physical and genetic mapping, BSMV-induced gene silencing\n(BSMV-VIGS), large-scale mutagenesis and genetic transformation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: How causal analysis can reveal autonomy in models of biological systems"}, {"role": "assistant", "content": "Standard techniques for studying biological systems largely focus on their\ndynamical, or, more recently, their informational properties, usually taking\neither a reductionist or holistic perspective. Yet, studying only individual\nsystem elements or the dynamics of the system as a whole disregards the\norganisational structure of the system - whether there are subsets of elements\nwith joint causes or effects, and whether the system is strongly integrated or\ncomposed of several loosely interacting components. Integrated information\ntheory (IIT), offers a theoretical framework to (1) investigate the\ncompositional cause-effect structure of a system, and to (2) identify causal\nborders of highly integrated elements comprising local maxima of intrinsic\ncause-effect power. Here we apply this comprehensive causal analysis to a\nBoolean network model of the fission yeast (Schizosaccharomyces pombe)\ncell-cycle. We demonstrate that this biological model features a non-trivial\ncausal architecture, whose discovery may provide insights about the real cell\ncycle that could not be gained from holistic or reductionist approaches. We\nalso show how some specific properties of this underlying causal architecture\nrelate to the biological notion of autonomy. Ultimately, we suggest that\nanalysing the causal organisation of a system, including key features like\nintrinsic control and stable causal borders, should prove relevant for\ndistinguishing life from non-life, and thus could also illuminate the origin of\nlife problem."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Determining Positive Cancer Rescue Mutations in p53 Based Cancers by\n  using Artificial Intelligence"}, {"role": "assistant", "content": "A mutation in a protein-coding gene in DNA can alter the protein structure\ncoded by the same gene. Structurally altered proteins usually lose their\nfunctions and sometimes gain an undesirable function instead. These types of\nmutations and their effects can result in genetic diseases or antibiotic\nresistant bacteria, among other health issues. Important curing methods have\nbeen developed for detecting mutations against AIDS as well as genetic\ndiseases. Another example is the influenza virus. The reasons why a vaccination\ndeveloped to fight against influenza does not work the following year are (a)\nthe mutation of its DNA and (b) the outbreak of the virus after it has been\nmutated especially if it is a virus that escaped the vaccinations target. Due\nto such reasons, it is highly important to know in advance the location of a\npotential mutation in a protein as well as the problems it might cause the\nmedical sciences. In this study we have used artificial neural networks, which\nare one of the latest artificial intelligence technologies, to determine the\neffects of cancer mutations. The model we developed has given more successful\nresults compared to other methods. We foresee that our model will bring a new\ndimension to medical research and the medical industry."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: How to disentangle psychobiological stress reactivity and recovery: A\n  comparison of model-based and non-compartmental analyses of cortisol\n  concentrations"}, {"role": "assistant", "content": "This article seeks to address the prevailing issue of how to measure specific\nprocess components of psychobiological stress responses. Particularly the\nchange of cortisol secretion due to stress exposure has been discussed as an\nendophenotype of many psychosomatic health outcomes. To assess its process\ncomponents, a large variety of non-compartmental parameters (i.e., composite\nmeasures of substance concentrations at different points in time) like the area\nunder the concentration-time curve (AUC) are utilized. However, a systematic\nevaluation and validation of these parameters based on a physiologically\nplausible model of cortisol secretion has not been performed so far. Thus, a\npopulation pharmacokinetic (mixed-effects SDE) model was developed and fitted\nto densely sampled salivary cortisol data of 10 males from Montreal, Canada,\nand sparsely sampled data of 200 mixed-sex participants from Dresden, Germany,\nwho completed the Trier Social Stress Test (TSST). Besides the two major\nprocess components representing (1) stress-related cortisol secretion\n(reactivity) and (2) cortisol elimination (recovery), the model incorporates\ntwo additional, often disregarded components: (3) the secretory delay after\nstress onset, and (4) deviations from the projected steady-state concentration.\nThe fitted model (R2 = 99%) was thereafter used to investigate the correlation\nstructure of the four individually varying, and readily interpretable model\nparameters and eleven popular non-compartmental parameters. Based on these\nanalyses, we recommend to use the minimum-maximum cortisol difference and the\nminimum concentration as proxy measures of reactivity and recovery,\nrespectively. Finally, statistical power analyses of the reactivity-related sex\neffect illustrate the consequences of using impure non-compartmental measures\nof the different process components that underlie the cortisol stress response."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Using Deep Convolutional Neural Networks to Circumvent Morphological\n  Feature Specification when Classifying Subvisible Protein Aggregates from\n  Micro-Flow Images"}, {"role": "assistant", "content": "Flow-Imaging Microscopy (FIM) is commonly used in both academia and industry\nto characterize subvisible particles (those $\\le 25 \\mu m$ in size) in protein\ntherapeutics. Pharmaceutical companies are required to record vast volumes of\nFIM data on protein therapeutic products, but are only mandated under US FDA\nregulations (i.e., USP $\\big \\langle 788 \\big \\rangle$) to control the number\nof particles exceeding $10$ and $25 \\mu m$ in delivered products. Hence, a vast\namount of digital images are available to analyze. Current state-of-the-art\nmethods rely on a relatively low-dimensional list of \"morphological features\"\nto characterize particles, but these methods ignore an enormous amount of\ninformation encoded in the existing large digital image repositories. Deep\nConvolutional Neural Networks (CNNs or \"ConvNets\") have demonstrated the\nability to extract predictive information from raw macroscopic image data\nwithout requiring the selection or specification of \"morphological features\" in\na variety of tasks. However, the heterogeneity, polydispersity of protein\ntherapeutics, and optical phenomena associated with subvisible FIM particle\nmeasurements introduce new challenges regarding the application of CNNs to FIM\nimage analysis. In this article, we demonstrate a supervised learning technique\nleveraging CNNs to extract information from raw images in order to predict the\nprocess conditions or stress states (freeze-thaw, mechanical shaking, etc.)\nthat produced a variety of different protein images. We demonstrate that our\nnew classifier (in combination with a sample \"image pooling\" strategy) can\nobtain nearly perfect predictions using as few as 20 FIM images from a given\nprotein formulation in a variety of scenarios of relevance to protein\ntherapeutics quality control and process monitoring."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Analyzing huge pathology images with open source software"}, {"role": "assistant", "content": "Backgr: Digital pathology images are increasingly used both for diagnosis and\nresearch, because slide scanners are nowadays broadly available and because the\nquantitative study of these images yields new insights in systems biology.\nHowever, such virtual slides build up a technical challenge since the images\noccupy often several gigabytes and cannot be fully opened in a computer's\nmemory. Moreover, there is no standard format. Therefore, most common open\nsource tools such as ImageJ fail at treating them, and the others require\nexpensive hardware while still being prohibitively slow.\n  Res: We have developed several cross-platform open source software tools to\novercome these limitations. The NDPITools provide a way to transform microscopy\nimages initially in the loosely supported NDPI format into one or several\nstandard TIFF files, and to create mosaics (division of huge images into small\nones, with or without overlap) in various TIFF and JPEG formats. They can be\ndriven through ImageJ plugins. The LargeTIFFTools achieve similar functionality\nfor huge TIFF images which do not fit into RAM. We test the performance of\nthese tools on several digital slides and compare them, when applicable, to\nstandard software. A statistical study of the cells in a tissue sample from an\noligodendroglioma was performed on an average laptop computer to demonstrate\nthe efficiency of the tools.\n  Concl: Our open source software enables dealing with huge images with\nstandard software on average computers. Our tools are cross-platform,\nindependent of proprietary libraries, and very modular, allowing them to be\nused in other open source projects. They have excellent performance in terms of\nexecution speed and RAM requirements. They open promising perspectives both to\nthe clinician who wants to study a single slide and to the research team or\ndata centre who do image analysis of many slides on a computer cluster."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Dithymoquinone as a novel inhibitor for\n  3-carboxy-4-methyl-5-propyl-2-furanpropanoic acid (CMPF) to prevent renal\n  failure"}, {"role": "assistant", "content": "3-carboxy-4-methyl-5-propyl-2-furanpropanoic acid (CMPF) is a major\nendogenous ligand found in the human serum albumin (HSA) of renal failure\npatients. It gets accumulated in the HSA and its concentration in sera of\npatients may reflect the chronicity of renal failure [1-4]. It is considered\nuremic toxin due to its damaging effect on the renal cells. The high\nconcentrations of CMPF inhibit the binding of other ligands to HSA. Removal of\nCMPF is difficult through conventional hemodialysis due to its strong binding\naffinity. We hypothesized that the competitive inhibition may be helpful in\nremoval of CMPF binding to HSA. A compound with higher HSA binding affinity\nthan CMPF could be useful to prevent CMPF from binding so that CMPF could be\nexcreted by the body through the urine. We studied an active compound\ndihydrothymoquinone/ dithymoquinone (DTQ) found in black cumin seed (Nigella\nsativa), which has higher binding affinity for HSA. Molecular docking\nsimulations were performed to find the binding affinity of CMPF and DTQ with\nHSA. DTQ was found to have higher binding affinity possessing more interactions\nwith the binding residues than the CMPF. We studied the binding pocket\nflexibility of CMPF and DTQ to analyze the binding abilities of both the\ncompounds. We have also predicted the ADME properties for DTQ which shows\nhigher lipophilicity, higher gastrointestinal (GI) absorption, and blood-brain\nbarrier (BBB) permeability. We discovered that DTQ has potential to act as an\ninhibitor of CMPF and can be considered as a candidate for the formation of the\ntherapeutic drug against CMPF."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Application of electromagnetic centroids to colocalization of\n  fluorescing objects in tissue sections"}, {"role": "assistant", "content": "Light microscopy as well as image acquisition and processing suffer from\nphysical and technical prejudices which preclude a correct interpretation of\nbiological observations which can be reflected in, e.g., medical and\npharmacological praxis. Using the examples of a diffracting microbead and\nfluorescently labelled tissue, this article clarifies some ignored aspects of\nimage build-up in the light microscope and introduce algorithms for maximal\nextraction of information from the 3D microscopic experiments. We provided a\ncorrect set-up of the microscope and we sought a voxel (3D pixel) called an\nelectromagnetic centroid which localizes the information about the object. In\ndiffraction imaging and light emission, this voxel shows a minimal intensity\nchange in two consecutive optical cuts. This approach further enabled us to\nidentify z-stack of a DAPI-stained tissue section where at least one object of\na relevant fluorescent marker was in focus. The spatial corrections (overlaps)\nof the DAPI-labelled region with in-focus autofluorescent regions then enabled\nus to co-localize these three regions in the optimal way when considering\nphysical laws and information theory. We demonstrate that superresolution down\nto the Nobelish level can be obtained from commonplace widefield bright-field\nand fluorescence microscopy and bring new perspectives on co-localization in\nfluorescent microscopy."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: High-resolution reconstruction of cellular traction-force distributions:\n  the role of physically motivated constraints and compressive regularization"}, {"role": "assistant", "content": "We develop a method to reconstruct, from measured displacements of an\nunderlying elastic substrate, the spatially dependent forces that cells or\ntissues impart on it. Given newly available high-resolution images of substrate\ndisplacements, it is desirable to be able to reconstruct small scale, compactly\nsupported focal adhesions which are often localized and exist only within the\nfootprint of a cell. In addition to the standard quadratic data mismatch terms\nthat define least-squares fitting, we motivate a regularization term in the\nobjective function that penalizes vectorial invariants of the reconstructed\nsurface stress while preserving boundaries. We solve this inverse problem by\nproviding a numerical method for setting up a discretized inverse problem that\nis solvable by standard convex optimization techniques. By minimizing the\nobjective function subject to a number of important physically motivated\nconstraints, we are able to efficiently reconstruct stress fields with\nlocalized structure from simulated and experimental substrate displacements.\nOur method incorporates the exact solution for the stress tensor accurate to\nfirst-order finite-differences and motivates the use of distance-based cut-offs\nfor data inclusion and problem sparsification."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Pulsing corals: A story of scale and mixing"}, {"role": "assistant", "content": "Effective methods of fluid transport vary across scale. A commonly used\ndimensionless number for quantifying the effective scale of fluid transport is\nthe Reynolds number, Re, which gives the ratio of inertial to viscous forces.\nWhat may work well for one Re regime may not produce significant flows for\nanother. These differences in scale have implications for many organisms,\nranging from the mechanics of how organisms move through their fluid\nenvironment to how hearts pump at various stages in development. Some\norganisms, such as soft pulsing corals, actively contract their tentacles to\ngenerate mixing currents that enhance photosynthesis. Their unique morphology\nand intermediate scale where both viscous and inertial forces are significant\nmake them a unique model organism for understanding fluid mixing. In this\npaper, 3D fluid-structure interaction simulations of a pulsing soft coral are\nused to quantify fluid transport and fluid mixing across a wide range of Re.\nThe results show that net transport is negligible for $Re<10$, and continuous\nupward flow is produced for $Re\\geq 10$."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Protection of hamsters from mortality by reducing fecal moxifloxacin\n  concentration with DAV131A in a model of moxifloxacin-induced Clostridium\n  difficile colitis"}, {"role": "assistant", "content": "BackgroundLowering the gut exposure to antibiotics during treatments can\nprevent microbiota disruption. We evaluated the effect of an activated\ncharcoal-based adsorbent, DAV131A, on fecal free moxifloxacin concentration and\nmortality in a hamster model of moxifloxacin-induced C. difficile\ninfection.Methods215 hamsters receiving moxifloxacin subcutaneously (D1-D5)\nwere orally infected at D3 with C. difficile spores. They received various\ndoses (0-1800mg/kg/day) and schedules (BID, TID) of DAV131A (D1-D8).\nMoxifloxacin concentration and C. difficile counts were determined at D3, and\nmortality at D12. We compared mortality, moxifloxacin concentration and C.\ndifficile counts according to DAV131A regimens, and modelled the link between\nDAV131A regimen, moxifloxacin concentration and mortality. ResultsAll hamsters\nthat received no DAV131A died, but none of those that received 1800mg/kg/day. A\nsignificant dose-dependent relationship between DAV131A dose and (i) mortality\nrates, (ii) moxifloxacin concentration and (iii) C. difficile counts was\nevidenced. Mathematical modeling suggested that (i) lowering moxifloxacin\nconcentration at D3, which was 58$\\mu$g/g (95%CI=50-66) without DAV131A, to\n17$\\mu$g/g (14-21) would reduce mortality by 90% and (ii) this would be\nachieved with a daily DAV131A dose of 703mg/kg (596-809).ConclusionsIn this\nmodel of C. difficile infection, DAV131A reduced mortality in a dose-dependent\nmanner by decreasing fecal free moxifloxacin concentration."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Gradient Descent Method for Optimization of Model Microvascular\n  Networks"}, {"role": "assistant", "content": "Within animals, oxygen exchange occurs within networks containing potentially\nbillions of microvessels that are distributed throughout the animal's body.\nInnovative imaging methods now allow for mapping of the architecture and blood\nflows within real microvascular networks. However, these data streams have so\nfar yielded little new understanding of the physical principles that underlie\nthe organization of microvascular networks, which could allow healthy networks\nto be quantitatively compared with networks that have been damaged, e.g. due to\ndiabetes. A natural mathematical starting point for understanding network\norganization is to construct networks that are optimized accordingly to\nspecified functions. Here we present a method for deriving transport networks\nthat optimize general functions involving the fluxes and conductances within\nthe network. In our method Kirchoff's laws are imposed via Lagrange\nmultipliers, creating a large, but sparse system of auxiliary equations. By\ntreating network conductances as adiabatic variables, we derive a gradient\ndescent method in which conductances are iteratively adjusted, and auxiliary\nvariables are solved for by two inversions of O(N^2) sized sparse matrices. In\nparticular our algorithm allows us to validate the hypothesis that\nmicrovascular networks are organized to uniformly partition the flow of red\nblood cells through vessels. The theoretical framework can also be used to\nconsider more general sets of objective functions and constraints within\ntransport networks, including incorporating the non-Newtonian rheology of blood\n(i.e. the Fahraeus-Lindqvist effect). More generally by forming linear\ncombinations of objective functions, we can explore tradeoffs between different\noptimization functions, giving more insight into the diversity of biological\ntransport networks seen in nature."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Antibacterial properties of nonwoven wound dressings coated with Manuka\n  honey or methylglyoxal"}, {"role": "assistant", "content": "Manuka honey (MH) is used as an antibacterial agent in bioactive wound\ndressings via direct impregnation onto a suitable substrate. MH provides unique\nantibacterial activity when compared with conventional honeys, owing partly to\none of its constituents, methylglyoxal (MGO). Aiming to investigate an\nantibiotic-free antimicrobial strategy, we studied the antibacterial activity\nof both MH and MGO (at equivalent MGO concentrations) when applied as a\nphysical coating to a nonwoven fabric wound dressing. When physically coated on\nto a cellulosic hydroentangled nonwoven fabric, it was found that\nconcentrations of 0.0054 mg cm-2 of MGO in the form of MH and MGO was\nsufficient to achieve 100 CFU% bacteria reduction against gram-positive\nStaphylococcus aureus and gram-negative Klebsiella pneumoniae, based on BS EN\nISO 20743:2007. A 3- to 20- fold increase in MGO concentration (0.0170 - 0.1 mg\ncm-2) was required to facilitate a good antibacterial effect (based on BS EN\nISO 20645:2004) in terms of zone of inhibition and lack of growth under the\nsample. The minimum inhibitory concentration (MIC) and minimum bactericidal\nconcentration (MBC) was also assessed for MGO in liquid form against three\nprevalent wound and healthcare-associated pathogens, i.e. Staphylococcus\naureus, gram-negative Pseudomonas aeruginosa and gram-positive Enterococcus\nfaecalis. Other than the case of MGO-containing fabrics, solutions with much\nhigher MGO concentrations (128 mg L-1 - 1024 mg L-1) were required to provide\neither a bacteriostatic or bactericidal effect. The results presented in this\nstudy therefore demonstrate the relevance of MGO-based coating as an\nenvironment-friendly strategy for the design of functional dressings with\nantibiotic-free antimicrobial chemistries."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Cefazolin versus anti-staphylococcal penicillins for treatment of\n  methicillin-susceptible Staphylococcus aureus bacteraemia: a narrative review"}, {"role": "assistant", "content": "Anti-staphylococcal penicillins (ASPs) are recommended as first-line agents\nin methicillin-susceptible Staphylococcus aureus (MSSA) bacteraemia. Concerns\nabout their safety profile have contributed to the increased use of cefazolin.\nThe comparative clinical effectiveness and safety profile of cefazolin versus\nASPs for such infections remain unclear. Furthermore, uncertainty persists\nconcerning the use of cefazolin due to controversies over its efficacy in deep\nMSSA infections and its possible negative ecological impact."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Pharmacokinetics and Molecular Docking studies of Plant-Derived Natural\n  Compounds to Exploring Potential Anti-Alzheimer Activity"}, {"role": "assistant", "content": "Alzheimer disease (AD) is the leading cause of dementia, accounts for 60 to\n80 percent cases. Two main factors called beta amyloid plaques and tangles are\nprime suspects in damaging and killing nerve cells. However, oxidative stress,\nthe process which produces free radicals in cells, is believed to promote its\nprogression to the extent that it may responsible for the cognitive and\nfunctional decline observed in AD. As of today there are few FDA approved drugs\nin the market for treatment, but their cholinergic adverse effect, potentially\ndistressing toxicity and limited targets in AD pathology limits their use.\nTherefore, it is crucial to find an effective compounds to combat AD. We choose\n45 plant derived natural compounds that have antioxidant properties to slow\ndown disease progression by quenching free redicals or promoting endogenous\nantioxidant capacity. However, we performed molecular docking studies to\ninvestigate the binding interactions between natural compounds and 13 various\nanti Alzheimer drug targets. Three known Cholinesterase inhibitors (Donepezil,\nGalantamine and Rivastigmine) were taken as reference drugs over natural\ncompounds for comparison and drug likeness studies. Few of these compounds\nshowed good inhibitory activity besides anti oxidant activity. Most of these\ncompounds followed pharmacokinetics properties that make them potentially\npromising drug candidates for the treatment of Alzheimer disease."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: DNA Sequence Alignment by Window based Optical Correlator"}, {"role": "assistant", "content": "In genomics, pattern matching against a sequence of nucleotides plays a\npivotal role for DNA sequence alignment and comparing genomes. This helps\ntackling some diseases, such as cancer in humans. The complexity of searching\nbiological sequences in big databases has transformed sequence alignment\nproblem into a challenging field of research in bioinformatics. A large number\nof research has been carried to solve this problem based on electronic\ncomputers. The required extensive amount of computations for handling this huge\ndatabase in electronic computers leads to vast amounts of energy consumption\nfor electrical processing and cooling. On the other hand, optical processing\ndue to its parallel nature is much faster than electrical counterpart at a\nfraction of energy consumption level and cost. In this paper, an algorithm\nbased on optical parallel processing is proposed that not only locate\nsimilarity between sequences but also determines the exact location of edits.\nThe proposed algorithm is based on partitioning the read sequence into some\nparts, namely, windows, then, computing their correlation with reference\nsequence in parallel. Multiple metamaterial based optical correlators are used\nin parallel to optically implement the architecture. Design limitations and\nchallenges of the architecture are also discussed in details. The simulation\nresults, comparing with the well-known BLAST algorithm, demonstrate superior\nspeed, accuracy, and much lower power consumption."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Emerging whole-cell modeling principles and methods"}, {"role": "assistant", "content": "Whole-cell computational models aim to predict cellular phenotypes from\ngenotype by representing the entire genome, the structure and concentration of\neach molecular species, each molecular interaction, and the extracellular\nenvironment. Whole-cell models have great potential to transform bioscience,\nbioengineering, and medicine. However, numerous challenges remain to achieve\nwhole-cell models. Nevertheless, researchers are beginning to leverage recent\nprogress in measurement technology, bioinformatics, data sharing, rule-based\nmodeling, and multi-algorithmic simulation to build the first whole-cell\nmodels. We anticipate that ongoing efforts to develop scalable whole-cell\nmodeling tools will enable dramatically more comprehensive and more accurate\nmodels, including models of human cells."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Entropy production selects nonequilibrium states in multistable systems"}, {"role": "assistant", "content": "Far-from-equilibrium thermodynamics underpins the emergence of life, but how\nhas been a long-outstanding puzzle. Best candidate theories based on the\nmaximum entropy production principle could not be unequivocally proven, in part\ndue to complicated physics, unintuitive stochastic thermodynamics, and the\nexistence of alternative theories such as the minimum entropy production\nprinciple. Here, we use a simple, analytically solvable, one-dimensional\nbistable chemical system to demonstrate the validity of the maximum entropy\nproduction principle. To generalize to multistable stochastic system, we use\nthe stochastic least-action principle to derive the entropy production and its\nrole in the stability of nonequilibrium steady states. This shows that in a\nmultistable system, all else being equal, the steady state with the highest\nentropy production is favored, with a number of implications for the evolution\nof biological, physical, and geological systems."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Simulating Organogenesis in COMSOL: Comparison Of Methods For Simulating\n  Branching Morphogenesis"}, {"role": "assistant", "content": "During organogenesis tissue grows and deforms. The growth processes are\ncontrolled by diffusible proteins, so-called morphogens. Many different\npatterning mechanisms have been proposed. The stereotypic branching program\nduring lung development can be recapitulated by a receptor-ligand based Turing\nmodel. Our group has previously used the Arbitrary Lagrangian-Eulerian (ALE)\nframework for solving the receptor-ligand Turing model on growing lung domains.\nHowever, complex mesh deformations which occur during lung growth severely\nlimit the number of branch generations that can be simulated. A new Phase-Field\nimplementation avoids mesh deformations by considering the surface of the\nmodelling domains as interfaces between phases, and by coupling the\nreaction-diffusion framework to these surfaces. In this paper, we present a\nrigorous comparison between the Phase-Field approach and the ALE-based\nsimulation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A General Approach to Coding in Early Olfactory and Visual Neural\n  Populations"}, {"role": "assistant", "content": "Recent experimental and theoretical work on neural populations belonging to\ntwo separate early sensory systems, olfaction and vision, has challenged the\nnotion that the two operate under different computational paradigms by\nproviding evidence for the respective neural population codes having three\ncentral, common features: they are highly redundant; they are organized such\nthat information is carried in the identity, and not the relative timing, of\nthe active neurons; they are capable of error correction. We present the first\nmodel that captures these three properties in a general manner, making it\npossible to investigate whether similar structure is present in other\npopulation codes. Our model also makes specific predictions about additional,\nas yet unseen, structure in such codes. If these predictions are found in real\ndata, this would provide new evidence that such population codes are operating\nunder more general computational principles."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Creation and analysis of biochemical constraint-based models: the COBRA\n  Toolbox v3.0"}, {"role": "assistant", "content": "COnstraint-Based Reconstruction and Analysis (COBRA) provides a molecular\nmechanistic framework for integrative analysis of experimental data and\nquantitative prediction of physicochemically and biochemically feasible\nphenotypic states. The COBRA Toolbox is a comprehensive software suite of\ninteroperable COBRA methods. It has found widespread applications in biology,\nbiomedicine, and biotechnology because its functions can be flexibly combined\nto implement tailored COBRA protocols for any biochemical network. Version 3.0\nincludes new methods for quality controlled reconstruction, modelling,\ntopological analysis, strain and experimental design, network visualisation as\nwell as network integration of chemoinformatic, metabolomic, transcriptomic,\nproteomic, and thermochemical data. New multi-lingual code integration also\nenables an expansion in COBRA application scope via high-precision,\nhigh-performance, and nonlinear numerical optimisation solvers for multi-scale,\nmulti-cellular and reaction kinetic modelling, respectively. This protocol can\nbe adapted for the generation and analysis of a constraint-based model in a\nwide variety of molecular systems biology scenarios. This protocol is an update\nto the COBRA Toolbox 1.0 and 2.0. The COBRA Toolbox 3.0 provides an\nunparalleled depth of constraint-based reconstruction and analysis methods."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Anticipation induces polarized collective motion in attraction based\n  models"}, {"role": "assistant", "content": "In most models of collective motion in animal groups each individual updates\nits heading based on the current positions and headings of its neighbors.\nSeveral authors have investigated the effects of including anticipation into\nmodels of this type, and have found that anticipation inhibits polarized\ncollective motion in alignment based models and promotes milling and swarming\nin the one attraction-repulsion model studied. However, it was recently\nreported that polarized collective motion does emerge in an alignment based\nasynchronous lattice model with mutual anticipation. To our knowledge this is\nthe only reported case where polarized collective motion has been observed in a\nmodel with anticipation. Here we show that including anticipation induces\npolarized collective motion in a synchronous, off lattice, attraction based\nmodel. This establishes that neither asynchrony, mutual anticipation nor motion\nrestricted to a lattice environment are strict requirements for anticipation to\npromote polarized collective motion. In addition, unlike alignment based models\nthe attraction based model used here does not produce any type of polarized\ncollective motion in the absence of anticipation. Here anticipation is a direct\npolarization inducing mechanism. We believe that utilizing anticipation instead\nof frequently used alternatives such as explicit alignment terms, asynchronous\nupdates and asymmetric interactions to generate polarized collective motion may\nbe advantageous in some cases."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: SELYMATRA: Web Application for the analysis of mass spectra"}, {"role": "assistant", "content": "Surface Enhanced Laser Desorption/Ionization-Time Of Flight Mass Spectrometry\n(SELDI-TOF MS) is a variant of the MALDI. It is uses in many cases especially\nfor the analysis of protein profiling and for preliminary screening tasks of\ncomplex sample aimed for the searching of biomarker. Unfortunately, these\nanalysis are time consuming and strictly limited about the protein\nidentification. Seldi analysis of mass spectra (SELYMATRA) is a Web Application\n(WA) developed with the aim of reduce these lacks automating the identification\nprocesses and introducing the possibility to predict the proteins present in\ncomplex mixtures from cells and tissues analysed by Mass Spectrometry.\nSELYMATRA has the following characteristics. The architectural pattern used to\ndevelop the WA is the Model-View-Controller (MVC), extremely used in the\ndevelopment of software system. The WA expects an user to upload data in a\nMicrosoft Excel spreadsheet file format, usually generated by means of the\nproprietary Mass Spectrometry softwares. Several parameters can be set such as\nexperiment conditions, range of isoelectric point, range of pH, relative errors\nand so on. The WA compare the mass value among two mass spectra (sample vs\ncontrol) to extract differences, and according to the parameters set, it\nqueries a local database for the prediction of the most likely proteins related\nto the masses differently expressed. The WA was validated in a cellular model\noverexpressing a tagged NURR1 receptor. SELYMATRA is available at\nhttp://140.164.61.23:8080/SELYMATRA."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: An elementary proof of the total progeny size of a birth-death process,\n  with application to network component sizes"}, {"role": "assistant", "content": "We revisit the size distribution of finite components in infinite\nConfiguration Model networks. We provide an elementary combinatorial proof\nabout the sizes of birth-death trees which is more intuitive than previous\nproofs. We use this to rederive the component size distribution for\nConfiguration Model networks. Our derivation provides a more intuitive\ninterpretation of the formula as contrasted with the previous derivation based\non contour integrations. We demonstrate that the formula performs well, even on\nnetworks with heavy tails which violate assumptions of the derivation. We\nexplain why the result should remain robust for these networks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Entrainment in the Master Equation"}, {"role": "assistant", "content": "The master equation plays an important role in many scientific fields\nincluding physics, chemistry, systems biology, physical finance, and\nsociodynamics. We consider the master equation with periodic transition rates.\nThis may represent an external periodic excitation like the 24h solar day in\nbiological systems or periodic traffic lights in a model of vehicular traffic.\nUsing tools from systems and control theory, we prove that under mild technical\nconditions every solution of the master equation converges to a periodic\nsolution with the same period as the rates. In other words, the master equation\nentrains (or phase locks) to periodic excitations. We describe two applications\nof our theoretical results to important models from statistical mechanics and\nepidemiology."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Microscale magnetic resonance detectors: a technology roadmap for in\n  vivo metabolomics"}, {"role": "assistant", "content": "One of the great challenges in biology is to observe, at sufficient detail,\nthe real-time workings of the cell. Many methods exist to do cell measurements\ninvasively. For example, mass spectrometry has tremendous mass sensitivity but\ndestroys the cell. Molecular tagging can reveal exquisite detail using STED\nmicroscopy, but is currently neither relevant for a large number of different\nmolecules, nor is it applicable to very small molecules. For marker free\nnon-invasive measurements, only magnetic resonance has sufficient molecular\nspecificity, but the technique suffers from low sensitivity and resolution. In\nthis presentation we will consider the roadmap for achieving in vivo\nmetabolomic measurements with more sensitivity and resolution. The roadmap will\npoint towards the technological advances that are necessary for magnetic\nresonance microscopy to answer questions relevant to cell biology."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Theoretical foundations for the Human Cell Atlas"}, {"role": "assistant", "content": "In Schiebinger et al. (2017), the authors use optimal transport of measures\non empirical distributions arising from biological experiments to relate the\nsingle cell RNA sequencing profiles for induced pluripotent stem cells\ndifferentiating. But such algorithms could be arbitrarily applied to any\ndatasets from any collection of experiments. We consider here a natural\nquestion that arises: in a manner consistent with conventionally accepted\nassumptions about biology, in which cases can the results of two experiments be\nmapped to each other in this manner? The answer to this question is of\nfundamental practical importance in developing algorithms that use this method\nfor analysing and integrating complex datasets collected as part of the Human\nCell Atlas. Here, we develop a formulation of biology in terms of sheaves of\n$C^*(X)$-modules for a smooth manifold $X$ equipped with certain structures,\nthat enables this question to be formally answered, leading to formal\nstatements about experimental inference and phenotypic identifiability. These\nstructures capture a perspective on biology that is consistent with a standard,\nwidely accepted biological perspective and is mathematically intuitive. Our\nmethods provide a framework in which to design complex experiments and the\nalgorithms to analyse them in a way that their conclusions can be believed."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Practical Identifiability and Uncertainty Quantification of a Pulsatile\n  Cardiovascular Model"}, {"role": "assistant", "content": "Mathematical models are essential tools to study how the cardiovascular\nsystem maintains homeostasis. The utility of such models is limited by the\naccuracy of their predictions, which can be determined by uncertainty\nquantification (UQ). A challenge associated with the use of UQ is that many\npublished methods assume that the underlying model is identifiable (e.g. that a\none-to-one mapping exists from the parameter space to the model output). In\nthis study we present a novel methodology that is used here to calibrate a\nlumped-parameter model to left ventricular pressure and volume time series data\nsets. Key steps include using (1) literature and available data to determine\nnominal parameter values; (2) sensitivity analysis and subset selection to\ndetermine a set of identifiable parameters; (3) optimization to find a point\nestimate for identifiable parameters; and (4) frequentist and Bayesian UQ\ncalculations to assess the predictive capability of the model. Our results show\nthat it is possible to determine 5 identifiable model parameters that can be\nestimated to our experimental data from three rats, and that computed UQ\nintervals capture the measurement and model error."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Developpement des methodes de correlation d images pour l analyse de la\n  mobilite moleculaire dans un systeme biologique complexe spatialement et\n  temporellement"}, {"role": "assistant", "content": "Fluorescence spectroscopy is an image correlation technique to analyze and\ncharacterize the molecular dynamics from a sequence of fluorescence images.\nMany image correlation techniques have been developed for different\napplications [1]. But in practice the use of these techniques is often limited\nto a manually selected region of analysis where it is assumed that the observed\nmolecules have homogeneous and constant behavior over time. Due to the spatial\nand temporal complexity of biological objects, this assumption is frequently at\nfault. It is then necessary to propose a robust method for discriminating the\ndifferent behaviors over time from experience, as well as identification of the\ntype of dynamics (diffusion or flow). This paper presents an original system of\nautomatic discrimination and identification of spatially and temporally uniform\nregions for the analysis of molecular different dynamics over time by\ncalculating STICS (Spatio-Temporal Image Correlation Spectroscopy) at different\ntime lags. An evaluation of system performance is presented on simulated images\nand images acquired by fluorescence microscopy on actin cytoskeleton."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Using Positional Heel-marker Data to More Accurately Calculate Stride\n  Length for Treadmill Walking: A Step Length Approach"}, {"role": "assistant", "content": "Treadmill walking is a convenient tool for studying the human gait; however,\na common gait parameter, stride length, can be difficult to calculate directly\nbecause relevant reference points continually move backwards. Although there is\nno direct calculation of stride length itself, we can use positional\nheel-marker data to directly determine a similar parameter, step length, and we\ncan sum two step lengths to result in one stride length. This proposed method\nof calculation is simple but seems to be unexplored in other literature, so\nthis paper displays the details of the calculation. Our experimental results\ndiffered from the expected values by 2.2% and had a very low standard\ndeviation, suggesting that this method is viable for practical use. The ability\nto calculate stride length for treadmill walking using heel-marker data may\nallow for quick and accurate gait calculations that further contribute to the\nversatility of heel data as a tool for gait analysis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Elucidation of time-dependent systems biology cell response patterns\n  with time course network enrichment"}, {"role": "assistant", "content": "Advances in OMICS technologies emerged both massive expression data sets and\nhuge networks modelling the molecular interplay of genes, RNAs, proteins and\nmetabolites. Network enrichment methods combine these two data types to extract\nsubnetwork responses from case/control setups. However, no methods exist to\nintegrate time series data with networks, thus preventing the identification of\ntime-dependent systems biology responses. We close this gap with Time Course\nNetwork Enrichment (TiCoNE). It combines a new kind of human-augmented\nclustering with a novel approach to network enrichment. It finds temporal\nexpression prototypes that are mapped to a network and investigated for\nenriched prototype pairs interacting more often than expected by chance. Such\npatterns of temporal subnetwork co-enrichment can be compared between different\nconditions. With TiCoNE, we identified the first distinguishing temporal\nsystems biology profiles in time series gene expression data of human lung\ncells after infection with Influenza and Rhino virus. TiCoNE is available\nonline (https://ticone.compbio.sdu.dk) and as Cytoscape app in the Cytoscape\nApp Store (http://apps.cytoscape.org/)."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Efficient simulation techniques for biochemical reaction networks"}, {"role": "assistant", "content": "Discrete-state, continuous-time Markov models are becoming commonplace in the\nmodelling of biochemical processes. The mathematical formulations that such\nmodels lead to are opaque, and, due to their complexity, are often considered\nanalytically intractable. As such, a variety of Monte Carlo simulation\nalgorithms have been developed to explore model dynamics empirically. Whilst\nwell-known methods, such as the Gillespie Algorithm, can be implemented to\ninvestigate a given model, the computational demands of traditional simulation\ntechniques remain a significant barrier to modern research.\n  In order to further develop and explore biologically relevant stochastic\nmodels, new and efficient computational methods are required. In this thesis,\nhigh-performance simulation algorithms are developed to estimate summary\nstatistics that characterise a chosen reaction network. The algorithms make use\nof variance reduction techniques, which exploit statistical properties of the\nmodel dynamics, to improve performance.\n  The multi-level method is an example of a variance reduction technique. The\nmethod estimates summary statistics of well-mixed, spatially homogeneous models\nby using estimates from multiple ensembles of sample paths of different\naccuracies. In this thesis, the multi-level method is developed in three\ndirections: firstly, a nuanced implementation framework is described; secondly,\na reformulated method is applied to stiff reaction systems; and, finally,\ndifferent approaches to variance reduction are implemented and compared.\n  The variance reduction methods that underpin the multi-level method are then\nre-purposed to understand how the dynamics of a spatially-extended Markov model\nare affected by changes in its input parameters. By exploiting the inherent\ndynamics of spatially-extended models, an efficient finite difference scheme is\nused to estimate parametric sensitivities robustly."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: DeepQuality: Mass Spectra Quality Assessment via Compressed Sensing and\n  Deep Learning"}, {"role": "assistant", "content": "Motivation: Mass spectrometry-based proteomics is among the most commonly\nused methods for scrutinizing proteomic profiles in different organs for\nbiological or medical researches. All the proteomic analyses including\npeptide/protein identification and quantification, differential expression\nanalysis, biomarker discovery and so on are all based on the matching of mass\nspectra with peptide sequences, which is significantly influenced by the\nquality of the spectra, such as the peak numbers, noisy peaks, signal-to-noise\nratios, etc. Hence, it is crucial to assess the quality of the spectra in order\nfor filtering and/or post-processing after identification. The handcrafted\nfeatures representing spectra quality, however, need human expertise to design\nand are difficult to optimize, and thus the existing assessing algorithms are\nstill lacking in accuracy. Thus, there is a critical need for the robust and\nadaptive algorithm for mass spectra quality assessment. Results: We have\ndeveloped a novel mass spectrum assessment software DeepQuality, based on the\nstate-of-the-art compressed sensing and deep learning algorithms. We evaluated\nthe algorithm on two publicly available tandem MS data sets, resulting in the\nAUC of 0.96 and 0.92, respectively, a significant improvement compared with the\nAUC of 0.85 and 0.91 of the existing method SpectrumQuality v2.0. Availability:\nSoftware available at https://github.com/horsepurve/DeepQuality"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Retention Time of Peptides in Liquid Chromatography Is Well Estimated\n  upon Deep Transfer Learning"}, {"role": "assistant", "content": "A fully automatic prediction for peptide retention time (RT) in liquid\nchromatography (LC), termed as DeepRT, was developed using deep learning\napproach, an ensemble of Residual Network (ResNet) and Long Short-Term Memory\n(LSTM). In contrast to the traditional predictor based on the hand-crafted\nfeatures for peptides, DeepRT learns features from raw amino acid sequences and\nmakes relatively accurate prediction of peptide RTs with 0.987 R2 for\nunmodified peptides. Furthermore, by virtue of transfer learning, DeepRT\nenables utilization of the peptides datasets generated from different LC\nconditions and of different modification status, resulting in the RT prediction\nof 0.992 R2 for unmodified peptides and 0.978 R2 for post-translationally\nmodified peptides. Even though chromatographic behaviors of peptides are quite\ncomplicated, the study here demonstrated that peptide RT prediction could be\nlargely improved by deep transfer learning. The DeepRT software is freely\navailable at https://github.com/horsepurve/DeepRT, under Apache2 open source\nLicense."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Label-free quantitative screening of breast tissue using Spatial Light\n  Interference Microscopy (SLIM)"}, {"role": "assistant", "content": "Breast cancer is the most common type of cancer among women worldwide. The\nstandard histopathology of breast tissue, the primary means of disease\ndiagnosis, involves manual microscopic examination of stained tissue by a\npathologist. Because this method relies on qualitative information, it can\nresult in inter-observer variation. Furthermore, for difficult cases the\npathologist often needs additional markers of malignancy to help in making a\ndiagnosis. We present a quantitative method for label-free tissue screening\nusing Spatial Light Interference Microscopy (SLIM). By extracting tissue\nmarkers of malignancy based on the nanostructure revealed by the optical\npath-length, our method provides an objective and potentially automatable\nmethod for rapidly flagging suspicious tissue. We demonstrated our method by\nimaging a tissue microarray comprising 68 different subjects - 34 with\nmalignant and 34 with benign tissues. Three-fold cross validation results\nshowed a sensitivity of 94% and specificity of 85% for detecting cancer. The\nquantitative biomarkers we extract provide a repeatable and objective basis for\ndetermining malignancy. Thus, these disease signatures can be automatically\nclassified through machine learning packages, since our images do not vary from\nscan to scan or instrument to instrument, i.e., they represent intrinsic\nphysical attributes of the sample, independent of staining quality."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Study of bioheat transfer phase change during cryosurgery for an\n  irregular tumor tissue using EFGM"}, {"role": "assistant", "content": "Cryosurgery has been consistently used as an effective treatment to eradicate\nirregular tumor tissues. During this process, many difficulties occur such as\nintense cooling may also damage the neighboring normal tissues due to the\nrelease of large amount of cold from the cooling probe. In order to protect the\nnormal tissues in the vicinity of target tumor tissues, coolant was released in\na regulated manner accompanied with the nanoparticle to regulate the size and\norientation of ice balls formed together with improved probe capacity. The\nphase change occurs in the target tumor tissues during cryosurgery treatment.\nThe effective heat capacity method is used for simulation of phase change in\nbio-heat transfer equation to take into account the latent heat of phase\ntransition. The bio-heat transfer equation is solved by using element free\nGalerkin method (EFGM) to simulate the phase change problem of biological\ntissues subject to nano cryosurgery. In this study, Murshed model with\ncylindrical nanoparticles is used for the high thermal conductivity of\nnanofluids as compared to Leong Model with the spherical nanoparticle. The\nimportant effects of the interfacial layer at the mushy region (i.e. liquid to\nthe solid interface), size and concentration of nanoparticles are shown on the\nfreezing process. This type of problem has applications in biomedical treatment\nsuch as drug delivery. Application of cryosurgery in bio-fluids used for drug\ndelivery in cancer therapy can be made more efficient in the presence of\nnanoparticles (such as Iron oxide ($Fe_{3}O_{4}$), alumina ($Al_{2}O_{3}$) and\ngold ($Au$))."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Generating behavioral acts of predetermined apparent complexity"}, {"role": "assistant", "content": "Behavior of natural and artificial agents consists of behavioral episodes or\nacts. This study introduces a quantitative measure of behavioral acts -- their\napparent complexity. The measure is based on the concept of the Kolmogorov\ncomplexity. It is an apparent measure because it is determined solely by the\nreadings of the signals that directly encode percepts and actions during\nbehavior. The article describes an algorithm of generating behavioral acts of\npredetermined apparent complexity. Such acts can be used to evaluate and\ndevelop learning abilities of artificial agents."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Determination of carbohydrates in infant milk powders by\n  ultra-performance liquid chromatography with evaporative light scattering\n  detector and BEH HILIC column"}, {"role": "assistant", "content": "The possibility of carbohydrate separation in BEH HILIC (Ethylene Bridged\nHybride, Hydrophilic Interaction Liquid Chromatography) column was studied by\nultra-performance liquid chromatography (UPLC) with evaporative light\nscattering detector (ELSD) and mobile phase containing amine compounds as\nmodifiers. The chromatography conditions and ELSD parameters were optimized to\nseparate five typical carbohydrates and applied to analysis of four infant milk\npowders. The linear ranges of carbohydrate determination were 20-300mg/L for\nfructose and glucose, 20-250mg/L for sucrose and lactose, and 35-180mg/L for\nfructo-oligosaccharide. The LODs were 16.4mg/L for fructose and glucose,\n17.3mg/L for sucrose, 20.0mg/L for lactose, and 46.7mg/L for\nfructo-oligosaccharide. Relative standard deviations (RSDs) ranged between\n3.45-4.23%, 1.46-4.17%, 4.14-5.60%, 1.39-4.09%, and 2.49-3.61% for fructose,\nglucose, sucrose, lactose, and fructo-oilgosaccharide, respectively and\nrecoveries ranged between 95.0 and 105.4%"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Scalable Inference of Ordinary Differential Equation Models of\n  Biochemical Processes"}, {"role": "assistant", "content": "Ordinary differential equation models have become a standard tool for the\nmechanistic description of biochemical processes. If parameters are inferred\nfrom experimental data, such mechanistic models can provide accurate\npredictions about the behavior of latent variables or the process under new\nexperimental conditions. Complementarily, inference of model structure can be\nused to identify the most plausible model structure from a set of candidates,\nand thus gain novel biological insight. Several toolboxes can infer model\nparameters and structure for small- to medium-scale mechanistic models out of\nthe box. However, models for highly multiplexed datasets can require hundreds\nto thousands of state variables and parameters. For the analysis of such\nlarge-scale models, most algorithms require intractably high computation times.\nThis chapter provides an overview of state-of-the-art methods for parameter and\nmodel inference, with an emphasis on scalability."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Accurate autocorrelation modeling substantially improves fMRI\n  reliability"}, {"role": "assistant", "content": "Given the recent controversies in some neuroimaging statistical methods, we\ncompare the most frequently used functional Magnetic Resonance Imaging (fMRI)\nanalysis packages: AFNI, FSL and SPM, with regard to temporal autocorrelation\nmodeling. This process, sometimes known as pre-whitening, is conducted in\nvirtually all task fMRI studies. We employ eleven datasets containing 980 scans\ncorresponding to different fMRI protocols and subject populations. Though\nautocorrelation modeling in AFNI is not perfect, its performance is much higher\nthan the performance of autocorrelation modeling in FSL and SPM. The residual\nautocorrelated noise in FSL and SPM leads to heavily confounded first level\nresults, particularly for low-frequency experimental designs. Our results show\nsuperior performance of SPM's alternative pre-whitening: FAST, over SPM's\ndefault. The reliability of task fMRI studies would increase with more accurate\nautocorrelation modeling. Furthermore, reliability could increase if the\npackages provided diagnostic plots. This way the investigator would be aware of\npre-whitening problems."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Computational strategies for dissecting the high-dimensional complexity\n  of adaptive immune repertoires"}, {"role": "assistant", "content": "The adaptive immune system recognizes antigens via an immense array of\nantigen-binding antibodies and T-cell receptors, the immune repertoire. The\ninterrogation of immune repertoires is of high relevance for understanding the\nadaptive immune response in disease and infection (e.g., autoimmunity, cancer,\nHIV). Adaptive immune receptor repertoire sequencing (AIRR-seq) has driven the\nquantitative and molecular-level profiling of immune repertoires thereby\nrevealing the high-dimensional complexity of the immune receptor sequence\nlandscape. Several methods for the computational and statistical analysis of\nlarge-scale AIRR-seq data have been developed to resolve immune repertoire\ncomplexity in order to understand the dynamics of adaptive immunity. Here, we\nreview the current research on (i) diversity, (ii) clustering and network,\n(iii) phylogenetic and (iv) machine learning methods applied to dissect,\nquantify and compare the architecture, evolution, and specificity of immune\nrepertoires. We summarize outstanding questions in computational immunology and\npropose future directions for systems immunology towards coupling AIRR-seq with\nthe computational discovery of immunotherapeutics, vaccines, and\nimmunodiagnostics."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: BioMM: Biologically-informed Multi-stage Machine learning for\n  identification of epigenetic fingerprints"}, {"role": "assistant", "content": "The identification of reproducible biological patterns from high-dimensional\ndata is a bottleneck for understanding the biology of complex illnesses such as\nschizophrenia. To address this, we developed a biologically informed,\nmulti-stage machine learning (BioMM) framework. BioMM incorporates biological\npathway information to stratify and aggregate high-dimensional biological data.\nWe demonstrate the utility of this method using genome-wide DNA methylation\ndata and show that it substantially outperforms conventional machine learning\napproaches. Therefore, the BioMM framework may be a fruitful machine learning\nstrategy in high-dimensional data and be the basis for future, integrative\nanalysis approaches."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Integrative biological simulation praxis: Considerations from physics,\n  philosophy, and data/model curation practices"}, {"role": "assistant", "content": "Integrative biological simulations have a varied and controversial history in\nthe biological sciences. From computational models of organelles, cells, and\nsimple organisms, to physiological models of tissues, organ systems, and\necosystems, a diverse array of biological systems have been the target of\nlarge-scale computational modeling efforts. Nonetheless, these research agendas\nhave yet to prove decisively their value among the broader community of\ntheoretical and experimental biologists. In this commentary, we examine a range\nof philosophical and practical issues relevant to understanding the potential\nof integrative simulations. We discuss the role of theory and modeling in\ndifferent areas of physics and suggest that certain sub-disciplines of physics\nprovide useful cultural analogies for imagining the future role of simulations\nin biological research. We examine philosophical issues related to modeling\nwhich consistently arise in discussions about integrative simulations and\nsuggest a pragmatic viewpoint that balances a belief in philosophy with the\nrecognition of the relative infancy of our state of philosophical\nunderstanding. Finally, we discuss community workflow and publication practices\nto allow research to be readily discoverable and amenable to incorporation into\nsimulations. We argue that there are aligned incentives in widespread adoption\nof practices which will both advance the needs of integrative simulation\nefforts as well as other contemporary trends in the biological sciences,\nranging from open science and data sharing to improving reproducibility."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Assessing Chronic Kidney Disease from Office Visit Records Using\n  Hierarchical Meta-Classification of an Imbalanced Dataset"}, {"role": "assistant", "content": "Chronic Kidney Disease (CKD) is an increasingly prevalent condition affecting\n13% of the US population. The disease is often a silent condition, making its\ndiagnosis challenging. Identifying CKD stages from standard office visit\nrecords can help in early detection of the disease and lead to timely\nintervention. The dataset we use is highly imbalanced. We propose a\nhierarchical meta-classification method, aiming to stratify CKD by severity\nlevels, employing simple quantitative non-text features gathered from office\nvisit records, while addressing data imbalance. Our method effectively\nstratifies CKD severity levels obtaining high average sensitivity, precision\nand F-measure (~93%). We also conduct experiments in which the dimensionality\nof the data is significantly reduced to include only the most salient features.\nOur results show that the good performance of our system is retained even when\nusing the reduced feature sets, as well as under much reduced training sets,\nindicating that our method is stable and generalizable."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Spatially-extended hybrid methods: a review"}, {"role": "assistant", "content": "Many biological and physical systems exhibit behaviour at multiple spatial,\ntemporal or population scales. Multiscale processes provide challenges when\nthey are to be simulated using numerical techniques. While coarser methods such\nas partial differential equations are typically fast to simulate, they lack the\nindividual-level detail that may be required in regions of low concentration or\nsmall spatial scale. However, to simulate at such an individual-level\nthroughout a domain and in regions where concentrations are high can be\ncomputationally expensive. Spatially-coupled hybrid methods provide a bridge,\nallowing for multiple representations of the same species in one spatial domain\nby partitioning space into distinct modelling subdomains. Over the past twenty\nyears, such hybrid methods have risen to prominence, leading to what is now a\nvery active research area across multiple disciplines including chemistry,\nphysics and mathematics.\n  There are three main motivations for undertaking this review. Firstly, we\nhave collated a large number of spatially-extended hybrid methods and presented\nthem in a single coherent document, while comparing and contrasting them, so\nthat anyone with a need for a multi-scale hybrid method will be able to find\nthe most appropriate one for their need. Secondly, we have provided canonical\nexamples with algorithms and accompanying code, serving to demonstrate how\nthese types of methods work in practice. Finally, we have presented papers that\nemploy these methods on real biological and physical problems, demonstrating\ntheir utility. We also consider some open research questions in the area of\nhybrid method development and the future directions for the field."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantitative toxicity prediction using topology based multi-task deep\n  neural networks"}, {"role": "assistant", "content": "The understanding of toxicity is of paramount importance to human health and\nenvironmental protection. Quantitative toxicity analysis has become a new\nstandard in the field. This work introduces element specific persistent\nhomology (ESPH), an algebraic topology approach, for quantitative toxicity\nprediction. ESPH retains crucial chemical information during the topological\nabstraction of geometric complexity and provides a representation of small\nmolecules that cannot be obtained by any other method. To investigate the\nrepresentability and predictive power of ESPH for small molecules, ancillary\ndescriptors have also been developed based on physical models. Topological and\nphysical descriptors are paired with advanced machine learning algorithms, such\nas deep neural network (DNN), random forest (RF) and gradient boosting decision\ntree (GBDT), to facilitate their applications to quantitative toxicity\npredictions. A topology based multi-task strategy is proposed to take the\nadvantage of the availability of large data sets while dealing with small data\nsets. Four benchmark toxicity data sets that involve quantitative measurements\nare used to validate the proposed approaches. Extensive numerical studies\nindicate that the proposed topological learning methods are able to outperform\nthe state-of-the-art methods in the literature for quantitative toxicity\nanalysis. Our online server for computing element-specific topological\ndescriptors (ESTDs) is available at http://weilab.math.msu.edu/TopTox/"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Experimental Analysis of XPCR-based protocols"}, {"role": "assistant", "content": "This paper reports some experimental results validating in a broader context\na variant of PCR, called XPCR, previously introduced and tested on relatively\nshort synthetic DNA sequences. Basic XPCR technique confirmed to work as\nexpected, to concatenate two genes of different lengths, while a library of all\npermutations of three different genes (extracted from the bacterial strain\nBulkolderia fungorum DBT1) has been realized in one step by multiple XPCR.\n  Limits and potentialities of the protocols have been discussed, and tested in\nseveral experimental conditions, by aside showing that overlap concatenation of\nmultiple copies of one only gene is not realizable by these procedures, due to\nstrand displacement phenomena. In this case, in fact, one copy of the gene is\nobtained as a unique amplification product."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Experimental assessment of critical anthropogenic sediment burial in\n  eelgrass Zostera marina"}, {"role": "assistant", "content": "Seagrass meadows, one of the worlds most important and productive coastal\nhabitats, are threatened by a range of anthropogenic actions. Burial of\nseagrass plants due to coastal activities is one important anthropogenic\npressure leading to decline of local populations. In our study, we assessed the\nresponse of eelgrass Zostera marina to sediment burial from physiological,\nmorphological, and population parameters. In a full factorial field experiment,\nburial level (5-20 cm) and burial duration (4-16 weeks) were manipulated.\nNegative effects were visible even at the lowest burial level (5 cm) and\nshortest duration (4 weeks), with increasing effects over time and burial\nlevel. Buried seagrasses showed higher shoot mortality, delayed growth and\nflowering and lower carbohydrate storage. The observed effects will likely have\nan impact on next years survival of buried plants. Our results have\nimplications for the management of this important coastal plant."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Modeling-based determination of physiological parameters of systemic\n  VOCs by breath gas analysis, part 2"}, {"role": "assistant", "content": "In a recent paper we presented a simple two compartment model which describes\nthe influence of inhaled concentrations on exhaled breath concentrations for\nvolatile organic compounds (VOCs) with small Henry constants. In this paper we\nextend this investigation concerning the influence of inhaled concentrations on\nexhaled breath concentrations for VOCs with higher Henry constants.\n  To this end we extend our model with an additional compartment which takes\ninto account the influence of the upper airways on exhaled breath VOC\nconcentrations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantification of sulfated polysaccharides in mouse and rat plasma by\n  the Heparin Red mix-and-read fluorescence assay"}, {"role": "assistant", "content": "Sulfated polysaccharides constitute a large and complex group of\nmacromolecules which possess a wide range of important biological properties.\nMany of them hold promise as new therapeutics, but determination of their blood\nlevels during pharmacokinetic studies can be challenging. Heparin Red, a\ncommercial mix-and-read fluorescence assay, has recently emerged as a tool in\nclinical drug development and pharmacokinetic analysis for the quantification\nof sulfated polysaccharides in human plasma. The present study describes the\napplication of Heparin Red to the detection of heparin, a highly sulfated\npolysaccharide, and fucoidan, a less sulfated polysaccharide, in spiked mouse\nand rat plasmas. While the standard assay protocol for human plasma matrix gave\nless satisfactory results, a modified protocol was developed that provides\nwithin a detection range 0 to 10 micrograms per mL better limits of\nquantification, 1.1 to 2.3 micrograms per mL for heparin, and 1.7 to 3.4\nmicrograms per mL for fucoidan. The required plasma sample volume of only 20\nmicroliters is advantegous in particular when blood samples need to be\ncollected from mice. Our results suggest that Heparin Red is a promising tool\nfor the preclinical evaluation of sulfated polysaccharides with varying\nsulfation degrees in mouse and rat models."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: An effect of large permanent charge: Decreasing flux to zero with\n  increasing transmembrane potential to infinity"}, {"role": "assistant", "content": "In this work, we examine effects of large permanent charges on ionic flow\nthrough ion channels based on a quasi-one dimensional Poisson-Nernst-Planck\nmodel. It turns out large positive permanent charges inhibit the flux of cation\nas expected, but strikingly, as the transmembrane electrochemical potential for\nanion increases in a particular way, the flux of anion decreases. The latter\nphenomenon was observed experimentally but the cause seemed to be unclear. The\nmechanisms for these phenomena are examined with the help of the profiles of\nthe ionic concentrations, electric fields and electrochemical potentials. The\nunderlying reasons for the near zero flux of cation and for the decreasing flux\nof anion are shown to be different over different regions of the permanent\ncharge. Our model is oversimplified. More structural detail and more\ncorrelations between ions can and should be included. But the basic finding\nseems striking and important and deserving of further investigation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Gene expression for simulation of biological tissue"}, {"role": "assistant", "content": "BioDynaMo is a biological processes simulator developed by an international\ncommunity of researchers and software engineers working closely with\nneuroscientists. The authors have been working on gene expression, i.e. the\nprocess by which the heritable information in a gene - the sequence of DNA base\npairs - is made into a functional gene product, such as protein or RNA.\nTypically, gene regulatory models employ either statistical or analytical\napproaches, being the former already well understood and broadly used. In this\npaper, we utilize analytical approaches representing the regulatory networks by\nmeans of differential equations, such as Euler and Runge-Kutta methods. The two\nsolutions are implemented and have been submitted for inclusion in the\nBioDynaMo project and are compared for accuracy and performance."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multi-View Sparse Vector Decomposition to Deal With Missing Values in\n  Alcohol Dependence Study"}, {"role": "assistant", "content": "Due to the heterogeneity of the phenotype defined by Diagnostic and\nStatistical Manual of Mental Disorders (DSM) IV, it is not an optimal option to\nidentify the genetic variation that underlies the risk for alcohol dependence\n(AD) and identifying subtypes of AD becomes an important topic. Traditional\nunsupervised cluster analysis and latent class analysis are the most commonly\nused methods to obtain the subtypes, but without the guidance of the genetic\ninformation, all these methods may lead to subtypes of little utility in\ngenetic analysis. Recently, some multi-view co-clustering methods are proposed\nto ameliorate this drawback. However, these new methods did not take the\nmissing values inside the data into consideration. To get around this\nlimitation, we extended one of the multi-view methods to dealing with the\nmissing values and clustering simultaneously. We applied this method to 2230\nEuropean-American sample and found that the well-known generic variant\nrs1229984 (in the ADH1B candidate gene) for the subtype is more significant\nthan that corresponding to case-control association test. Finally, we verify it\non the 1707 replication sample and find it significant, too."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: An Unsupervised Homogenization Pipeline for Clustering Similar Patients\n  using Electronic Health Record Data"}, {"role": "assistant", "content": "Electronic health records (EHR) contain a large variety of information on the\nclinical history of patients such as vital signs, demographics, diagnostic\ncodes and imaging data. The enormous potential for discovery in this rich\ndataset is hampered by its complexity and heterogeneity.\n  We present the first study to assess unsupervised homogenization pipelines\ndesigned for EHR clustering. To identify the optimal pipeline, we tested\naccuracy on simulated data with varying amounts of redundancy, heterogeneity,\nand missingness. We identified two optimal pipelines: 1) Multiple Imputation by\nChained Equations (MICE) combined with Local Linear Embedding; and 2) MICE,\nZ-scoring, and Deep Autoencoders."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: TopP-S: Persistent homology based multi-task deep neural networks for\n  simultaneous predictions of partition coefficient and aqueous solubility"}, {"role": "assistant", "content": "Aqueous solubility and partition coefficient are important physical\nproperties of small molecules. Accurate theoretical prediction of aqueous\nsolubility and partition coefficient plays an important role in drug design and\ndiscovery. The prediction accuracy depends crucially on molecular descriptors\nwhich are typically derived from theoretical understanding of the chemistry and\nphysics of small molecules. The present work introduces an algebraic topology\nbased method, called element specific persistent homology (ESPH), as a new\nrepresentation of small molecules that is entirely different from conventional\nchemical and/or physical representations. ESPH describes molecular properties\nin terms of multiscale and multicomponent topological invariants. Such\ntopological representation is systematical, comprehensive, and scalable with\nrespect to molecular size and composition variations. However, it cannot be\nliterally translated into a physical interpretation. Fortunately, it is readily\nsuitable for machine learning methods, rendering topological learning\nalgorithms. Due to the inherent correlation between solubility and partition\ncoefficient, a uniform ESPH representation is developed for both properties,\nwhich facilitates multi-task deep neural networks for their simultaneous\npredictions. This strategy leads to more accurate prediction of relatively\nsmall data sets. A total of six data sets is considered in the present work to\nvalidate the proposed topological and multi-task deep learning approaches. It\nis demonstrate that the proposed approaches achieve some of the most accurate\npredictions of aqueous solubility and partition coefficient. Our software is\navailable online at {\\url{http://weilab.math.msu.edu/TopP-S/}}"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Comorbid CAD and Ventricular Hypertrophy Compromise The Perfusion of\n  Myocardial Tissue at Subcritical Stenosis of Epicardial Coronaries"}, {"role": "assistant", "content": "BACKGROUND: Most studies of CAD revascularization have been based on and\nreported according to angiographic criteria which don't consider the relation\nbetween the resulting effective flow distal to the stenosis and the demand of a\nhypertrophied myocardial tissue.\n  MODEL: Mathematical model of the myocardial perfusion in comorbid CAD and\nventricular hypertrophy using Poiseuille's law. The analysis yields that the\ncurve, which represents the relation between the perfusion and the severity of\nCAD depending on angiographic and/or angiophysiologic criteria, is shifted to\nthe right by the effect of myocardial tissue hypertrophy. The right shift of\nsaid curve, which is directly proportional to the degree of ventricular\nhypertrophy, indicates that the perfusion of the corresponding myocardial\ntissue is compromised at angiographically and/or angiophysiologically\nsubsignificant stenosis of the supplying epicardial vessel.\n  RESULTS: Patients with comorbid CAD and left ventricular hypertrophy are more\nsensitive to CAD-related hemodynamic changes. They are more prone to develop\nischemic complications, than their peers with isolated CAD regarding the same\ndegree of coronary stenosis.\n  CONCLUSION: Patients with comorbid CAD and ventricular hypertrophy suffer\nfrom myocardial hypoperfusion at angiographically and/or angiophysiologically\nsubcritical epicardial stenosis. Accordingly; the comorbidity of both diseases\nshould be considered upon designing of the treatment regime."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The Spectrum of Mechanism-oriented Models for Explanations of Biological\n  Phenomena"}, {"role": "assistant", "content": "Within the diverse interdisciplinary life sciences domains, semantic,\nworkflow, and methodological ambiguities can prevent the appreciation of\nexplanations of phenomena, handicap the use of computational models, and hamper\ncommunication among scientists, engineers, and the public. Members of the life\nsciences community commonly, and too often loosely, draw on \"mechanistic model\"\nand similar phrases when referring to the processes of discovering and\nestablishing causal explanations of biological phenomena. Ambiguities in\nmodeling and simulation terminology and methods diminish clarity, credibility,\nand the perceived significance of research findings. To encourage improved\nsemantic and methodological clarity, we describe the spectrum of\nMechanism-oriented Models being used to develop explanations of biological\nphenomena. We cluster them into three broad groups. We then expand the three\ngroups into a total of seven workflow-related model types having clearly\ndistinguishable features. We name each type and illustrate with diverse\nexamples drawn from the literature. These model types are intended to\ncontribute to the foundation of an ontology of mechanism-based simulation\nresearch in the life sciences. We show that it is within the model-development\nworkflows that the different model types manifest and exert their scientific\nusefulness by enhancing and extending different forms and degrees of\nexplanation. The process starts with knowledge about the phenomenon and\ncontinues with explanatory and mathematical descriptions. Those descriptions\nare transformed into software and used to perform experimental explorations by\nrunning and examining simulation output. The credibility of inferences is thus\nlinked to having easy access to the scientific and technical provenance from\neach workflow stage."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Bayesian reconstruction of HIV transmission trees from viral sequences\n  and uncertain infection times"}, {"role": "assistant", "content": "Genetic sequence data of pathogens are increasingly used to investigate\ntransmission dynamics in both endemic diseases and disease outbreaks; such\nresearch can aid in development of appropriate interventions and in design of\nstudies to evaluate them. Several methods have been proposed to infer\ntransmission chains from sequence data; however, existing methods do not\ngenerally reliably reconstruct transmission trees because genetic sequence data\nor inferred phylogenetic trees from such data are insufficient for accurate\ninference regarding transmission chains. In this paper, we demonstrate the lack\nof a one-to-one relationship between phylogenies and transmission trees, and\nalso show that information regarding infection times together with genetic\nsequences permit accurate reconstruction of transmission trees. We propose a\nBayesian inference method for this purpose and demonstrate that precision of\ninference regarding these transmission trees depends on precision of the\nestimated times of infection. We also illustrate the use of these methods to\nstudy features of epidemic dynamics, such as the relationship between\ncharacteristics of nodes and average number of outbound edges or inbound\nedges-- signifying possible transmission events from and to nodes. We study the\nperformance of the proposed method in simulation experiments and demonstrate\nits superiority in comparison to an alternative method. We apply them to a\ntransmission cluster in San Diego and investigate the impact of biological,\nbehavioral, and demographic factors."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Loss-function learning for digital tissue deconvolution"}, {"role": "assistant", "content": "The gene expression profile of a tissue averages the expression profiles of\nall cells in this tissue. Digital tissue deconvolution (DTD) addresses the\nfollowing inverse problem: Given the expression profile $y$ of a tissue, what\nis the cellular composition $c$ of that tissue? If $X$ is a matrix whose\ncolumns are reference profiles of individual cell types, the composition $c$\ncan be computed by minimizing $\\mathcal L(y-Xc)$ for a given loss function\n$\\mathcal L$. Current methods use predefined all-purpose loss functions. They\nsuccessfully quantify the dominating cells of a tissue, while often falling\nshort in detecting small cell populations.\n  Here we learn the loss function $\\mathcal L$ along with the composition $c$.\nThis allows us to adapt to application-specific requirements such as focusing\non small cell populations or distinguishing phenotypically similar cell\npopulations. Our method quantifies large cell fractions as accurately as\nexisting methods and significantly improves the detection of small cell\npopulations and the distinction of similar cell types."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Extension of the non-parametric cluster-based time-frequency statistics\n  to the full time windows and to single condition tests"}, {"role": "assistant", "content": "Oscillatory processes are central for the understanding of the neural bases\nof cognition and behaviour. To analyse these processes, time-frequency (TF)\ndecomposition methods are applied and non-parametric cluster-based statistical\nprocedure are used for comparing two or more conditions. While this combination\nis a powerful method, it has two drawbacks. One the unreliable estimation of\nsignals outside the cone-of-influence and the second relates to the length of\nthe time frequency window used for the analysis. Both impose constrains on the\nnon-parametric statistical procedure for inferring an effect in the TF domain.\nHere we extend the method to reliably infer oscillatory differences within the\nfull TF map and to test single conditions. We show that it can be applied in\nsmall time windows irrespective of the cone-of-influence and we further develop\nits application to single-condition case for testing the hypothesis of the\npresence or not of time-varying signals. We present tests of this new method on\nreal EEG and behavioural data and show that its sensitivity to single-condition\ntests is at least as good as classic Fourier analysis. Statistical inference in\nthe full TF map is available and efficient in detecting differences between\nconditions as well as the presence of time-varying signal in single condition."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Evaluation of Parallel Tempering to Accelerate Bayesian Parameter\n  Estimation in Systems Biology"}, {"role": "assistant", "content": "Models of biological systems often have many unknown parameters that must be\ndetermined in order for model behavior to match experimental observations.\nCommonly-used methods for parameter estimation that return point estimates of\nthe best-fit parameters are insufficient when models are high dimensional and\nunder-constrained. As a result, Bayesian methods, which treat model parameters\nas random variables and attempt to estimate their probability distributions\ngiven data, have become popular in systems biology. Bayesian parameter\nestimation often relies on Markov Chain Monte Carlo (MCMC) methods to sample\nmodel parameter distributions, but the slow convergence of MCMC sampling can be\na major bottleneck. One approach to improving performance is parallel tempering\n(PT), a physics-based method that uses swapping between multiple Markov chains\nrun in parallel at different temperatures to accelerate sampling. The\ntemperature of a Markov chain determines the probability of accepting an\nunfavorable move, so swapping with higher temperatures chains enables the\nsampling chain to escape from local minima. In this work we compared the MCMC\nperformance of PT and the commonly-used Metropolis-Hastings (MH) algorithm on\nsix biological models of varying complexity. We found that for simpler models\nPT accelerated convergence and sampling, and that for more complex models, PT\noften converged in cases MH became trapped in non-optimal local minima. We also\ndeveloped a freely-available MATLAB package for Bayesian parameter estimation\ncalled PTempEst (http://github.com/RuleWorld/ptempest), which is closely\nintegrated with the popular BioNetGen software for rule-based modeling of\nbiological systems."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Public archives for biological image data"}, {"role": "assistant", "content": "Public data archives are the backbone of modern biological and biomedical\nresearch. While archives for biological molecules and structures are\nwell-established, resources for imaging data do not yet cover the full range of\nspatial and temporal scales or application domains used by the scientific\ncommunity. In the last few years, the technical barriers to building such\nresources have been solved and the first examples of scientific outputs from\npublic image data resources, often through linkage to existing molecular\nresources, have been published. Using the successes of existing biomolecular\nresources as a guide, we present the rationale and principles for the\nconstruction of image data archives and databases that will be the foundation\nof the next revolution in biological and biomedical informatics and discovery."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: FoodRepo: An Open Food Repository of Barcoded Food Products"}, {"role": "assistant", "content": "In the past decade, digital technologies have started to profoundly influence\nhealthcare systems. Digital self-tracking has facilitated more precise\nepidemiological studies, and in the field of nutritional epidemiology, mobile\napps have the potential to alleviate a significant part of the journaling\nburden by, for example, allowing users to record their food intake via a simple\nscan of packaged products barcodes. Such studies thus rely on databases of\ncommercialized products, their barcodes, ingredients, and nutritional values,\nwhich are not yet openly available with sufficient geographical and product\ncoverage. In this paper, we present FoodRepo (https://www.foodrepo.org), an\nopen food repository of barcoded food items, whose database is programmatically\naccessible through an application programming interface (API). Furthermore, an\nopen source license gives the appropriate rights to anyone to share and reuse\nFoodRepo data, including for commercial purposes. With currently more than\n21,000 items available on the Swiss market, our database represents a solid\nstarting point for large-scale studies in the field of digital nutrition, with\nthe aim to lead to a better understanding of the intricate connections between\ndiets and health in general, and metabolic disorders in particular."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quasi-Monte Carlo methods applied to tau-leaping in stochastic\n  biological systems"}, {"role": "assistant", "content": "Quasi-Monte Carlo methods have proven to be effective extensions of\ntraditional Monte Carlo methods in, amongst others, problems of quadrature and\nthe sample path simulation of stochastic differential equations. By replacing\nthe random number input stream in a simulation procedure by a low-discrepancy\nnumber input stream, variance reductions of several orders have been observed\nin financial applications.\n  Analysis of stochastic effects in well-mixed chemical reaction networks often\nrelies on sample path simulation using Monte Carlo methods, even though these\nmethods suffer from typical slow $\\mathcal{O}(N^{-1/2})$ convergence rates as a\nfunction of the number of sample paths $N$. This paper investigates the\ncombination of (randomised) quasi-Monte Carlo methods with an efficient sample\npath simulation procedure, namely $\\tau$-leaping. We show that this combination\nis often more effective than traditional Monte Carlo simulation in terms of the\ndecay of statistical errors. The observed convergence rate behaviour is,\nhowever, non-trivial due to the discrete nature of the models of chemical\nreactions. We explain how this affects the performance of quasi-Monte Carlo\nmethods by looking at a test problem in standard quadrature."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: How far can neural correlations reduce uncertainty? Comparison of\n  Information Transmission Rates for Markov and Bernoulli processes"}, {"role": "assistant", "content": "The nature of neural codes is central to neuroscience. Do neurons encode\ninformation through relatively slow changes in the emission rates of individual\nspikes (rate code), or by the precise timing of every spike (temporal codes)?\nHere we compare the loss of information due to correlations for these two\npossible neural codes. The essence of Shannon's definition of information is to\ncombine information with uncertainty: the higher the uncertainty of a given\nevent, the more information is conveyed by that event. Correlations can reduce\nuncertainty or the amount of information, but by how much? In this paper we\naddress this question by a direct comparison of the information per symbol\nconveyed by the words coming from a binary Markov source (temporal codes) with\nthe information per symbol coming from the corresponding Bernoulli source\n(uncorrelated, rate code source). In a previous paper we found that a crucial\nrole in the relation between Information Transmission Rates (ITR) and Firing\nRates is played by a parameter s, which is the sum of transitions probabilities\nfrom the no-spike-state to the spike-state and vice versa. It turned out that\nalso in this case a crucial role is played by the same parameter s. We found\nbounds of the quotient of ITRs for these sources, i.e. this quotient's minimal\nand maximal values. Next, making use of the entropy grouping axiom, we\ndetermined the loss of information in a Markov source in relation to its\ncorresponding Bernoulli source for a given length of word. Our results show\nthat in practical situations in the case of correlated signals the loss of\ninformation is relatively small, thus temporal codes, which are more\nenergetically efficient, can replace the rate code effectively. These phenomena\nwere confirmed by experiments."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Unified Bayesian estimator of EEG reference at infinity: rREST"}, {"role": "assistant", "content": "The choice of reference for electroencephalogram (EEG) is a long-lasting\nunsolved issue resulting in inconsistent usages and endless debates. Currently,\nboth average reference (AR) and reference electrode standardization technique\n(REST) are two primary, irreconcilable contenders. We propose a theoretical\nframework to resolve this issue by formulating both a) estimation of potentials\nat infinity, and, b) determination of the reference, as a unified Bayesian\nlinear inverse problem. We find that AR and REST are very particular cases of\nthis unified framework: AR results from biophysically non-informative prior;\nwhile REST utilizes the prior of EEG generative model. We develop the\nregularized versions of AR and REST, named rAR, and rREST, respectively. Both\ndepend on a regularization parameter that is the noise to signal ratio.\nTraditional and new estimators are evaluated with this framework, by both\nsimulations and analysis of real EEGs. Generated artificial EEGs, show that\nrelative error in estimating the EEG potentials at infinity is lowest for\nrREST. It also reveals that realistic volume conductor models improve the\nperformances of REST and rREST. For practical applications, it is shown that\naverage lead field gives the results comparable to the individual lead field.\nFinally, it is shown that the selection of the regularization parameter with\nGeneralized Cross-Validation (GCV) is close to the 'oracle' choice based on the\nground truth. When evaluated with the real 89 resting state EEGs, rREST\nconsistently yields the lowest GCV. This study provides a novel perspective on\nthe EEG reference problem by means of a unified inverse solution framework. It\nmay allow additional principled theoretical formulations and numerical\nevaluation of performance."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Clustering Gene Expression Time Series with Coregionalization: Speed\n  propagation of ALS"}, {"role": "assistant", "content": "Clustering of gene expression time series gives insight into which genes may\nbe coregulated, allowing us to discern the activity of pathways in a given\nmicroarray experiment. Of particular interest is how a given group of genes\nvaries with different model conditions or genetic background. Amyotrophic\nlateral sclerosis (ALS), an irreversible diverse neurodegenerative disorder\nshowed consistent phenotypic differences and the disease progression is\nheterogeneous with significant variability. This paper demonstrated about\nfinding some significant gene expression profiles and its associated or\nco-regulated cluster of gene expressions from four groups of data with\ndifferent genetic background or models conditions. Gene enrichment score\nanalysis and pathway analysis of judicially selected clusters lead toward\nidentifying features underlying the differential speed of disease progression.\nGene ontology overrepresentation analysis showed clusters from the proposed\nmethod are less likely to be clustered just by chance. In this paper, we\ndevelop a new clustering method that allows each cluster to be parameterised\naccording to whether the behaviour of the genes across conditions is correlated\nor anti-correlated. Our proposed method unveil the potency of latent\ninformation shared between multiple model conditions and their replicates\nduring modelling gene expression data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Maximum Lyapunov exponent revisited: Long-term attractor divergence of\n  gait dynamics is highly sensitive to the noise structure of stride intervals"}, {"role": "assistant", "content": "The local dynamic stability method (maximum Lyapunov exponent) can assess\ngait stability. Two variants of the method exist: the short-term divergence\nexponent (DE), and the long-term DE. Only the short-term DE can predict fall\nrisk. The significance of long-term DE has been unclear so far. Some studies\nhave suggested that the complex, fractal-like structure of fluctuations among\nconsecutive strides correlates with long-term DE. The aim, therefore, was to\nassess whether the long-term DE is a gait complexity index. The study\nreanalyzed a dataset of trunk accelerations from 100 healthy adults walking at\npreferred speed on a treadmill for 10 minutes. By interpolation, the stride\nintervals were modified within the acceleration signals for the purpose of\nconserving the original shape of the signal, while imposing a known\nstride-to-stride fluctuation structure. 4 types of hybrid signals with\ndifferent noise structures were built: constant, anti-correlated, random, and\ncorrelated (fractal). Short- and long-term DEs were then computed. The results\nshow that long-term DEs, but not short-term DEs, are sensitive to the noise\nstructure of stride intervals. It was that observed that random hybrid signals\nexhibited significantly lower long-term DEs than hybrid correlated signals did\n(0.100 vs 0.144, i.e. a 44% difference). Long-term DEs from constant hybrid\nsignals were close to zero (0.006). Short-term DEs of anti-correlated, random,\nand correlated hybrid signals were closely grouped (2.49, 2.50, and 2.51). The\nshort- and long-term DEs, although they are both computed from divergence\ncurves, should not be interpreted in a similar way. The long-term DE is very\nlikely an index of gait complexity, which may be associated with gait\nautomaticity or cautiousness. To better differentiate between short- and\nlong-term DEs, the use of the term attractor complexity index (ACI) is proposed\nfor the latter."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Blue mussel shell shape plasticity and natural environments: a\n  quantitative approach"}, {"role": "assistant", "content": "Shape variability represents an important direct response of organisms to\nselective environments. Here, we use a combination of geometric morphometrics\nand generalised additive mixed models (GAMMs) to identify spatial patterns of\nnatural shell shape variation in the North Atlantic and Arctic blue mussels,\nMytilus edulis and M. trossulus, with environmental gradients of temperature,\nsalinity and food availability across 3980 km of coastlines. New statistical\nmethods and multiple study systems at various geographical scales allowed the\nuncoupling of the developmental and genetic contributions to shell shape and\nmade it possible to identify general relationships between blue mussel shape\nvariation and environment that are independent of age and species influences.\nWe find salinity had the strongest effect on the latitudinal patterns of\nMytilus shape, producing shells that were more elongated, narrower and with\nmore parallel dorsoventral margins at lower salinities. Temperature and food\nsupply, however, were the main drivers of mussel shape heterogeneity. Our\nfindings revealed similar shell shape responses in Mytilus to less favourable\nenvironmental conditions across the different geographical scales analysed. Our\nresults show how shell shape plasticity represents a powerful indicator to\nunderstand the alterations of blue mussel communities in rapidly changing\nenvironments."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: 4D blood flow mapping using SPIM-microPIV in the developing zebrafish\n  heart"}, {"role": "assistant", "content": "Fluid-structure interaction in the developing heart is an active area of\nresearch in developmental biology. However, investigation of heart dynamics is\nmostly limited to computational fluid dynamics simulations using heart wall\nstructure information only, or single plane blood flow information - so there\nis a need for 3D + time resolved data to fully understand cardiac function. We\npresent an imaging platform combining selective plane illumination microscopy\n(SPIM) with micro particle image velocimetry ({\\textmu}PIV) to enable\n3D-resolved flow mapping in a microscopic environment, free from many of the\nsources of error and bias present in traditional epifluorescence-based\n{\\textmu}PIV systems. By using our new system in conjunction with optical heart\nbeat synchronisation, we demonstrte the ability obtain non-invasive 3D + time\nresolved blood flow measurements in the heart of a living zebrafish embryo."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Theory of Morphogenesis"}, {"role": "assistant", "content": "A model of morphogenesis is proposed based on seven explicit postulates. The\nmathematical import and biological significance of the postulates are explored\nand discussed."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Simulation of live-cell imaging system reveals hidden uncertainties in\n  cooperative binding measurements"}, {"role": "assistant", "content": "We propose a computational method to quantitatively evaluate the systematic\nuncertainties that arise from undetectable sources in biological measurements\nusing live-cell imaging techniques. We then demonstrate this method in\nmeasuring biological cooperativity of molecular binding networks: in\nparticular, ligand molecules binding to cell surface receptor proteins. Our\nresults show how the non-statistical uncertainties lead to invalid\nidentification of the measured cooperativity. Through this computational\nscheme, the biological interpretation can be more objectively evaluated and\nunderstood under a specific experimental configuration of interest."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Protein Mutation Stability Ternary Classification using Neural Networks\n  and Rigidity Analysis"}, {"role": "assistant", "content": "Discerning how a mutation affects the stability of a protein is central to\nthe study of a wide range of diseases. Machine learning and statistical\nanalysis techniques can inform how to allocate limited resources to the\nconsiderable time and cost associated with wet lab mutagenesis experiments. In\nthis work we explore the effectiveness of using a neural network classifier to\npredict the change in the stability of a protein due to a mutation. Assessing\nthe accuracy of our approach is dependent on the use of experimental data about\nthe effects of mutations performed in vitro. Because the experimental data is\nprone to discrepancies when similar experiments have been performed by multiple\nlaboratories, the use of the data near the juncture of stabilizing and\ndestabilizing mutations is questionable. We address this later problem via a\nsystematic approach in which we explore the use of a three-way classification\nscheme with stabilizing, destabilizing, and inconclusive labels. For a\nsystematic search of potential classification cutoff values our classifier\nachieved 68 percent accuracy on ternary classification for cutoff values of\n-0.6 and 0.7 with a low rate of classifying stabilizing as destabilizing and\nvice versa."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Using RuleBuilder to graphically define and visualize BioNetGen-language\n  patterns and reaction rules"}, {"role": "assistant", "content": "RuleBuilder is a tool for drawing graphs that can be represented by the\nBioNetGen language (BNGL), which is used to formulate mathematical, rule-based\nmodels of biochemical systems. BNGL provides an intuitive plain-text, or\nstring, representation of such systems, which is based on a graphical\nformalism. Reactions are defined in terms of graph-rewriting rules that specify\nthe necessary intrinsic properties of the reactants, a transformation, and a\nrate law. Rules may also contain contextual constraints that restrict\napplication of the rule. In some cases, the specification of contextual\nconstraints can be verbose, making a rule difficult to read. RuleBuilder is\ndesigned to ease the task of reading and writing individual reaction rules, as\nwell as individual BNGL patterns similar to those found in rules. The software\nassists in the reading of existing models by converting BNGL strings of\ninterest into a graph-based representation composed of nodes and edges.\nRuleBuilder also enables the user to construct de novo a visual representation\nof BNGL strings using drawing tools available in its interface. As objects are\nadded to the drawing canvas, the corresponding BNGL string is generated on the\nfly, and objects are similarly drawn on the fly as BNGL strings are entered\ninto the application. RuleBuilder thus facilitates construction and\ninterpretation of rule-based models."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Ridge Regression Estimated Linear Probability Model Predictions of\n  N-glycosylation in Proteins with Structural and Sequence Data"}, {"role": "assistant", "content": "Absent experimental evidence, a robust methodology to predict the likelihood\nof N-glycosylation in human proteins is essential for guiding experimental\nwork. Based on the distribution of amino acids in the neighborhood of the NxS/T\nsequon (N-site); the structural attributes of the N-site that include\nAccessible Surface Area, secondary structural elements, main-chain phi-psi,\nturn types; the relative location of the N-site in the primary sequence; and\nthe nature of the glycan bound, the ridge regression estimated linear\nprobability model is used to predict this likelihood. This model yields a\nKolmogorov-Smirnov (Gini coefficient) statistic value of about 74% (89%), which\nis reasonable."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Contribution of Data Categories to Readmission Prediction Accuracy"}, {"role": "assistant", "content": "Identification of patients at high risk for readmission could help reduce\nmorbidity and mortality as well as healthcare costs. Most of the existing\nstudies on readmission prediction did not compare the contribution of data\ncategories. In this study we analyzed relative contribution of 90,101 variables\nacross 398,884 admission records corresponding to 163,468 patients, including\npatient demographics, historical hospitalization information, discharge\ndisposition, diagnoses, procedures, medications and laboratory test results. We\nestablished an interpretable readmission prediction model based on Logistic\nRegression in scikit-learn, and added the available variables to the model one\nby one in order to analyze the influences of individual data categories on\nreadmission prediction accuracy. Diagnosis related groups (c-statistic\nincrement of 0.0933) and discharge disposition (c-statistic increment of\n0.0269) were the strongest contributors to model accuracy. Additionally, we\nalso identified the top ten contributing variables in every data category."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Efficient algorithms to discover alterations with complementary\n  functional association in cancer"}, {"role": "assistant", "content": "Recent large cancer studies have measured somatic alterations in an\nunprecedented number of tumours. These large datasets allow the identification\nof cancer-related sets of genetic alterations by identifying relevant\ncombinatorial patterns. Among such patterns, mutual exclusivity has been\nemployed by several recent methods that have shown its effectivenes in\ncharacterizing gene sets associated to cancer. Mutual exclusivity arises\nbecause of the complementarity, at the functional level, of alterations in\ngenes which are part of a group (e.g., a pathway) performing a given function.\nThe availability of quantitative target profiles, from genetic perturbations or\nfrom clinical phenotypes, provides additional information that can be leveraged\nto improve the identification of cancer related gene sets by discovering groups\nwith complementary functional associations with such targets.\n  In this work we study the problem of finding groups of mutually exclusive\nalterations associated with a quantitative (functional) target. We propose a\ncombinatorial formulation for the problem, and prove that the associated\ncomputation problem is computationally hard. We design two algorithms to solve\nthe problem and implement them in our tool UNCOVER. We provide analytic\nevidence of the effectiveness of UNCOVER in finding high-quality solutions and\nshow experimentally that UNCOVER finds sets of alterations significantly\nassociated with functional targets in a variety of scenarios. In addition, our\nalgorithms are much faster than the state-of-the-art, allowing the analysis of\nlarge datasets of thousands of target profiles from cancer cell lines. We show\nthat on one such dataset from project Achilles our methods identify several\nsignificant gene sets with complementary functional associations with targets."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Learn to segment single cells with deep distance estimator and deep cell\n  detector"}, {"role": "assistant", "content": "Single cell segmentation is critical and challenging in live cell imaging\ndata analysis. Traditional image processing methods and tools require\ntime-consuming and labor-intensive efforts of manually fine-tuning parameters.\nSlight variations of image setting may lead to poor segmentation results.\nRecent development of deep convolutional neural networks(CNN) provides a\npotentially efficient, general and robust method for segmentation. Most\nexisting CNN-based methods treat segmentation as a pixel-wise classification\nproblem. However, three unique problems of cell images adversely affect\nsegmentation accuracy: lack of established training dataset, few pixels on cell\nboundaries, and ubiquitous blurry features. The problem becomes especially\nsevere with densely packed cells, where a pixel-wise classification method\ntends to identify two neighboring cells with blurry shared boundary as one\ncell, leading to poor cell count accuracy and affecting subsequent analysis.\nHere we developed a different learning strategy that combines strengths of CNN\nand watershed algorithm. The method first trains a CNN to learn Euclidean\ndistance transform of binary masks corresponding to the input images. Then\nanother CNN is trained to detect individual cells in the Euclidean distance\ntransform. In the third step, the watershed algorithm takes the outputs from\nthe previous steps as inputs and performs the segmentation. We tested the\ncombined method and various forms of the pixel-wise classification algorithm on\nsegmenting fluorescence and transmitted light images. The new method achieves\nsimilar pixel accuracy but significant higher cell count accuracy than\npixel-wise classification methods do, and the advantage is most obvious when\napplying on noisy images of densely packed cells."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Fixed-Parameter Tractable Sampling for RNA Design with Multiple Target\n  Structures"}, {"role": "assistant", "content": "The design of multi-stable RNA molecules has important applications in\nbiology, medicine, and biotechnology. Synthetic design approaches profit\nstrongly from effective in-silico methods, which can tremendously impact their\ncost and feasibility. We revisit a central ingredient of most in-silico design\nmethods: the sampling of sequences for the design of multi-target structures,\npossibly including pseudoknots. For this task, we present the efficient, tree\ndecomposition-based algorithm. Our fixed parameter tractable approach is\nunderpinned by establishing the P-hardness of uniform sampling. Modeling the\nproblem as a constraint network, our program supports generic\nBoltzmann-weighted sampling for arbitrary additive RNA energy models; this\nenables the generation of RNA sequences meeting specific goals like expected\nfree energies or \\GCb-content. Finally, we empirically study general properties\nof the approach and generate biologically relevant multi-target\nBoltzmann-weighted designs for a common design benchmark. Generating seed\nsequences with our program, we demonstrate significant improvements over the\npreviously best multi-target sampling strategy (uniform sampling).Our software\nis freely available at: https://github.com/yannponty/RNARedPrint ."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The Quaternion-Based Spatial Coordinate and Orientation Frame Alignment\n  Problems"}, {"role": "assistant", "content": "We review the general problem of finding a global rotation that transforms a\ngiven set of points and/or coordinate frames (the \"test\" data) into the best\npossible alignment with a corresponding set (the \"reference\" data). For 3D\npoint data, this \"orthogonal Procrustes problem\" is often phrased in terms of\nminimizing a root-mean-square deviation or RMSD corresponding to a Euclidean\ndistance measure relating the two sets of matched coordinates. We focus on\nquaternion eigensystem methods that have been exploited to solve this problem\nfor at least five decades in several different bodies of scientific literature\nwhere they were discovered independently. While numerical methods for the\neigenvalue solutions dominate much of this literature, it has long been\nrealized that the quaternion-based RMSD optimization problem can also be solved\nusing exact algebraic expressions based on the form of the quartic equation\nsolution published by Cardano in 1545; we focus on these exact solutions to\nexpose the structure of the entire eigensystem for the traditional 3D spatial\nalignment problem. We then explore the structure of the less-studied\norientation data context, investigating how quaternion methods can be extended\nto solve the corresponding 3D quaternion orientation frame alignment (QFA)\nproblem, noting the interesting equivalence of this problem to the\nrotation-averaging problem, which also has been the subject of independent\nliterature threads. We conclude with a brief discussion of the combined 3D\ntranslation-orientation data alignment problem. Appendices are devoted to a\ntutorial on quaternion frames, a related quaternion technique for extracting\nquaternions from rotation matrices, and a review of quaternion\nrotation-averaging methods relevant to the orientation-frame alignment problem.\nSupplementary Material covers extensions of quaternion methods to the 4D\nproblem."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A survey and a new selection criterion for statistical home range\n  estimation"}, {"role": "assistant", "content": "The home range of a specific animal describes the geographic area where this\nindividual spends most of the time while carrying out its usual activities\n(eating, resting, reproduction, ...). Although a well-established definition of\nthis concept is lacking, there is a variety of home range estimators. The first\nobjective of this work is to review and categorize the statistical\nmethodologies proposed in the literature to approximate the home range of an\nanimal, based on a sample of observed locations. The second aim is to address\nthe open question of choosing the \"best\" home range from a collection of them\nbased on the same sample. We introduce a numerical index, based on a\npenalization criterion, to rank the estimated home ranges. The key idea is to\nbalance the excess area covered by the estimator (with respect to the original\nsample) and a shape descriptor measuring the over-adjustment of the home range\nto the data. To our knowledge, apart from computing the home range area, our\nranking procedure is the first one which is both applicable to real data and to\nany type of home range estimator. Further, the optimization of the selection\nindex provides in fact a way to select the smoothing parameter for the kernel\nhome range estimator. For clarity of exposition, we have applied all the\nestimation procedures and our selection proposal to a set of real locations of\na Mongolian wolf using R as the statistical software. As a byproduct, this\nreview contains a thorough revision of the implementation of home range\nestimators in the R language."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Amino-acid network clique analysis of protein mutation correlation\n  effects: a case study of lysozme"}, {"role": "assistant", "content": "Optimizing amino-acid mutations has been a most challenging task in modern\nbio- industrial enzyme designing. It is well known that many successful designs\noften hinge on extensive correlations among mutations at different sites within\nthe enzyme, however, the underpinning mechanism for these correlations is far\nfrom clear. Here, we present a topology-based model to quantitively\ncharacterize correlation effects between mutations. The method is based on the\nmolecular dynamic simulations and the amino-acid network clique analysis that\nsimply examines if two single mutation sites belong to some 3-clique. We\nanalyzed 13 dual mutations of T4 phage lysozyme and found that the clique-based\nmodel successfully distinguishes highly correlated or non-additive double-site\nmutations from those with less correlation or additive mutations. We also\napplied the model to the protein Eglin c whose topology is significantly\ndistinct from that of T4 phage lysozyme, and found that the model can, to some\nextension, still identify non-additive mutations from additive ones. Our\ncalculations showed that mutation correlation effects may heavily depend on\ntopology relationship among mutation sites, which can be quantitatively\ncharacterized using amino-acid network k-cliques. We also showed that\ndouble-site mutation correlations can be significantly altered by exerting a\nthird mutation, indicating that more detailed physico-chemistry interactions\nmight be considered with the network model for better understanding of the\nelusive mutation-correlation principle."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Intertrochanteric Fracture Visualization and Analysis Using a Map\n  Projection Technique"}, {"role": "assistant", "content": "Understanding intertrochanteric fracture distribution is an important topic\nin orthopaedics due to its high morbidity and mortality. The intertrochanteric\nfracture can contain high-dimensional information including complicated 3D\nfracture lines, which often make it difficult to visualize or to obtain\nvaluable statistics for clinical diagnosis and prognosis applications. This\npaper proposed a map projection technique to map the high-dimensional\ninformation into a 2D parametric space. This method can preserve the 3D\nproximal femur surface and structure while visualizing the entire fracture line\nwith a single plot/view. Using this method and a standardization technique, a\ntotal of 100 patients with different ages and genders are studied based on the\noriginal radiographs acquired by CT scan. The comparison shows that the\nproposed map projection representation is more efficient and rich in\ninformation visualization than the conventional heat map technique. Using the\nproposed method, a fracture probability can be obtained at any location in the\n2D parametric space, from which the most probable fracture region can be\naccurately identified. The study shows that age and gender have significant\ninfluences on intertrochanteric fracture frequency and fracture line\ndistribution."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Universal statistics of incubation periods and other detection times via\n  diffusion models"}, {"role": "assistant", "content": "We suggest an explanation of typical incubation times statistical features\nbased on the universal behavior of exit times for diffusion models. We give a\nmathematically rigorous proof of the characteristic right skewness of the\nincubation time distribution for very general one-dimensional diffusion models.\nImposing natural simple conditions on the drift coefficient, we also study\nthese diffusion models under the assumption of noise smallness and show that\nthe limiting exit time distributions in the limit of vanishing noise are\nGaussian and Gumbel. Thus they match the existing data as well as the other\nexisting models do. The character of our models, however, allows us to argue\nthat the features of the exit time distributions that we describe are universal\nand manifest themselves in various other situations where the times involved\ncan be described as detection or halting times, for example, response times\nstudied in psychology."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Unified representation of the C3, C4, and CAM photosynthetic pathways\n  with the Photo3 model"}, {"role": "assistant", "content": "Recently, interest in crassulacean acid metabolism (CAM) photosynthesis has\nrisen and new, physiologically based CAM models have emerged. These models show\npromise, yet unlike the more widely used physiological models of C3 and C4\nphotosynthesis, their complexity has thus far inhibited their adoption in the\ngeneral community. Indeed, most efforts to assess the potential of CAM still\nrely on empirically based environmental productivity indices, which makes\nuniform comparisons between CAM and non-CAM species difficult. In order to\nrepresent C3, C4, and CAM photosynthesis in a consistent, physiologically based\nmanner, we introduce the Photo3 model. This work builds on a common\nphotosynthetic and hydraulic core and adds additional components to depict the\ncircadian rhythm of CAM photosynthesis and the carbon-concentrating mechanism\nof C4 photosynthesis. This allows consistent comparisons of the three\nphotosynthetic types for the first time. It also allows the representation of\nintermediate C3-CAM behavior through the adjustment of a single model\nparameter. Model simulations of *Opuntia ficus-indica* (CAM), *Sorghum bicolor*\n(C4), and *Triticum aestivum* (C3) capture the diurnal behavior of each species\nas well as the cumulative effects of long-term water limitation. The results\nshow potential for use in understanding CAM productivity, ecology, and climate\nfeedbacks and in evaluating the tradeoffs between C3, C4, and CAM\nphotosynthesis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Sample Size for Concurrent Species Detection in a Species-Rich\n  Assemblage"}, {"role": "assistant", "content": "Monitoring the distribution of microfossils in stratigraphic successions is\nan essential tool for biostratigraphic, evolutionary and\npaleoecologic/paleoceanographic studies. To estimate the relative abundance (%)\nof a given species, it is necessary to estimate in advance the minimum number\nof specimens to be used in the count (n). This requires an a priori assumption\nabout a specified level of confidence, and about the species population\nproportion (p). It is common use to apply the binomial distribution to\ndetermine n to detect the presence of more than one species in the same sample,\nalthough the multinomial distribution should necessarily be used instead.\n  The mathematical theory of sample size computation using the multinomial\ndistribution is adapted to the computation of n for any number of species to be\ndetected together (K) at any level of confidence. Easy-to-use extensive tables\nshow n, for a combination of K and p. These tables indicate a large difference\nfor n between that indicated by the binomial and those by the multinomial\ndistribution when many species are to be detected simultaneously. Counting only\n300 specimens (with 95 % confidence level) or 500 (99 %) is not enough to\ndetect more than one taxon.\n  The reconstructed history of the micro-biosphere may therefore, in many\ninstances, need to be largely revised. This revision should affect our\nunderstanding of the ecological and evolutionary relationships between the past\nchanges in the biosphere and the other major reservoirs (hydrosphere, geosphere\nand atmosphere). In biostratigraphy and biochronology, using a much larger\nsample size, when more than one marker species is to be detected in the\nneighborhood of the same biozone boundary, may help clarifying the nature of\nthe apparent inconsistencies given by the observed reversals in the ordinal\n(rank) biostratigraphic data shown as intersections of the correlation lines"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Use of accelerometers to measure physical activity of group-housed\n  pregnant sows. Method development and use in six pig herds"}, {"role": "assistant", "content": "The development of precision livestock farming which adjusts the food needs\nof each animal requires detailed knowledge of its behavior and particularly\nphysical activity. Individual differences between animals can be observed for\ngroup-housed sows. Accelerometer technology offers opportunities for automatic\nmonitoring of animal behavior. The aim of the first step was to develop a\nmethodology to attach the accelerometer on the sow's leg, and an algorithm to\nautomatically detect standing and lying posture. Accelerometers (Hobo Pendant\nG) were put in a metal case and fastened with two cable ties on the leg of 6\ngroup-housed sows. The data loggers recorded the acceleration on one axis every\n20 s. Data were then validated by 9 hours of direct observations. The automatic\nrecording device showed data of high sensitivity (98.8%) and specificity\n(99.8%). Then, accelerometers were placed on 12 to 13 group-housed sows for 2\nto 4 consecutive days in 6 commercial farms equipped with electronic sow\nfeeding. On average each day, sows spent 259 minutes ($\\pm$ 114) standing and\nchanged posture 29 ($\\pm$ 12) times. The sow's standing time was repeatable day\nto day. Differences between sows and herds were significant. Based on\nbehavioral data, 5 categories of sows were identified. This study suggests that\nthe consideration of individual behavior of each animal would improve herd\nmanagement."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Improved resection margins in breast-conserving surgery using Terahertz\n  Pulsed imaging data"}, {"role": "assistant", "content": "New statistical methods were employed to improve the ability to distinguish\nbenign from malignant breast tissue ex vivo in a recent study. The ultimately\naim was to improve the intraoperative assessment of positive tumour margins in\nbreast-conserving surgery (BCS), potentially reducing patient re-operation\nrates. A multivariate Bayesian classifier was applied to the waveform samples\nproduced by a Terahertz Pulsed Imaging (TPI) handheld probe system in order to\ndiscriminate tumour from benign breast tissue, obtaining a sensitivity of 96%\nand specificity of 95%.\n  We compare these results to traditional and to state-of-the-art methods for\ndetermining resection margins. Given the general nature of the classifier, it\nis expected that this method can be applied to other tumour types where\nresection margins are also critical."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Animal Movement Tools (amt): R-Package for Managing Tracking Data and\n  Conducting Habitat Selection Analyses"}, {"role": "assistant", "content": "1. Advances in tracking technology have led to an exponential increase in\nanimal location data, greatly enhancing our ability to address interesting\nquestions in movement ecology, but also presenting new challenges related to\ndata manage- ment and analysis. 2. Step-Selection Functions (SSFs) are commonly\nused to link environmental covariates to animal location data collected at fine\ntemporal resolution. SSFs are estimated by comparing observed steps connecting\nsuccessive animal locations to random steps, using a likelihood equivalent of a\nCox proportional hazards model. By using common statistical distributions to\nmodel step length and turn angle distributions, and including habitat- and\nmovement-related covariates (functions of distances between points, angular\ndeviations), it is possible to make inference regarding habitat selection and\nmovement processes, or to control one process while investigating the other.\nThe fitted model can also be used to estimate utilization distributions and\nmechanistic home ranges. 3. Here, we present the R-package amt (animal movement\ntools) that allows users to fit SSFs to data and to simulate space use of\nanimals from fitted models. The amt package also provides tools for managing\ntelemetry data. 4. Using fisher (Pekania pennanti ) data as a case study, we\nillustrate a four-step approach to the analysis of animal movement data,\nconsisting of data management, exploratory data analysis, fitting of models,\nand simulating from fitted models."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: PanGeneHome : A Web Interface to Analyze Microbial Pangenomes"}, {"role": "assistant", "content": "PanGeneHome is a web server dedicated to the analysis of available microbial\npangenomes. For any prokaryotic taxon with at least three sequenced genomes,\nPanGeneHome provides (i) conservation level of genes, (ii) pangenome and\ncore-genome curves, estimated pangenome size and other metrics, (iii)\ndendrograms based on gene content and average amino acid identity (AAI) for\nthese genomes, and (iv) functional categories and metabolic pathways\nrepresented in the core, accessory and unique gene pools of the selected taxon.\nIn addition, the results for these different analyses can be compared for any\nset of taxa. With the availability of 615 taxa, covering 182 species and 49\norders, PanGeneHome provides an easy way to get a glimpse on the pangenome of a\nmicrobial group of interest. The server and its documentation are available at\nhttp://pangenehome.lmge.uca.fr."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Response to Comment on \"Cell nuclei have lower refractive index and mass\n  density than cytoplasm\""}, {"role": "assistant", "content": "In a recent study entitled \"Cell nuclei have lower refractive index and mass\ndensity than cytoplasm\", we provided strong evidence indicating that the\nnuclear refractive index (RI) is lower than the RI of the cytoplasm for several\ncell lines. In a complementary study in 2017, entitled \"Is the nuclear\nrefractive index lower than cytoplasm? Validation of phase measurements and\nimplications for light scattering technologies\", Steelman et al. observed a\nlower nuclear RI also for other cell lines and ruled out methodological error\nsources such as phase wrapping and scattering effects. Recently, Yurkin\ncomposed a comment on these 2 publications, entitled \"How a phase image of a\ncell with nucleus refractive index smaller than that of the cytoplasm should\nlook like?\", putting into question the methods used for measuring the cellular\nand nuclear RI in the aforementioned publications by suggesting that a lower\nnuclear RI would produce a characteristic dip in the measured phase profile in\nsitu. We point out the difficulty of identifying this dip in the presence of\nother cell organelles, noise, or blurring due to the imaging point spread\nfunction. Furthermore, we mitigate Yurkin's concerns regarding the ability of\nthe simple-transmission approximation to compare cellular and nuclear RI by\nanalyzing a set of phase images with a novel, scattering-based approach. We\nconclude that the absence of a characteristic dip in the measured phase\nprofiles does not contradict the usage of the simple-transmission approximation\nfor the determination of the average cellular or nuclear RI. Our response can\nbe regarded as an addition to the response by Steelman, Eldridge and Wax. We\nkindly ask the reader to attend to their thorough ascertainment prior to\nreading our response."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Brain Age from the Electroencephalogram of Sleep"}, {"role": "assistant", "content": "The human electroencephalogram (EEG) of sleep undergoes profound changes with\nage. These changes can be conceptualized as \"brain age\", which can be compared\nto an age norm to reflect the deviation from normal aging process. Here, we\ndevelop an interpretable machine learning model to predict brain age based on\ntwo large sleep EEG datasets: the Massachusetts General Hospital sleep lab\ndataset (MGH, N = 2,621) covering age 18 to 80; and the Sleep Hearth Health\nStudy (SHHS, N = 3,520) covering age 40 to 80. The model obtains a mean\nabsolute deviation of 8.1 years between brain age and chronological age in the\nhealthy participants in the MGH dataset. As validation, we analyze a subset of\nSHHS containing longitudinal EEGs 5 years apart, which shows a 5.5 years\ndifference in brain age. Participants with neurological and psychiatric\ndiseases, as well as diabetes and hypertension medications show an older brain\nage compared to chronological age. The findings raise the prospect of using\nsleep EEG as a biomarker for healthy brain aging."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Measuring and modeling interventions in aging"}, {"role": "assistant", "content": "At the physiological level, aging is neither rigid nor unchangeable. Instead,\nthe molecular and mechanisms driving aging are sufficiently plastic that a\nvariety of diverse interventions--dietary, pharmaceutical, and genetic--have\nbeen developed to radically manipulate aging. These interventions, shown to\nincrease the health and lifespan of laboratory animals, are now being explored\nfor therapeutic applications in humans.\n  This clinical potential makes it especially important to understand how,\nquantitatively, aging is altered by lifespan-extending interventions. Do\ninterventions delay the onset of aging? Slow it down? Ameliorate only its\nsymptoms? Perhaps some interventions will alter only a subset of aging\nmechanisms, leading to complex and unintuitive systemic outcomes. Statistical\nand analytic models provide a crucial framework in which to interpret the\nphysiological responses to interventions in aging.\n  This review covers a range of quantitative models of lifespan data and places\nthem in the context of recent experimental work. The careful application of\nthese models can help experimentalists move beyond merely identifying\nstatistically significant differences in lifespan, to instead use lifespan data\nas a versatile means for probing the underlying physiological dynamics of\naging."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Affinity Network Fusion and Semi-supervised Learning for Cancer Patient\n  Clustering"}, {"role": "assistant", "content": "Defining subtypes of complex diseases such as cancer and stratifying patient\ngroups with the same disease but different subtypes for targeted treatments is\nimportant for personalized and precision medicine. Approaches that incorporate\nmulti-omic data are more advantageous to those using only one data type for\npatient clustering and disease subtype discovery. However, it is challenging to\nintegrate multi-omic data as they are heterogeneous and noisy. In this paper,\nwe present Affinity Network Fusion (ANF) to integrate multi-omic data for\npatient clustering. ANF first constructs patient affinity networks for each\nomic data type, and then calculates a fused network for spectral clustering. We\napplied ANF to a processed harmonized cancer dataset downloaded from GDC data\nportal consisting of 2193 patients, and generated promising results on\nclustering patients into correct disease types. Moreover, we developed a\nsemi-supervised model combining ANF and neural network for few-shot learning.\nIn several cases, the model can achieve greater than 90% acccuracy on test set\nwith training less than 1% of the data. This demonstrates the power of ANF in\nlearning a good representation of patients, and shows the great potential of\nsemi-supervised learning in cancer patient clustering."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Ridge Regression Estimated Linear Probability Model Predictions of\n  O-glycosylation in Proteins with Structural and Sequence Data"}, {"role": "assistant", "content": "The likelihood of O-GlcNAc glycosylation in human proteins is predicted using\nthe ridge regression estimated linear probability model (LPM). To achieve this,\nsequences from three similar post-translational modifications (PTMs) of\nproteins occurring at, or very near, the S or T site are analyzed:\nN-glycosylation, O-mucin type (O-GalNAc) glycosylation, and phosphorylation.\nResults found include: 1) The consensus composite sequon for O-glycosylation\ndoes NOT have W on either side of the glycosylation site. 2) The same holds for\nthe consensus sequon for phosphorylation. 3) For LPM estimation, N-glycosylated\nsequences are found to be good approximations to non-O-glycosylatable\nsequences. 4) The selective positioning of an amino acid along the sequence,\ndifferentiates the PTMs of proteins. 5) Some N-glycosylated sequences are also\nphosphorylated at the S or T site. 6) ASA values for N-glycosylated sequences\nare stochastically larger than those for O-GlcNAc glycosylated sequences. 7)\nStructural attributes (beta turn II, II', helix, beta bridges, beta hairpin,\nand the phi angle) are significant LPM predictors of O-GlcNAc glycosylation.\nThe LPM with sequence and structural data as explanatory variables yields a\nKolmogorov-Smirnov (KS) statistic value of 99%. 8) With only sequence data, the\nKS statistic erodes to 80%, underscoring the germaneness of structural\ninformation, which is sparse on O-glycosylated sequences. With 50% as the\ncutoff probability for predicting O-GlcNAc glycosylation, this LPM mispredicts\n21% of out-of-sample O-GlcNAc glycosylated sequences as not being glycosylated.\nThe 95% confidence interval around this mispredictions rate is 16% to 26%"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Out-of-Sample Extrapolation with Neuron Editing"}, {"role": "assistant", "content": "While neural networks can be trained to map from one specific dataset to\nanother, they usually do not learn a generalized transformation that can\nextrapolate accurately outside the space of training. For instance, a\ngenerative adversarial network (GAN) exclusively trained to transform images of\nblack-haired men to blond-haired men might not have the same effect on images\nof black-haired women. This is because neural networks are good at generation\nwithin the manifold of the data that they are trained on. However, generating\nnew samples outside of the manifold or extrapolating \"out-of-sample\" is a much\nharder problem that has been less well studied. To address this, we introduce a\ntechnique called neuron editing that learns how neurons encode an edit for a\nparticular transformation in a latent space. We use an autoencoder to decompose\nthe variation within the dataset into activations of different neurons and\ngenerate transformed data by defining an editing transformation on those\nneurons. By performing the transformation in a latent trained space, we encode\nfairly complex and non-linear transformations to the data with much simpler\ndistribution shifts to the neuron's activations. We motivate our technique on\nan image domain and then move to our two main biological applications: removal\nof batch artifacts representing unwanted noise and modeling the effect of drug\ntreatments to predict synergy between drugs."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Osmosis through a Semi-permeable Membrane: a Consistent Approach to\n  Interactions"}, {"role": "assistant", "content": "The movement of ionic solutions is an essential part of biology and\ntechnology. Fluidics, from nano- to micro- to microfluidics, is a burgeoning\narea of technology which is all about the movement of ionic solutions, on\nvarious scales. Many cells, tissues, and organs of animals and plants depend on\nosmosis, as the movement of fluids is called in biology. Indeed, the movement\nof fluids through channel proteins (that have a hole down their middle) is\nfluidics on an atomic scale. Ionic fluids are complex fluids, with energy\nstored in many ways. Ionic fluids flow driven by gradients of concentration,\nchemical and electrical potential, and hydrostatic pressure. Each flow is\nclassically described by its own field theory, independent of the others, but\nof course, in reality every gradient drives every kind of flow to a varying\nextent. Combining field equations is tricky and so the theory of complex fluids\nderives the equations, rather than assumes their interactions. When field\nequations are derived, rather than assumed, their variables are consistent.\nThat is to say all variables satisfy all equations under all conditions with\none set of parameters. Here we treat a classical osmotic cell in this spirit,\nusing a sharp interface method to derive boundary conditions consistent with\nall flows and fields. We allow volume to change with concentration, since\nchanges of volume are a property of ionic solutions known to all who make them\nin the laboratory. We consider flexible and inflexible membranes. We show how\nto combine the energetics of the membrane with the energetics of the\nsurrounding complex fluids. The results seem general but need application to\nspecific situations of technological, biological and experimental importance\nbefore the consequences of consistency can be understood."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Structural neuroimaging as clinical predictor: a review of machine\n  learning applications"}, {"role": "assistant", "content": "In this paper, we provide an extensive overview of machine learning\ntechniques applied to structural magnetic resonance imaging (MRI) data to\nobtain clinical classifiers. We specifically address practical problems\ncommonly encountered in the literature, with the aim of helping researchers\nimprove the application of these techniques in future works. Additionally, we\nsurvey how these algorithms are applied to a wide range of diseases and\ndisorders (e.g. Alzheimer's disease (AD), Parkinson's disease (PD), autism,\nmultiple sclerosis, traumatic brain injury, etc.) in order to provide a\ncomprehensive view of the state of the art in different fields."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Key challenges facing data-driven multicellular systems biology"}, {"role": "assistant", "content": "Increasingly sophisticated experiments, coupled with large-scale\ncomputational models, have the potential to systematically test biological\nhypotheses to drive our understanding of multicellular systems. In this short\nreview, we explore key challenges that must be overcome to achieve robust,\nrepeatable data-driven multicellular systems biology. If these challenges can\nbe solved, we can grow beyond the current state of isolated tools and datasets\nto a community-driven ecosystem of interoperable data, software utilities, and\ncomputational modeling platforms. Progress is within our grasp, but it will\ntake community (and financial) commitment."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Generalizing the first-difference correlated random walk for marine\n  animal movement data"}, {"role": "assistant", "content": "Animal telemetry data are often analysed with discrete time movement models\nassuming rotation in the movement. These models are defined with equidistant\ndistant time steps. However, telemetry data from marine animals are observed\nirregularly. To account for irregular data, a time-irregularised\nfirst-difference correlated random walk model with drift is introduced. The\nmodel generalizes the commonly used first-difference correlated random walk\nwith regular time steps by allowing irregular time steps, including a drift\nterm, and by allowing different autocorrelation in the two coordinates. The\nmodel is applied to data from a ringed seal collected through the Argos\nsatellite system, and is compared to related movement models through\nsimulations. Accounting for irregular data in the movement model results in\naccurate parameter estimates and reconstruction of movement paths. Measured by\ndistance, the introduced model can provide more accurate movement paths than\nthe regular time counterpart. Extracting accurate movement paths from uncertain\ntelemetry data is important for evaluating space use patterns for marine\nanimals, which in turn is crucial for management. Further, handling irregular\ndata directly in the movement model allows efficient simultaneous analysis of\nseveral animals."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Foreign Object Detection and Quantification of Fat Content Using A Novel\n  Multiplexing Electric Field Sensor"}, {"role": "assistant", "content": "There is an ever growing need to ensure the quality of food and assess\nspecific quality parameters in all the links of the food chain, ranging from\nprocessing, distribution and retail to preparing food. Various imaging and\nsensing technologies, including X-ray imaging, ultrasound, and near infrared\nreflectance spectroscopy have been applied to the problem. Cost and other\nconstraints restrict the application of some of these technologies. In this\nstudy we test a novel Multiplexing Electric Field Sensor (MEFS), an approach\nthat allows for a completely non-invasive and non-destructive testing approach.\nOur experiments demonstrate the reliable detection of certain foreign objects\nand provide evidence that this sensor technology has the capability of\nmeasuring fat content in minced meat. Given the fact that this technology can\nalready be deployed at very low cost, low maintenance and in various different\nform factors, we conclude that this type of MEFS is an extremely promising\ntechnology for addressing specific food quality issues."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Local migration quantification method for scratch assays"}, {"role": "assistant", "content": "Motivation: The scratch assay is a standard experimental protocol used to\ncharacterize cell migration. It can be used to identify genes that regulate\nmigration and evaluate the efficacy of potential drugs that inhibit cancer\ninvasion. In these experiments, a scratch is made on a cell monolayer and\nrecolonisation of the scratched region is imaged to quantify cell migration\nrates. A drawback of this methodology is the lack of its reproducibility\nresulting in irregular cell-free areas with crooked leading edges. Existing\nquantification methods deal poorly with such resulting irregularities present\nin the data. Results: We introduce a new quantification method that can analyse\nlow quality experimental data. By considering in-silico and in-vitro data, we\nshow that the method provides a more accurate statistical classification of the\nmigration rates than two established quantification methods. The application of\nthis method will enable the quantification of migration rates of scratch assay\ndata previously unsuitable for analysis. Availability and Implementation: The\nsource code and the implementation of the algorithm as a GUI along with an\nexample dataset and user instructions, are available in\nhttps://bitbucket.org/anavictoria-ponce/local_migration_quantification_scratch_assays/src/master/.\nThe datasets are available in\nhttps://ganymed.math.uni-heidelberg.de/~victoria/publications.shtml."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Develop machine learning based predictive models for engineering protein\n  solubility"}, {"role": "assistant", "content": "Protein activity is a significant characteristic for recombinant proteins\nwhich can be used as biocatalysts. High activity of proteins reduces the cost\nof biocatalysts. A model that can predict protein activity from amino acid\nsequence is highly desired, as it aids experimental improvement of proteins.\nHowever, only limited data for protein activity are currently available, which\nprevents the development of such models. Since protein activity and solubility\nare correlated for some proteins, the publicly available solubility dataset may\nbe adopted to develop models that can predict protein solubility from sequence.\nThe models could serve as a tool to indirectly predict protein activity from\nsequence. In literature, predicting protein solubility from sequence has been\nintensively explored, but the predicted solubility represented in binary values\nfrom all the developed models was not suitable for guiding experimental designs\nto improve protein solubility. Here we propose new machine learning models for\nimproving protein solubility in vivo. We first implemented a novel approach\nthat predicted protein solubility in continuous numerical values instead of\nbinary ones. After combing it with various machine learning algorithms, we\nachieved a prediction accuracy of 76.28 percent when Support Vector Machine\nalgorithm was used. Continuous values of solubility are more meaningful in\nprotein engineering, as they enable researchers to choose proteins with higher\npredicted solubility for experimental validation, while binary values fail to\ndistinguish proteins with the same value. There are only two possible values so\nmany proteins have the same one."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Time-lagged Ordered Lasso for network inference"}, {"role": "assistant", "content": "Accurate gene regulatory networks can be used to explain the emergence of\ndifferent phenotypes, disease mechanisms, and other biological functions. Many\nmethods have been proposed to infer networks from gene expression data but have\nbeen hampered by problems such as low sample size, inaccurate constraints, and\nincomplete characterizations of regulatory dynamics. Since expression\nregulation is dynamic, time-course data can be used to infer causality, but\nthese datasets tend to be short or sparsely sampled. In addition, temporal\nmethods typically assume that the expression of a gene at a time point depends\non the expression of other genes at only the immediately preceding time point,\nwhile other methods include additional time points without any constraints to\naccount for their temporal distance. These limitations can contribute to\ninaccurate networks with many missing and anomalous links.\n  We adapted the time-lagged Ordered Lasso, a regularized regression method\nwith temporal monotonicity constraints, for \\textit{de novo} reconstruction. We\nalso developed a semi-supervised method that embeds prior network information\ninto the Ordered Lasso to discover novel regulatory dependencies in existing\npathways. We evaluated these approaches on simulated data for a repressilator,\ntime-course data from past DREAM challenges, and a HeLa cell cycle dataset to\nshow that they can produce accurate networks subject to the dynamics and\nassumptions of the time-lagged Ordered Lasso regression."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Agglomerative Hierarchical Clustering Analysis of co/multi-morbidities"}, {"role": "assistant", "content": "Although co/multi-morbidities are associated with significant increase in\nmortality, the lack of appropriate quantitative exploratory techniques often\nimpede their analysis. In the current study, we study the clustering of\nmultimorbid patients in the Texas patient population. To this end we employ\nagglomerative hierarchical clustering to find clusters within the patient\npopulation. The analysis revealed the presence of nine distinct, clinically\nrelevant clusters of co/multi-morbidities within the study population of\ninterest. This technique provides a quantitative exploratory analysis of the\nco/multi-morbidities present in a specific population."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Nutrient removal from agricultural run-off in demonstrative full scale\n  tubular photobioreactors for microalgae growth"}, {"role": "assistant", "content": "The objective of this paper is to present the design, construction and\noperation of 3 full scale semi-closed, horizontal tubular photobioreactors\n(PBR) used to remove nutrients of a mixture of agricultural run-off (90%) and\ntreated domestic wastewater (10%). The microalgal biomass produced in the PBRs\nwas harvested in a static lamella settling tank. Each PBR treated in average\n2.3 m3/d. PBRs were submitted to strong seasonal changes regarding solar\nradiation and temperature, which had a direct impact in the activity of\nmicroalgae and the efficiency of the system. Higher mixed liquor pH values were\nregistered in summer (daily average> 10). Most of the influent and effluent\nnitrogen content was inorganic (average of 9.0 mg N/L and 3.17 mg N/L,\nrespectively), and in the form of nitrate (62% and 50%, respectively). Average\nnitrogen removal efficiency was 65%, with values of around 90% in summer, 80%\nin autumn, 50 % in winter and 60% in spring. Most of the influent and effluent\nphosphorus content was in the form of ortophosphate. Influent average was 0.62\nmg P/L, but with great variations and in a considerable number of samples not\ndetected. Removal efficiency (when influent values were detected) was very high\nduring all the study, usually greater than 95%, and there were not clear\nseasonal trends for efficiency as observed for TIN. Volumetric biomass\nproduction greatly changed between seasons with much lower values in winter (7\ng VSS/m3d) than in summer (43 g VSS/m3d). Biomass separation efficiency of the\nsettler was very good in either terms of turbidity and total suspended solids,\nbeing most of the time lower than 5 UNT and 15 mg/L, respectively. Overall this\nstudy demonstrated the reliable and good effectiveness of microalgae based\ntechnologies such as the PBR to remove nutrients at a full scale size."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: PGLasso: Microbial Community Detection through Phylogenetic Graphical\n  Lasso"}, {"role": "assistant", "content": "Due to the recent advances in high-throughput sequencing technologies, it\nbecomes possible to directly analyze microbial communities in the human body\nand in the environment. Knowledge of how microbes interact with each other and\nform functional communities can provide a solid foundation to understand\nmicrobiome related diseases; this can serve as a key step towards precision\nmedicine. In order to understand how microbes form communities, we propose a\ntwo step approach: First, we infer the microbial co-occurrence network by\nintegrating a graph inference algorithm with phylogenetic information obtained\ndirectly from metagenomic data. Next, we utilize a network-based community\ndetection algorithm to cluster microbes into functional groups where microbes\nin each group are highly correlated. We also curate a \"gold standard\" network\nbased on the microbe-metabolic relationships which are extracted directly from\nthe metagenomic data. Utilizing community detection on the resulting microbial\nmetabolic pathway bipartite graph, the community membership for each microbe\ncan be viewed as the true label when evaluating against other existing methods.\nOverall, our proposed framework Phylogenetic Graphical Lasso (PGLasso)\noutperforms existing methods with gains larger than 100% in terms of Adjusted\nRand Index (ARI) which is commonly used to quantify the goodness of\nclusterings."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Robust Retrospective Frequency and Phase Correction for Single-voxel MR\n  Spectroscopy"}, {"role": "assistant", "content": "Purpose: subject motion and static field (B$_0$) drift are known to reduce\nthe quality of single voxel MR spectroscopy data due to incoherent averaging.\nRetrospective correction has previously been shown to improve data quality by\nadjusting the phase and frequency offset of each average to match a reference\nspectrum. In this work, a new method (RATS) is developed to be tolerant to\nlarge frequency shifts (greater than 7Hz) and baseline instability resulting\nfrom inconsistent water suppression. Methods: in contrast to previous\napproaches, the variable-projection method and baseline fitting is incorporated\ninto the correction procedure to improve robustness to fluctuating baseline\nsignals and optimization instability. RATS is compared to an alternative\nmethod, based on time-domain spectral registration (TDSR), using simulated data\nto model frequency, phase and baseline instability. In addition, a J-difference\nedited glutathione in-vivo dataset is processed using both approaches and\ncompared. Results: RATS offers improved accuracy and stability for large\nfrequency shifts and unstable baselines. Reduced subtraction artifacts are\ndemonstrated for glutathione edited MRS when using RATS, compared with\nuncorrected or TDSR corrected spectra. Conclusion: the RATS algorithm has been\nshown to provide accurate retrospective correction of SVS MRS data in the\npresence of large frequency shifts and baseline instability. The method is\nrapid, generic and therefore readily incorporated into MRS processing pipelines\nto improve lineshape, SNR and aid quality assessment."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Structural biology meets data science: Does anything change?"}, {"role": "assistant", "content": "Data science has emerged from the proliferation of digital data, coupled with\nadvances in algorithms, software and hardware (e.g., GPU computing).\nInnovations in structural biology have been driven by similar factors, spurring\nus to ask: can these two fields impact one another in deep and hitherto\nunforeseen ways? We posit that the answer is yes. New biological knowledge lies\nin the relationships between sequence, structure, function and disease, all of\nwhich play out on the stage of evolution, and data science enables us to\nelucidate these relationships at scale. Here, we consider the above question\nfrom the five key pillars of data science: acquisition, engineering, analytics,\nvisualization and policy, with an emphasis on machine learning as the premier\nanalytics approach."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Extreme value analysis of gut microbial alterations in colorectal cancer"}, {"role": "assistant", "content": "Gut microbes play a key role in colorectal carcinogenesis, yet reaching a\nconsensus on microbial signatures remains a challenge. This is in part due to a\nreliance on mean value estimates. We present an extreme value analysis for\novercoming these limitations. By characterizing a power law fit to the relative\nabundances of microbes, we capture the same microbial signatures as more\ncomplex meta-analyses. Importantly, we show that our method is robust to the\nvariations inherent in microbial community profiling and point to future\ndirections for developing sensitive, reliable analytical methods."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Adaptive, locally-linear models of complex dynamics"}, {"role": "assistant", "content": "The dynamics of complex systems generally include high-dimensional,\nnon-stationary and non-linear behavior, all of which pose fundamental\nchallenges to quantitative understanding. To address these difficulties we\ndetail a new approach based on local linear models within windows determined\nadaptively from the data. While the dynamics within each window are simple,\nconsisting of exponential decay, growth and oscillations, the collection of\nlocal parameters across all windows provides a principled characterization of\nthe full time series. To explore the resulting model space, we develop a novel\nlikelihood-based hierarchical clustering and we examine the eigenvalues of the\nlinear dynamics. We demonstrate our analysis with the Lorenz system undergoing\nstable spiral dynamics and in the standard chaotic regime. Applied to the\nposture dynamics of the nematode $C. elegans$ our approach identifies\nfine-grained behavioral states and model dynamics which fluctuate close to an\ninstability boundary, and we detail a bifurcation in a transition from forward\nto backward crawling. Finally, we analyze whole-brain imaging in $C. elegans$\nand show that the stability of global brain states changes with oxygen\nconcentration."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Global optimization using Gaussian Processes to estimate biological\n  parameters from image data"}, {"role": "assistant", "content": "Parameter estimation is a major challenge in computational modeling of\nbiological processes. This is especially the case in image-based modeling where\nthe inherently quantitative output of the model is measured against image data,\nwhich is typically noisy and non-quantitative. In addition, these models can\nhave a high computational cost, limiting the number of feasible simulations,\nand therefore rendering most traditional parameter estimation methods\nunsuitable. In this paper, we present a pipeline that uses Gaussian process\nlearning to estimate biological parameters from noisy, non-quantitative image\ndata when the model has a high computational cost. This approach is first\nsuccessfully tested on a parametric function with the goal of retrieving the\noriginal parameters. We then apply it to estimating parameters in a biological\nsetting by fitting artificial in-situ hybridization (ISH) data of the\ndeveloping murine limb bud. We expect that this method will be of use in a\nvariety of modeling scenarios where quantitative data is missing and the use of\nstandard parameter estimation approaches in biological modeling is prohibited\nby the computational cost of the model."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Converting Alzheimer s disease map into a heavyweight ontology: a formal\n  network to integrate data"}, {"role": "assistant", "content": "Alzheimer s disease (AD) pathophysiology is still imperfectly understood and\ncurrent paradigms have not led to curative outcome. Omics technologies offer\ngreat promises for improving our understanding and generating new hypotheses.\nHowever, integration and interpretation of such data pose major challenges,\ncalling for adequate knowledge models. AlzPathway is a disease map that gives a\ndetailed and broad account of AD pathophysiology. However, AlzPathway lacks\nformalism, which can lead to ambiguity and misinterpretation. Ontologies are an\nadequate framework to overcome this limitation, through their axiomatic\ndefinitions and logical reasoning properties. We introduce the AD Map Ontology\n(ADMO) an ontological upper model based on systems biology terms. We then\npropose to convert AlzPathway into an ontology and to integrate it into ADMO.\nWe demonstrate that it allows one to deal with issues related to redundancy,\nnaming, consistency, process classification and pathway relationships. Further,\nit opens opportunities to expand the model using elements from other resources,\nsuch as generic pathways from Reactome or clinical features contained in the\nADO (AD Ontology). A version of the ontology will be made freely available to\nthe community on Bioportal at the time of the confer-ence."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Minimal Power Model for Human Running Performance"}, {"role": "assistant", "content": "Models for human running performances of various complexities and underlying\nprinciples have been proposed, often combining data from world record\nperformances and bio-energetic facts of human physiology. Here we present a\nnovel, minimal and universal model for human running performance that employs a\nrelative metabolic power scale. The main component is a self-consistency\nrelation for the time dependent maximal power output. The analytic approach\npresented here is the first to derive the observed logarithmic scaling between\nworld (and other) record running speeds and times from basic principles of\nmetabolic power supply. Various female and male record performances (world,\nnational) and also personal best performances of individual runners for\ndistances from 800m to the marathon are excellently described by this model,\nwith mean errors of (often much) less than 1%. The model defines endurance in a\nway that demonstrates symmetry between long and short racing events that are\nseparated by a characteristic time scale comparable to the time over which a\nrunner can sustain maximal oxygen uptake. As an application of our model, we\nderive personalized characteristic race speeds for different durations and\ndistances."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Serverless computing provides on-demand high performance computing for\n  biomedical research"}, {"role": "assistant", "content": "Cloud computing offers on-demand, scalable computing and storage, and has\nbecome an essential resource for the analyses of big biomedical data. The usual\napproach to cloud computing requires users to reserve and provision virtual\nservers. An emerging alternative is to have the provider allocate machine\nresources dynamically. This type of serverless computing has tremendous\npotential for biomedical research in terms of ease-of-use, instantaneous\nscalability and cost effectiveness. In our proof of concept example, we\ndemonstrate how serverless computing provides low cost access to hundreds of\nCPUs, on demand, with little or no setup. In particular, we illustrate that the\nall-against-all pairwise comparison among all unique human proteins can be\naccomplished in approximately 2 minutes, at a cost of less than $1, using\nAmazon Web Services Lambda. This is a 250x speedup compared to running the same\ntask on a typical laptop computer."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: IGLOSS: iterative gapless local similarity search"}, {"role": "assistant", "content": "Searching for local sequence patterns is one of the basic tasks in\nbioinformatics. Sequence patterns might have structural, functional or some\nother relevance, and numerous methods have been developed to detect and analyze\nthem. These methods often depend on the wealth of information already\ncollected. The explosion in the number of newly available sequences calls for\nnovel methods to explore local sequence similarity. We have developed a high\nsensitivity web-based iterative local similarity scanner, that finds sequence\npatterns similar to a submitted query."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Automated identification of flagella from videomicroscopy via the medial\n  axis transform"}, {"role": "assistant", "content": "Ubiquitous in eukaryotic organisms, the flagellum is a well-studied organelle\nthat is well-known to be responsible for motility in a variety of organisms.\nCommonly necessitated in their study is the capability to image and\nsubsequently track the movement of one or more flagella using videomicroscopy,\nrequiring digital isolation and location of the flagellum within a sequence of\nframes. Such a process in general currently requires some researcher input,\nproviding some manual estimate or reliance on an experiment-specific heuristic\nto correctly identify and track the motion of a flagellum. Here we present a\nfully-automated method of flagellum identification from videomicroscopy based\non the fact that the flagella are of approximately constant width when viewed\nby microscopy. We demonstrate the effectiveness of the algorithm by application\nto captured videomicroscopy of Leishmania mexicana, a parasitic monoflagellate\nof the family Trypanosomatidae. ImageJ Macros for flagellar identification are\nprovided, and high accuracy and remarkable throughput are achieved via this\nunsupervised method, obtaining results comparable in quality to previous\nstudies of closely-related species but achieved without the need for precursory\nmeasurements or the development of a specialised heuristic, enabling in general\nthe automated generation of digitised kinematic descriptions of flagellar\nbeating from videomicroscopy."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: State-switching continuous-time correlated random walks"}, {"role": "assistant", "content": "Continuous-time models have been developed to capture features of animal\nmovement across temporal scales. In particular, one popular model is the\ncontinuous-time correlated random walk, in which the velocity of an animal is\nformulated as an Ornstein-Uhlenbeck process, to capture the autocorrelation in\nthe speed and direction of its movement. In telemetry analyses, discrete-time\nstate-switching models (such as hidden Markov models) have been increasingly\npopular to identify behavioural phases from animal tracking data. We propose a\nmultistate formulation of the continuous-time correlated random walk, with an\nunderlying Markov process used as a proxy for the animal's behavioural state\nprocess. We present a Markov chain Monte Carlo algorithm to carry out Bayesian\ninference for this multistate continuous-time model. Posterior samples of the\nhidden state sequence, of the state transition rates, and of the\nstate-dependent movement parameters can be obtained. We investigate the\nperformance of the method in a simulation study, and we illustrate its use in a\ncase study of grey seal (Halichoerus grypus) tracking data. The method we\npresent makes use of the state-space model formulation of the continuous-time\ncorrelated random walk, and can accommodate irregular sampling frequency and\nmeasurement error. It will facilitate the use of continuous-time models to\nestimate movement characteristics and infer behavioural states from animal\ntelemetry data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Review on Image- and Network-based Brain Data Analysis Techniques for\n  Alzheimer's Disease Diagnosis Reveals a Gap in Developing Predictive Methods\n  for Prognosis"}, {"role": "assistant", "content": "Unveiling pathological brain changes associated with Alzheimer's disease (AD)\nis a challenging task especially that people do not show symptoms of dementia\nuntil it is late. Over the past years, neuroimaging techniques paved the way\nfor computer-based diagnosis and prognosis to facilitate the automation of\nmedical decision support and help clinicians identify cognitively intact\nsubjects that are at high-risk of developing AD. As a progressive\nneurodegenerative disorder, researchers investigated how AD affects the brain\nusing different approaches: 1) image-based methods where mainly neuroimaging\nmodalities are used to provide early AD biomarkers, and 2) network-based\nmethods which focus on functional and structural brain connectivities to give\ninsights into how AD alters brain wiring. In this study, we reviewed\nneuroimaging-based technical methods developed for AD and mild-cognitive\nimpairment (MCI) classification and prediction tasks, selected by screening all\nMICCAI proceedings published between 2010 and 2016. We included papers that fit\ninto image-based or network-based categories. The majority of papers focused on\nclassifying MCI vs. AD brain states, which has enabled the discovery of\ndiscriminative or altered brain regions and connections. However, very few\nworks aimed to predict MCI progression based on early neuroimaging-based\nobservations. Despite the high importance of reliably identifying which early\nMCI patient will convert to AD, remain stable or reverse to normal over\nmonths/years, predictive models are still lagging behind."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Volume tensor of pheasant brain compartments estimated by Fakir probe"}, {"role": "assistant", "content": "The volume tensor provides robust estimate of object shape and orientation in\nspace. The tensor is estimated from 3D data set by the Fakir probe, an\ninteractive method using intersections of the objects boundary with a virtual\nlines. The method thus can be applied to objects that cannot be segmented\nautomatically. Marking the intersections instead of segmenting the whole object\nreduces the workload required for obtaining sufficiently precise results. We\npresent theoretical results on the variance of estimate of integrals by\nsystematic sampling that enable calculation of the shape estimate precision. To\ndemonstrate the ability of Fakir technique, we measure the changes in shape and\norientation of pheasant brain compartments during development."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Same but not alike: Structure, flexibility and energetics of domains in\n  multi-domain proteins are influenced by the presence of other domains"}, {"role": "assistant", "content": "The majority of the proteins encoded in the genomes of eukaryotes contain\nmore than one domain. Reasons for high prevalence of multi-domain proteins in\nvarious organisms have been attributed to higher stability and functional and\nfolding advantages over single-domain proteins. Despite these advantages, many\nproteins are composed of only one domain while their homologous domains are\npart of multi-domain proteins. In the study presented here, differences in the\nproperties of protein domains in single-domain and multi-domain systems and\ntheir influence on functions are discussed. We studied 20 pairs of identical\nprotein domains, which were crystallized in two forms (a) tethered to other\nproteins domains and (b) tethered to fewer protein domains than (a) or not\ntethered to any protein domain. Results suggest that tethering of domains in\nmulti-domain proteins influences the structural, dynamic and energetic\nproperties of the constituent protein domains. 50% of the protein domain pairs\nshow significant structural deviations while 90% of the protein domain pairs\nshow differences in dynamics and 12% of the residues show differences in the\nenergetics. To gain further insights on the influence of tethering on the\nfunction of the domains, 4 pairs of homologous protein domains, where one of\nthem is a full-length single-domain protein and the other protein domain is a\npart of a multi-domain protein, were studied. Analyses showed that identical\nand structurally equivalent functional residues show differential dynamics in\nhomologous protein domains, though comparable dynamics between in-silico\ngenerated chimera protein and multi-domain proteins were observed. From these\nobservations, the differences observed in the functions of homologous proteins\ncould be attributed to the presence of tethered domain. Overall, we conclude\nthat tethered domains in multi-domain proteins not only provide stability or\nfolding advantages but also influence pathways resulting in differences in\nfunction or regulatory properties."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Metrics for describing dyadic movement: a review"}, {"role": "assistant", "content": "In movement ecology, the few works that have taken collective behaviour into\naccount are data-driven and rely on simplistic theoretical assumptions, relying\nin metrics that may or may not be measuring what is intended. In the present\npaper, we focus on pairwise joint-movement behaviour, where individuals move\ntogether during at least a segment of their path. We investigate the adequacy\nof twelve metrics introduced in previous works for assessing joint movement by\nanalysing their theoretical properties and confronting them with contrasting\ncase scenarios. Three criteria are taken into account for review of those\nmetrics: 1) practical use, 2) dependence on parameters and underlying\nassumptions, and 3) computational cost. When analysing the similarities between\nthe metrics as defined, we show how some of them can be expressed using general\nmathematical forms. In addition, we evaluate the ability of each metric to\nassess specific aspects of joint-movement behaviour: proximity (closeness in\nspace-time) and coordination (synchrony) in direction and speed. We found that\nsome metrics are better suited to assess proximity and others are more\nsensitive to coordination. To help readers choose metrics, we elaborate a\ngraphical representation of the metrics in the coordination and proximity space\nbased on our results, and give a few examples of proximity and coordination\nfocus in different movement studies."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: RNAmountAlign: efficient software for local, global, semiglobal pairwise\n  and multiple RNA sequence/structure alignment"}, {"role": "assistant", "content": "Alignment of structural RNAs is an important problem with a wide range of\napplications. Since function is often determined by molecular structure, RNA\nalignment programs should take into account both sequence and base-pairing\ninformation for structural homology identi^Lcation. A number of successful\nalignment programs are heuristic versions of Sanko^K's optimal algorithm. Most\nof them require O(n4) run time. This paper describes C++ software,\nRNAmountAlign, for RNA sequence/structure alignment that runs in O(n3) time and\nO(n2) space; moreover, our software returns a p-value (transformable to expect\nvalue E) based on Karlin-Altschul statistics for local alignment, as well as\nparameter ^Ltting for local and global alignment. Using incremental mountain\nheight, a representation of structural information computable in cubic time,\nRNAmountAlign implements quadratic time pairwise local, global and\nglobal/semiglobal (query search) alignment using a weighted combination of\nsequence and structural similarity. RNAmountAlign is capable of performing\nprogressive multiple alignment as well. Benchmarking of RNAmountAlign against\nLocARNA, LARA, FOLDALIGN, DYNALIGN and STRAL shows that RNAmountAlign has\nreasonably good accuracy and much faster run time supporting all alignment\ntypes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: GL-BLSTM: a novel structure of bidirectional long-short term memory for\n  disulfide bonding state prediction"}, {"role": "assistant", "content": "Background: Disulfide bonds are crucial to protein structural formation.\nDeveloping an effective method topredict disulfide bonding formation is\nimportant for protein structural modeling and functional study. Mostcurrent\nmethods still have shortcomings, including low accuracy and strict requirements\nfor the selection ofdiscriminative features. Results: In this study, we\nintroduced a nested structure of Bidirectional Long-short Term\nMemory(BLSTM)neural network called Global-Local-BLSTM (GL-BLSTM) for disulfide\nbonding state prediction. Based on thepatterns of disulfide bond formation, a\nBLSTM network called Local-BLSTM is used to extract context-basedfeatures\naround every Cys residue. Another BLSTM network called Global-BLSTM is\nintroduced aboveLocal-BLSTM layer to integrate context-based features of all\nCys residues in the same protein chain, therebyinvolving inter-residue\nrelationships in the training process. According to our experimental\nresults,GL-BLSTMnetwork performs much better than other methods, GL-BLSTM\nreached 90.26% accuracy at residue-level and 83.66% at protein-level. This\nmodel has reached the state of the art in this field. Conclusion: GL-BLSTMs\nspecial structure and mechanisms are beneficial to disulfide bonding state\nprediction.By applying bidirectional LSTM, it can extract context based\nfeatures by processing protein sequences, therebyobtain more discriminative\ninformation than traditional machine learning methods. Whats more,\nGL-BLSTMsspecial two-layer structure enables it to extract both local and\nglobal features, in which global features areplaying important roles in\nimproving prediction accuracy, especially at protein-level. Keywords: Disulfide\nbonds; Prediction; Deep learning; Bidirectional long short term memory"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Random field theory-based p-values: A review of the SPM implementation"}, {"role": "assistant", "content": "P-values and null-hypothesis significance testing are popular data-analytical\ntools in functional neuroimaging. Sparked by the analysis of resting-state fMRI\ndata, there has been a resurgence of interest in the validity of some of the\np-values evaluated with the widely used software SPM in recent years. The\ndefault parametric p-values reported in SPM are based on the application of\nresults from random field theory to statistical parametric maps, a framework\ncommonly referred to as RFT. While RFT was established two decades ago and has\nsince been applied in a plethora of fMRI studies, there does not exist a\nunified documentation of the mathematical and computational underpinnings of\nRFT as implemented in current versions of SPM. Here, we provide such a\ndocumentation with the aim of contributing to contemporary efforts towards\nhigher levels of computational transparency in functional neuroimaging."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Information-theoretic analysis of multivariate single - cell signaling\n  responses using SLEMI"}, {"role": "assistant", "content": "Mathematical methods of information theory constitute essential tools to\ndescribe how stimuli are encoded in activities of signaling effectors.\nExploring the information-theoretic perspective, however, remains conceptually,\nexperimentally and computationally challenging. Specifically, existing\ncomputational tools enable efficient analysis of relatively simple systems,\nusually with one input and output only. Moreover, their robust and readily\napplicable implementations are missing. Here, we propose a novel algorithm to\nanalyze signaling data within the framework of information theory. Our approach\nenables robust as well as statistically and computationally efficient analysis\nof signaling systems with high-dimensional outputs and a large number of input\nvalues. Analysis of the NF-kB single - cell signaling responses to TNF-a\nuniquely reveals that the NF-kB signaling dynamics improves discrimination of\nhigh concentrations of TNF-a with a modest impact on discrimination of low\nconcentrations. Our readily applicable R-package, SLEMI - statistical learning\nbased estimation of mutual information, allows the approach to be used by\ncomputational biologists with only elementary knowledge of information theory."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Tutorial on agent-based models in NetLogo applied to immunology and\n  virology"}, {"role": "assistant", "content": "This tutorial introduces participants to the design and implementation of an\nagent-based model using NetLogo through one of two different projects:\nmodelling T cell movement within a lymph node or modelling the progress of a\nviral infection in an in vitro cell culture monolayer. Each project is broken\ninto a series of incremental steps of increasing complexity. Each step is\ndescribed in detail and the code to type in is initially provided. However,\neach project has room to grow in complexity and biological realism so\nparticipants are encouraged to expand their project beyond the scope of the\ntutorial or to develop a project of their own."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Latent Space Temporal Model of Microbial Abundance to Predict Domination\n  and Bacteremia"}, {"role": "assistant", "content": "Gut microbial composition has been linked to multiple health outcomes. Yet,\ntemporal analysis of this composition had been limited to deterministic models.\nIn this paper, we introduce a probabilistic model for the dynamics of\nintestinal microbiomes that takes into account interaction among bacteria as\nwell as external effects such as antibiotics. The model successfully deals with\npragmatic issues such as random measurement error and varying time intervals\nbetween measurements through latent space modeling. We demonstrate utility of\nthe model by using latent state features to predict the clinical events of\nintestinal domination and bacteremia, improving accuracy over existing methods.\nWe further leverage this framework to validate known links between antibiotics\nand clinical outcomes, while discovering new ones."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Statistical and mathematical modeling of spatiotemporal dynamics of stem\n  cells"}, {"role": "assistant", "content": "Statistical and mathematical modeling are crucial to describe, interpret,\ncompare and predict the behavior of complex biological systems including the\norganization of hematopoietic stem and progenitor cells in the bone marrow\nenvironment. The current prominence of high-resolution and live-cell imaging\ndata provides an unprecedented opportunity to study the spatiotemporal dynamics\nof these cells within their stem cell niche and learn more about aberrant, but\nalso unperturbed, normal hematopoiesis. However, this requires careful\nquantitative statistical analysis of the spatial and temporal behavior of cells\nand the interaction with their microenvironment. Moreover, such quantification\nis a prerequisite for the construction of hypothesis-driven mathematical models\nthat can provide mechanistic explanations by generating spatiotemporal dynamics\nthat can be directly compared to experimental observations. Here, we provide a\nbrief overview of statistical methods in analyzing spatial distribution of\ncells, cell motility, cell shapes and cellular genealogies. We also describe\ncell- based modeling formalisms that allow researchers to simulate emergent\nbehavior in a multicellular system based on a set of hypothesized mechanisms.\nTogether, these methods provide a quantitative workflow for the analytic and\nsynthetic study of the spatiotemporal behavior of hematopoietic stem and\nprogenitor cells."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Near real-time enumeration of live and dead bacteria using a fibre-based\n  spectroscopic device"}, {"role": "assistant", "content": "A rapid, cost-effective and easy method that allows on-site determination of\nthe concentration of live and dead bacterial cells using a fibre-based\nspectroscopic device (the optrode system) is proposed and demonstrated.\nIdentification of live and dead bacteria was achieved by using the commercially\navailable dyes SYTO 9 and propidium iodide, and fluorescence spectra were\nmeasured by the optrode. Three spectral processing methods were evaluated for\ntheir effectiveness in predicting the original bacterial concentration in the\nsamples: principal components regression (PCR), partial least squares\nregression (PLSR) and support vector regression (SVR). Without any sample\npre-concentration, PCR achieved the most reliable results. It was able to\nquantify live bacteria from $10^{8}$ down to $10^{6.2}$ bacteria/mL and showed\nthe potential to detect as low as $10^{5.7}$ bacteria/mL. Meanwhile,\nenumeration of dead bacteria using PCR was achieved between $10^{8}$ and\n$10^{7}$ bacteria/mL. The general procedures described in this article can be\napplied or modified for the enumeration of bacteria within populations stained\nwith fluorescent dyes. The optrode is a promising device for the enumeration of\nlive and dead bacterial populations particularly where rapid, on-site\nmeasurement and analysis is required."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Missing Value Estimation Algorithms on Cluster and Representativeness\n  Preservation of Gene Expression Microarray Data"}, {"role": "assistant", "content": "Missing values are largely inevitable in gene expression microarray studies.\nData sets often have significant omissions due to individuals dropping out of\nexperiments, errors in data collection, image corruptions, and so on. Missing\ndata could potentially undermine the validity of research results - leading to\ninaccurate predictive models and misleading conclusions. Imputation - a\nrelatively flexible, general purpose approach towards dealing with missing data\n- is now available in massive numbers, making it possible to handle missing\ndata. While these estimation methods are becoming increasingly more effective\nin resolving the discrepancies between true and estimated values, its effect on\nclustering outcomes is largely disregarded.\n  This study seeks to reveal the vast differences in agglomerative hierarchal\nclustering outcomes estimation methods can construct in comparison to the\nprecision exhibited (presented through the cophenetic correlation coefficient)\nin comparison to their high efficiency and effectivity in value preservation of\ntrue and imputed values (presented through the root-mean-squared error). We\nargue against the traditional approach towards the development of imputation\nmethods and instead, advocate towards methods that reproduce a data set's\noriginal, natural cluster.\n  By using a number of advanced imputation methods, we reveal extensive\ndifferences between original and reconstructed clusters that could\nsignificantly transform the interpretations of the data as a whole."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Risk evaluation and behaviour: defining appropriate frames of reference"}, {"role": "assistant", "content": "Many biological, psychological and economic experiments have been designed\nwhere an organism or individual must choose between two options that have the\nsame expected reward but differ in the variance of reward received. In this\nway, designed empirical approaches have been developed for evaluating risk\npreferences. Here, however, we show that if the experimental subject is\ninferring the reward distribution (to optimize some process), they will never\nagree in finite time that the expected rewards are equal. In turn, we argue\nthat this makes discussions of risk preferences, and indeed the motivations of\nbehaviour, not so simple or straightforward to interpret. We use this\nparticular experiment to highlight the serious need to consider the frame of\nreference of the experimental subject in studies of behaviour."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Ordinal Synchronization: Using ordinal patterns to capture\n  interdependencies between time series"}, {"role": "assistant", "content": "We introduce Ordinal Synchronization ($OS$) as a new measure to quantify\nsynchronization between dynamical systems. $OS$ is calculated from the\nextraction of the ordinal patterns related to two time series, their\ntransformation into $D$-dimensional ordinal vectors and the adequate\nquantification of their alignment. $OS$ provides a fast and robust-to noise\ntool to assess synchronization without any implicit assumption about the\ndistribution of data sets nor their dynamical properties, capturing in-phase\nand anti-phase synchronization. Furthermore, varying the length of the ordinal\nvectors required to compute $OS$ it is possible to detect synchronization at\ndifferent time scales. We test the performance of $OS$ with data sets coming\nfrom unidirectionally coupled electronic Lorenz oscillators and brain imaging\ndatasets obtained from magnetoencephalographic recordings, comparing the\nperformance of $OS$ with other classical metrics that quantify synchronization\nbetween dynamical systems."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Profiling lung cancer patients using electronic health records"}, {"role": "assistant", "content": "If Electronic Health Records contain a large amount of information about the\npatients condition and response to treatment, which can potentially\nrevolutionize the clinical practice, such information is seldom considered due\nto the complexity of its extraction and analysis. We here report on a first\nintegration of an NLP framework for the analysis of clinical records of lung\ncancer patients making use of a telephone assistance service of a major Spanish\nhospital. We specifically show how some relevant data, about patient\ndemographics and health condition, can be extracted; and how some relevant\nanalyses can be performed, aimed at improving the usefulness of the service. We\nthus demonstrate that the use of EHR texts, and their integration inside a data\nanalysis framework, is technically feasible and worth of further study."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: RKappa: Software for Analyzing Rule-Based Models"}, {"role": "assistant", "content": "RKappa is a framework for the development, simulation and analysis of\nrule-base models within the mature statistically empowered R environment. It is\ndesigned for model editing, parameter identification, simulation, sensitivity\nanalysis and visualisation. The framework is optimised for high-performance\ncomputing platforms and facilitates analysis of large-scale systems biology\nmodels where knowledge of exact mechanisms is limited and parameter values are\nuncertain. The RKappa software is an open source (GLP3 license) package for R,\nwhich is freely available online ( https://github.com/lptolik/R4Kappa )."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Step-by-Step Guide to Using BioNetFit"}, {"role": "assistant", "content": "BioNetFit is a software tool designed for solving parameter identification\nproblems that arise in the development of rule-based models. It solves these\nproblems through curve fitting (i.e., nonlinear regression). BioNetFit is\ncompatible with deterministic and stochastic simulators that accept BioNetGen\nlanguage (BNGL)-formatted files as inputs, such those available within the\nBioNetGen framework. BioNetFit can be used on a laptop or standalone multicore\nworkstation as well as on many Linux clusters, such as those that use the Slurm\nWorkload Manager to schedule jobs. BioNetFit implements a metaheuristic\npopulation-based global optimization procedure, an evolutionary algorithm (EA),\nto minimize a user-defined objective function, such as a residual sum of\nsquares (RSS) function. BioNetFit also implements a bootstrapping procedure for\ndetermining confidence intervals for parameter estimates. Here, we provide\nstep-by-step instructions for using BioNetFit to estimate the values of\nparameters of a BNGL-encoded model and to define bootstrap confidence\nintervals. The process entails the use of several plain-text files, which are\nprocessed by BioNetFit and BioNetGen. In general, these files include 1) one or\nmore EXP files, which each contains (experimental) data to be used in parameter\nidentification/bootstrapping; 2) a BNGL file containing a model section, which\ndefines a (rule-based) model, and an actions section, which defines simulation\nprotocols that generate GDAT and/or SCAN files with model predictions\ncorresponding to the data in the EXP file(s); and 3) a CONF file that\nconfigures the fitting/bootstrapping job and that defines algorithmic parameter\nsettings."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Spatial Stochastic Modeling with MCell and CellBlender"}, {"role": "assistant", "content": "This chapter provides a brief introduction to the theory and practice of\nspatial stochastic simulations. It begins with an overview of different methods\navailable for biochemical simulations highlighting their strengths and\nlimitations. Spatial stochastic modeling approaches are indicated when\ndiffusion is relatively slow and spatial inhomogeneities involve relatively\nsmall numbers of particles. The popular software package MCell allows\nparticle-based stochastic simulations of biochemical systems in complex three\ndimensional (3D) geometries, which are important for many cell biology\napplications. Here, we provide an overview of the simulation algorithms used by\nMCell and the underlying theory. We then give a tutorial on building and\nsimulating MCell models using the CellBlender graphical user interface, that is\nbuilt as a plug-in to Blender, a widely-used and freely available software\nplatform for 3D modeling. The tutorial starts with simple models that\ndemonstrate basic MCell functionality and then advances to a number of more\ncomplex examples that demonstrate a range of features and provide examples of\nimportant biophysical effects that require spatially-resolved stochastic\ndynamics to capture."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Highly Accurate Model Based Registration Method for FIB-SEM Images of\n  Neurons"}, {"role": "assistant", "content": "Focused Ion Beam Scanning Electron Microscope (FIB-SEM) imaging is a\ntechnique that image materials section-by-section at nano-resolution, e.g.,5\nnanometer width voxels. FIB-SEM is well suited for imaging ultrastructures in\ncells. Unfortunately, typical setups will introduce a slight sub-pixel\ntranslation from section to section typically referred to as drift. Over\nmultiple sections, drift compound to skew distance measures and geometric\nstructures significantly from the pre-imaged stage. Popular correction\napproaches often involve standard image registration methods available in\npackages such as ImageJ or similar software. These methods transform the images\nto maximize the similarity between consecutive two-dimensional sections under\nsome measure. We show how these standard approaches will both significantly\nunderestimate the drift, as well as producing biased corrections as they tend\nto align the images such that the normal of planar biological structures are\nperpendicular to the sectioning direction causing poor or incorrect correction\nof the images. In this paper, we present a highly accurate correction method\nfor estimating drift in isotropic electron microscope images with visible\nvesicles."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Reference environments: A universal tool for reproducibility in\n  computational biology"}, {"role": "assistant", "content": "The drive for reproducibility in the computational sciences has provoked\ndiscussion and effort across a broad range of perspectives: technological,\nlegislative/policy, education, and publishing. Discussion on these topics is\nnot new, but the need to adopt standards for reproducibility of claims made\nbased on computational results is now clear to researchers, publishers and\npolicymakers alike. Many technologies exist to support and promote reproduction\nof computational results: containerisation tools like Docker, literate\nprogramming approaches such as Sweave, knitr, iPython or cloud environments\nlike Amazon Web Services. But these technologies are tied to specific\nprogramming languages (e.g. Sweave/knitr to R; iPython to Python) or to\nplatforms (e.g. Docker for 64-bit Linux environments only). To date, no single\napproach is able to span the broad range of technologies and platforms\nrepresented in computational biology and biotechnology.\n  To enable reproducibility across computational biology, we demonstrate an\napproach and provide a set of tools that is suitable for all computational work\nand is not tied to a particular programming language or platform. We present\npublished examples from a series of papers in different areas of computational\nbiology, spanning the major languages and technologies in the field\n(Python/R/MATLAB/Fortran/C/Java). Our approach produces a transparent and\nflexible process for replication and recomputation of results. Ultimately, its\nmost valuable aspect is the decoupling of methods in computational biology from\ntheir implementation. Separating the 'how' (method) of a publication from the\n'where' (implementation) promotes genuinely open science and benefits the\nscientific community as a whole."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Scaling behavior in the heart rate variability characteristics with age"}, {"role": "assistant", "content": "In this work we study the characteristics of the heart rate variability (HRV)\nas a function of age and gender. The analyzed data include previous results\nreported in the literature. The data obtained in this work expand the range of\nage studied until now revealing new behaviors not reported before. We analyze\nsome measurements in the time domain,in the frequency domain and nonlinear\nmeasurements. We report scaling behaviors and abrupt changes in some\nmeasurements. There is also a progressive decrease in the dimensionality of the\ndynamic system governing the HRV, with the increase in age that is interpreted\nin terms ofautonomic regulation of cardiac activity."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Reconstructing 3D Motion Trajectory of Large Swarm of Flying Objects"}, {"role": "assistant", "content": "This paper addresses the problem of reconstructing the motion trajectories of\nthe individuals in a large collection of flying objects using two temporally\nsynchronized and geometrically calibrated cameras. The 3D trajectory\nreconstruction problem involves two challenging tasks - stereo matching and\ntemporal tracking. Existing methods separate the two and process them one at a\ntime sequentially, and suffer from frequent irresolvable ambiguities in stereo\nmatching and in tracking. We unify the two tasks, and propose an optimization\napproach to solving stereo matching and temporal tracking simultaneously. It\ntreats 3D trajectory acquisition problem as selecting appropriate stereo\ncorrespondence out of all possible ones for each object via minimizing a cost\nfunction. Experiment results show that the proposed method offers significant\nperformance advantage over existing approaches. The proposed method has\nsuccessfully been applied to reconstruct 3D motion trajectories of hundreds of\nsimultaneously flying fruit flies (Drosophila Melanogaster), which could\nfacilitate the study the insect's collective behavior."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Coherent Control of Optogenetic Switching by Stimulated Depletion\n  Quenching"}, {"role": "assistant", "content": "Optogenetics is a revolutionary new field of biotechnology, achieving optical\ncontrol over biological functions in living cells by genetically inserting\nlight sensitive proteins into cellular signaling pathways. Applications of\noptogenetic switches are expanding rapidly, but the technique is hampered by\nspectral cross-talk: the broad absorption spectra of compatible biochemical\nchromophores limits the number of switches that can be independently controlled\nand restricts the dynamic range of each switch. In the present work we develop\nand implement a non-linear optical photoswitching capability, Stimulated\nDepletion Quenching (SDQ), is used to overcome spectral cross-talk by\nexploiting the molecules' unique dynamic response to ultrashort laser pulses.\nSDQ is employed to enhance the control of Cph8, a photo-reversible phytochrome\nbased optogenetic switch designed to control gene expression in E. Coli\nbacteria. The Cph8 switch can not be fully converted to it's biologically\ninactive state ($P_{FR}$) by linear photos-witching, as spectral cross-talk\ncauses a reverse photoswitching reaction to revert to it back to the active\nstate ($P_{R}$). SDQ selectively halts this reverse reaction while allowing the\nforward reaction to proceed. The results of this proof of concept experiment\nlay the foundation for future experiments that will use optimal pulse shaping\nto further enhance control of Cph8 and enable simultaneous, multiplexed control\nof multiple optogenetic switches."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A stochastic modeling framework for single cell migration: coupling\n  contractility and focal adhesions"}, {"role": "assistant", "content": "The interaction of the actin cytoskeleton with cell-substrate adhesions is\nnecessary for cell migration. While the trajectories of motile cells have a\nstochastic character, investigations of cell motility mechanisms rarely\nelaborate on the origins of the observed randomness. Here, guided by a few\nfundamental attributes of cell motility, we construct a minimal stochastic cell\nmigration model from ground-up. The resulting model couples a deterministic\nactomyosin contractility mechanism with stochastic cell-substrate adhesion\nkinetics, and yields a well-defined piecewise deterministic process. Numerical\nsimulations reproduce several experimentally observed results, including\nanomalous diffusion, tactic migration, and contact guidance. This work provides\na basis for the development of cell-cell collision and population migration\nmodels."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Common lines modeling for reference free ab-initio reconstruction in\n  cryo-EM"}, {"role": "assistant", "content": "We consider the problem of estimating an unbiased and reference-free ab-inito\nmodel for non-symmetric molecules from images generated by single-particle\ncryo-electron microscopy. The proposed algorithm finds the globally optimal\nassignment of orientations that simultaneously respects all common lines\nbetween all images. The contribution of each common line to the estimated\norientations is weighted according to a statistical model for common lines'\ndetection errors. The key property of the proposed algorithm is that it finds\nthe global optimum for the orientations given the common lines. In particular,\nany local optima in the common lines energy landscape do not affect the\nproposed algorithm. As a result, it is applicable to thousands of images at\nonce, very robust to noise, completely reference free, and not biased towards\nany initial model. A byproduct of the algorithm is a set of measures that allow\nto asses the reliability of the obtained ab-initio model. We demonstrate the\nalgorithm using class averages from two experimental data sets, resulting in\nab-initio models with resolutions of 20A or better, even from class averages\nconsisting of as few as three raw images per class."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Modelling N2O dynamics of activated sludge biomass under nitrifying and\n  denitrifying conditions: pathway contributions and uncertainty analysis"}, {"role": "assistant", "content": "Nitrous oxide (N2O) is a potent greenhouse gas emitted during biological\nwastewater treatment. A pseudo-mechanistic model describing three biological\npathways for nitric oxide (NO) and N2O production was calibrated for mixed\nculture biomass from an activated sludge process using laboratory-scale\nexperiments. The model (NDHA) comprehensively describes N2O producing pathways\nby both autotrophic ammonium oxidizing bacteria and heterotrophic bacteria.\nExtant respirometric assays and anaerobic batch experiments were designed to\ncalibrate endogenous and exogenous processes (heterotrophic denitrification and\nautotrophic ammonium/nitrite oxidation) together with the associated net N2O\nproduction. Ten parameters describing heterotrophic processes and seven for\nautotrophic processes were accurately estimated (variance/mean < 25%). The\nmodel predicted NO and N2O dynamics at varying dissolved oxygen, ammonium and\nnitrite levels and was validated against an independent set of experiments with\nthe same biomass. Aerobic ammonium oxidation experiments at two oxygen levels\nused for model evaluation (2 and 0.5 mg/L) indicated that both the nitrifier\ndenitrification (42, 64%) and heterotrophic denitrification (7, 17%) pathways\nincreased and dominated N2O production at high nitrite and low oxygen\nconcentrations; while the nitrifier nitrification pathway showed the largest\ncontribution at high dissolved oxygen levels (51, 19%). The uncertainty of the\nbiological parameter estimates was propagated to N2O model outputs via Monte\nCarlo simulations as 95% confidence intervals. The accuracy of the estimated\nparameters resulted in a low uncertainty of the N2O emission factors (4.6 +-\n0.6% and 1.2 +- 0.1%)."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Application of laser biospeckle analysis for assessment of seed priming\n  techniques"}, {"role": "assistant", "content": "Seed priming is one of the well-established and low cost method to improve\nseed germination properties, productivity, and stress tolerance in different\ncrops. It is a pre-germination treatment that partially hydrates the seed and\nallows controlled imbibition. This stimulates and induces initial germination\nprocess, but prevents radicle emergence. Consequently, treated seeds are\nfortified with enhanced germination characteristics, improved physiological\nparameters, uniformity in growth, and improved capability to cope up with\ndifferent biotic and abiotic stresses. Existing techniques for evaluating the\neffectiveness of seed priming suffer from several drawbacks, including very\nhigh operating time, indirect and destructive analysis, bulky experimental\narrangement, high cost, and require extensive analytical expertise. To\ncircumvent these drawbacks, we propose a biospeckle based technique to analyse\nthe effects of different priming treatments on germination characteristics of\nseeds. The study employs non-primed (T0) and priming treatments (T1-T75),\nincluding hydropriming and chemical priming (using three chemical agents namely\nsodium chloride, potassium nitrate, and urea) for different time durations and\nsolution concentrations. The results conclusively establish biospeckle analysis\nas an efficient active tool for seed priming analysis. Furthermore, the\nproposed setup is extremely simple, low-cost, involves non-mechanical scanning\nand is highly stable."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Uniformisation techniques for stochastic simulation of chemical reaction\n  networks"}, {"role": "assistant", "content": "This work considers the method of uniformisation for continuous-time Markov\nchains in the context of chemical reaction networks. Previous work in the\nliterature has shown that uniformisation can be beneficial in the context of\ntime-inhomogeneous models, such as chemical reaction networks incorporating\nextrinsic noise. This paper lays focus on the understanding of uniformisation\nfrom the viewpoint of sample paths of chemical reaction networks. In\nparticular, an efficient pathwise stochastic simulation algorithm for\ntime-homogeneous models is presented which is complexity-wise equal to\nGillespie's direct method. This new approach therefore enlarges the class of\nproblems for which the uniformisation approach forms a computationally\nattractive choice. Furthermore, as a new application of the uniformisation\nmethod, we provide a novel variance reduction method for (raw) moment\nestimators of chemical reaction networks based upon the combination of\nstratification and uniformisation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Segmentation of laterally symmetric overlapping objects: application to\n  images of collective animal behaviour"}, {"role": "assistant", "content": "Video analysis is currently the main non-intrusive method for the study of\ncollective behavior. However, 3D-to-2D projection leads to overlapping of\nobserved objects. The situation is further complicated by the absence of stall\nshapes for the majority of living objects. Fortunately, living objects often\npossess a certain symmetry which was used as a basis for morphological\nfingerprinting. This technique allowed us to record forms of symmetrical\nobjects in a pose-invariant way. When combined with image skeletonization, this\ngives a robust, nonlinear, optimization-free, and fast method for detection of\noverlapping objects, even without any rigid pattern. This novel method was\nverified on fish (European bass, Dicentrarchus labrax, and tiger barbs, Puntius\ntetrazona) swimming in a reasonably small tank, which forced them to exhibit a\nlarge variety of shapes. Compared with manual detection, the correct number of\nobjects was determined for up to almost $90 \\%$ of overlaps, and the mean\nDice-Sorensen coefficient was around $0.83$. This implies that this method is\nfeasible in real-life applications such as toxicity testing."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Objective estimation of sensory thresholds based on neurophysiological\n  parameters"}, {"role": "assistant", "content": "Reliable determination of sensory thresholds is the holy grail of signal\ndetection theory. However, there exists no gold standard for the estimation of\nthresholds based on neurophysiological parameters, although a reliable\nestimation method is crucial for both scientific investigations and clinical\ndiagnosis. Whenever it is impossible to communicate with the subjects, as in\nstudies with animals or neonatales, thresholds have to be derived from neural\nrecordings. In such cases when the threshold is estimated based on neuronal\nmeasures, the standard approach is still the subjective setting of the\nthreshold to the value where at least a \"clear\" neuronal signal is detectable.\nThese measures are highly subjective, strongly depend on the noise, and\nfluctuate due to the low signal-to-noise ratio near the threshold. Here we show\na novel method to reliably estimate physiological thresholds based on\nneurophysiological parameters. Using surrogate data, we demonstrate that\nfitting the responses to different stimulus intensities with a hard sigmoid\nfunction, in combination with subsampling, provides a robust threshold value as\nwell as an accurate uncertainty estimate. This method has no systematic\ndependence on the noise and does not even require samples in the full dynamic\nrange of the sensory system. It is universally applicable to all types of\nsensory systems, ranging from somatosensory stimulus processing in the cortex\nto auditory processing in the brain stem."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Diffusion Kurtosis Imaging maps neural damage in the EAE model of\n  multiple sclerosis"}, {"role": "assistant", "content": "Diffusion kurtosis imaging (DKI), is an imaging modality that yields novel\ndisease biomarkers and in combination with nervous tissue modeling, provides\naccess to microstructural parameters. Recently, DKI and subsequent estimation\nof microstructural model parameters has been used for assessment of tissue\nchanges in neurodegenerative diseases and their animal models. In this study,\nmouse spinal cords from the experimental autoimmune encephalomyelitis (EAE)\nmodel of multiple sclerosis (MS) were investigated for the first time using DKI\nin combination with biophysical modeling to study the relationship between\nmicrostructural metrics and degree of animal dysfunction. Thirteen spinal cords\nwere extracted from animals of variable disability and scanned in a high-field\nMRI scanner along with five control specimen. Diffusion weighted data were\nacquired together with high resolution T2* images. Diffusion data were fit to\nestimate diffusion and kurtosis tensors and white matter modeling parameters,\nwhich were all used for subsequent statistical analysis using a linear mixed\neffects model. T2* images were used to delineate focal\ndemyelination/inflammation. Our results unveil a strong relationship between\ndisability and measured microstructural parameters in normal appearing white\nmatter and gray matter. The changes we found in biophysical modeling parameters\nand in particular in extra-axonal axial diffusivity were clearly different from\nprevious studies employing other animal models of MS. In conclusion, our data\nsuggest that DKI and microstructural modeling can provide a unique contrast\ncapable of detecting EAE-specific changes correlating with clinical disability.\nThese findings could close the gap between MRI findings and clinical\npresentation in patients and deepen our understanding of EAE and the MS\nmechanisms."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Harmonic holes as the submodules of brain network and network\n  dissimilarity"}, {"role": "assistant", "content": "Persistent homology has been applied to brain network analysis for finding\nthe shape of brain networks across multiple thresholds. In the persistent\nhomology, the shape of networks is often quantified by the sequence of\n$k$-dimensional holes and Betti numbers.The Betti numbers are more widely used\nthan holes themselves in topological brain network analysis. However, the holes\nshow the local connectivity of networks, and they can be very informative\nfeatures in analysis. In this study, we propose a new method of measuring\nnetwork differences based on the dissimilarity measure of harmonic holes (HHs).\nThe HHs, which represent the substructure of brain networks, are extracted by\nthe Hodge Laplacian of brain networks. We also find the most contributed HHs to\nthe network difference based on the HH dissimilarity. We applied our proposed\nmethod to clustering the networks of 4 groups, normal control (NC), stable and\nprogressive mild cognitive impairment (sMCI and pMCI), and Alzheimer's disease\n(AD). The results showed that the clustering performance of the proposed method\nwas better than that of network distances based on only the global change of\ntopology."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Suppression of the Spectral Cross Talk of Optogenetic Switching by\n  Stimulated Depletion Quenching. Theoretical Analysis"}, {"role": "assistant", "content": "Optogenetics is a rapidly growing field of biotechnology, potentially\nallowing a deeper understanding and control of complex biological networks. The\nmajor challenge is the multiplexed control of several optogenetic components in\nthe presence of significant spectral cross talk. We propose and demonstrate\nthrough simulations a new control approach of Stimulated Depletion Quenching.\nThis approach is applied to the phytochrome Cph8 bidirectional optogenetic\nswitch, and the results show significant improvement of its dynamic range."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Deep learning framework DNN with conditional WGAN for protein solubility\n  prediction"}, {"role": "assistant", "content": "Protein solubility plays a critical role in improving production yield of\nrecombinant proteins in biocatalyst and pharmaceutical field. To some extent,\nprotein solubility can represent the function and activity of biocatalysts\nwhich are mainly composed of recombinant proteins. Highly soluble proteins are\nmore effective in biocatalytic processes and can reduce the cost of\nbiocatalysts. Screening proteins by experiments in vivo is time-consuming and\nexpensive. In literature, large amounts of machine learning models have been\ninvestigated, whereas parameters of those models are underdetermined with\ninsufficient data of protein solubility. A data augmentation algorithm that can\nenlarge the dataset of protein solubility and improve the performance of\nprediction model is highly desired, which can alleviate the common issue of\ninsufficient data in biotechnology applications for developing machine learning\nmodels. We first implemented a novel approach that a data augmentation\nalgorithm, conditional WGAN was used to improve prediction performance of DNN\nfor protein solubility from protein sequence by generating artificial data.\nAfter adding mimic data produced from conditional WGAN, the prediction\nperformance represented by $R^{2}$ was improved compared with the $R^{2}$\nwithout data augmentation. After tuning the hyperparameters of two algorithms\nand organizing the dataset, we achieved a $R^{2}$ value of $45.04\\%$, which\nenhanced $R^{2}$ about $10\\%$ compared with the previous study using the same\ndataset. Data augmentation opens the door to applications of machine learning\nmodels on biological data, as machine learning models always fail to be well\ntrained by small datasets."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Reconstructing the visual perception of honey bees in complex 3-D worlds"}, {"role": "assistant", "content": "Over the last decades, honeybees have been a fascinating model to study\ninsect navigation. While there is some controversy about the complexity of\nunderlying neural correlates, the research of honeybee navigation makes\nprogress through both the analysis of flight behavior and the synthesis of\nagent models. Since visual cues are believed to play a crucial role for the\nbehavioral output of a navigating bee we have developed a realistic\n3-dimensional virtual world, in which simulated agents can be tested, or in\nwhich the visual input of experimentally traced animals can be reconstructed.\nIn this paper we present implementation details on how we reconstructed a large\n3-dimensional world from aerial imagery of one of our field sites, how the\ndistribution of ommatidia and their view geometry was modeled, and how the\nsystem samples from the scene to obtain realistic bee views. This system is\nmade available as an open-source project to the community on\n\\url{http://github.com/bioroboticslab/bee_view}."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multi-level Approximate Bayesian Computation"}, {"role": "assistant", "content": "Approximate Bayesian Computation is widely used to infer the parameters of\ndiscrete-state continuous-time Markov networks. In this work, we focus on\nmodels that are governed by the Chemical Master Equation (the CME). Whilst\noriginally designed to model biochemical reactions, CME-based models are now\nfrequently used to describe a wide range of biological phenomena\nmathematically. We describe and implement an efficient multi-level ABC method\nfor investigating model parameters. In short, we generate sample paths of\nCME-based models with varying time resolutions. We start by generating\nlow-resolution sample paths, which require only limited computational resources\nto construct. Those sample paths that compare well with experimental data are\nselected, and the temporal resolutions of the chosen sample paths are\nrecursively increased. Those sample paths unlikely to aid in parameter\ninference are discarded at an early stage, leading to an optimal use of\ncomputational resources. The efficacy of the multi-level ABC is demonstrated\nthrough two case studies."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantification of sulfated polysaccharides in urine by the Heparin Red\n  mix-and-read fluorescence assay"}, {"role": "assistant", "content": "Quantification of sulfated polysaccharides in urine samples is relevant to\npharmacokinetic studies in drug development projects and to the non-invasive\ndiagnosis and therapy monitoring of mucopolysaccharidoses. The Heparin Red Kit\nis a particularly simple and user friendly fluorescence assay for the\nquantification of sulfated polysaccharides and has recently emerged as a novel\ntool for the monitoring of their blood levels during pharmacokinetic studies in\nclinical trials. The standard protocol for the blood plasma matrix is, however,\nnot suited for urine samples due to matrix interference. The present study\nidentifies inorganic sulfate as the interfering component in urine. The sulfate\nlevel of urine is typically 1-2 orders of magnitude higher compared with the\nblood plasma level. Addition of either hydrochloric acid or magnesium chloride\ncounteracts sulfate interference but still enables sensitive detection of\nsulfated polysaccharides such as heparin, heparan sulfate and dermatan sulfate\nat low microgramm per milliliter levels. This study extends the application\nrange of the Heparin Red Kit by a simple modification of the assay protocol to\nthe direct quantification of various sulfated polysaccharides in human urine."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Fast Proteome Identification and Quantification from Data-Dependent\n  Acquisition - Tandem Mass Spectrometry using Free Software Tools"}, {"role": "assistant", "content": "Identification of nearly all proteins in a system using data-dependent\nacquisition (DDA) mass spectrometry has become routine for simple organisms,\nsuch as bacteria and yeast. Still, quantification of the identified proteins\nmay be a complex process and require multiple different software packages. This\nprotocol describes identification and label-free quantification of proteins\nfrom bottom-up proteomics experiments. This method can be used to quantify all\nthe detectable proteins in any DDA dataset collected with high-resolution\nprecursor scans. This protocol may be used to quantify proteome remodeling in\nresponse to a drug treatment or a gene knockout. Notably, the method uses the\nlatest and fastest freely-available software, and the entire protocol can be\ncompleted in a few hours with data from organisms with relatively small\ngenomes, such as yeast or bacteria."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The observation resolution -- a neglected aspect with critical influence\n  on movement-based foraging indices"}, {"role": "assistant", "content": "Movement-based indices such as moves per minute (MPM) and proportion time\nmoving (PTM) are common methodologies to quantify foraging behaviour. Hundreds\nof studies have reported these indices without specifying the temporal\nresolution of their original data, despite the likelihood that the minimal stop\nand move durations can affect MPM and PTM estimates. Our goal was to\nempirically determine the sensitivity of these foraging indices to changes in\nthe temporal resolution of the observation. We used a high speed camera to\nrecord movement sequences of 20 Acanthodactylus boskianus lizards. We gradually\ndecreased the data resolution by ignoring short stops and either ignoring,\nelongating or leaving short moves unchanged. We then used the manipulated data\nto calculate the foraging indices at different temporal resolutions. We found\nthat movement-based indices are very sensitive to the observation resolution,\nso that realistic variation in the minimal duration of stops and moves could\nlead to 68 percent and 48 percent difference in MPM and PTM estimates,\nrespectively. When using the highest resolution, our estimate of MPM was an\norder of magnitude higher than all prior reported values for lizards. Also, the\ndistribution of stop durations was well described by a single heavy tailed\ndistribution above 0.35 seconds. This suggests that for A. boskianus there is\nno reason to ignore short stops above this threshold. Our results raise major\nconcerns regarding the use of already published movement based indices, and\nenable us to recommend how new foraging data should be collected."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Impact of the reference choice on scalp EEG connectivity estimation"}, {"role": "assistant", "content": "Several scalp EEG functional connectivity studies, mostly clinical, seem to\noverlook the reference electrode impact. The subsequent interpretation of brain\nconnectivity is thus often biased by the choice a non-neutral reference. This\nstudy aims at systematically investigating these effects. As EEG reference, we\nexamined: the vertex electrode (Cz), the digitally linked mastoids (DLM), the\naverage reference (AVE), and the Reference Electrode Standardization Technique\n(REST). As a connectivity metric, we used the imaginary part of coherency. We\ntested simulated and real data (eyes open resting state), by evaluating the\ninfluence of electrode density, effect of head model accuracy in the REST\ntransformation, and impact on the characterization of the topology of\nfunctional networks from graph analysis. Simulations demonstrated that REST\nsignificantly reduced the distortion of connectivity patterns when compared to\nAVE, Cz and DLM references. Moreover, the availability of high-density EEG\nsystems and an accurate knowledge of the head model are crucial elements to\nimprove REST performance. For real data, a systematic change of the spatial\npattern of functional connectivity depending on the chosen reference was also\nobserved. The distortion of connectivity patterns was larger for the Cz\nreference, and progressively decreases when using the DLM, the AVE, the REST.\nStrikingly, we also showed that network attributes derived from graph analysis,\ni.e., node degree and local efficiency, are significantly influenced by the EEG\nreference choice. Overall, this study highlights that significant differences\narise in scalp EEG functional connectivity and graph network properties, in\ndependence of the chosen reference. We hope our study will convey the message\nthat caution should be taken when interpreting and comparing results obtained\nfrom different laboratories when using different reference schemes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: An Indel-Resistant Error-Correcting Code for DNA-Based Information\n  Storage"}, {"role": "assistant", "content": "Synthetic DNA can in principle be used for the archival storage of arbitrary\ndata. Because errors are introduced during DNA synthesis, storage, and\nsequencing, an error-correcting code (ECC) is necessary for error-free recovery\nof the data. Previous work has utilized ECCs that can correct substitution\nerrors, but not insertion or deletion errors (indels), instead relying on\nsequencing depth and multiple alignment to detect and correct indels -- in\neffect an inefficient multiple-repetition code. This paper describes an ECC,\ntermed \"HEDGES\", that corrects simultaneously for substitutions, insertions,\nand deletions in a single read. Varying code rates allow for correction of up\nto ~10% nucleotide errors and achieve 50% or better of the estimated Shannon\nlimit."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Optimizing adaptive cancer therapy: dynamic programming and evolutionary\n  game theory"}, {"role": "assistant", "content": "Recent clinical trials have shown that the adaptive drug therapy can be more\nefficient than a standard MTD-based policy in treatment of cancer patients. The\nadaptive therapy paradigm is not based on a preset schedule; instead, the doses\nare administered based on the current state of tumor. But the adaptive\ntreatment policies examined so far have been largely ad hoc. In this paper we\npropose a method for systematically optimizing the rules of adaptive policies\nbased on an Evolutionary Game Theory model of cancer dynamics. Given a set of\ntreatment objectives, we use the framework of dynamic programming to find the\noptimal treatment strategies. In particular, we optimize the total drug usage\nand time to recovery by solving a Hamilton-Jacobi-Bellman equation based on a\nmathematical model of tumor evolution. We compare adaptive/optimal treatment\nstrategy with MTD-based treatment policy. We show that optimal treatment\nstrategies can dramatically decrease the total amount of drugs prescribed as\nwell as increase the fraction of initial tumour states from which the recovery\nis possible. We also examine the optimization trade-offs between the total\nadministered drugs and recovery time. The adaptive therapy combined with\noptimal control theory is a promising concept in the cancer treatment and\nshould be integrated into clinical trial design."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A network approach to quantifying radiotherapy effect on cancer:\n  Radiosensitive gene group centrality"}, {"role": "assistant", "content": "Radiotherapy plays a vital role in cancer treatment, for which accurate\nprognosis is important for guiding sequential treatment and improving the\ncurative effect for patients. An issue of great significance in radiotherapy is\nto assess tumor radiosensitivity for devising the optimal treatment strategy.\nPrevious studies focused on gene expression in cells closely associated with\nradiosensitivity, but factors such as the response of a cancer patient to\nirradiation and the patient survival time are largely ignored. For clinical\ncancer treatment, a specific pre-treatment indicator taking into account cancer\ncell type and patient radiosensitivity is of great value but it has been\nmissing. Here, we propose an effective indicator for radiosensitivity:\nradiosensitive gene group centrality (RSGGC), which characterizes the\nimportance of the group of genes that are radiosensitive in the whole gene\ncorrelation network. We demonstrate, using both clinical patient data and\nexperimental cancer cell lines, which RSGGC can provide a quantitative estimate\nof the effect of radiotherapy, with factors such as the patient survival time\nand the survived fraction of cancer cell lines under radiotherapy fully taken\ninto account. Our main finding is that, for patients with a higher RSGGC score\nbefore radiotherapy, cancer treatment tends to be more effective. The RSGGC can\nhave significant applications in clinical prognosis, serving as a key measure\nto classifying radiosensitive and radioresistant patients."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Evolutionary Games, Complex Networks and Nonlinear Analysis for\n  Epileptic Seizures Forecasting"}, {"role": "assistant", "content": "Epileptic seizures detection and forecasting is nowadays widely recognized as\na problem of great significance and social resonance, and still remains an\nopen, grand challenge. Furthermore, the development of mobile warning systems\nand wearable, non invasive, advisory devices are increasingly and strongly\nrequested, from the patient community and their families and also from\ninstitutional stakeholders. According to the many recent studies, exploiting\nmachine learning capabilities upon intracranial EEG (iEEG), in this work we\ninvestigate a combination of novel game theory dynamical model on networks for\nbrain electrical activity and nonlinear time series analysis based on\nrecurrences quantification. These two methods are then melted together within a\nsupervised learning scheme and finally, prediction performances are assessed\nusing EEG scalp datasets, specifically recorded for this study. Our study\nachieved mean sensitivity of 70.9% and a mean time in warning of 20.3%, thus\nshowing an increase of the improvement over chance metric from 42%, reported in\nthe most recent study, to 50.5%. Moreover, the real time implementation of the\nproposed approach is currently under development on a prototype of a wearable\ndevice."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Isolating phyllotactic patterns embedded in the secondary growth of\n  sweet cherry (Prunus avium L.) using magnetic resonance imaging"}, {"role": "assistant", "content": "Epicormic branches arise from dormant buds patterned during the growth of\nprevious years. Dormant epicormic buds remain on the surface of trees, pushed\noutward from the pith during secondary growth, but maintaining vascular\nconnections. Epicormic buds can be reactivated, either through natural\nprocesses or intentionally, to rejuvenate orchards and control tree\narchitecture. Because epicormic structures are embedded within secondary\ngrowth, tomographic approaches are a useful method to study them and understand\ntheir development.\n  We apply techniques from image processing to determine the locations of\nepicormic vascular traces embedded within secondary growth of sweet cherry\n(Prunus avium L.), revealing the juvenile phyllotactic pattern in the trunk of\nan adult tree. Techniques include breadth-first search to find the pith of the\ntree, edge detection to approximate the radius, and a conversion to polar\ncoordinates to threshold and segment phyllotactic features. Intensity values\nfrom Magnetic Resonance Imaging (MRI) of the trunk are projected onto the\nsurface of a perfect cylinder to find the locations of traces in the \"boundary\nimage\". Mathematical phyllotaxy provides a means to capture the patterns in the\nboundary image by modeling phyllotactic parameters. Our cherry tree specimen\nhas the conspicuous parastichy pair $(2,3)$, phyllotactic fraction 2/5, and\ndivergence angle of approximately 143 degrees.\n  The methods described not only provide a framework to study phyllotaxy, but\nfor image processing of volumetric image data in plants. Our results have\npractical implications for orchard rejuvenation and directed approaches to\ninfluence tree architecture. The study of epicormic structures, which are\nhidden within secondary growth, using tomographic methods also opens the\npossibility of studying the genetic and environmental basis of such structures."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Influence of Multiple Sequence Alignment Depth on Potts Statistical\n  Models of Protein Covariation"}, {"role": "assistant", "content": "Potts statistical models have become a popular and promising way to analyze\nmutational covariation in protein Multiple Sequence Alignments (MSAs) in order\nto understand protein structure, function and fitness. But the statistical\nlimitations of these models, which can have millions of parameters and are fit\nto MSAs of only thousands or hundreds of effective sequences using a procedure\nknown as inverse Ising inference, are incompletely understood. In this work we\npredict how model quality degrades as a function of the number of sequences\n$N$, sequence length $L$, amino-acid alphabet size $q$, and the degree of\nconservation of the MSA, in different applications of the Potts models: In\n\"fitness\" predictions of individual protein sequences, in predictions of the\neffects of single-point mutations, in \"double mutant cycle\" predictions of\nepistasis, and in 3-d contact prediction in protein structure. We show how as\nMSA depth $N$ decreases an \"overfitting\" effect occurs such that sequences in\nthe training MSA have overestimated fitness, and we predict the magnitude of\nthis effect and discuss how regularization can help correct for it, use a\nregularization procedure motivated by statistical analysis of the effects of\nfinite sampling. We find that as $N$ decreases the quality of point-mutation\neffect predictions degrade least, fitness and epistasis predictions degrade\nmore rapidly, and contact predictions are most affected. However, overfitting\nbecomes negligible for MSA depths of more than a few thousand effective\nsequences, as often used in practice, and regularization becomes less\nnecessary. We discuss the implications of these results for users of Potts\ncovariation analysis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Observability and Structural Identifiability of Nonlinear Biological\n  Systems"}, {"role": "assistant", "content": "Observability is a modelling property that describes the possibility of\ninferring the internal state of a system from observations of its output. A\nrelated property, structural identifiability, refers to the theoretical\npossibility of determining the parameter values from the output. In fact,\nstructural identifiability becomes a particular case of observability if the\nparameters are considered as constant state variables. It is possible to\nsimultaneously analyse the observability and structural identifiability of a\nmodel using the conceptual tools of differential geometry. Many complex\nbiological processes can be described by systems of nonlinear ordinary\ndifferential equations, and can therefore be analysed with this approach. The\npurpose of this review article is threefold: (I) to serve as a tutorial on\nobservability and structural identifiability of nonlinear systems, using the\ndifferential geometry approach for their analysis; (II) to review recent\nadvances in the field; and (III) to identify open problems and suggest new\navenues for research in this area."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Apple Machine Learning Algorithms Successfully Detect Colon Cancer but\n  Fail to Predict KRAS Mutation Status"}, {"role": "assistant", "content": "Colon cancer is the second leading cause of cancer-related death in the\nUnited States of America. Its prognosis has significantly improved with the\nadvancement of targeted therapies based on underlying molecular changes. The\nKRAS mutation is one of the most frequent molecular alterations seen in colon\ncancer and its presence can affect treatment selection. We attempted to use\nApple machine learning algorithms to diagnose colon cancer and predict the KRAS\nmutation status from histopathological images. We captured 250 colon cancer\nimages and 250 benign colon tissue images. Half of colon cancer images were\ncaptured from KRAS mutation-positive tumors and another half from KRAS\nmutation-negative tumors. Next, we created Image Classifier Model using Apple\nCreateML machine learning module. The trained and validated model was able to\nsuccessfully differentiate between colon cancer and benign colon tissue images\nwith 98 % recall and 98 % precision. However, our model failed to reliably\nidentify KRAS mutations, with the highest realized accuracy of 66 %. Although\nnot yet perfected, in the near future Apple CreateML modules can be used in\ndiagnostic smartphone-based applications and potentially alleviate shortages of\nmedical professionals in understaffed parts of the world."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Breaking the bonds of weak coupling: the dynamic causal modelling of\n  oscillator amplitudes"}, {"role": "assistant", "content": "Models of coupled oscillators are useful in describing a wide variety of\nphenomena in physics, biology and economics. These models typically rest on the\npremise that the oscillators are weakly coupled, meaning that amplitudes can be\nassumed to be constant and dynamics can therefore be described purely in terms\nof phase differences. Whilst mathematically convenient, the restrictive nature\nof the weak coupling assumption can limit the explanatory power of these\nphase-coupled oscillator models. We therefore propose an extension to the\nweakly-coupled oscillator model that incorporates both amplitude and phase as\ndependent variables. We use the bilinear neuronal state equations of dynamic\ncausal modelling as a foundation in deriving coupled differential equations\nthat describe the activity of both weakly and strongly coupled oscillators. We\nshow that weakly-coupled oscillator models are inadequate in describing the\nprocesses underlying the temporally variable signals observed in a variety of\nsystems. We demonstrate that phase-coupled models perform well on simulations\nof weakly coupled systems but fail when connectivity is no longer weak. On the\nother hand, using Bayesian model selection, we show that our phase-amplitude\ncoupling model can describe non-weakly coupled systems more effectively despite\nthe added complexity associated with using amplitude as an extra dependent\nvariable. We demonstrate the advantage of our phase-amplitude model in the\ncontext of model-generated data, as well as of a simulation of inter-connected\npendula, neural local field potential recordings in rodents under anaesthesia\nand international economic gross domestic product data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multi-directional dynamic model for traumatic brain injury detection"}, {"role": "assistant", "content": "Traumatic brain injury (TBI) is a complex injury that is hard to predict and\ndiagnose, with many studies focused on associating head kinematics to brain\ninjury risk. Recently, there has been a push towards using computationally\nexpensive finite element (FE) models of the brain to create tissue deformation\nmetrics of brain injury. Here, we developed a 3 degree-of-freedom\nlumped-parameter brain model, built based on the measured natural frequencies\nof a FE brain model simulated with live human impact data, to be used to\nrapidly estimate peak brain strains experienced during head rotational\naccelerations. On our dataset, the simplified model correlates with peak\nprincipal FE strain by an R2 of 0.80. Further, coronal and axial model\ndisplacement correlated with fiber-oriented peak strain in the corpus callosum\nwith an R2 of 0.77. Using the maximum displacement predicted by our brain\nmodel, we propose an injury criteria and compare it against a number of\nexisting rotational and translational kinematic injury metrics on a dataset of\nhead kinematics from 27 clinically diagnosed injuries and 887 non-injuries. We\nfound that our proposed metric performed comparably to peak angular\nacceleration, linear acceleration, and angular velocity in classifying injury\nand non-injury events. Metrics which separated time traces into their\ndirectional components had improved deviance to those which combined components\ninto a single time trace magnitude. Our brain model can be used in future work\nas a computationally efficient alternative to FE models for classifying\ninjuries over a wide range of loading conditions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Extraction of electrokinetically separated analytes with on-demand\n  encapsulation"}, {"role": "assistant", "content": "Microchip electrokinetic methods are capable of increasing the sensitivity of\nmolecular assays by enriching and purifying target analytes. However, their use\nis currently limited to assays that can be performed under a high external\nelectric field, as spatial separation and focusing is lost when the electric\nfield is removed. We present a novel method that uses two-phase encapsulation\nto overcome this limitation. The method uses passive filling and pinning of an\noil phase in hydrophobic channels to encapsulate electrokinetically separated\nand focused analytes with a brief pressure pulse. The resulting encapsulated\nsample droplet maintains its concentration over long periods of time without\nrequiring an electric field and can be manipulated for further analysis, either\non- or off- chip. We demonstrate the method by encapsulating DNA\noligonucleotides in a 240 pL aqueous segment after isotachophoresis (ITP)\nfocusing, and show that the concentration remains at 60% of the initial value\nfor tens of minutes, a 22-fold increase over free diffusion after 20 minutes.\nFurthermore, we demonstrate manipulation of a single droplet by selectively\nencapsulating amplicon after ITP purification from a polymerase chain reaction\n(PCR) mix, and performing parallel off-chip detection reactions using the\ndroplet. We provide geometrical design guidelines for devices implementing the\nencapsulation method, and show how the method can be scaled to multiple analyte\nzones."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Estimating information in time-varying signals"}, {"role": "assistant", "content": "Across diverse biological systems -- ranging from neural networks to\nintracellular signaling and genetic regulatory networks -- the information\nabout changes in the environment is frequently encoded in the full temporal\ndynamics of the network nodes. A pressing data-analysis challenge has thus been\nto efficiently estimate the amount of information that these dynamics convey\nfrom experimental data. Here we develop and evaluate decoding-based estimation\nmethods to lower bound the mutual information about a finite set of inputs,\nencoded in single-cell high-dimensional time series data. For biological\nreaction networks governed by the chemical Master equation, we derive\nmodel-based information approximations and analytical upper bounds, against\nwhich we benchmark our proposed model-free decoding estimators. In contrast to\nthe frequently-used k-nearest-neighbor estimator, decoding-based estimators\nrobustly extract a large fraction of the available information from\nhigh-dimensional trajectories with a realistic number of data samples. We apply\nthese estimators to previously published data on Erk and Ca signaling in\nmammalian cells and to yeast stress-response, and find that substantial amount\nof information about environmental state can be encoded by non-trivial response\nstatistics even in stationary signals. We argue that these single-cell,\ndecoding-based information estimates, rather than the commonly-used tests for\nsignificant differences between selected population response statistics,\nprovide a proper and unbiased measure for the performance of biological\nsignaling networks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Bayesian inference over model-spaces increases the accuracy of model\n  comparison and allows formal testing of hypotheses about model distributions\n  in experimental populations"}, {"role": "assistant", "content": "Determining the best model or models for a particular data set, a process\nknown as Bayesian model comparison, is a critical part of probabilistic\ninference. Typically, this process assumes a fixed model-space (that is, a\nfixed set of candidate models). However, it is also possible to perform\nBayesian inference over model-spaces themselves, thus determining which spaces\nprovide the best explanation for observed data. Model-space inference (MSI)\nallows the effective exclusion of poorly performing models (a process analogous\nto Automatic Relevance Detection), and thus mitigates against the well-known\nphenomenon of model dilution, resulting in posterior probability estimates that\nare, on average, more accurate than those produced when using a fixed\nmodel-space. We focus on model comparison in the context of multiple\nindependent data sets (as produced, for example, by multi-subject behavioural\nor neuroimaging studies), and cast our proposal as a development of\nrandom-effects Bayesian Model Selection, the current state-of-the-art in the\nfield. We demonstrate the increased accuracy of MSI using simulated behavioural\nand neuroimaging data, as well as by assessing predictive performance in\npreviously-acquired empirical data. Additionally, we explore other applications\nof MSI, including formal testing for a diversity of models within a population,\nand comparison of model-spaces between populations. Our approach thus provides\nan important new tool for model comparison."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multiple Microtubule Tracking in Microscopy Time-Lapse Images Using\n  Piecewise-stationary Multiple Motion Model Kalman Smoother"}, {"role": "assistant", "content": "Microtubules are inherently dynamic sub-cellular filamentuous polymers that\nare spatially organized within the cell by motor proteins which cross-link and\nmove microtubules. In-vitro microtubule motility assays, in which motors\nattached to a surface move microtubules along it, have been used traditionally\nto study motor function. However, the way in which microtubule-microtubule\ninteractions affect microtubule movement remains largely unexplored. To address\nthis question, time-lapse image series of in-vitro microtubule motility assays\nwere obtained using total internal reflection fluorescence (TIRF) microscopy.\nCategorized as a general problem of multiple object tracking (MOT), particular\nchallenges arising in this project include low feature diversity, dynamic\ninstability, sudden changes in microtubules motility patterns, as well as their\ninstantaneous appearance/disappearance. This work describes a new application\nof piecewise-stationary multiple motion model Kalman smoother (PMMS) for\nmodeling individual microtubules motility trends. To both evaluate the\ncapability of this procedure and optimize its hyper-parameters, a large dataset\nsimulating the series of time-lapse images was used first. Next, we applied it\nto the sequence of frames from the real data. Results of our analyses provide a\nquantitative description of microtubule velocity which, in turn, enumerates the\noccurrence of microtubule-microtubule interactions per frame."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Hybrid Modelling in Oncology: Sucesses, Challenges and Hopes"}, {"role": "assistant", "content": "In this review we make the statement that hybrid models in oncology are\nrequired as a mean for enhanced data integration. In the context of systems\noncology, experimental and clinical data need to be at the heart of the models\ndevelopments from conception to validation to ensure a relevant use of the\nmodels in the clinical context. The main applications pursued are to improve\ndiagnosis and to optimize therapies.We first present the Successes achieved\nthanks to hybrid modelling approaches to advance knowledge, treatments or drug\ndiscovery. Then we present the Challenges than need to be addressed to allow\nfor a better integration of the model parts and of the data into the models.\nAnd Finally, the Hopes with a focus towards making personalised medicine a\nreality. Mathematics Subject Classification. 35Q92, 68U20, 68T05, 92-08, 92B05."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: ariaDNE: A Robustly Implemented Algorithm for Dirichlet Energy of the\n  Normal"}, {"role": "assistant", "content": "Point 1: Shape characterizers are metrics that quantify aspects of the\noverall geometry of a 3D digital surface. When computed for biological objects,\nthe values of a shape characterizer are largely independent of homology\ninterpretations and often contain a strong ecological and functional signal.\nThus shape characterizers are useful for understanding evolutionary processes.\nDirichlet Normal Energy (DNE) is a widely used shape characterizer in\nmorphological studies.\n  Point 2: Recent studies found that DNE is sensitive to various procedures for\npreparing 3D mesh from raw scan data, raising concerns regarding comparability\nand objectivity when utilizing DNE in morphological research. We provide a\nrobustly implemented algorithm for computing the Dirichlet energy of the normal\n(ariaDNE) on 3D meshes.\n  Point 3: We show through simulation that the effects of preparation-related\nmesh surface attributes such as triangle count, mesh representation, noise,\nsmoothing and boundary triangles are much more limited on ariaDNE than DNE.\nFurthermore, ariaDNE retains the potential of DNE for biological studies,\nillustrated by its effectiveness in differentiating species by dietary\npreferences.\n  Point 4: Use of ariaDNE can dramatically enhance assessment of ecological\naspects of morphological variation by its stability under different 3D model\nacquisition methods and preparation procedure. Towards this goal, we provide\nscripts for computing ariaDNE and ariaDNE values for specimens used in\npreviously published DNE analyses."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Vagal contributions to fetal heart rate variability: an omics approach"}, {"role": "assistant", "content": "Fetal heart rate variability (fHRV) is an important indicator of health and\ndisease, yet its physiological origins, neural contributions in particular, are\nnot well understood. We aimed to develop novel experimental and data analytical\napproaches to identify fHRV measures reflecting the vagus nerve contributions\nto fHRV. In near-term ovine fetuses, a comprehensive set of 46 fHRV measures\nwas computed from fetal pre-cordial electrocardiogram recorded during surgery\nand 72 hours later without (n=24) and with intra-surgical bilateral cervical\nvagotomy (n=15). The fetal heart rate did not change due to vagotomy. We\nidentify fHRV measures specific to the vagal modulation of fHRV: Multiscale\ntime irreversibility asymmetry index (AsymI), Detrended fluctuation analysis\n(DFA) alpha1, Kullback-Leibler permutation entropy (KLPE) and Scale dependent\nLyapunov exponent slope (SDLE alpha). We provide a systematic delineation of\nvagal contributions to fHRV across signal-analytical domains which should be\nrelevant for the emerging field of bioelectronic medicine and the deciphering\nof the vagus code. Our findings also have clinical significance for in utero\nmonitoring of fetal health during surgery."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A simple mechanochemical model for calcium signalling in embryonic\n  epithelial cells"}, {"role": "assistant", "content": "Calcium (Ca2+) signalling is one of the most important mechanisms of\ninformation propagation in the body. In embryogenesis the interplay between\nCa2+ signalling and mechanical forces is critical to the healthy development of\nan embryo but poorly understood. Several types of embryonic cells exhibit\ncalcium-induced contractions and many experiments indicate that Ca2+ signals\nand contractions are coupled via a two-way mechanochemical coupling. We present\na new analysis of experimental data that supports the existence of this\ncoupling during Apical Constriction in Neural Tube Closure. We then propose a\nmechanochemical model, building on early models that couple Ca2+ dynamics to\ncell mechanics and replace the bistable Ca2+ release with modern,\nexperimentally validated Ca2+ dynamics. We assume that the cell is a linear\nviscoelastic material and model the Ca2+-induced contraction stress with a Hill\nfunction saturating at high Ca2+ levels. We also express, for the first time,\nthe \"stretch-activation\" Ca2+ flux in the early mechanochemical models as a\nbottom-up contribution from stretch-sensitive Ca2+ channels on the cell\nmembrane. We reduce the model to three ordinary differential equations and\nanalyse its bifurcation structure semi-analytically as the $IP_3$\nconcentration, and the \"strength\" of stretch activation, $\\lambda$ vary. The\nCa2+ system ($\\lambda=0$, no mechanics) exhibits relaxation oscillations for a\ncertain range of $IP_3$ values. As $\\lambda$ is increased the range of $IP_3$\nvalues decreases, the oscillation amplitude decreases and the frequency\nincreases. Oscillations vanish for a sufficiently high value of $\\lambda$.\nThese results agree with experiments in embryonic cells that also link the loss\nof Ca2+ oscillations to embryo abnormalities. The work addresses a very\nimportant and understudied question on the coupling of chemical and mechanical\nsignalling in embryogenesis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Rapid and cost-effective evaluation of bacterial viability using\n  fluorescence spectroscopy"}, {"role": "assistant", "content": "The fluorescence spectra of bacterial samples stained with SYTO 9 and\npropidium iodide (PI) were used to monitor bacterial viability. Stained\nmixtures of live and dead Escherichia coli with proportions of live:dead cells\nvarying from 0 to 100% were measured using the optrode, a cost effective and\nconvenient fibre-based spectroscopic device. We demonstrated several approaches\nto obtaining the proportions of live:dead E. coli in a mixture of both live and\ndead, from analyses of the fluorescence spectra collected by the optrode. To\nfind a suitable technique for predicting the percentage of live bacteria in a\nsample, four analysis methods were assessed and compared: SYTO 9:PI\nfluorescence intensity ratio, an adjusted fluorescence intensity ratio,\nsingle-spectrum support vector regression (SVR) and multi-spectra SVR. Of the\nfour analysis methods, multi-spectra SVR obtained the most reliable results and\nwas able to predict the percentage of live bacteria in 10^8 bacteria/mL samples\nbetween c. 7% and 100% live, and in 10^7 bacteria/mL samples between c. 7% and\n73% live. By demonstrating the use of multi-spectra SVR and the optrode to\nmonitor E. coli viability, we raise points of consideration for spectroscopic\nanalysis of SYTO 9 and PI and aim to lay the foundation for future work that\nuse similar methods for different bacterial species."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The threshold age of Keyfitz' entropy"}, {"role": "assistant", "content": "BACKGROUND Indicators of relative inequality of lifespans are important\nbecause they capture the dimensionless shape of aging. They are markers of\ninequality at the population level and express the uncertainty at the time of\ndeath at the individual level. In particular, Keyfitz' entropy $\\bar{H}$\nrepresents the elasticity of life expectancy to a change in mortality and it\nhas been used as an indicator of lifespan variation. However, it is unknown how\nthis measure changes over time and whether a threshold age exists, as it does\nfor other lifespan variation indicators.\n  RESULTS The time derivative of $\\bar{H}$ can be decomposed into changes in\nlife disparity $e^\\dagger$ and life expectancy at birth $e_o$. Likewise,\nchanges over time in $\\bar{H}$ are a weighted average of age-specific rates of\nmortality improvements. These weights reflect the sensitivity of $\\bar{H}$ and\nshow how mortality improvements can increase (or decrease) the relative\ninequality of lifespans. Further, we prove that $\\bar{H}$, as well as\n$e^\\dagger$, in the case that mortality is reduced in every age, has a\nthreshold age below which saving lives reduces entropy, whereas improvements\nabove that age increase entropy.\n  CONTRIBUTION We give a formal expression for changes over time of $\\bar{H}$\nand provide a formal proof of the threshold age that separates reductions and\nincreases in lifespan inequality from age-specific mortality improvements."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Unveiling new disease, pathway, and gene associations via multi-scale\n  neural networks"}, {"role": "assistant", "content": "Diseases involve complex processes and modifications to the cellular\nmachinery. The gene expression profile of the affected cells contains\ncharacteristic patterns linked to a disease. Hence, biological knowledge\npertaining to a disease can be derived from a patient cell's profile, improving\nour diagnosis ability, as well as our grasp of disease risks. This knowledge\ncan be used for drug re-purposing, or by physicians to evaluate a patient's\ncondition and co-morbidity risk. Here, we look at differential gene expression\nobtained from microarray technology for patients diagnosed with various\ndiseases. Based on this data and cellular multi-scale organization, we aim to\nuncover disease--disease links, as well as disease-gene and disease--pathways\nassociations. We propose neural networks with structures inspired by the\nmulti-scale organization of a cell. We show that these models are able to\ncorrectly predict the diagnosis for the majority of the patients. Through the\nanalysis of the trained models, we predict and validate disease-disease,\ndisease-pathway, and disease-gene associations with comparisons to known\ninteractions and literature search, proposing putative explanations for the\nnovel predictions that come from our study."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Modeling and inference of spatio-temporal protein dynamics across brain\n  networks"}, {"role": "assistant", "content": "Models of misfolded proteins (MP) aim at discovering the bio-mechanical\npropagation properties of neurological diseases (ND) by identifying plausible\nassociated dynamical systems. Solving these systems along the full disease\ntrajectory is usually challenging, due to the lack of a well defined time axis\nfor the pathology. This issue is addressed by disease progression models (DPM)\nwhere long-term progression trajectories are estimated via time\nreparametrization of individual observations. However, due to their loose\nassumptions on the dynamics, DPM do not provide insights on the bio-mechanical\nproperties of MP propagation. Here we propose a unified model of\nspatio-temporal protein dynamics based on the joint estimation of long-term MP\ndynamics and time reparameterization of individuals observations. The model is\nexpressed within a Gaussian Process (GP) regression setting, where constraints\non the MP dynamics are imposed through non--linear dynamical systems. We use\nstochastic variational inference on both GP and dynamical system parameters for\nscalable inference and uncertainty quantification of the trajectories.\nExperiments on simulated data show that our model accurately recovers\nprescribed rates along graph dynamics and precisely reconstructs the underlying\nprogression. When applied to brain imaging data our model allows the\nbio-mechanical interpretation of amyloid deposition in Alzheimer's disease,\nleading to plausible simulations of MP propagation, and achieving accurate\npredictions of individual MP deposition in unseen data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Pressure Actuated Cellular Structures"}, {"role": "assistant", "content": "This postdoctoral thesis starts by reviewing the historic development of\nairplane structures and high lift devices from an engineering point of view.\nHowever, the main purpose of this document is the development of a novel\nconcept for shape changing, gapless high lift devices that is inspired by the\nnastic movement of plants. A particular focus is put on the efficient\nsimulation and optimization of compliant pressure actuated cellular structures."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: 3D mesh processing using GAMer 2 to enable reaction-diffusion\n  simulations in realistic cellular geometries"}, {"role": "assistant", "content": "Recent advances in electron microscopy have enabled the imaging of single\ncells in 3D at nanometer length scale resolutions. An uncharted frontier for in\nsilico biology is the ability to simulate cellular processes using these\nobserved geometries. Enabling such simulations requires watertight meshing of\nelectron micrograph images into 3D volume meshes, which can then form the basis\nof computer simulations of such processes using numerical techniques such as\nthe Finite Element Method. In this paper, we describe the use of our recently\nrewritten mesh processing software, GAMer 2, to bridge the gap between poorly\nconditioned meshes generated from segmented micrographs and boundary marked\ntetrahedral meshes which are compatible with simulation. We demonstrate the\napplication of a workflow using GAMer 2 to a series of electron micrographs of\nneuronal dendrite morphology explored at three different length scales and show\nthat the resulting meshes are suitable for finite element simulations. This\nwork is an important step towards making physical simulations of biological\nprocesses in realistic geometries routine. Innovations in algorithms to\nreconstruct and simulate cellular length scale phenomena based on emerging\nstructural data will enable realistic physical models and advance discovery at\nthe interface of geometry and cellular processes. We posit that a new frontier\nat the intersection of computational technologies and single cell biology is\nnow open."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Differentiation of skin incision and laparoscopic trocar insertion via\n  quantifying transient bradycardia measured by electrocardiogram"}, {"role": "assistant", "content": "Background. Most surgical procedures involve structures deeper than the skin.\nHowever, the difference in surgical noxious stimulation between skin incision\nand laparoscopic trocar insertion is unknown. By analyzing instantaneous heart\nrate (IHR) calculated from the electrocardiogram, in particular the transient\nbradycardia in response to surgical stimuli, this study investigates surgical\nnoxious stimuli arising from skin incision and laparoscopic trocar insertion.\nMethods. Thirty-five patients undergoing laparoscopic cholecystectomy were\nenrolled in this prospective observational study. Sequential surgical steps\nincluding umbilical skin incision (11 mm), umbilical trocar insertion (11 mm),\nxiphoid skin incision (5 mm), xiphoid trocar insertion (5 mm), subcostal skin\nincision (3 mm), and subcostal trocar insertion (3 mm) were investigated. IHR\nwas derived from electrocardiography and calculated by the modern time-varying\npower spectrum. Similar to the classical heart rate variability analysis, the\ntime-varying low frequency power (tvLF), time-varying high frequency power\n(tvHF), and tvLF-to-tvHF ratio (tvLHR) were calculated. Prediction probability\n(PK) analysis and global pointwise F-test were used to compare the performance\nbetween indices and the heart rate readings from the patient monitor. Results.\nAnalysis of IHR showed that surgical stimulus elicits a transient bradycardia,\nfollowed by the increase of heart rate. Transient bradycardia is more\nsignificant in trocar insertion than skin incision. The IHR change quantifies\ndifferential responses to different surgical intensity. Serial PK analysis\ndemonstrates de-sensitization in skin incision, but not in laparoscopic trocar\ninsertion. Conclusions. Quantitative indices present the transient bradycardia\nintroduced by noxious stimulation. The results indicate different effects\nbetween skin incision and trocar insertion."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Accurate and robust segmentation of neuroanatomy in T1-weighted MRI by\n  combining spatial priors with deep convolutional neural networks"}, {"role": "assistant", "content": "Neuroanatomical segmentation in magnetic resonance imaging (MRI) of the brain\nis a prerequisite for volume, thickness and shape measurements. This work\nintroduces a new highly accurate and versatile method based on 3D convolutional\nneural networks for the automatic segmentation of neuroanatomy in T1-weighted\nMRI. In combination with a deep 3D fully convolutional architecture, efficient\nlinear registration-derived spatial priors are used to incorporate additional\nspatial context into the network. An aggressive data augmentation scheme using\nrandom elastic deformations is also used to regularize the networks, allowing\nfor excellent performance even in cases where only limited labelled training\ndata are available. Applied to hippocampus segmentation in an elderly\npopulation (mean Dice coefficient = 92.1%) and sub-cortical segmentation in a\nhealthy adult population (mean Dice coefficient = 89.5%), we demonstrate new\nstate-of-the-art accuracies and a high robustness to outliers with the same\narchitecture. Further validation on a multi-structure segmentation task in a\nscan-rescan dataset demonstrates accuracy (mean Dice coefficient = 86.6%)\nsimilar to the scan-rescan reliability of expert manual segmentations (mean\nDice coefficient = 86.9%), and improved reliability compared to both expert\nmanual segmentations and automated segmentations using FIRST. Furthermore, our\nmethod maintains a highly competitive runtime performance (e.g. requiring only\n10 seconds for left/right hippocampal segmentation in 1x1x1 MNI stereotaxic\nspace), orders of magnitude faster than conventional multi-atlas segmentation\nmethods."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: IMPACT: Interval-based Multi-pass Proteomic Alignment with Constant\n  Traceback"}, {"role": "assistant", "content": "Darwin is a genomics co-processor that achieved a 15000x acceleration on long\nread assembly through innovative hardware and algorithm co-design. Darwins\nalgorithms and hardware implementation were specifically designed for DNA\nanalysis pipelines. This paper analyzes the feasibility of applying Darwins\nalgorithms to the problem of protein sequence alignment. In addition to a\nbehavioral analysis of Darwin when aligning proteins, we propose an algorithmic\nimprovement to Darwins alignment algorithm, GACT, in the form of a multi-pass\nvariant that increases its accuracy on protein sequence alignment. Concretely,\nour proposed multi-pass variant of GACT achieves on average 14\\% better\nalignment scores."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Comprehensive review of models and methods for inferences in\n  bio-chemical reaction networks"}, {"role": "assistant", "content": "Key processes in biological and chemical systems are described by networks of\nchemical reactions. From molecular biology to biotechnology applications,\ncomputational models of reaction networks are used extensively to elucidate\ntheir non-linear dynamics. Model dynamics are crucially dependent on parameter\nvalues which are often estimated from observations. Over past decade, the\ninterest in parameter and state estimation in models of (bio-)chemical reaction\nnetworks (BRNs) grew considerably. Statistical inference problems are also\nencountered in many other tasks including model calibration, discrimination,\nidentifiability and checking as well as optimum experiment design, sensitivity\nanalysis, bifurcation analysis and other. The aim of this review paper is to\nexplore developments of past decade to understand what BRN models are commonly\nused in literature, and for what inference tasks and inference methods. Initial\ncollection of about 700 publications excluding books in computational biology\nand chemistry were screened to select over 260 research papers and 20 graduate\ntheses concerning estimation problems in BRNs. The paper selection was\nperformed as text mining using scripts to automate search for relevant keywords\nand terms. The outcome are tables revealing the level of interest in different\ninference tasks and methods for given models in literature as well as recent\ntrends. In addition, a brief survey of general estimation strategies is\nprovided to facilitate understanding of estimation methods which are used for\nBRNs. Our findings indicate that many combinations of models, tasks and methods\nare still relatively sparse representing new research opportunities to explore\nthose that have not been considered - perhaps for a good reason. The paper\nconcludes by discussing future research directions including research problems\nwhich cannot be directly deduced from presented tables."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Robust and fast heart rate variability analysis of long and noisy\n  electrocardiograms using neural networks and images"}, {"role": "assistant", "content": "Heart rate variability studies depend on the robust calculation of the\ntachogram, the heart rate times series, usually by the detection of R peaks in\nthe electrocardiogram (ECG). ECGs however are subject to a number of sources of\nnoise which are difficult to filter and therefore reduce the tachogram\naccuracy. We describe a pipeline for fast calculation of tachograms from noisy\nECGs of several hours' length. The pipeline consists of three stages. A neural\nnetwork (NN) trained to detect R peaks and distinguish these from noise; a\nmeasure to robustly detect false positives (FPs) and negatives (FNs) produced\nby the NN; a simple \"alarm\" algorithm for automatically removing FPs and\ninterpolating FNs. In addition, we introduce the approach of encoding ECGs,\ntachograms and other cardiac time series in the form of raster images, which\ngreatly speeds and eases their visual inspection and analysis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A pharmacokinetic model of lead absorption and calcium competitive\n  dynamics"}, {"role": "assistant", "content": "Lead is a naturally-occurring element. It has been known to man for a long\ntime, and it is one of the longest established poisons. The current consensus\nis that no level of lead exposure should be deemed \"safe.\" New evidence\nregarding the blood levels at which morbidities occur has prompted the CDC to\nreduce the screening guideline of 10 $\\mu$g/dl to 2 $\\mu$g/dl. Measurable\ncognitive decline (reduced IQ, academic deficits) have been found to occur at\nlevels below 10mg/dl.\n  Knowledge of lead pharmacology allows us to better understand its absorption\nand metabolization, mechanisms that produce its medical consequences. Based\nupon an original and very simplified compartmental model of Rabinowitz (1973)\nwith only three major compartments (blood, bone and soft tissue), extensive\nbiophysical models sprouted over the following two decades. However, none of\nthese models have been specifically designed to use new knowledge of lead\nmolecular dynamics to understand its deleterious effects on the brain. We build\nand analyze a compartmental model of lead pharmacokinetics, focused\nspecifically on addressing neurotoxicity. We use traditional phase space\nmethods, parameter sensitivity analysis and bifurcation theory to study the\ntransitions in the system's behavior in response to various physiological\nparameters.\n  We conclude that modeling the complex interaction of lead and calcium along\ntheir dynamic trajectory may successfully explain counter-intuitive effects on\nsystemic function and neural behavior which could not be addressed by existing\nlinear models. Our results encourage further efforts towards using nonlinear\nphenomenology in conjunction with empirically driven system parameters, to\nobtain a biophysical model able to provide clinical assessments and\npredictions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: In Vivo Wireless Sensors for Gut Microbiome Redox Monitoring"}, {"role": "assistant", "content": "A perturbed gut microbiome has recently been linked with multiple disease\nprocesses, yet researchers currently lack tools that can provide in vivo,\nquantitative, and real-time insight into these processes and associated\nhost-microbe interactions. We propose an in vivo wireless implant for\nmonitoring gastrointestinal tract redox states using oxidation-reduction\npotentials (ORP). The implant is powered and conveniently interrogated via\nultrasonic waves. We engineer the sensor electronics, electrodes, and\nencapsulation materials for robustness in vivo, and integrate them into an\nimplant that endures autoclave sterilization and measures ORP for 12 days\nimplanted in the cecum of a live rat. The presented implant platform paves the\nway for long-term experimental testing of biological hypotheses, offering new\nopportunities for understanding gut redox pathophysiology mechanisms, and\nfacilitating translation to disease diagnosis and treatment applications."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantitative analysis of timing in animal vocal sequences"}, {"role": "assistant", "content": "Timing features such as the silence gaps between vocal units -- inter-call\nintervals (ICIs) -- often correlate with biological information such as context\nor genetic information. Such correlates between the ICIs and biological\ninformation have been reported for a diversity of animals. Yet, few\nquantitative approaches for investigating timing exist to date. Here, we\npropose a novel approach for quantitatively comparing timing in animal\nvocalisations in terms of the typical ICIs. As features, we use the\ndistribution of silence gaps parametrised with a kernel density estimate (KDE)\nand compare the distributions with the symmetric Kullback-Leibler divergence\n(sKL-divergence). We use this technique to compare timing in vocalisations of\ntwo frog species, a group of zebra finches and calls from parrots of the same\nspecies. As a main finding, we demonstrate that in our dataset, closely related\nspecies have more similar distributions than species genetically more distant,\nwith sKL-divergences across-species larger than within-species distances.\nCompared with more standard methods such as Fourier analysis, the proposed\nmethod is more robust to different durations present in the data samples,\nflexibly applicable to different species and easy to interpret. Investigating\ntiming in animal vocalisations may thus contribute to taxonomy, support\nconservation efforts by helping monitoring animals in the wild and may shed\nlight onto the origins of timing structures in animal vocal communication."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Classification of diffusion modes in single-particle tracking data:\n  Feature-based versus deep-learning approach"}, {"role": "assistant", "content": "Single-particle trajectories measured in microscopy experiments contain\nimportant information about dynamic processes undergoing in a range of\nmaterials including living cells and tissues. However, extracting that\ninformation is not a trivial task due to the stochastic nature of particles'\nmovement and the sampling noise. In this paper, we adopt a deep-learning method\nknown as a convolutional neural network (CNN) to classify modes of diffusion\nfrom given trajectories. We compare this fully automated approach working with\nraw data to classical machine learning techniques that require data\npreprocessing and extraction of human-engineered features from the trajectories\nto feed classifiers like random forest or gradient boosting. All methods are\ntested using simulated trajectories for which the underlying physical model is\nknown. From the results it follows that CNN is usually slightly better than the\nfeature-based methods, but at the costs of much longer processing times.\nMoreover, there are still some borderline cases, in which the classical methods\nperform better than CNN."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Density distributions and depth in flocks"}, {"role": "assistant", "content": "Recent experimental evidence suggests that interactions in flocks of birds do\nnot involve a characteristic length scale. Bird flocks have also been revealed\nto have an inhomogeneous density distribution, with the density of birds near\nthe border greater than near the centre. We introduce a strictly metric-free\nmodel for collective behaviour that incorporates a distributed motional bias,\nproviding control of the density distribution. A simple version of this model\nis then able to provide a good fit to published data for the density variation\nacross flocks of Starlings. We find that it is necessary for individuals on the\nedge of the flock to have an inward motional bias but that birds in the\ninterior of the flock instead must have an outward bias. We discuss the ability\nof individuals to determine their depth within a flock and show how this might\nbe achieved by relatively simple analysis of their visual environment."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Categorical Compositional Distributional Modelling for the Language of\n  Life"}, {"role": "assistant", "content": "The Categorical Compositional Distributional (DisCoCat) Model is a powerful\nmathematical model for composing the meaning of sentences in natural languages.\nSince we can think of biological sequences as the \"language of life\", it is\nattempting to apply the DisCoCat model on the language of life to see if we can\nobtain new insights and a better understanding of the latter. In this work, we\ntook an initial step towards that direction. In particular, we choose to focus\non proteins as the linguistic features of protein are the most prominent as\ncompared with other macromolecules such as DNA or RNA. Concretely, we treat\neach protein as a sentence and its constituent domains as words. The meaning of\na word or the sentence is just its biological function, and the arrangement of\ndomains in a protein corresponds to the syntax. Putting all those into the\nDisCoCat framework, we can \"compute\" the function of a protein based on the\nfunctions of its domains with the grammar rules that combine them together.\nSince the functions of both the protein and its domains are represented in\nvector spaces, we provide a novel way to formalize the functional\nrepresentation of proteins."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The homeostatic dynamics of feeding behaviour identify novel mechanisms\n  of anorectic agents"}, {"role": "assistant", "content": "Better understanding of feeding behaviour will be vital in reducing obesity\nand metabolic syndrome, but we lack a standard model that captures the\ncomplexity of feeding behaviour. We construct an accurate stochastic model of\nrodent feeding at the bout level in order to perform quantitative behavioural\nanalysis. Analysing the different effects on feeding behaviour of PYY 3-36,\nlithium chloride, GLP-1 and leptin shows the precise behavioural changes caused\nby each anorectic agent, and demonstrates that these changes do not mimic\nsatiety. In the ad libitum fed state during the light period, meal initiation\nis governed by complete stomach emptying, whereas in all other conditions there\nis a graduated response. We show how robust homeostatic control of feeding\nthwarts attempts to reduce food intake, and how this might be overcome. In\nsilico experiments suggest that introducing a minimum intermeal interval or\nmodulating gastric emptying can be as effective as anorectic drug\nadministration."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Fetus: the radar of maternal stress, a cohort study"}, {"role": "assistant", "content": "Objective: We hypothesized that prenatal stress (PS) exerts lasting impact on\nfetal heart rate (fHR). We sought to validate the presence of such PS signature\nin fHR by measuring coupling between maternal HR (mHR) and fHR. Study design:\nProspective observational cohort study in stressed group (SG) mothers with\ncontrols matched for gestational age during screening at third trimester using\nCohen Perceived Stress Scale (PSS) questionnaire with PSS-10 equal or above 19\nclassified as SG. Women with PSS-10 less than 19 served as control group (CG).\nSetting: Klinikum rechts der Isar of the Technical University of Munich.\nPopulation: Singleton 3rd trimester pregnant women. Methods: Transabdominal\nfetal electrocardiograms (fECG) were recorded. We deployed a signal processing\nalgorithm termed bivariate phase-rectified signal averaging (BPRSA) to quantify\ncoupling between mHR and fHR resulting in a fetal stress index (FSI). Maternal\nhair cortisol was measured at birth. Differences were assumed to be significant\nfor p value less than 0.05. Main Outcome Measures: Differences for FSI between\nboth groups. Results: We screened 1500 women enrolling 538 of which 16.5 %\nshowed a PSS-10 score equal or above 19 at 34+0 weeks. Fifty five women\neventually comprised the SG and n=55 served as CG. Median PSS was 22.0 (IQR\n21.0-24.0) in the SG and 9.0 (6.0-12.0) in the CG, respectively. Maternal hair\ncortisol was higher in SG than CG at 86.6 (48.0-169.2) versus 53.0 (34.4-105.9)\npg/mg. At 36+5 weeks, FSI was significantly higher in fetuses of stressed\nmothers when compared to controls [0.43 (0.18-0.85) versus 0.00 (-0.49-0.18)].\nConclusion: Our findings show a persistent effect of PS affecting fetuses in\nthe last trimester."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A tutorial on group effective connectivity analysis, part 2: second\n  level analysis with PEB"}, {"role": "assistant", "content": "This tutorial provides a worked example of using Dynamic Causal Modelling\n(DCM) and Parametric Empirical Bayes (PEB) to characterise inter-subject\nvariability in neural circuitry (effective connectivity). This involves\nspecifying a hierarchical model with two or more levels. At the first level,\nstate space models (DCMs) are used to infer the effective connectivity that\nbest explains a subject's neuroimaging timeseries (e.g. fMRI, MEG, EEG).\nSubject-specific connectivity parameters are then taken to the group level,\nwhere they are modelled using a General Linear Model (GLM) that partitions\nbetween-subject variability into designed effects and additive random effects.\nThe ensuing (Bayesian) hierarchical model conveys both the estimated connection\nstrengths and their uncertainty (i.e., posterior covariance) from the subject\nto the group level; enabling hypotheses to be tested about the commonalities\nand differences across subjects. This approach can also finesse parameter\nestimation at the subject level, by using the group-level parameters as\nempirical priors. We walk through this approach in detail, using data from a\npublished fMRI experiment that characterised individual differences in\nhemispheric lateralization in a semantic processing task. The preliminary\nsubject specific DCM analysis is covered in detail in a companion paper. This\ntutorial is accompanied by the example dataset and step-by-step instructions to\nreproduce the analyses."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: How to Hallucinate Functional Proteins"}, {"role": "assistant", "content": "Here we present a novel approach to protein design and phenotypic inference\nusing a generative model for protein sequences. BioSeqVAE, a variational\nautoencoder variant, can hallucinate syntactically valid protein sequences that\nare likely to fold and function. BioSeqVAE is trained on the entire known\nprotein sequence space and learns to generate valid examples of protein\nsequences in an unsupervised manner. The model is validated by showing that its\nlatent feature space is useful and that it accurately reconstructs sequences.\nIts usefulness is demonstrated with a selection of relevant downstream design\ntasks. This work is intended to serve as a computational first step towards a\ngeneral purpose structure free protein design tool."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Global analysis of a simplified model of anaerobic digestion and a new\n  result for the chemostat"}, {"role": "assistant", "content": "A. Bornh\\\"oft, R. Hanke-Rauschenbach, and K. Sundmacher, [Nonlinear Dyn., 73\n(2013), pp. 535-549] introduced a qualitative simplification to the ADM1 model\nfor anaerobic digestion. We obtain global results for this model by first\nanalyzing the limiting system, a model of single species growth in the\nchemostat in which the response function is non-monotone and the species decay\nrate is included. Using a Lyapunov function argument and the theory of\nasymptotically autonomous systems, we prove that even in the parameter regime\nwhere there is bistability, no periodic orbits exist and every solution\nconverges to one of the equilibrium points. We then describe two algorithms for\nstochastically perturbing the parameters of the model. Simulations done with\nthese two algorithms are compared with simulations done using the Gillespie and\ntau-leaping algorithms. They illustrate the severe impact environmental factors\nmay have on anaerobic digestion in the transient phase."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: ColourQuant: a high-throughput technique to extract and quantify colour\n  phenotypes from plant images"}, {"role": "assistant", "content": "Colour patterning contributes to important plant traits that influence\necological interactions, horticultural breeding, and agricultural performance.\nHigh-throughput phenotyping of colour is valuable for understanding plant\nbiology and selecting for traits related to colour during plant breeding. Here\nwe present ColourQuant, an automated high-throughput pipeline that allows users\nto extract colour phenotypes from images. This pipeline includes methods for\ncolour phenotyping using mean pixel values, Gaussian density estimator of Lab\ncolour, and the analysis of shape-independent colour patterning by circular\ndeformation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Hierarchical microplates as drug depots with controlled geometry,\n  rigidity and therapeutic efficacy"}, {"role": "assistant", "content": "A variety of microparticles have been proposed for the sustained and\nlocalized delivery of drugs whit the objective of increasing therapeutic\nindexes by circumventing filtering organs and biological barriers. Yet, the\ngeometrical, mechanical and therapeutic properties of such microparticles\ncannot be simultaneously and independently tailored during the fabrication\nprocess in order to optimize their performance. In this work, a top-down\napproach is employed to realize micron-sized polymeric particles, called\nmicroPlates (uPLs), for the sustained release of therapeutic agents. uPLs are\nsquare hydrogel particles, with an edge length of 20 um and a height of 5 um,\nmade out of poly (lactic co glycolic acid) (PLGA). During the synthesis\nprocess, the uPL Young's modulus can be varied from 0.6 to 5 MPa by changing\nPLGA amounts from 1 to 7.5 mg, without affecting the uPL geometry. Within the\nporous uPL matrix, different classes of therapeutic payloads can be\nincorporated including molecular agents, such as the anti-inflammatory\ndexamethasone (DEX), and nanoparticles, containing themselves imaging and\ntherapeutic molecules. As a proof of principle, uPLs are loaded with free DEX\nand 200 nm spherical polymeric nanoparticles, carrying DEX molecules\n(DEX-SPNs). Electron and fluorescent confocal microscopy analyses document the\nuniform distribution and stability of molecular and nano agents within the uPL\nmatrix. This multiscale, hierarchical microparticle releases DEX for at least\n10 days. The inclusion of DEX-SPNs serves to minimize the initial burst release\nand modulate the diffusion of DEX molecules out of the uPL matrix. The\npharmacological and therapeutic properties together with the fine tuning of\ngeometry and mechanical stiffness make uPLs a unique polymeric depot for the\npotential treatment of cancer, cardiovascular and chronic, inflammatory\ndiseases."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Using satellite image classification and digital terrain modelling to\n  assess forest species distribution on mountain slopes.A case study in Varatec\n  Forest District"}, {"role": "assistant", "content": "The relation between ecological conditions and geomorphological factors is\nconsidered the basis for species distribution in Romania. In this context, the\nlocation of each species within parts of the mountain slopes is difficult on a\nmedium to brad scale level. The paper presents methodology to combine\nvegetation data, obtained from IKONOS satellite images, and Digital Elevation\nModel obtained from digitized topographic maps. The study area is a northern\nslope of the Stanisoarei Mountains with a gradient of species from beech mixed\nand coniferous stands."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Branching principles of animal and plant networks identified by\n  combining extensive data, machine learning, and modeling"}, {"role": "assistant", "content": "Branching in vascular networks and in overall organismic form is one of the\nmost common and ancient features of multicellular plants, fungi, and animals.\nBy combining machine-learning techniques with new theory that relates vascular\nform to metabolic function, we enable novel classification of diverse branching\nnetworks--mouse lung, human head and torso, angiosperm and gymnosperm plants.\nWe find that ratios of limb radii--which dictate essential biologic functions\nrelated to resource transport and supply--are best at distinguishing branching\nnetworks. We also show how variation in vascular and branching geometry\npersists despite observing a convergent relationship across organisms for how\nmetabolic rate depends on body mass."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Climbing Escher's stairs: a way to approximate stability landscapes in\n  multidimensional systems"}, {"role": "assistant", "content": "Stability landscapes are useful for understanding the properties of dynamical\nsystems. These landscapes can be calculated from the system's dynamical\nequations using the physical concept of scalar potential. Unfortunately, for\nmost biological systems with two or more state variables such potentials do not\nexist. Here we use an analogy with art to provide an accessible explanation of\nwhy this happens. Additionally, we introduce a numerical method for decomposing\ndifferential equations into two terms: the gradient term that has an associated\npotential, and the non-gradient term that lacks it. In regions of the state\nspace where the magnitude of the non-gradient term is small compared to the\ngradient part, we use the gradient term to approximate the potential as\nquasi-potential. The non-gradient to gradient ratio can be used to estimate the\nlocal error introduced by our approximation. Both the algorithm and a\nready-to-use implementation in the form of an R package are provided."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: AptaBlocks Online - A web-based toolkit for the in-silico assembly of\n  RNA complexes"}, {"role": "assistant", "content": "Summary: The AptaBlocks Web Interface is focused on providing graphical,\nintuitive, and platform independent access to AptaBlocks, an experimentally\nvalidated algorithmic approach for the in-silico design of oligonucleotide\nsticky bridges. The availability of AptaBlocks online to the nucleic acid\nresearch community at large makes this software a highly effective tool for\naccelerating the design and development of novel oligonucleotide based drugs\nand other biotechnologies.\n  Availability: The AptaBlocks Web Interface is freely available at\nwww.ncbi.nlm.nih.gov/CBBresearch/Przytycka/index.cgi\\#aptablocks"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A new SWATH ion library for mouse adult hippocampal neural stem cells"}, {"role": "assistant", "content": "Over the last years, the SWATH data-independent acquisition protocol\n(Sequential Window acquisition of All THeoretical mass spectra) has become a\ncornerstone for the worldwide proteomics community. In this approach, a\nhigh-resolution quadrupole-ToF mass spectrometer acquires thousands of MS/MS\ndata by selecting not just a single precursor at a time, but by allowing a\nbroad m/z range to be fragmented. This acquisition window is then sequentially\nmoved from the lowest to the highest mass selection range. This technique\nenables the acquisition of thousands of high-resolution MS/MS spectra per\nminute in a standard LC-MS run. In the subsequent data analysis phase, the\ncorresponding dataset is searched in a triple quadrupole-like mode, thus not\nconsidering the whole MS/MS scan spectrum, but by searching for several\nprecursor to fragment transitions that identify and quantify the corresponding\npeptide. This search is made possible with the use of an ion library,\npreviously acquired in a classical data dependent, full-spectrum mode. The\nSWATH protocol, combining the protein identification power of high-resolution\nMS/MS spectra with the robustness and accuracy in analyte quantification of\ntriple-quad targeted workflows, has become very popular in proteomics research.\nThe major drawback lies in the ion library itself, which is normally demanding\nand time-consuming to build. Conversely, through the realignment of\nchromatographic retention times, an ion library of a given proteome can\nrelatively easily be tailored upon any proteomics experiment done on the same\nproteome. We are thus hereby sharing with the worldwide proteomics community\nour newly acquired ion library of mouse adult hippocampal neural stem cells.\nGiven the growing effort in neuroscience research involving proteomics\nexperiments, we believe that this data might be of great help for the\nneuroscience community."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Layer-Wise Relevance Propagation for Explaining Deep Neural Network\n  Decisions in MRI-Based Alzheimer's Disease Classification"}, {"role": "assistant", "content": "Deep neural networks have led to state-of-the-art results in many medical\nimaging tasks including Alzheimer's disease (AD) detection based on structural\nmagnetic resonance imaging (MRI) data. However, the network decisions are often\nperceived as being highly non-transparent, making it difficult to apply these\nalgorithms in clinical routine. In this study, we propose using layer-wise\nrelevance propagation (LRP) to visualize convolutional neural network decisions\nfor AD based on MRI data. Similarly to other visualization methods, LRP\nproduces a heatmap in the input space indicating the importance/relevance of\neach voxel contributing to the final classification outcome. In contrast to\nsusceptibility maps produced by guided backpropagation (\"Which change in voxels\nwould change the outcome most?\"), the LRP method is able to directly highlight\npositive contributions to the network classification in the input space. In\nparticular, we show that (1) the LRP method is very specific for individuals\n(\"Why does this person have AD?\") with high inter-patient variability, (2)\nthere is very little relevance for AD in healthy controls and (3) areas that\nexhibit a lot of relevance correlate well with what is known from literature.\nTo quantify the latter, we compute size-corrected metrics of the summed\nrelevance per brain area, e.g., relevance density or relevance gain. Although\nthese metrics produce very individual \"fingerprints\" of relevance patterns for\nAD patients, a lot of importance is put on areas in the temporal lobe including\nthe hippocampus. After discussing several limitations such as sensitivity\ntoward the underlying model and computation parameters, we conclude that LRP\nmight have a high potential to assist clinicians in explaining neural network\ndecisions for diagnosing AD (and potentially other diseases) based on\nstructural MRI data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Neurovascular coupling: insights from multi-modal dynamic causal\n  modelling of fMRI and MEG"}, {"role": "assistant", "content": "This technical note presents a framework for investigating the underlying\nmechanisms of neurovascular coupling in the human brain using multi-modal\nmagnetoencephalography (MEG) and functional magnetic resonance (fMRI)\nneuroimaging data. This amounts to estimating the evidence for several\nbiologically informed models of neurovascular coupling using variational\nBayesian methods and selecting the most plausible explanation using Bayesian\nmodel comparison. First, fMRI data is used to localise active neuronal sources.\nThe coordinates of neuronal sources are then used as priors in the\nspecification of a DCM for MEG, in order to estimate the underlying generators\nof the electrophysiological responses. The ensuing estimates of neuronal\nparameters are used to generate neuronal drive functions, which model the pre\nor post synaptic responses to each experimental condition in the fMRI paradigm.\nThese functions form the input to a model of neurovascular coupling, the\nparameters of which are estimated from the fMRI data. This establishes a\nBayesian fusion technique that characterises the BOLD response - asking, for\nexample, whether instantaneous or delayed pre or post synaptic signals mediate\nhaemodynamic responses. Bayesian model comparison is used to identify the most\nplausible hypotheses about the causes of the multimodal data. We illustrate\nthis procedure by comparing a set of models of a single-subject auditory fMRI\nand MEG dataset. Our exemplar analysis suggests that the origin of the BOLD\nsignal is mediated instantaneously by intrinsic neuronal dynamics and that\nneurovascular coupling mechanisms are region-specific. The code and example\ndataset associated with this technical note are available through the\nstatistical parametric mapping (SPM) software package."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Landing Dynamics of a Seagull Examined by Field Observation and\n  Mathematical Modeling"}, {"role": "assistant", "content": "A seagull ({\\it Larus crassirostris}) has a high ability to realize its safe,\naccurate and smooth landing. We examined how a seagull controls its angle of\nattack when landing on a specific target. First, we recorded the landing\nbehavior of an actual seagull by multiple video cameras and quantified the\nflight trajectory and the angle of attack as time series data. Second, we\nintroduced a mathematical model that describes how a seagull controls its speed\nby changing its angle of attack. Based on the numerical simulation combining\nthe mathematical model and empirical data, we succeeded in qualitatively\nexplaining the landing behavior of an actual seagull, which demonstrates that\nthe control the angle of attack is important for landing behavior."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: From Risk Prediction Models to Risk Assessment Service: A Formulation of\n  Development Paradigm"}, {"role": "assistant", "content": "Risk assessment services fulfil the task of generating a risk report from\npersonal information and are developed for purposes like disease prognosis,\nresource utilization prioritization, and informing clinical interventions. A\nmajor component of a risk assessment service is a risk prediction model. For a\nmodel to be easily integrated into risk assessment services, efforts are needed\nto design a detailed development roadmap for the intended service at the time\nof model development. However, methodology for such design is less described.\nWe thus reviewed existing literature and formulated a six-stage risk assessment\nservice development paradigm, from requirements analysis, service development,\nmodel validation, pilot study, to iterative service deployment and assessment\nand refinement. The study aims at providing a prototypic development roadmap\nwith checkpoints for the design of risk assessment services."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Erythrocyte-Inspired Discoidal Polymeric Nanoconstructs carrying Tissue\n  Plasminogen Activator for the Enhanced Lysis of Blood Clots"}, {"role": "assistant", "content": "Tissue plasminogen activator (tPA) is the sole approved therapeutic molecule\nfor the treatment of acute ischemic stroke. Yet, only a small percentage of\npatients could benefit from this life-saving treatment because of medical\ncontraindications and severe side effects, including brain hemorrhage,\nassociated with delayed administration. Here, a nano therapeutic agent is\nrealized by directly associating the clinical formulation of tPA to the porous\nstructure of soft discoidal polymeric nanoconstructs (tPA-DPNs). The porous\nmatrix of DPNs protects tPA from rapid degradation, allowing tPA-DPNs to\npreserve over 70 % of the tPA original activity after 3 h of exposure to serum\nproteins. Under dynamic conditions, tPA-DPNs dissolve clots more efficiently\nthan free tPA, as demonstrated in a microfluidic chip where clots are formed\nmimicking in vivo conditions. At 60 min post treatment initiation, the clot\narea reduces by half (57 + 8 %) with tPA-DPNs, whereas a similar result (56 +\n21 %) is obtained only after 90 min for free tPA. In murine mesentery venules,\nthe intravenous administration of 2.5 mg/kg of tPA-DPNs resolves almost 90 % of\nthe blood clots, whereas a similar dose of free tPA successfully recanalize\nonly about 40 % of the treated vessels. At about 1/10 of the clinical dose (1.0\nmg/kg), tPA-DPNs still effectively dissolve 70 % of the clots, whereas free tPA\nworks efficiently only on 16 % of the vessels. In vivo, discoidal tPA-DPNs\noutperform the lytic activity of 200 nm spherical tPA-coated nanoconstructs in\nterms of both percentage of successful recanalization events and clot area\nreduction. The conjugation of tPA with preserved lytic activity, the\ndeformability and blood circulating time of DPNs together with the faster blood\nclot dissolution would make tPA-DPNs a promising nanotool for enhancing both\npotency and safety of thrombolytic therapies."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: PyBioNetFit and the Biological Property Specification Language"}, {"role": "assistant", "content": "In systems biology modeling, important steps include model parameterization,\nuncertainty quantification, and evaluation of agreement with experimental\nobservations. To help modelers perform these steps, we developed the software\nPyBioNetFit. PyBioNetFit is designed for parameterization, and also supports\nuncertainty quantification, checking models against known system properties,\nand solving design problems. PyBioNetFit introduces the Biological Property\nSpecification Language (BPSL) for the formal declaration of system properties.\nBPSL allows qualitative data to be used alone or in combination with\nquantitative data for parameterization model checking, and design. PyBioNetFit\nperforms parameterization with parallelized metaheuristic optimization\nalgorithms (differential evolution, particle swarm optimization, scatter\nsearch) that work directly with existing model definition standards: BioNetGen\nLanguage (BNGL) and Systems Biology Markup Language (SBML). We demonstrate\nPyBioNetFit's capabilities by solving 31 example problems, including the\nchallenging problem of parameterizing a model of cell cycle control in yeast.\nWe benchmark PyBioNetFit's parallelization efficiency on computer clusters,\nusing up to 288 cores. Finally, we demonstrate the model checking and design\napplications of PyBioNetFit and BPSL by analyzing a model of therapeutic\ninterventions in autophagy signaling."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Google Auto ML versus Apple Create ML for Histopathologic Cancer\n  Diagnosis; Which Algorithms Are Better?"}, {"role": "assistant", "content": "Artificial Intelligence is set to revolutionize multiple fields in the coming\nyears. One subset of AI, machine learning, shows immense potential for\napplication in a diverse set of medical specialties, including diagnostic\npathology. In this study, we investigate the utility of the Apple Create ML and\nGoogle Cloud Auto ML, two machine learning platforms, in a variety of\npathological scenarios involving lung and colon pathology. First, we evaluate\nthe ability of the platforms to differentiate normal lung tissue from cancerous\nlung tissue. Also, the ability to accurately distinguish two subtypes of lung\ncancer (adenocarcinoma and squamous cell carcinoma) is examined and compared.\nSimilarly, the ability of the two programs to differentiate colon\nadenocarcinoma from normal colon is assessed as is done with lung tissue. Also,\ncases of colon adenocarcinoma are evaluated for the presence or absence of a\nspecific gene mutation known as KRAS. Finally, our last experiment examines the\nability of the Apple and Google platforms to differentiate between\nadenocarcinomas of lung origin versus colon origin. In our trained models for\nlung and colon cancer diagnosis, both Apple and Google machine learning\nalgorithms performed very well individually and with no statistically\nsignificant differences found between the two platforms. However, some critical\nfactors set them apart. Apple Create ML can be used on local computers but is\nlimited to an Apple ecosystem. Google Auto ML is not platform specific but runs\nonly in Google Cloud with associated computational fees. In the end, both are\nexcellent machine learning tools that have great potential in the field of\ndiagnostic pathology, and which one to choose would depend on personal\npreference, programming experience, and available storage space."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Estimating the density of resident coastal fish using underwater\n  cameras: accounting for individual detectability"}, {"role": "assistant", "content": "Technological advances in underwater video recording are opening novel\nopportunities for monitoring wild fish. However, extracting data from videos is\noften challenging. Nevertheless, it has been recently demonstrated that\naccurate and precise estimates of density for animals (whose normal activities\nare restricted to a bounded area or home range) can be obtained from counts\naveraged across a relatively low number of video frames. The method, however,\nrequires that individual detectability (PID, the probability of detecting a\ngiven animal provided that it is actually within the area surveyed by a camera)\nhas to be known. Here we propose a Bayesian implementation for estimating PID\nafter combining counts from cameras with counts from any reference method. The\nproposed framework was demonstrated using Serranus scriba as a case-study, a\nwidely distributed and resident coastal fish. Density and PID were calculated\nafter combining fish counts from unbaited remote underwater video (RUV) and\nunderwater visual censuses (UVC) as reference method. The relevance of the\nproposed framework is that after estimating PID, fish density can be estimated\naccurately and precisely at the UVC scale (or at the scale of the preferred\nreference method) using RUV only. This key statement has been extensively\ndemonstrated using computer simulations yielded by real empirical data.\nFinally, we provide a simulation tool-kit for comparing the expected precision\nattainable for different sampling effort and for species with different levels\nof PID. Overall, the proposed method may contribute to substantially enlarge\nthe spatio-temporal scope of density monitoring programs for many resident\nfish."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A probabilistic atlas for cell identification"}, {"role": "assistant", "content": "We propose a general framework for a collaborative machine learning system to\nassist bioscience researchers with the task of labeling specific cell\nidentities from microscopic still or video imaging. The distinguishing features\nof this approach versus prior approaches include: (1) use of a statistical\nmodel of cell features that is iteratively improved, (2) generation of\nprobabilistic guesses at cell ID rather than single best-guesses for each cell,\n(3) tracking of joint probabilities of features within and across cells, and\n(4) ability to exploit multi-modal features, such as cell position, morphology,\nreporter intensities, and activity. We provide an example implementation of\nsuch a system applicable to labeling fluorescently tagged \\textit{C. elegans}\nneurons. As a proof of concept, we use a generative spring-mass model to\nsimulate sequences of cell imaging datasets with variable cell positions and\nfluorescence intensities. Training on synthetic data, we find that atlases that\ntrack inter-cell positional correlations give higher labeling accuracies than\nthose that treat cell positions independently. Tracking an additional feature\ntype, fluorescence intensity, boosts accuracy relative to a position-only\natlas, suggesting that multiple cell features could be leveraged to improve\nautomated label predictions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Estimation of mutual information for real-valued data with error bars\n  and controlled bias"}, {"role": "assistant", "content": "Estimation of mutual information between (multidimensional) real-valued\nvariables is used in analysis of complex systems, biological systems, and\nrecently also quantum systems. This estimation is a hard problem, and\nuniversally good estimators provably do not exist. Kraskov et al. (PRE, 2004)\nintroduced a successful mutual information estimation approach based on the\nstatistics of distances between neighboring data points, which empirically\nworks for a wide class of underlying probability distributions. Here we improve\nthis estimator by (i) expanding its range of applicability, and by providing\n(ii) a self-consistent way of verifying the absence of bias, (iii) a method for\nestimation of its variance, and (iv) a criterion for choosing the values of the\nfree parameter of the estimator. We demonstrate the performance of our\nestimator on synthetic data sets, as well as on neurophysiological and systems\nbiology data sets."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Unifying Modular and Core-Periphery Structure in Functional Brain\n  Networks over Development"}, {"role": "assistant", "content": "At rest, human brain functional networks display striking modular\narchitecture in which coherent clusters of brain regions are activated. The\nmodular account of brain function is pervasive, reliable, and reproducible.\nYet, a complementary perspective posits a core-periphery or rich-club account\nof brain function, where hubs are densely interconnected with one another,\nallowing for integrative processing. Unifying these two perspectives has\nremained difficult due to the fact that the methodological tools to identify\nmodules are entirely distinct from the methodological tools to identify\ncore-periphery structure. Here we leverage a recently-developed model-based\napproach -- the weighted stochastic block model -- that simultaneously uncovers\nmodular and core-periphery structure, and we apply it to fMRI data acquired at\nrest in 872 youth of the Philadelphia Neurodevelopmental Cohort. We demonstrate\nthat functional brain networks display rich meso-scale organization beyond that\nsought by modularity maximization techniques. Moreover, we show that this\nmeso-scale organization changes appreciably over the course of\nneurodevelopment, and that individual differences in this organization predict\nindividual differences in cognition more accurately than module organization\nalone. Broadly, our study provides a unified assessment of modular and\ncore-periphery structure in functional brain networks, providing novel insights\ninto their development and implications for behavior."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Unbiased on-lattice domain growth"}, {"role": "assistant", "content": "Domain growth is a key process in many areas of biology, including embryonic\ndevelopment, the growth of tissue, and limb regeneration. As a result,\nmechanisms for incorporating it into traditional models for cell movement,\ninteraction, and proliferation are of great importance. A previously well-used\nmethod in order to incorporate domain growth into on-lattice reaction-diffusion\nmodels causes a build up of particles on the boundaries of the domain, which is\nparticularly evident when diffusion is low in comparison to the rate of domain\ngrowth. Here, we present a new method which addresses this unphysical build up\nof particles at the boundaries, and demonstrate that it is accurate even for\nscenarios in which the previous method fails. Further, we discuss for which\nparameter regimes it is feasible to continue using the original method due to\ndiffusion dominating the domain growth mechanism."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Digging Deeper: Methodologies for High-Content Phenotyping and\n  Knowledge-Abstraction in C. elegans"}, {"role": "assistant", "content": "Deep phenotyping is an emerging conceptual paradigm and experimental approach\nthat seeks to measure many aspects of phenotypes and link them to understand\nthe underlying biology. Successful deep phenotyping has mostly been applied in\ncultured cells, less so in multicellular organisms. Recently, however, it has\nbeen recognized that such an approach could lead to better understanding of how\ngenetics, the environment, and stochasticity affect development, physiology,\nand behavior of an organism. Over the last 50 years, the nematode\nCaenorhabditis elegans has become an invaluable model system for understanding\nthe role of the genes underlying a phenotypic trait. Recent technological\ninnovation has taken advantage of the worm physical attributes to increase the\nthroughput and informational content of experiments. Coupling these technical\nadvancements with computational or analytical tools has enabled a boom in deep\nphenotyping studies of C. elegans. In this review, we highlight how these new\ntechnologies and tools are digging into the biological origins of complex\nmultidimensional phenotypes seen in the worm."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Uterine muscle networks: Connectivity analysis of the EHG during\n  pregnancy and Labor"}, {"role": "assistant", "content": "In this paper, we propose a new framework to analyze the electrical activity\nof the uterus recorded by electrohysterography (EHG), from abdominal electrodes\n(a grid of 4x4 electrodes) during pregnancy and labor. We evaluate the\npotential use of the synchronization between EHG signals in characterizing\nelectrical activity of the uterus during pregnancy and labor. The complete\nprocessing pipeline consists of i) estimating the correlation between the\ndifferent EHG signals, ii) quantifying the connectivity matrices using graph\ntheory-based analysis and iii) testing the clinical impact of network measures\nin pregnancy monitoring and labor detection. We first compared several\nconnectivity methods to compute the adjacency matrix represented as a graph of\na set of nodes (electrodes) connected by edges (connectivity values). We then\nevaluated the performance of different graph measures in the classification of\npregnancy and labor contractions (number of women=35). A comparison with the\nalready existing parameters used in the state of the art of labor detection and\npreterm labor prediction was also performed. Results show higher performance of\nconnectivity methods when combined with network measures. Denser graphs were\nobserved during labor than during pregnancy. The network-based metrics showed\nthe highest classification rate when compared to already existing features.\nThis network-based approach can be used not only to characterize the\npropagation of the uterine contractions, but also may have high clinical impact\nin labor detection and likely in the prediction of premature labor."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Physical Model for Self-Similar Seashells"}, {"role": "assistant", "content": "This paper presents a simple physical model for self-similar (gnomonic, or\nfirst-order) seashell growth which is expressed in coordinate-free terms. The\nshell is expressed as the solution of a differential equation which expresses\nthe growth dynamics, and may be used to investigate shell growth from both the\nlocal viewpoint of the organism building it and moving with the shell opening\n(aperture), as well as that of a researcher making global measurements upon a\ncomplete motionless shell. Coordinate systems needed to express the global and\nlocal descriptions of the shell are chosen. The parameters of growth, or their\ninformation equivalent, remain constant in the local system, and are used by\nthe organism to build the shell, and are likely mirrored in the DNA of the\norganism building it. The transformations between local and global\nrepresentations are provided. The global model of Cortie, which is very similar\nto the present model, is expressed in terms of the present model, and the\nglobal parameters provided by Cortie for various species of mollusk may be used\nto calculate the equivalent local parameters.Mathematica code is provided to\nimplement these transformations, as well as to plot the shells using both\nglobal and local parameters."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Mathematical modeling of variability in intracellular signaling"}, {"role": "assistant", "content": "Cellular signaling is essential in information processing and decision\nmaking. Therefore, a variety of experimental approaches have been developed to\nstudy signaling on bulk and single-cell level. Single-cell measurements of\nsignaling molecules demonstrated a substantial cell-to-cell variability,\nraising questions about its causes and mechanisms and about how cell\npopulations cope with or exploit cellular heterogeneity. To gain insights from\nsingle-cell signaling data, analysis and modeling approaches have been\nintroduced. This review discusses these modeling approaches, with a focus on\nrecent advances in the development and calibration of mechanistic models.\nAdditionally, it outlines current and future challenges."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Regulation of Heart Beats by the Autonomous Nervous System in Health and\n  Disease: Point-Process-Theory based Models and Simulation [V-I]"}, {"role": "assistant", "content": "We have advanced a point-process based framework for the regulation of heart\nbeats by the autonomous nervous system and analyzed the model with and without\nfeedback. The model without feedback was found amenable to several analytical\nresults that help develop an intuition about the way the heart interacts with\nthe nervous system. However, in reality, feedback, baroreflex and chemoreflex\ncontrols are important to model healthy and unhealthy scenarios for the heart.\nBased on the Hurst exponent as an index of health of the heart we show how the\nstate of the nervous system may tune it in health and disease. Monte Carlo\nsimulation is used to generate RR interval series of the Electrocardiogram\n(ECG) for different sympathetic and parasympathetic nerve excitations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: TiCoNE 2: A Composite Clustering Model for Robust Cluster Analyses on\n  Noisy Data"}, {"role": "assistant", "content": "Identifying groups of similar objects using clustering approaches is one of\nthe most frequently employed first steps in exploratory biomedical data\nanalysis. Many clustering methods have been developed that pursue different\nstrategies to identify the optimal clustering for a data set.\n  We previously published TiCoNE, an interactive clustering approach coupled\nwith de-novo network enrichment of identified clusters. However, in this first\nversion time-series and network analysis remained two separate steps in that\nonly time-series data was clustered, and identified clusters mapped to and\nenriched within a network in a second separate step.\n  In this work, we present TiCoNE 2: An extension that can now seamlessly\nincorporate multiple data types within its composite clustering model.\nSystematic evaluation on 50 random data sets, as well as on 2,400 data sets\ncontaining enriched cluster structure and varying levels of noise, shows that\nour approach is able to successfully recover cluster patterns embedded in\nrandom data and that it is more robust towards noise than non-composite models\nusing only one data type, when applied to two data types simultaneously.\n  Herein, each data set was clustered using five different similarity functions\ninto k=10/30 clusters, resulting to ~5,000 clusterings in total. We evaluated\nthe quality of each derived clustering with the Jaccard index and an internal\nvalidity score. We used TiCoNE to calculate empirical p-values for all\ngenerated clusters with different permutation functions, resulting in ~80,000\ncluster p-values. We show, that derived p-values can be used to reliably\ndistinguish between foreground and background clusters.\n  TiCoNE 2 allows researchers to seamlessly analyze time-series data together\nwith biological interaction networks in an intuitive way and thereby provides\nmore robust results than single data type cluster analyses."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Deep phenotyping in C. elegans"}, {"role": "assistant", "content": "Deep phenotyping study has become an emerging field to understand the gene\nfunction and the structure of biological networks. For the living animal C.\nelegans, recent advances in genome-editing tools, microfluidic devices and\nphenotypic analyses allow for a deeper understanding of the\ngenotype-to-phenotype pathway. In this article, I reviewed the evolution of\ndeep phenotyping study in cell development, neuron activity, and the behaviors\nof intact animals."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multi-Scale Simulation Modeling for Prevention and Public Health\n  Management of Diabetes in Pregnancy and Sequelae"}, {"role": "assistant", "content": "Diabetes in pregnancy (DIP) is an increasing public health priority in the\nAustralian Capital Territory, particularly due to its impact on risk for\ndeveloping Type 2 diabetes. While earlier diagnostic screening results in\ngreater capacity for early detection and treatment, such benefits must be\nbalanced with the greater demands this imposes on public health services. To\naddress such planning challenges, a multi-scale hybrid simulation model of DIP\nwas built to explore the interaction of risk factors and capture the dynamics\nunderlying the development of DIP. The impact of interventions on health\noutcomes at the physiological, health service and population level is measured.\nOf particular central significance in the model is a compartmental model\nrepresenting the underlying physiological regulation of glycemic status based\non beta-cell dynamics and insulin resistance. The model also simulated the\ndynamics of continuous BMI evolution, glycemic status change during pregnancy\nand diabetes classification driven by the individual-level physiological model.\nWe further modeled public health service pathways providing diagnosis and care\nfor DIP to explore the optimization of resource use during service delivery.\nThe model was extensively calibrated against empirical data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Using statistical techniques and replication samples for imputation of\n  metabolite missing values"}, {"role": "assistant", "content": "Background: Data preparation, such as missing values imputation and\ntransformation, is the first step in any data analysis and requires crucial\nattention. Particularly, analysis of metabolites demands more preparation since\nthose small compounds have recently been measurable in large scales with mass\nspectrometry techniques. We introduce novel statistical techniques for\nmetabolite missing values imputation by utilizing replication samples. Results:\nTo understand the nature of the missing values using replication samples, we\nobtained the empirical distribution of missing values and observed that the\nrate of missing values is approximately distributed as uniform across the\nmetabolite range. Therefore, the missing values cannot be imputed with the\nlowest values. Using the identified distribution, we illustrated a simulation\nstudy to find an optimal imputation approach for metabolites. Conclusions: We\ndemonstrated that the missing values in metabolomic data sets might not be\nnecessarily low value. After identification of the nature of missing values, we\nvalidated K nearest neighborhood as an optimal approach for imputation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Detection of Thalassaemia Carriers by Automated Feature Extraction of\n  Dried Blood Drops"}, {"role": "assistant", "content": "Thalassaemia, triggered by defects in the globin genes, is one of the most\ncommon monogenic diseases. The beta-thalassaemia carrier state is clinically\nasymptomatic, thus, making it onerous to diagnose. The current gold standard\ntechnique is implausible to be used for onsite carrier detection as the method\nnecessitates expensive instruments, skilled manpower and time. In this study,\nwe have tried to classify the carriers from the healthy samples based on their\nblood droplet drying patterns using image analysis based tools and subsequently\ndevelop an in-house program for automated classification of the same. This\nautomatic, rapid, less laborious and cost-effective technique will\nsignificantly increase the total number of carriers that are screened for\nthalassaemia per year in the country, thus, reducing the burden in the state\nrun advanced health facilities."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A distribution-dependent analysis of open-field test movies"}, {"role": "assistant", "content": "Although the open-field test has been widely used, its reliability and\ncompatibility are frequently questioned. Although many indicating parameters\nwere introduced for this test, they did not take data distributions into\nconsideration. This oversight may have caused the problems mentioned above.\nHere, an exploratory approach for the analysis of video records of tests of\nelderly mice was taken that described the distributions using the least number\nof parameters. First, the locomotor activity of the animals was separated into\ntwo clusters: dash and search. The accelerations found in each of the clusters\nwere distributed normally. The speed and the duration of the clusters exhibited\nan exponential distribution. Although the exponential model includes a single\nparameter, an additional parameter that indicated instability of the behaviour\nwas required in many cases for fitting to the data. As this instability\nparameter exhibited an inverse correlation with speed, the function of the\nbrain that maintained stability would be required for a better performance.\nAccording to the distributions, the travel distance, which has been regarded as\nan important indicator, was not a robust estimator of the animals' condition."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Mathematical Discovery of Natural Laws in Biomedical Sciences: A New\n  Methodology"}, {"role": "assistant", "content": "As biomedical sciences discover new layers of complexity in the mechanisms of\nlife and disease, mathematical models trying to catch up with these\ndevelopments become mathematically intractable. As a result, in the grand\nscheme of things, mathematical models have so far played an auxiliary role in\nbiomedical sciences. We propose a new methodology allowing mathematical\nmodeling to give, in certain cases, definitive answers to systemic biomedical\nquestions that elude empirical resolution. Our methodology is based on two\nideas: (1) employing mathematical models that are firmly rooted in established\nbiomedical knowledge yet so general that they can account for any, or at least\nmany, biological mechanisms, both known and unknown; (2) finding model\nparameters whose likelihood-maximizing values are independent of observations\n(existence of such parameters implies that the model must not meet regularity\nconditions required for the consistency of maximum likelihood estimator). These\nuniversal parameter values may reveal general patterns (that we call natural\nlaws) in biomedical processes. We illustrate this approach with the discovery\nof a clinically important natural law governing cancer metastasis.\nSpecifically, we found that under minimal, and fairly realistic, mathematical\nand biomedical assumptions the likelihood-maximizing scenario of metastatic\ncancer progression in an individual patient is invariably the same: Complete\nsuppression of metastatic growth before primary tumor resection followed by an\nabrupt growth acceleration after surgery. This scenario is widely observed in\nclinical practice and supported by a wealth of experimental studies on animals\nand clinical case reports published over the last 110 years. The above most\nlikely scenario does not preclude other possibilities e.g. metastases may start\naggressive growth before primary tumor resection or remain dormant after\nsurgery."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Automatic Retrosynthetic Pathway Planning Using Template-free Models"}, {"role": "assistant", "content": "We present an attention-based Transformer model for automatic retrosynthesis\nroute planning. Our approach starts from reactants prediction of single-step\norganic reactions for given products, followed by Monte Carlo tree search-based\nautomatic retrosynthetic pathway prediction. Trained on two datasets from the\nUnited States patent literature, our models achieved a top-1 prediction\naccuracy of over 54.6% and 63.0% with more than 95% and 99.6% validity rate of\nSMILES, respectively, which is the best up to now to our knowledge. We also\ndemonstrate the application potential of our model by successfully performing\nmulti-step retrosynthetic route planning for four case products, i.e.,\nantiseizure drug Rufinamide, a novel allosteric activator, an inhibitor of\nhuman acute-myeloid-leukemia cells and a complex intermediate of drug\ncandidate. Further, by using heuristics Monte Carlo tree search, we achieved\nautomatic retrosynthetic pathway searching and successfully reproduced\npublished synthesis pathways. In summary, our model has achieved the\nstate-of-the-art performance on single-step retrosynthetic prediction and\nprovides a novel strategy for automatic retrosynthetic pathway planning."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Unified framework for modeling multivariate distributions in biological\n  sequences"}, {"role": "assistant", "content": "Revealing the functional sites of biological sequences, such as evolutionary\nconserved, structurally interacting or co-evolving protein sites, is a\nfundamental, and yet challenging task. Different frameworks and models were\ndeveloped to approach this challenge, including Position-Specific Scoring\nMatrices, Markov Random Fields, Multivariate Gaussian models and most recently\nAutoencoders. Each of these methods has certain advantages, and while they have\ngenerated a set of insights for better biological predictions, these have been\nrestricted to the corresponding methods and were difficult to translate to the\ncomplementary domains. Here we propose a unified framework for the\nabove-mentioned models, that allows for interpretable transformations between\nthe different methods and naturally incorporates the advantages and insight\ngained individually in the different communities. We show how, by using the\nunified framework, we are able to achieve state-of-the-art performance for\nprotein structure prediction, while enhancing interpretability of the\nprediction process."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Using Data Mining to Explore Calmodulin Bibliography"}, {"role": "assistant", "content": "In this chapter, we present a strategy and the technics to approach a\nscientific field from a set of articles gathered from the bibliographic\ndatabase, Web of Science. The strategy is based on methods developed to analyze\nsocial networks. We illustrate the use of such strategy in studying the\ncalmodulin field. Such method allows to structure a huge number of articles\nwhen writing a review, to detect the key opinion leaders in a given field and\nto locate his own research topic in the landscape of the themes deciphered by\nour own community. We show that the free software VosViewer may be used without\nknowledge in computing science and with a short learning period. iii."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Cell image classification: a comparative overview"}, {"role": "assistant", "content": "Cell image classification methods are currently being used in numerous\napplications in cell biology and medicine. Applications include understanding\nthe effects of genes and drugs in screening experiments, understanding the role\nand subcellular localization of different proteins, as well as diagnosis and\nprognosis of cancer from images acquired using cytological and histological\ntechniques. We review three different approaches for cell image classification:\nnumerical feature extraction, end to end classification with neural networks,\nand transport-based morphometry. In addition, we provide comparisons on four\ndifferent cell imaging datasets to highlight the relative strength of each\nmethod."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Circuitscape in Julia: High Performance Connectivity Modelling to\n  Support Conservation Decisions"}, {"role": "assistant", "content": "Connectivity across landscapes influences a wide range of\nconservation-relevant ecological processes, including species movements, gene\nflow, and the spread of wildfire, pests, and diseases. Recent improvements in\nremote sensing data suggest great potential to advance connectivity models, but\ncomputational constraints hinder these advances. To address this challenge, we\nupgraded the widely-used Circuitscape connectivity package to the high\nperformance Julia programming language. Circuitscape.jl allows users to solve\nproblems faster via improved parallel processing and solvers, and supports\napplications to larger problems (e.g., datasets with hundreds of millions of\ncells). We document speed improvements of up to 1800\\%. We also demonstrate\nscaling of problem sizes up to 437 million grid cells. These improvements allow\nmodelers to work with higher resolution data, larger landscapes and perform\nsensitivity analysis effortlessly. These improvements accelerate the pace of\ninnovation, helping modelers address pressing challenges like species range\nshifts under climate change. Our collaboration between ecologists and computer\nscientists has led to the use of connectivity models to inform conservation\ndecisions. Further, these next generation connectivity models will produce\nresults faster, facilitating stronger engagement with decision-makers."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Automated generation of bacterial resource allocation models"}, {"role": "assistant", "content": "Resource Balance Analysis (RBA) is a computational method based on resource\nallocation, which performs accurate quantitative predictions of whole-cell\nstates (i.e. growth rate, meta-bolic fluxes, abundances of molecular machines\nincluding enzymes) across growth conditions. We present an integrated workflow\nof RBA together with the Python package RBApy. RBApy builds bacterial RBA\nmodels from annotated genome-scale metabolic models by add-ing descriptions of\ncellular processes relevant for growth and maintenance. The package in-cludes\nfunctions for model simulation and calibration and for interfacing to Escher\nmaps and Proteomaps for visualization. We demonstrate that RBApy faithfully\nreproduces results ob-tained by a hand-curated and experimentally validated RBA\nmodel for Bacillus subtilis. We also present a calibrated RBA model of\nEscherichia coli generated from scratch, which ob-tained excellent fits to\nmeasured flux values and enzyme abundances. RBApy makes whole-cell modeling\naccessible for a wide range of bacterial wild-type and engineered strains, as\nil-lustrated with a CO2-fixing Escherichia coli strain."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Numerical Representations of Metabolic Systems"}, {"role": "assistant", "content": "Metabolomics is becoming a mature part of analytical chemistry as evidenced\nby the growing number of publications and attendees of international\nconferences dedicated to this topic. Yet, a systematic treatment of the\nfundamental structure and properties of metabolomics data is lagging behind. We\nwant to fill this gap by introducing two fundamental theories concerning\nmetabolomics data: data theory and measurement theory. Our approach is to ask\nsimple questions, the answers of which require applying these theories to\nmetabolomics. We show that we can distinguish at least four different levels of\nmetabolomics data with different properties and warn against confusing data\nwith numbers."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Flow cytometry to assess the counts and physiological state of\n  Cronobacter sakazakii cells after heat exposure"}, {"role": "assistant", "content": "Cronobacter sakazakii is an opportunistic pathogen associated with outbreaks\nof neonatal necrotizing enterocolitis, septicemia, and meningitis.\nReconstituted powdered infant formulae (PIF) is the most common vehicle of\ninfection. Plate count methods do not provide direct information on the\nphysiological status of cells. Flow cytometry (FC) has been used to gain\ninsights into the physiological states of C. sakazakii after heat treatments,\nand to compare FC results with plate counts. The percentage of compromised\ncells increased as the percentage of live cells increased after the 100 C\ntreatment. However, the number of compromised cells after 60 or 65 C treatments\ndecreased as the percentage of live cells increased, showing that both mild\ntemperatures would not be completely effective eliminating all bacteria but\ncompromising their membranes, and showing that mild heat treatments are not\nenough to guarantee the safety of PIF. FC was capable to detect C. sakazakii\ncompromised cells that cannot be detected with classical plate count methods,\nthus it could be used to decreasing the risk of pathogenic viable but\nnon-culturable cells to be in the ingested food. Linear regression analysis\nshowed good correlations between plate count results vs FC results."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Parameter Estimation and Uncertainty Quantification for Systems Biology\n  Models"}, {"role": "assistant", "content": "Mathematical models can provide quantitative insight into immunoreceptor\nsignaling, but require parameterization and uncertainty quantification before\nmaking reliable predictions. We review currently available methods and software\ntools to address these problems. We consider gradient-based and gradient-free\nmethods for point estimation of parameter values, and methods of profile\nlikelihood, bootstrapping, and Bayesian inference for uncertainty\nquantification. We consider recent and potential future applications of these\nmethods to systems-level modeling of immune-related phenomena."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Second-generation stoichiometric mathematical model to predict methane\n  emissions from oil sands tailings"}, {"role": "assistant", "content": "Microbial metabolism of fugitive hydrocarbons produces greenhouse gas (GHG)\nemissions from oil sands tailings ponds (OSTP) and end pit lakes (EPL) that\nretain semisolid wastes from surface mining of oil sands ores. Predicting GHG\nproduction, particularly methane (CH4), would help oil sands operators mitigate\ntailings emissions and would assist regulators evaluating the trajectory of\nreclamation scenarios. Using empirical datasets from laboratory incubation of\nOSTP sediments with pertinent hydrocarbons, we developed a stoichiometric model\nfor CH4 generation by indigenous microbes. This model improved on previous\nfirst-approximation models by considering long-term biodegradation kinetics for\n18 relevant hydrocarbons from three different oil sands operations, lag times,\nnutrient limitations, and microbial growth and death rates. Laboratory\nmeasurements were used to estimate model parameter values and to validate the\nnew model. Goodness of fit analysis showed that the stoichiometric model\npredicted CH4 production well; normalized mean square error analysis revealed\nthat it surpassed previous models. Comparison of model predictions with field\nmeasurements of CH4 emissions further validated the new model. Importantly, the\nmodel also identified parameters that are currently lacking but are needed to\nenable future robust modeling of CH4 production from OSTP and EPL in situ."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Target Flow-Pressure Operating Range for Designing a Failing Fontan\n  Cavopulmonary Support Device"}, {"role": "assistant", "content": "Fontan operation as the current standard of care for the palliation of single\nventricle defects results in significant late complications. Using a mechanical\ncirculatory device for the right circulation to serve the function of the\nmissing subpulmonary ventricle could potentially stabilize the failing Fontan\ncirculation. This study aims to elucidate the hydraulic operating regions that\nshould be targeted for designing cavopulmonary blood pumps. By integrating\nnumerical analysis and available clinical information, the interaction of the\ncavopulmonary support via the IVC and full assist configurations with a wide\nrange of simulated adult failing scenarios was investigated; with IVC and full\nassist corresponding to the inferior venous return or the entire venous return,\nrespectively, being routed through the device. We identified the desired\nhydraulic operating regions for a cavopulmonary assist device by clustering all\nhead pressures and corresponding pump flows that result in hemodynamic\nimprovement for each simulated failing Fontan physiology. Results show that IVC\nsupport can produce beneficial hemodynamics in only a small fraction of failing\nFontan scenarios. Cavopulmonary assist device could increase cardiac index by\n35% and decrease the inferior vena cava pressure by 45% depending on the\npatient's pre-support hemodynamic state and surgical configuration of the\ncavopulmonary assist device (IVC or full support). The desired flow-pressure\noperating regions we identified can serve as the performance criteria for\ndesigning cavopulmonary assist devices as well as evaluating off-label use of\ncommercially available left-side blood pumps for failing Fontan cavopulmonary\nsupport."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Digital image quantification of rice sheath blight: Optimized\n  segmentation and automatic classification"}, {"role": "assistant", "content": "Rapid and accurate phenotypic screening of rice germplasms is crucial in\nscreening for sources of rice sheath blight resistance. However, visual and/or\ncaliper-based estimations of coalescing, necrotic, ShB disease lesions are\ntime-consuming, labor-intensive and exposed to human rater subjectivity. Here,\nwe propose the use of RGB images and image processing techniques to quantify\nShB disease progression in terms of lesion height and diseased area. To be\nspecific, we developed a pixel color- and coordinate-based K-Means Clustering\n(PCC-KMC) algorithm utilizing Mahalanobis metric aimed at accurate segmentation\nof symptomatic and non-symptomatic regions within rice stem images. The\nperformance of PCC-KMC was evaluated using Lin's concordance correlation\ncoefficient by comparing its results to visual measurements of ShB lesion\nheight and to lesion/diseased area measured using ImageJ. Low bias and high\nprecision were observed for absolute lesion height (bias=0.93, precision=0.94)\nand absolute symptomatic area (bias=0.98, precision=0.97) studies. Moreover, we\nintroduced a convolutional neural network (CNN) for the automatic annotation on\nclusters, termed PCC-KMC-CNN. Our CNN was trained based on 85%:15% of\ncomposition for training and testing dataset from total 168 ShB-infected stem\nsample images, recording 92% accuracy and 0.21 loss. PCC-KMC-CNN also showed\nhigh accuracy and precision for the absolute lesion height (bias=0.86,\nprecision=0.90) and absolute diseased area (bias=0.99, precision=0.97) studies.\nThese results demonstrate that the present methodology has great potential and\npromise to substitute the traditional visual-based ShB disease severity\nassessment."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: MOD-Finder: Identify multi-omics data sets related to defined chemical\n  exposure"}, {"role": "assistant", "content": "Summary: Integration of multi-omics data on chemical exposure of cells or\norganisms promises a more complete representation of the responding pathways\nthan single omics data. Data of different omics layers, like transcriptome or\nproteome is deposited in different repositories. Additionally, precisely\nspecifying a chemical of interest that was used in the exposure experiments\nsuffers from different nomenclatures and non-uniquely mapping of chemical\nidentifiers. The manual search for corresponding omics data sets of different\nlayers for exposure with a chemical of interest is thus a tedious task. We have\ndeveloped MOD-Finder (Multi-Omics Data set Finder) to efficiently search for\nchemical-related omics data sets in several publicly available databases in an\nautomated manner. A plain and simple presentation of the returned omics data\nsets is augmented with effect information that are assumed to be triggered by\nthe chemical of interest.\n  Availability and Implementation: MOD-Finder is implemented in R using the\nShiny package. The web service is available at https://webapp.ufz.de/mod_finder\nand the source code under the GNU GPL v3 license at\nhttps://github.com/yigbt/MOD-Finder.\n  Supplementary information: Supplementary data are available at\nhttps://www.ufz.de/index.php?en=44919"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Robust Nucleus Detection with Partially Labeled Exemplars"}, {"role": "assistant", "content": "Quantitative analysis of cell nuclei in microscopic images is an essential\nyet challenging source of biological and pathological information. The major\nchallenge is accurate detection and segmentation of densely packed nuclei in\nimages acquired under a variety of conditions. Mask R-CNN-based methods have\nachieved state-of-the-art nucleus segmentation. However, the current pipeline\nrequires fully annotated training images, which are time consuming to create\nand sometimes noisy. Importantly, nuclei often appear similar within the same\nimage. This similarity could be utilized to segment nuclei with only partially\nlabeled training examples. We propose a simple yet effective region-proposal\nmodule for the current Mask R-CNN pipeline to perform few-exemplar learning. To\ncapture the similarities between unlabeled regions and labeled nuclei, we apply\ndecomposed self-attention to learned features. On the self-attention map, we\nobserve strong activation at the centers and edges of all nuclei, including\nunlabeled nuclei. On this basis, our region-proposal module propagates partial\nannotations to the whole image and proposes effective bounding boxes for the\nbounding box-regression and binary mask-generation modules. Our method\neffectively learns from unlabeled regions thereby improving detection\nperformance. We test our method with various nuclear images. When trained with\nonly 1/4 of the nuclei annotated, our approach retains a detection accuracy\ncomparable to that from training with fully annotated data. Moreover, our\nmethod can serve as a bootstrapping step to create full annotations of\ndatasets, iteratively generating and correcting annotations until a\npredetermined coverage and accuracy are reached. The source code is available\nat https://github.com/feng-lab/nuclei."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Inferring long-range interactions between immune and tumor cells --\n  pitfalls and (partial) solutions"}, {"role": "assistant", "content": "Upcoming immunotherapies for cancer treatment rely on the ability of the\nimmune system to detect and eliminate tumors in the body. A highly simplified\nversion of this process can be studied in a Petri dish: starting with a random\ndistribution of immune and tumor cells, it can be observed in detail how\nindividual immune cells migrate towards nearby tumor cells, establish contact,\nand attack. Nevertheless, it remains unclear whether the immune cells find\ntheir targets by chance, or if they approach them 'on purpose', using remote\nsensing mechanisms such as chemotaxis. In this work, we present methods to\ninfer the strength and range of long-range cell-cell interactions from\ntime-lapse recorded cell trajectories, using a maximum likelihood method to fit\nthe model parameters. First, we model the interactions as a distance-dependent\n'force' that attracts immune cells towards their nearest tumor cell. While this\napproach correctly recovers the interaction parameters of simulated cells with\nconstant migration properties, it detects spurious interactions in the case of\nindependent cells that spontaneously change their migration behavior over time.\nWe therefore use an alternative approach that models the interactions by\ndistance-dependent probabilities for positive and negative turning angles of\nthe migrating immune cell. We demonstrate that the latter approach finds the\ncorrect interaction parameters even with temporally switching cell migration."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Numerical Optimization of Plasmid DNA Delivery Combined with\n  Hyaluronidase Injection for Electroporation Protocol"}, {"role": "assistant", "content": "The definition of an innovative therapeutic protocol requires the fine tuning\nof all the involved operations in order to maximize the efficiency. In some\ncases, the price of the experiments, or their duration, represents a great\nobstacle and the full potential of the protocol risks to be reduced or even\nhidden by a non-optimal application.\n  The implementation of a numerical model of the protocol may represent the\nsolution, allowing a systematic exploration of all the different alternatives,\nshedding the light on the most promising combination and also identifying the\nkey elements/parameters.\n  In this paper, the injection of a plasmid, preceded by a hyaluronidase\ninjection, is simulated through a mathematical model. Some key elements of the\nadministration protocol are identified by means of a mathematical optimization\nprocedure, maximizing the efficacy of the therapy. As a side effect of the\nextensive investigation, robust solutions able to reduce the effects of human\nerrors in the administration are also obtained."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Combinatorial protein-protein interactions on a polymerizing scaffold"}, {"role": "assistant", "content": "Scaffold proteins organize cellular processes by bringing signaling molecules\ninto interaction, sometimes by forming large signalosomes. Several of these\nscaffolds are known to polymerize. Their assemblies should therefore not be\nunderstood as stoichiometric aggregates, but as combinatorial ensembles. We\nanalyze the combinatorial interaction of ligands loaded on polymeric scaffolds,\nin both a continuum and discrete setting, and compare it with multivalent\nscaffolds with fixed number of binding sites. The quantity of interest is the\nabundance of ligand interaction possibilities---the catalytic potential\n$Q$---in a configurational mixture. Upon increasing scaffold abundance,\nscaffolding systems are known to first increase opportunities for ligand\ninteraction and then to shut them down as ligands become isolated on distinct\nscaffolds. The polymerizing system stands out in that the dependency of $Q$ on\nprotomer concentration switches from being dominated by a first order to a\nsecond order term within a range determined by the polymerization affinity.\nThis behavior boosts $Q$ beyond that of any multivalent scaffold system. In\naddition, the subsequent drop-off is considerably mitigated in that $Q$\ndecreases with half the power in protomer concentration than for any\nmultivalent scaffold. We explain this behavior in terms of how the\nconcentration profile of the polymer length distribution adjusts to changes in\nprotomer concentration and affinity. The discrete case turns out to be similar,\nbut the behavior can be exaggerated at small protomer numbers because of a\nmaximal polymer size, analogous to finite-size effects in bond percolation on a\nlattice."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Characterizing the limits of human stability during motion: perturbative\n  experiment validates a model-based approach for the Sit-to-Stand task"}, {"role": "assistant", "content": "Falls affect a growing number of the population each year. Clinical methods\nto identify those at greatest risk for falls usually evaluate individuals while\nthey perform specific motions such as balancing or Sit-to-Stand (STS).\nUnfortunately these techniques have been shown to have poor predictive power\nand are unable to identify the magnitude, direction, and timing of\nperturbations that can cause an individual to lose stability during motion. To\naddress this limitation, the recently proposed Stability Basin (SB) aims to\ncharacterize the set of perturbations that will cause an individual to fall\nunder a specific motor control strategy. The SB is defined as the set of\nconfigurations that do not lead to failure for an individual under their chosen\ncontrol strategy. This paper presents a novel method to compute the SB and the\nfirst experimental validation of the SB with an 11-person perturbative STS\nexperiment involving forwards or backwards pulls from a motor-driven cable. The\nindividually-constructed SBs are used to identify when a trial fails, i.e.,\nwhen an individual must switch control strategies (indicated by a step or sit)\nto recover from a perturbation. The constructed SBs correctly predict the\noutcome of trials where failure was observed with over 90% accuracy, and\ncorrectly predict the outcome of successful trials with over 95% accuracy. The\nSB was compared to three other methods and was found to estimate the stable\nregion with over 45% more accuracy in all cases. This study demonstrates that\nSBs offer a novel model-based approach for quantifying stability during motion,\nwhich could be used in physical therapy for individuals at risk of falling."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Improving the soil water module of the Decision Support System for\n  Agrotechnology Transfer cropping system model for subsurface irrigation"}, {"role": "assistant", "content": "Ensuring that crops use water and nutrients efficiently is an important\nstrategy for increasing the profitability of farming and reducing the\nenvironmental load from agriculture. Subsurface irrigation can be an\nalternative to surface irrigation as a means of losing less irrigation water,\nbut the application timing and amount are often difficult to determine.\nWell-defined soil and crop models are useful for assisting decision support,\nbut most of the models developed to date have been for surface irrigation. The\npresent study examines whether the Decision Support System for Agrotechnology\nTransfer (DSSAT, version 4.5) cropping system model is applicable for the\nproduction of processing tomatoes with subsurface irrigation, and it revises\nthe soil module to simulate irrigation schemes with subsurface irrigation. Five\nfarmed fields in California, USA, are used to test the performance of the\nmodel. The original DSSAT model fails to produce fruit yield by overestimating\nthe water deficiency. The soil water module is then revised by introducing the\nmovement of soil moisture due to a vertical soil moisture gradient. Moreover,\nan external parameter optimization system is constructed to minimize the error\nbetween the simulation and observations. The revised module reduces the errors\nin the soil moisture profile at each field compared to those by the original\nDSSAT model. The average soil moisture error decreases from 0.065m^3/m^3 to\n0.029m^3/m^3. The yields estimated by the modified model are in a reasonable\nrange from 80 to 150 ton/ha, which is commonly observed under well-managed\nconditions. The present results show that although further testing is required\nfor yield prediction, the present modification to the original DSSAT model\nimproves the precision of the soil moisture profile under subsurface irrigation\nand can be used for decision support for efficient producting of processing\ntomatoes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Three errors and two problems in a recent paper: gazenet: End-to-end\n  eye-movement event detection with deep neural networks (Zemblys, Niehorster,\n  and Holmqvist, 2019)"}, {"role": "assistant", "content": "Zemblys et al. \\cite{gazeNet} reported on a method for the classification of\neye-movements (\"gazeNet\"). I have found 3 errors and two problems with that\npaper that are explained herein. \\underline{\\textit{\\textbf{Error 1}}} The\ngazeNet classification method was built assuming that a hand-scored dataset\nfrom Lund University was all collected at 500 Hz, but in fact, six of the 34\nrecording files were actually collected at 200Hz. Of the six datasets that were\nused as the training set for the gazeNet algorithm, 2 were actually collected\nat 200Hz. \\underline{\\textit{\\textbf{Problem 1}}} has to do with the fact that\neven among the 500Hz data, the inter-timestamp intervals varied widely.\n\\underline{\\textit{\\textbf{Problem 2}}} is that there are many unusual\ndiscontinuities in the saccade trajectories from the Lund University dataset\nthat make it a very poor choice for the construction of an automatic\nclassification method. \\underline{\\textit{\\textbf{Error 2}}} The gazeNet\nalgorithm was trained on the Lund dataset, and then compared to other methods,\nnot trained on this dataset, in terms of performance on this dataset. This is\nan inherently unfair comparison, and yet no where in the gazeNet paper is this\nunfairness mentioned. \\underline{\\textit{\\textbf{Error 3}}} arises out of the\nnovel event-related agreement analysis employed by the gazeNet authors.\nAlthough the authors intended to classify unmatched events as either false\npositives or false negatives, many are actually being classified as true\nnegatives. True negatives are not errors, and any unmatched event misclassified\nas a true negative is actually driving kappa higher, whereas unmatched events\nshould be driving kappa lower."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Walking for short distances and turning in lower-limb amputees: a study\n  in low-cost prosthesis users"}, {"role": "assistant", "content": "Preferred walking speed is a widely-used performance measure for people with\nmobility issues, but is usually measured in straight line walking for fixed\ndistances or durations. However, daily walking involves walking for bouts of\ndifferent distances and walking with turning. Here, we studied walking for\nshort distances and walking in circles in unilateral lower-limb amputees\nwearing an above or below-knee passive prosthesis, specifically, a Jaipur foot\nprosthesis. Analogous to earlier results in non-amputees, we found that their\npreferred walking speeds are lower for short distances and lower for circles of\nsmaller radii. Using inverse optimization, we estimated the cost of changing\nspeeds and turning such that the observed preferred walking speeds in our\nexperiments minimizes the total energy cost. The inferred costs of changing\nspeeds and turning were much larger than for non-amputees. These findings could\ninform prosthesis design and rehabilitation therapy to better assist changing\nspeeds and turning tasks in amputee walking. Further, measuring the preferred\nspeed for a range of distances and radii is a more robust subject-specific\nmeasure of walking performance."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Growth and mortality of endangered land crabs (Cardisoma guanhumi)\n  assessed through tagging with PITs and novel bootstrapped methods"}, {"role": "assistant", "content": "The land crab Cardisoma guanhumi Latreille, 1828 is harvested in several\ncountries in Latin America, and a critically endangered species. This is the\nfirst study to conduct bootstrapped tagging analysis (BTA) together with\nbootstrapped length-frequency analyses (BLFA). Crabs were sampled monthly in a\nmangrove patch at Itamaraca Island (Brazil), over 12 months, and marked with\nPIT tags. Both methods (BTA and BLFA) indicate very slow growth and Linf far\nabove Lmax. BTA estimates were K = 0.12 y-1 (95% CI: 0.024 to 0.26 y-1), Linf =\n118 mm (95% CI: 81 to 363 mm), Phi' = 1.23 log10(cm y-1) (95% CI: 0.86 to 1.36\nlog10(cm y-1)). Seasonality in growth was significant (p = 0.006, 95% CI for C:\n0.15 to 0.93, median: C = 0.56). Pairs of K and Linf always followed narrow\nPhi' isopleths. Total mortality was Z = 2.18 y-1 (95% CI = 1.7 to 4.5 y-1).\nSlow growth and a very high Z/K ratio highlight the need for protective\nmeasures. BTA results were 2.2 to 3 times more precise than BLFA. Traditional\nlength-based methods produced grossly biased results, indicating the urgent\nneed for new, robust approaches and a critical reevaluation of long-standing\nmethods and paradigms."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Acoustomicrofluidic separation of tardigrades from raw cultures for\n  sample preparation"}, {"role": "assistant", "content": "Tardigrades are microscopic animals widely known for their survival\ncapabilities under extreme conditions. They are the focus of current research\nin the fields of taxonomy, biogeography, genomics, proteomics, development,\nspace biology, evolution, and ecology. Tardigrades, such as Hypsibius\nexemplaris, are being advocated as a next-generation model organism for genomic\nand developmental studies. The raw culture of H. exemplaris usually contains\ntardigrades themselves, their eggs, and algal food and feces. Experimentation\nwith tardigrades often requires the demanding and laborious separation of\ntardigrades from raw samples to prepare pure and contamination-free tardigrade\nsamples. In this paper, we propose a two-step acousto-microfluidic separation\nmethod to isolate tardigrades from raw samples. In the first step, a passive\nmicrofluidic filter composed of an array of traps is used to remove large algal\nclusters in the raw sample. In the second step, a surface acoustic wave-based\nactive microfluidic separation device is used to continuously deflect\ntardigrades from their original streamlines inside the microchannel and thus\nselectively isolate them from algae and eggs. The experimental results\ndemonstrated the efficient tardigrade separation with a recovery rate of 96%\nand an algae impurity of 4% on average in a continuous, contactless, automated,\nrapid, biocompatible manner."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Novel imaging revealing inner dynamics for cardiovascular waveform\n  analysis via unsupervised manifold learning"}, {"role": "assistant", "content": "Cardiovascular waveforms contain information for clinical diagnosis. By\n\"learning\" and organizing the subtle change of waveform morphology from large\namounts of raw waveform data, unsupervised manifold learning helps delineate a\nhigh-dimensional structure and display it as a novel three-dimensional (3D)\nimage. We investigate the electrocardiography (ECG) waveform for ischemic heart\ndisease and arterial blood pressure (ABP) waveform in dynamic vasoactive\nepisodes. We model each beat or pulse to be a point lying on a manifold, like a\nsurface, and use the diffusion map (DMap) to establish the relationship among\nthose pulses. For ECG datasets, first we analyzed the non-ST-elevation ECG\nwaveform distribution from unstable angina to healthy control, and we\ninvestigated intraoperative ST-elevation ECG waveforms to show the dynamic ECG\nwaveform changes. For ABP datasets, we analyzed waveforms collected under\nendotracheal intubation and administration of vasodilator. To quantify the\ndynamic separation, we applied the support vector machine (SVM) analysis and\nthe trajectory analysis. For the non-ST-elevation ECG, a hierarchical tree\nstructure comprising consecutive ECG waveforms spanning from unstable angina to\nhealthy control is presented in the 3D image (accuracy=97.6%, macro-F1=96.1%).\nThe DMap helps quantify and visualize the evolving direction of intraoperative\nST-elevation myocardial episode in a 1-hour period (accuracy=97.58%,\nmacro-F1=96.06%). The ABP waveform analysis of Nicardipine administration shows\ninter-individual difference (accuracy=95.01%, macro-F1=96.9%) and their common\ndirections from intra-individual moving trajectories. The dynamic change of the\nABP waveform during endotracheal intubation shows a loop-like trajectory\nstructure, which can be further divided using the knowledge obtained from\nNicardipine. The 3D images provide clues of underneath physiological\nmechanisms."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Design and validation of a low cost programmable controlled environment\n  for study and production of plants, mushroom, and insect larvae"}, {"role": "assistant", "content": "Use of commercial growth chambers for study of biological processes involved\nin biomass growth and production pose certain limitations on the nature of\nstudies that can be performed in them. Optimization of biomass rearing and\nproduction process requires quantitative study of environment influences on the\norganism and eventually the products and byproducts consumed and produced. This\nwork presents a low cost modular system designed to facilitate quantitative\nstudy of growth processes and resource exchanges in organisms such as plants,\nfungi and insect larvae. The proposed system constitutes of modular units each\nperforming a specific function. A novel compact thermoelectric cooler based\nunit is designed for conditioning the air. Sensor cluster for measuring gas\nconcentrations, air properties (temperature, humidity, pressure), and growing\nmedium properties is implemented and tested. An actuator cluster for resource\nexchange and a wiring and control scheme for light spectrum adjustment is\nproposed. A three tier hierarchical software framework consisting of an\nopen-source cloud platform for data aggregation and user interaction, embedded\nfirmware for microcontroller, and an application development framework for test\nautomation and experiment regime design is developed and presented. A series of\nexperiments and tests were performed using the designed hardware and software\nto evaluate its capabilities and limitations. This controlled environment was\nused to study the photosynthesis and its dependency on temperature and light\nintensity in Ocimum basilicum. In a second experiment, evolution of metabolic\nactivity of Hermetia illucens larvae over its larval phase was studied and the\nmetabolic products and byproducts were quantitatively measured."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multiphysics analysis and practical implementation of an ionic soft\n  actuator-based microfluidic device toward the design of a POCT compatible\n  active micromixer"}, {"role": "assistant", "content": "Electroactive-Polymers (EAPs) are one of the best soft materials with great\napplications in active microfluidics. Ionic ones (i-EAPs) have more promising\nfeatures for being appropriate candidates to use in active microfluidic\ndevices. Here, as a case study, we have designed and fabricated a microfluidic\nmicromixer using an i-EAP named Ionic Polymer-Metal Composite (IPMC). In\nmicrofluidics, active devices have more functionality but due to their required\nfacilities are less effective for Point of Care Tests (POCTs). In the direction\nof solving this paradox, we should use some active components that they need\nminimum facilities. IPMC can be one of these components, hence by integrating\nthe IPMC actuator into a microfluidic channel, a micromixer chip was designed\nand put to the simulation and experimental tests. The result showed that the\nproposed micromixer is able to mix the micro fluids properly and IPMC actuator\nhas adequate potential to be an active component for POCT-based microfluidic\nchips."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Topological data analysis approaches to uncovering the timing of ring\n  structure onset in filamentous networks"}, {"role": "assistant", "content": "Improvements in experimental and computational technologies have led to\nsignificant increases in data available for analysis. Topological data analysis\n(TDA) is an emerging area of mathematical research that can identify structures\nin these data sets. Here we develop a TDA method to detect physical structures\nin a cell that persist over time. In most cells, protein filaments (actin)\ninteract with motor proteins (myosins) and organize into polymer networks and\nhigher-order structures. An example of these structures are ring channels that\nmaintain constant diameters over time and play key roles in processes such as\ncell division, development, and wound healing. The interactions of actin with\nmyosin can be challenging to investigate experimentally in living systems,\ngiven limitations in filament visualization \\textit{in vivo}. We therefore use\ncomplex agent-based models that simulate mechanical and chemical interactions\nof polymer proteins in cells. To understand how filaments organize into\nstructures, we propose a TDA method that assesses effective ring generation in\ndata consisting of simulated actin filament positions through time. We analyze\nthe topological structure of point clouds sampled along these actin filaments\nand propose an algorithm for connecting significant topological features in\ntime. We introduce visualization tools that allow the detection of dynamic ring\nstructure formation. This method provides a rigorous way to investigate how\nspecific interactions and parameters may impact the timing of filamentous\nnetwork organization."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: TbCAPs: A ToolBox for Co-Activation Pattern Analysis"}, {"role": "assistant", "content": "Functional magnetic resonance imaging provides rich spatio-temporal data of\nhuman brain activity during task and rest. Many recent efforts have focussed on\ncharacterising dynamics of brain activity. One notable instance is\nco-activation pattern (CAP) analysis, a frame-wise analytical approach that\ndisentangles the different functional brain networks interacting with a\nuser-defined seed region. While promising applications in various clinical\nsettings have been demonstrated, there is not yet any centralised, publicly\naccessible resource to facilitate the deployment of the technique.\n  Here, we release a working version of TbCAPs, a new toolbox for CAP analysis,\nwhich includes all steps of the analytical pipeline, introduces new\nmethodological developments that build on already existing concepts, and\nenables a facilitated inspection of CAPs and resulting metrics of brain\ndynamics. The toolbox is available on a public academic repository\n(https://c4science.ch/source/CAP_Toolbox.git).\n  In addition, to illustrate the feasibility and usefulness of our pipeline, we\ndescribe an application to the study of human cognition. CAPs are constructed\nfrom resting-state fMRI using as seed the right dorsolateral prefrontal cortex,\nand, in a separate sample, we successfully predict a behavioural measure of\ncontinuous attentional performance from the metrics of CAP dynamics (R=0.59)."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Prevention of Traumatic Brain Injury with Liquid Shock Absorption"}, {"role": "assistant", "content": "The discovery that repetitive mild traumatic brain injury (mTBI) can result\nin chronic traumatic encephalopathy (CTE) in high risk contact sports has led\nto increased scrutiny of head protective gear. In this work, we asked if it was\nphysically possible to prevent mTBI in American football with helmets alone.\nHere, we show that modern helmets of several types are unlikely to prevent mTBI\nfrom high speed collisions as might be seen in the NFL, but that introducing\nliquid as an energy absorbing medium can dramatically reduce the forces of\nimpact across a spectrum of impact severities. We hypothesized that a helmet\nwhich transmits a nearly constant force during football impacts is sufficient\nto reduce biomechanical loading in the brain below the threshold of mTBI. To\ntest this hypothesis, we first show that the optimal impact force transmitted\nto the head, in terms of brain strain, is in fact a constant force profile.\nThen, to generate a constant force with a helmet, we implement a computational\nmodel of a fluid-based shock absorber that adapts passively to any given impact\nspeed. Computer simulation of head impacts with liquid shock absorption\nindicate that, at the highest impact speed, the average brain tissue strain is\nreduced by 27.6% $\\pm$ 9.3 compared to existing helmet padding that is\navailable on the market. These simulations are based on the NFL's helmet test\nprotocol and predict that adding liquid shock absorbers could reduce the number\nof concussions by at least 75%. Taken together, these results suggest that the\nmajority of mTBI in football could be prevented with more efficient helmet\ntechnology."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Simple Modeling Framework For Prediction In The Human Glucose-Insulin\n  System"}, {"role": "assistant", "content": "In this paper, we build a new, simple, and interpretable mathematical model\nto estimate and forecast physiology related to the human glucose-insulin\nsystem, constrained by available data. By constructing a simple yet flexible\nmodel class with interpretable parameters, this general model can be\nspecialized to work in different settings, such as type 2 diabetes mellitus\n(T2DM) and intensive care unit (ICU); different choices of appropriate model\nfunctions describing uptake of nutrition and removal of glucose differentiate\nbetween the models. In both cases, the available data is sparse and collected\nin clinical settings, major factors that have constrained our model choice to\nthe simple form adopted.\n  The model has the form of a linear stochastic differential equation (SDE) to\ndescribe the evolution of the BG level. The model includes a term quantifying\nglucose removal from the bloodstream through the regulation system of the human\nbody and two other terms representing the effect of nutrition and externally\ndelivered insulin. The stochastic fluctuations encapsulate model error\nnecessitated by the simple model form and enable flexible incorporation of\ndata. The model parameters must be learned in a patient-specific fashion,\nleading to personalized models. We present experimental results on\npatient-specific parameter estimation and future BG level forecasting in T2DM\nand ICU settings. The resulting model leads to the prediction of the BG level\nas an expected value accompanied by a band around this value which accounts for\nuncertainties in the prediction. Such predictions, then, have the potential for\nuse as part of control systems that are robust to model imperfections and noisy\ndata. Finally, the model's predictive capability is compared with two different\nmodels built explicitly for T2DM and ICU contexts."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Prediction of 5-hydroxytryptamine Transporter Inhibitor based on Machine\n  Learning"}, {"role": "assistant", "content": "In patients with depression, the use of 5-HT reuptake inhibitors can improve\nthe condition. Topological fingerprints, ECFP4, and molecular descriptors were\nused. Some SERT and small molecules combined prediction models were established\nby using 5 machine learning methods. We selected the higher accuracy models(RF,\nSVM, LR) in five-fold cross-validation of training set to establish an\nintegrated model (VOL_CLF). The training set is from Chembl database and\noversampled by SMOTE algorithm to eliminate data imbalance. The unbalanced data\nfrom same sources (Chembl) was used as Test set 1; the unbalanced data with\ndifferent sources(Drugbank) was used as Test set 2 . The prediction accuracy of\nSERT inhibitors in Test set 1 was 90.7%~93.3%(VOL_CLF method was the highest);\nthe inhibitory recall rate was 84.6%-90.1%(RF method was the highest); the\nnon-inhibitor prediction accuracy rate was 76.1%~80.2%(RF method is the\nhighest); the non-inhibitor predictive recall rate is 81.2%~87.5% (SVM and\nVOL_CLF methods were the highest) The RF model in Test Set 2 performed better\nthan the other models. The SERT inhibitor predicted accuracy rate, recall rate,\nnon-inhibitor predicted accuracy rate, recall rate were 42.9%, 85.7%, 95.7%,\n73.3%.This study demonstrates that machine learning methods effectively predict\ninhibitors of serotonin transporters and accelerate drug screening."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Positive HBs antigen in the absence of hepatitis B virus infection"}, {"role": "assistant", "content": "French recommendations for the screening of hepatitis B virus (HBV) infection\nwere updated in 2019 with the association of three markers: HBs Ag, anti-HBs Ab\nand anti-HBc Ab. These three markers allow identification of infected patients,\nvaccinated patients and patients who have been in contact with HBV. A positive\nHBs Ag is usually associated with HBV infection but this interpretation must\ntake into account the clinical context. In particular, the absence of anti-HBc\nAb, normal ALAT levels and the absence of jaundice can be associated with\nrecent HBV vaccination or false-positive HBs Ag. Recent HBV vaccination can\nusually be confirmed by patient questioning, while confirmatory tests are\nuseful to detect false positive HBs Ag. If necessary, a second sample can be\nrequested to confirm the interpretation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Evaluation of the efficacy of RUTI and ID93/GLA-SE vaccines in\n  tuberculosis treatment: in silico trial through UISS-TB simulator"}, {"role": "assistant", "content": "Tuberculosis (TB) is one of the deadliest diseases worldwide, with 1,5\nmillion fatalities every year along with potential devastating effects on\nsociety, families and individuals. To address this alarming burden, vaccines\ncan play a fundamental role, even though to date no fully effective TB vaccine\nreally exists. Current treatments involve several combinations of antibiotics\nadministered to TB patients for up to two years, leading often to financial\nissues and reduced therapy adherence. Along with this, the development and\nspread of drug-resistant TB strains is another big complicating matter. Faced\nwith these challenges, there is an urgent need to explore new vaccination\nstrategies in order to boost immunity against tuberculosis and shorten the\nduration of treatment. Computational modeling represents an extraordinary way\nto simulate and predict the outcome of vaccination strategies, speeding up the\narduous process of vaccine pipeline development and relative time to market.\nHere, we present EU - funded STriTuVaD project computational platform able to\npredict the artificial immunity induced by RUTI and ID93/GLA-SE, two specific\ntuberculosis vaccines. Such an in silico trial will be validated through a\nphase 2b clinical trial. Moreover, STriTuVaD computational framework is able to\ninform of the reasons for failure should the vaccinations strategies against M.\ntuberculosis under testing found not efficient, which will suggest possible\nimprovements."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Antibacterial and Antioxidant Activities of Centeurea damascena\n  Methanolic Extract"}, {"role": "assistant", "content": "The family Asteraceae include large number of Centaurea species which have\nbeen applied in folk medicine. One of the family Asteraceae members is the\nCentaurea damascena which authentically been tested for its antibacterial and\nantioxidant activity as well as its toxicity. The aims of the study were to\ndetermine the antimicrobial and antioxidant activities and toxicity of\nmethanolic plant extracts of Centaurea damascena. The methanolic extracts were\nscreened for their antibacterial activity against nine bacteria (Staphylococcus\naureus ATCC 43300, Bacillus subtilis ATCC 6633, Micrococcus luteus ATCC 10240,\nand Staphylococcus epidermidis ATCC 12228, Escherichia coli ATCC 11293,\nPseudomonas aerugino and Klebsiella pneumoniae, Enterobacter aerogenes ATCC\n13048 and Salmonella typhi ATCC19430). The antibacterial activity was assessed\nby using the disc diffusion methods and the minimum inhibition concentrations\n(MIC) using microdilution method. The extracts from Centaurea damascena\npossessed antibacterial activity against several of the tested microorganisms.\nThe MIC of methanol extract of C. damascena ranged from 60 to 1100 microgram\nper mL. Free radical scavenging capacity of the C. damascena methanol extract\nwas calculated by DPPH and FRAP test. DPPH radicals were scavenged with an IC50\nvalue of 17.08 microgram per mL. Antioxidant capacities obtained by the FRAP\nwas 51.9 and expressed in mg Trolox per gram dry weight. The total phenolic\ncompounds of the methanol extracts of aerial parts, as estimated by\nFolin_Ciocalteu reagent method, was about 460 mg GAE per gram. The phenolic\ncontents in the extracts highly correlate with their antioxidant activity,\nconfirming that the antioxidant activity of this plant extracts is considerably\nphenolic contents-dependent."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Vitreoscilla sp. hemoglobin (VHb) Expression in Heterologous Hosts: Some\n  Aspects of Their Biotechnological Application"}, {"role": "assistant", "content": "It is worth mentioning that the high output of different physiological\nresponses under the expression of vgb, may have a considerable effect on the\nenzyme productivity, dairy industry, heavy metal uptake, biodegradation of\ndifferent organic pollutants and other applications. The expression of\nbacterial haemoglobin is useful in lessening the load of perceived toxic\nconditions such as high oxygen levels. This in turn probably has the same\nimpact on some peripheral toxic materials. This, hemoglobin biotechnology can\nbe extended to enhance production of pollutants degrading enzymes or production\nof some valuable manufacturing materials on the case by case bases. It is\nlikely that the mechanism of bacterial hemoglobin (VHb) effects is\nintermediated via an oxygen trapping action. This may drive the enrichment of\nATP production, which is mostly required for higher productivity of needed\nsubstances for that activity."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Antibactrial Activity of Asteriscus graveolens Methanolic Extract:\n  Synergistic Effect with Fungal Mediated Nanoparticles against Some Enteric\n  Bacterial Human Pathogens"}, {"role": "assistant", "content": "Antibactrial activity of Asteriscus graveolens methanolic extract and its\nsynergy effect with fungal mediated silver nanoparticles (AgNPs) against some\nenteric bacterial human pathogen was conducted. Silver nanoparticles were\nsynthesized by the fungal strain namely Tritirachium oryzae W5H as reported\nearly. In this study, MICs of AgNPs against E. aerogenes, Salmonella sp., E.\ncoli and C. albicans in order were 2.13, 19.15, 0.08 and 6.38 micrograms per\nmL, respectively, while the MICs of A. graveolens ethanolic extract against the\nsame bacteria were 4, 366, 3300 and 40 micrograms per mL, respectively. The MIC\nvalues at concentration less than 19.15 and 40 micrograms per mL indicating the\npotent bacteriostatic effect of AgNPs and A. graveolens ethanolic\nextract.Increasing in IFA was reported when Nitrofurantion and Trimethoprim\nwere combined with Etoh extract with maximum increase in IFA by 6 and 12 folds\nfor, respectively. Also, 10 folds increasing in IFA was reported when\ntrimethoprim was combined with AgNPs: Etoh extract.But, there were no\nsynergistic effect between the antifungal agents (Caspofungin and Micafungin)\ncombined with AgNPs and or A. graveolens ethanolic extract against C.\nalbicans.The potent synergistic effect of A. graveolens ethanolic extract\nand/or NPs with the conventional antibiotics is novel in inhibiting antibiotics\nresistant bacteria. In this study, remarkable increasing in the antibacterial\nactivity, when the most resistant antibiotics combined with A. graveolense\nthanolic extract and/or NPs was reported."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Biological Value of Centaurea damascena: Minireview"}, {"role": "assistant", "content": "The family Asteraceae include large number of Centaurea species which have\nbeen applied in folk medicine. One of the family Asteraceae members is the\nCentaurea damascena which authentically been tested for its antibacterial\nactivity. The aim of the study was to discuss antibacterial activities of\nessential oil composition and methanolic extract of the same plant aerial part\nleaves. Thirty-seven components were characterized with 86 of oxygenated\nterpenes. The composition in percentage was dominated by 11.45 Fokienol, 8.8\nthymol, 8.21 Alpha Terpineol, 7.24 Chrysanthemumic acid, 7.13 Terpinen4-ol and\n6.59 Borneol with a high degree of polymorphism in the occurrence of these\ncompounds as compared with the different species of centaurea.. Free radical\nscavenging capacity of the C. damascna methanol extract was calculated by DPPH\nand FRAP test. DPPH radicals were scavenged with an IC50 value of 17.08\nmicrogram per ml. Antioxidant capacities obtained by the FRAP was 51.9 and\nexpressed in mg Trolox gram per Liter dry weight. The total phenolic compounds\nof the methanol extracts of aerial parts, as estimated by Folin Ciocalteu\nreagent method, was about 460 milligram GAE per gram. The phenolic contents in\nthe extracts highly correlate with their antioxidant activity, confirming that\nthe antioxidant activity of this plant extracts is considerably phenolic\ncontents dependent."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Model-based simulation of maintenance therapy of childhood acute\n  lymphoblastic leukemia"}, {"role": "assistant", "content": "Acute lymphoblastic leukemia is the most common malignancy in childhood.\nSuccessful treatment requires initial high-intensity chemotherapy, followed by\nlow-intensity oral maintenance therapy with oral 6-mercaptopurine (6MP) and\nmethotrexate (MTX) until 2-3 years after disease onset. However, intra- and\ninterindividual variability in the pharmacokinetics (PK) and pharmacodynamics\n(PD) of 6MP and MTX make it challenging to balance the desired antileukemic\neffects with undesired excessive myelosuppression during maintenance therapy. A\nmodel to simulate the dynamics of different cell types, especially neutrophils,\nwould be a valuable contribution to improving treatment protocols (6MP and MTX\ndosing regimens) and a further step to understanding the heterogeneity in\ntreatment efficacy and toxicity. We applied and modified a recently developed\nsemi-mechanistic PK/PD model to neutrophils and analyzed their behavior using a\nnonlinear mixed-effects modeling approach and clinical data obtained from 116\npatients. The PK model of 6MP influenced the accuracy of absolute neutrophil\ncount (ANC) predictions, whereas the PD effect of MTX did not. Predictions\nbased on ANC were more accurate than those based on white blood cell counts.\nUsing the new cross-validated mathematical model, simulations of different\ntreatment protocols showed a linear dose-effect relationship and reduced ANC\nvariability for constant dosages. Advanced modeling allows the identification\nof optimized control criteria and the weighting of specific influencing factors\nfor protocol design and individually adapted therapy to exploit the optimal\neffect of maintenance therapy on survival."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: DTF: Deep Tensor Factorization for Predicting Anticancer Drug Synergy"}, {"role": "assistant", "content": "Motivation: Combination therapies have been widely used to treat cancers.\nHowever, it is cost- and time-consuming to experimentally screen synergistic\ndrug pairs due to the enormous number of possible drug combinations. Thus,\ncomputational methods have become an important way to predict and prioritize\nsynergistic drug pairs.\n  Results: We proposed a Deep Tensor Factorization (DTF) model, which\nintegrated a tensor factorization method and a deep neural network (DNN), to\npredict drug synergy. The former extracts latent features from drug synergy\ninformation while the latter constructs a binary classifier to predict the drug\nsynergy status. Compared to the tensor-based method, the DTF model performed\nbetter in predicting drug synergy. The area under the precision-recall curve\n(PR AUC) was 0.57 for DTF and 0.24 for the tensor method. We also compared the\nDTF model with DeepSynergy and logistic regression models and found that the\nDTF outperformed the logistic regression model and achieved almost the same\nperformance as DeepSynergy using several typical metrics for the classification\ntask. Applying the DTF model to predict missing entries in our drug-cell line\ntensor, we identified novel synergistic drug combinations for 10 cell lines\nfrom the 5 cancer types. A literature survey showed that some of these\npredicted drug synergies have been identified in vivo or in vitro. Thus, the\nDTF model could be valuable in silico tool for prioritizing novel synergistic\ndrug combinations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Binary Particle Swarm Optimization Approach for Gene Expression\n  Biclustering Problem"}, {"role": "assistant", "content": "Microarray techniques are widely used in Gene expression analysis. These\ntechniques are based on discovering submatrices of genes that share similar\nexpression patterns across a set of experimental conditions with coherence\nconstraint. Actually, these submatrices are called biclusters and the\nextraction process is called biclustering. In this paper we present a novel\nbinary particle swarm optimization model for the gene expression biclustering\nproblem. Hence, we apply the binary particle swarm optimization algorithm with\na proposed measure, called Discretized Column-based Measure (DCM) as a novel\ncost function for evaluating biclusters where biological relevance, MSR and the\nsize of the bicluster are considered as evaluation metrics for our results.\nResults are compared to the existing algorithms and they show the validity of\nour proposed approach."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: On generative models of T-cell receptor sequences"}, {"role": "assistant", "content": "T-cell receptors (TCR) are key proteins of the adaptive immune system,\ngenerated randomly in each individual, whose diversity underlies our ability to\nrecognize infections and malignancies. Modeling the distribution of TCR\nsequences is of key importance for immunology and medical applications. Here,\nwe compare two inference methods trained on high-throughput sequencing data: a\nknowledge-guided approach, which accounts for the details of sequence\ngeneration, supplemented by a physics-inspired model of selection; and a\nknowledge-free Variational Auto-Encoder based on deep artificial neural\nnetworks. We show that the knowledge-guided model outperforms the deep network\napproach at predicting TCR probabilities, while being more interpretable, at a\nlower computational cost."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Systematic external evaluation of published population pharmacokinetic\n  models for tacrolimus in adult liver transplant recipients"}, {"role": "assistant", "content": "Background:Diverse tacrolimus population pharmacokinetic models in adult\nliver transplant recipients have been established to describe the PK\ncharacteristics of tacrolimus in the last two decades. However, their\nextrapolated predictive performance remains unclear.Therefore,in this study,we\naimed to evaluate their external predictability and identify their potential\ninfluencing factors. Methods:The external predictability of each selected popPK\nmodel was evaluated using an independent dataset of 84 patients with 572 trough\nconcentrations prospectively collected from Huashan Hospital. Prediction and\nsimulation based diagnostics and Bayesian forecasting were conducted to\nevaluate model predictability. Furthermore, the effect of model structure on\nthe predictive performance was investigated.Results:Sixteen published popPK\nmodels were assessed. In prediction-based diagnostics,the prediction error\nwithin 30% was below 50% in all the published models. The simulation based\nnormalised prediction distribution error test and visual predictive check\nindicated large discrepancies between the observations and simulations in most\nof the models. Bayesian forecasting showed improvement in model predictability\nwith two to three prior observations. Additionally, the predictive performance\nof the nonlinear Michaelis Menten model was superior to that of linear\ncompartment models,indicating the underlying nonlinear kinetics of tacrolimus\nin liver transplant recipients.Conclusions:The published models performed\ninadequately in prediction and simulation based diagnostics. Bayesian\nforecasting may improve the predictive performance of the models. Furthermore,\nnonlinear kinetics of tacrolimus may be mainly caused by the properties of the\ndrug itself, and incorporating nonlinear kinetics may be considered to improve\nmodel predictability."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Population Pharmacokinetic Study of Tacrolimus in Pediatric Patients\n  with Primary Nephrotic Syndrome: A Comparison of Linear and Nonlinear\n  Michaelis Menten Pharmacokinetic Model"}, {"role": "assistant", "content": "Background Little is known about the population pharmacokinetics (PPK) of\ntacrolimus (TAC) in pediatric primary nephrotic syndrome (PNS). This study\naimed to compare the predictive performance between nonlinear and linear PK\nmodels and investigate the significant factors of TAC PK characteristics in\npediatric PNS. Methods Data were obtained from 71 pediatric patients with PNS,\nalong with 525 TAC trough concentrations at steady state. The demographic,\nmedical, and treatment details were collected. Genetic polymorphisms were\nanalyzed. The PPK models were developed using nonlinear mixed effects model\nsoftware. Two modeling strategies, linear compartmental and nonlinear Michaelis\nMenten (MM) models, were evaluated and compared. Results Body weight, age,\ndaily dose of TAC, co-therapy drugs (including azole antifungal agents and\ndiltiazem), and CYP3A5*3 genotype were important factors in the final linear\nmodel (onecompartment model), whereas only body weight, codrugs, and CYP3A5*3\ngenotype were the important factors in the nonlinear MM model. Apparent\nclearance and volume of distribution in the final linear model were 7.13 L/h\nand 142 L, respectively. The maximal dose rate (Vmax) of the nonlinear MM model\nwas 1.92 mg/day and the average concentration at steady state at half-Vmax (Km)\nwas 1.98 ng/mL. The nonlinear model described the data better than the linear\nmodel. Dosing regimens were proposed based on the nonlinear PK model.Conclusion\nOur findings demonstrate that the nonlinear MM model showed better predictive\nperformance than the linear compartmental model, providing reliable support for\noptimizing TAC dosing and adjustment in children with PNS."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: An Informatics-based Approach to Identify Key Pharmacological Components\n  in Drug-Drug Interactions"}, {"role": "assistant", "content": "Drug-drug interactions (DDI) can cause severe adverse drug reactions and pose\na major challenge to medication therapy. Recently, informatics-based approaches\nare emerging for DDI studies. In this paper, we aim to identify key\npharmacological components in DDI based on large-scale data from DrugBank, a\ncomprehensive DDI database. With pharmacological components as features,\nlogistic regression is used to perform DDI classification with a focus on\nsearching for most predictive features, a process of identifying key\npharmacological components. Using univariate feature selection with chi-squared\nstatistic as the ranking criteria, our study reveals that top 10% features can\nachieve comparable classification performance compared to that using all\nfeatures. The top 10% features are identified to be key pharmacological\ncomponents. Furthermore, their importance is quantified by feature coefficients\nin the classifier, which measures the DDI potential and provides a novel\nperspective to evaluate pharmacological components."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Heuristic algorithms in Evolutionary Computations and modular\n  organization of biological macromolecules: applications to directed evolution"}, {"role": "assistant", "content": "A while ago, the ideas of evolutionary biology inspired computer scientists\nto develop a thriving nowadays field of evolutionary computation (EC), in\ngeneral, and genetic algorithms (GA), in particular. At the same time, the\ndirected evolution of biological molecules (in vitro evolution) is reasonably\ninterpreted as an implementation of GA in biochemical experiments. One of the\ntheoretical foundations of GA, justifying the effectiveness of evolutionary\nsearch, is the concept of building blocks (BB). In EC, it is reasonable to\nmatch these BBs to domains and motifs of macromolecules in evolutionary and\nsynthetic biology. Computer scientists have shown and carefully studied the\nimportance of preserving already found BBs for the effectiveness of\nevolutionary search. For this purpose, dozens of algorithms have been\ndeveloped, including heuristic crossover algorithms. On the other hand, the\nexperimental procedures defining and preserving domains remain a poorly\ndeveloped area in the techniques of evolution in vitro. In this paper, we\ndemonstrate how several simple algorithms preserving the BBs can increase the\nefficiency of in vitro evolution in numerical experiments by almost an order of\nmagnitude. As test problems, we propose and use such well-known problems of\nsynthetic biology as the evolutionary search for strong bacterial promoters\n(with several motifs) and search for multi-domain RNA devices, as compared to\nthe classic GA tests (Royal Road functions). The success of these primary tests\nwith simple algorithms gives us every reason to expect that the implementation\nand application of more advanced and modern EC procedures will give an even\ngreater increase in efficiency. Such an increase in search efficiency will\nsignificantly reduce the cost of in vitro evolution experiments, which will\nfully cover the costs of developing new experimental procedures based on these\nalgorithms."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Analysis of dysautonomia in patients with Chagas Cardiomyopathy"}, {"role": "assistant", "content": "Chagas disease American trypanosomiasis is caused by a flagellated parasite:\ntrypanosoma cruzi, transmitted by an insect of the genus Triatoma and also by\nblood transfusions. In Latin America the number of infected people is\napproximately 6 million, with a population exposed to the risk of infection of\n550000. It is our interest to develop a non-invasive, low-cost methodology,\ncapable of detecting any alteration early on cardiaca produced by T. cruzi. We\nanalyzed the 24 hour RR records in patients with ECG abnormalities (CH2),\npatients without ECG alterations (CH1) who had positive serological findings\nfor Chagas disease and healthy (Control) matched by sex and age. We found\nsignificant differences between the Control, CH1 and CH2 groups that show\ndysautonomy and enervation of the autonomic nervous system."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Discovering and interpreting transcriptomic drivers of imaging traits\n  using neural networks"}, {"role": "assistant", "content": "Motivation. Cancer heterogeneity is observed at multiple biological levels.\nTo improve our understanding of these differences and their relevance in\nmedicine, approaches to link organ- and tissue-level information from\ndiagnostic images and cellular-level information from genomics are needed.\nHowever, these \"radiogenomic\" studies often use linear, shallow models, depend\non feature selection, or consider one gene at a time to map images to genes.\nMoreover, no study has systematically attempted to understand the molecular\nbasis of imaging traits based on the interpretation of what the neural network\nhas learned. These current studies are thus limited in their ability to\nunderstand the transcriptomic drivers of imaging traits, which could provide\nadditional context for determining clinical traits, such as prognosis.\n  Results. We present an approach based on neural networks that takes\nhigh-dimensional gene expressions as input and performs nonlinear mapping to an\nimaging trait. To interpret the models, we propose gene masking and gene\nsaliency to extract learned relationships from radiogenomic neural networks. In\nglioblastoma patients, our models outperform comparable classifiers (>0.10 AUC)\nand our interpretation methods were validated using a similar model to identify\nknown relationships between genes and molecular subtypes. We found that imaging\ntraits had specific transcription patterns, e.g., edema and genes related to\ncellular invasion, and 15 radiogenomic associations were predictive of\nsurvival. We demonstrate that neural networks can model transcriptomic\nheterogeneity to reflect differences in imaging and can be used to derive\nradiogenomic associations with clinical value."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A simulation-based comparative analysis of PID and LQG control for\n  closed-loop anesthesia delivery"}, {"role": "assistant", "content": "Closed loop anesthesia delivery (CLAD) systems can help anesthesiologists\nefficiently achieve and maintain desired anesthetic depth over an extended\nperiod of time. A typical CLAD system would use an anesthetic marker,\ncalculated from physiological signals, as real-time feedback to adjust\nanesthetic dosage towards achieving a desired set-point of the marker. Since\ncontrol strategies for CLAD vary across the systems reported in recent\nliterature, a comparative analysis of common control strategies can be useful.\nFor a nonlinear plant model based on well-established models of compartmental\npharmacokinetics and sigmoid-Emax pharmacodynamics, we numerically analyze the\nset-point tracking performance of three output-feedback linear control\nstrategies: proportional-integral-derivative (PID) control, linear quadratic\nGaussian (LQG) control, and an LQG with integral action (ILQG). Specifically,\nwe numerically simulate multiple CLAD sessions for the scenario where the plant\nmodel parameters are unavailable for a patient and the controller is designed\nbased on a nominal model and controller gains are held constant throughout a\nsession. Based on the numerical analyses performed here, conditioned on our\nchoice of model and controllers, we infer that in terms of accuracy and bias\nPID control performs better than ILQG which in turn performs better than LQG.\nIn the case of noisy observations, ILQG can be tuned to provide a smoother\ninfusion rate while achieving comparable steady-state response with respect to\nPID. The numerical analyses framework and findings, reported here, can help\nCLAD developers in their choice of control strategies. This paper may also\nserve as a tutorial paper for teaching control theory for CLAD."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Inferring the immune response from repertoire sequencing"}, {"role": "assistant", "content": "High-throughput sequencing of B- and T-cell receptors makes it possible to\ntrack immune repertoires across time, in different tissues, and in acute and\nchronic diseases or in healthy individuals. However, quantitative comparison\nbetween repertoires is confounded by variability in the read count of each\nreceptor clonotype due to sampling, library preparation, and expression noise.\nHere, we present a general Bayesian approach to disentangle repertoire\nvariations from these stochastic effects. Using replicate experiments, we first\nshow how to learn the natural variability of read counts by inferring the\ndistributions of clone sizes as well as an explicit noise model relating true\nfrequencies of clones to their read count. We then use that null model as a\nbaseline to infer a model of clonal expansion from two repertoire time points\ntaken before and after an immune challenge. Applying our approach to yellow\nfever vaccination as a model of acute infection in humans, we identify\ncandidate clones participating in the response."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Exploratory Projection to Latent Structure Models for use in\n  Transcriptomic Analysis"}, {"role": "assistant", "content": "In this paper, we ask if it is possible to increase the interpretability in\nmultivariate analysis by aligning and projecting covariates onto comparative\nsubspaces. We demonstrate our method as well as the interpretative power of PLS\ndecomposed models and how robust interpretability can lead to quantitative\ninsights.\n  We discuss the statistical properties of the PLS weights, $p$-values\nassociated with specific axes, as well as their alignment properties.\n  The applicability of this approach within life science is also demonstrated\nby applying it to three use cases of publically available datasets.\n  Further we present hierarchical pathway enrichment results stemming from\naligned $p$-values, which are compared with results derived from enrichment\nanalysis, as an external validation of our method.\n  We find that the method can uncover known results from genomics for all of\nthe studied use cases, i.e. microarray data from multiple sclerosis and\ndiabetes patients as well as RNA sequencing data from breast cancer patients."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Ultrasound in Locomotion Research -- The Quest for Wider Views"}, {"role": "assistant", "content": "In a systematic review, we investigate current applications of ultrasound in\nlocomotion research. Shortcomings in the range of view of ultrasound systems\naffect the direct validation of musculoskeletal simulations as inverse\napproaches have to be applied. We present currently used methods to estimate\nmuscle and tendon length in human plantarflexors."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Efficiently simulating discrete-state models with binary decision trees"}, {"role": "assistant", "content": "Stochastic simulation algorithms (SSAs) are widely used to numerically\ninvestigate the properties of stochastic, discrete-state models. The Gillespie\nDirect Method is the pre-eminent SSA, and is widely used to generate sample\npaths of so-called agent-based or individual-based models. However, the\nsimplicity of the Gillespie Direct Method often renders it impractical where\nlarge-scale models are to be analysed in detail. In this work, we carefully\nmodify the Gillespie Direct Method so that it uses a customised binary decision\ntree to trace out sample paths of the model of interest. We show that a\ndecision tree can be constructed to exploit the specific features of the chosen\nmodel. Specifically, the events that underpin the model are placed in\ncarefully-chosen leaves of the decision tree in order to minimise the work\nrequired to keep the tree up-to-date. The computational efficencies that we\nrealise can provide the apparatus necessary for the investigation of\nlarge-scale, discrete-state models that would otherwise be intractable. Two\ncase studies are presented to demonstrate the efficiency of the method."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Re-Examination of the Evidence used by Hooge et al (2018) \"Is human\n  classification by experienced untrained observers a gold standard in fixation\n  detection?\""}, {"role": "assistant", "content": "Hooge et al. asked the question: \"Is human classification by experienced\nuntrained observers a gold standard in fixation detection?\" They conclude the\nanswer is no. If they had entitled their paper: \"Is human classification by\nexperienced untrained observers a gold standard in fixation detection when data\nquality is very poor, data are error-filled, data presentation was not optimal,\nand the analysis was seriously flawed?\", I would have no case to make. In the\npresent report, I will present evidence to support my view that this latter\ntitle is justified. The low quality data assessment is based on using a\nrelatively imprecise eye-tracker, the absence of head restraint for any\nsubjects, and the use of infants as the majority of subjects (60 of 70\nsubjects). Allowing subjects with more than 50% missing data (as much as 95%)\nis also evidence of low quality data. The error-filled assessment is based on\nevidence that a number of the \"fixations\" classified by \"experts\" have obvious\nsaccades within them, and that, apparently, a number of fixations were\nclassified on the basis of no signal at all. The evidence for non-optimal data\npresentation stems from the fact that, in a number of cases, perfectly good\ndata was not presented to the coders. The flaws in the analysis are evidenced\nby the fact that entire stretches of missing data were considered classified,\nand that the measurement of saccade amplitude was based on many cases in which\nthere was no saccade at all. Without general evidence to the contrary, it is\ncorrect to assume that some human classifiers under some conditions may meet\nthe criteria for a gold standard, and classifiers under other conditions may\nnot. This conditionality is not recognized by Hooge et al. A fair assessment\nwould conclude that whether or not humans can be considered a gold standard is\nstill very much an open question."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Age dependence of fitness and body mass index in Korean adults"}, {"role": "assistant", "content": "The aim of this study was to investigate the age dependence of the fitness\nand body mass index (BMI) in Korean adults and to find an effective exercise to\nrestore the degradation of fitness due to aging. The age dependence of the\nfitness and BMI were calculated using their lump mean values (LMVs) and a\nlinear regression method. The fitness sensitivity percentage to age (FSPA) and\nfitness sensitivity percentage to BMI (FSPB) were introduced as indicators for\nthe effective improvement of the fitness. The results showed that the\ndegradation of fitness due to aging, especially the degradation of\ncardiorespiratory endurance and muscular endurance, could be improved\neffectively by controlling the 20-m multi-stage shuttle run and sit-up scores\nfor both males and females. The results also showed that the BMIs could be\neffectively controlled with enhancing the 10-m shuttle run and standing long\njump scores for both males and females. It is expected that the LMV, FSPA, and\nFSPB could be used to improve fitness effectively and to establish personal\nexercise aims."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Defining mass transfer in a capillary wave micro-bioreactor"}, {"role": "assistant", "content": "For high-throughput cell culture and associated analytics, droplet-based\ncultivation systems open up the opportunities for parallelization and rapid\ndata generation. In contrast to microfluidics with continuous flow, sessile\ndroplet approaches enhance the flexibility for fluid manipulation with usually\nless operational effort. Generating biologically favorable conditions and\npromoting cell growth in a droplet, however, is particularly challenging due to\nmass transfer limitations, which has to be solved by implementing an effective\nmixing technique. Here, capillary waves induced by vertical oscillation are\nused to mix inside a sessile droplet micro-bioreactor (MBR) system avoiding\nadditional moving parts inside the fluid. Depending on the excitation\nfrequency, different patterns are formed on the oscillating liquid surface,\nwhich are described by a model of a vibrated sessile droplet. Analyzing mixing\ntimes and oxygen transport into the liquid, a strong dependency of mass\ntransfer on the oscillation parameters, especially the excitation frequency, is\ndemonstrated. Oscillations at distinct capillary wave resonant frequencies lead\nto rapid homogenization with mixing times of 2 s and volumetric liquid-phase\nmass transfer coefficients of more than 340 h-1. This shows that the mass\ntransfer in a droplet MBR can be specifically controlled via capillary waves,\nwhat is subsequently demonstrated for cultivations of Escherichia coli BL21\ncells. Therefore, the presented MBR in combination with vertical oscillation\nmixing for intensified mass transfer is a promising tool for highly parallel\ncultivation and data generation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Single-cell entropy to quantify the cellular transcription from\n  single-cell RNA-seq data"}, {"role": "assistant", "content": "We present the use of single-cell entropy (scEntropy) to measure the order of\nthe cellular transcriptome profile from single-cell RNA-seq data, which leads\nto a method of unsupervised cell type classification through scEntropy followed\nby the Gaussian mixture model (scEGMM). scEntropy is straightforward in\ndefining an intrinsic transcriptional state of a cell. scEGMM is a coherent\nmethod of cell type classification that includes no parameters and no\nclustering; however, it is comparable to existing machine learning-based\nmethods in benchmarking studies and facilitates biological interpretation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Structural and hemodynamic properties in murine pulmonary arterial\n  networks under hypoxia-induced pulmonary hypertension"}, {"role": "assistant", "content": "Detection and monitoring of patients with pulmonary hypertension, defined as\nmean blood pressure in the main pulmonary artery above 25 mmHg, requires a\ncombination of imaging and hemodynamic measurements. This study demonstrates\nhow to combine imaging data from microcomputed tomography (micro-CT) images\nwith hemodynamic pressure and flow waveforms from control and hypertensive\nmice. Specific attention is devoted to developing a tool that processes CT\nimages, generating subject-specific arterial networks in which 1D fluid\ndynamics modeling is used to predict blood pressure and flow. Each arterial\nnetwork is modeled as a directed graph representing vessels along the principal\npathway to ensure perfusion of all lobes. The 1D model couples these networks\nwith structured tree boundary conditions informed by the image data. Fluid\ndynamics equations are solved in this network and compared to measurements of\npressure in the main pulmonary artery. Analysis of micro-CT images reveals that\nthe branching ratio is the same in the control and hypertensive animals, but\nthat the vessel length to radius ratio is significantly lower in the\nhypertensive animals. Fluid dynamics predictions show that in addition to\nchanged network geometry, vessel stiffness is higher in the hypertensive animal\nmodels than in the control models."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Millisecond insect tracking system"}, {"role": "assistant", "content": "Animals such as insects have provided a rich source of inspiration for\ndesigning robots. For example, animals navigate to goals via efficient\ncoordination of individual motor actions, and demonstrate natural solutions to\nproblems also faced by engineers. Recording individual body part positions\nduring large scale movement would therefore be useful. Such multi-scale\nobservations, however, are challenging. With video, for example, there is\ntypically a trade-off between the volume over which an animal can be recorded\nand spatial resolution within the volume. Even with high pixel-count cameras,\nmotion blur can be a challenge when using available light. Here we present a\nnew approach for tracking animals, such as insects, with an optical system that\nbypasses this tradeoff by actively pointing a telephoto video camera at the\nanimal. This system is based around high-speed pan-tilt mirrors which steer an\noptical path shared by a quadrant photodiode and a high-resolution, high-speed\ntelephoto video recording system. The mirror is directed to lock on to the\nimage of a 25-milligram retroreflector worn by the animal. This system allows\nhigh-magnification videography with reduced motion blur over a large tracking\nvolume. With our prototype, we obtained millisecond order closed-loop latency\nand recorded videos of flying insects in a tracking volume extending to an\naxial distance of 3 meters and horizontally and vertically by 40 degrees. The\nsystem offers increased capabilities compared to other video recording\nsolutions and may be useful for the study of animal behavior and the design of\nbio-inspired robots."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Machine Learning Models to Predict Inhibition of the Bile Salt Export\n  Pump"}, {"role": "assistant", "content": "Drug-induced liver injury (DILI) is the most common cause of acute liver\nfailure and a frequent reason for withdrawal of candidate drugs during\npreclinical and clinical testing. An important type of DILI is cholestatic\nliver injury, caused by buildup of bile salts within hepatocytes; it is\nfrequently associated with inhibition of bile salt transporters, such as the\nbile salt export pump (BSEP). Reliable in silico models to predict BSEP\ninhibition directly from chemical structures would significantly reduce costs\nduring drug discovery and could help avoid injury to patients. Unfortunately,\nmodels published to date have been insufficiently accurate to encourage wide\nadoption. We report our development of classification and regression models for\nBSEP inhibition with substantially improved performance over previously\npublished models. Our model development leveraged the ATOM Modeling PipeLine\n(AMPL) developed by the ATOM Consortium, which enabled us to train and evaluate\nthousands of candidate models. In the course of model development, we assessed\na variety of schemes for chemical featurization, dataset partitioning and class\nlabeling, and identified those producing models that generalized best to novel\nchemical entities. Our best performing classification model was a neural\nnetwork with ROC AUC = 0.88 on our internal test dataset and 0.89 on an\nindependent external compound set. Our best regression model, the first ever\nreported for predicting BSEP IC50s, yielded a test set $R^2 = 0.56$ and mean\nabsolute error 0.37, corresponding to a mean 2.3-fold error in predicted IC50s,\ncomparable to experimental variation. These models will thus be useful as\ninputs to mechanistic predictions of DILI and as part of computational\npipelines for drug discovery."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The ARF-AID system: Methods that preserve endogenous protein levels and\n  facilitate rapidly inducible protein degradation"}, {"role": "assistant", "content": "The ARF-AID (Auxin Response Factor-Auxin Inducible Degron) system is a\nre-engineered auxin-inducible protein degradation system. Inducible degron\nsystems are widely used to specifically and rapidly deplete proteins of\ninterest in cell lines and organisms. An advantage of inducible degradation is\nthat the biological system under study remains intact and functional until\nperturbation. This feature necessitates that the endogenous levels of the\nprotein are maintained. However, endogenous tagging of genes with AID can\nresult in chronic, auxin-independent proteasome-mediated degradation. The\nadditional expression of the ARF-PB1 domain in the re-engineered ARF-AID system\nprevents chronic degradation of AID-tagged proteins while preserving rapid\ndegradation of tagged proteins. Here we describe the protocol for engineering\nhuman cell lines to implement the ARF-AID system for specific and inducible\nprotein degradation. These methods are adaptable and can be extended from cell\nlines to organisms."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: In search of biomarkers and the ideotype of barley tolerant to water\n  scarcity"}, {"role": "assistant", "content": "In barley plants, water shortage causes many changes on the morphological,\nphysiological and biochemical levels resulting in the reduction of grain yield.\nIn the present study the results of various experiments on the response of the\nsame barley recombinant inbred lines to water shortage, including phenotypic,\nproteomic and metabolomic traits were integrated. Obtained results suggest that\nby a multi-omic approach it is possible to indicate proteomic and metabolomic\ntraits important for reaction of barley plants to reduced water availability.\nAnalysis of regression of drought effect (DE) for grain weight per plant on DE\nof proteomic and metabolomic traits allowed us to suggest ideotype of barley\nplants tolerant to water shortage. It was shown that grain weight under drought\nwas determined significantly by six proteins in leaves and five in roots, the\nfunction of which were connected with defence mechanisms, ion/electron\ntransport, carbon (in leaves) and nitrogen (in roots) metabolism, and in leaves\nadditionally by two proteins of unknown function. Out of numerous metabolites\ndetected in roots only Aspartic and Glutamic acids and one metabolite of\nunknown function, were found to have significant influence on grain weight per\nplant. The role of these traits as biomarkers, and especially as suggested\ntargets of ideotype breeding, has to be further studied. One of the direction\nto be followed is genetic co-localization of proteomic, metabolomic and\nphenotypic traits in the genetic and physical maps of barley genome that can\ndescribe putative functional associations between traits; this is the next step\nof our analysis that is in progress."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantifying myelin in brain tissue using color spatial light\n  interference microscopy (cSLIM)"}, {"role": "assistant", "content": "Deficient myelination of the brain is associated with neurodevelopmental\ndelays, particularly in high-risk infants, such as those born small in relation\nto their gestational age (SGA). New methods are needed to further study this\ncondition. Here, we employ Color Spatial Light Interference Microscopy (cSLIM),\nwhich uses a brightfield objective and RGB camera to generate pathlength-maps\nwith nanoscale sensitivity in conjunction with a regular brightfield image.\nUsing tissue sections stained with Luxol Fast Blue, the myelin structures were\nsegmented from a brightfield image. Using a binary mask, those portions were\nquantitatively analyzed in the corresponding phase maps. We first used the\nCLARITY method to remove tissue lipids and validate the sensitivity of cSLIM to\nlipid content. We then applied cSLIM to brain histology slices. These specimens\nare from a previous MRI study, which demonstrated that appropriate for\ngestational age (AGA) piglets have increased internal capsule myelination (ICM)\ncompared to small for gestational age (SGA) piglets and that a hydrolyzed fat\ndiet improved ICM in both. The identity of samples was blinded until after\nstatistical analyses."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Minimizing the number of optimizations for efficient community dynamic\n  flux balance analysis"}, {"role": "assistant", "content": "Dynamic flux balance analysis uses a quasi-steady state assumption to\ncalculate an organism's metabolic activity at each time-step of a dynamic\nsimulation, using the well-known technique of flux balance analysis. For\nmicrobial communities, this calculation is especially costly and involves\nsolving a linear constrained optimization problem for each member of the\ncommunity at each time step. However, this is unnecessary and inefficient, as\nprior solutions can be used to inform future time steps. Here, we show that a\nbasis for the space of internal fluxes can be chosen for each microbe in a\ncommunity and this basis can be used to simulate forward by solving a\nrelatively inexpensive system of linear equations at most time steps. We can\nuse this solution as long as the resulting metabolic activity remains within\nthe optimization problem's constraints (i.e. the solution to the linear system\nof equations remains a feasible to the linear program). As the solution becomes\ninfeasible, it first becomes a feasible but degenerate solution to the\noptimization problem, and we can solve a different but related optimization\nproblem to choose an appropriate basis to continue forward simulation. We\ndemonstrate the efficiency and robustness of our method by comparing with\ncurrently used methods on a four species community, and show that our method\nrequires at least $91\\%$ fewer optimizations to be solved. For reproducibility,\nwe prototyped the method using Python. Source code is available at\n\\verb|https://github.com/jdbrunner/surfin_fba|."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Detecting long-range interactions between migrating cells"}, {"role": "assistant", "content": "Chemotaxis enables cells to systematically approach distant targets that emit\na diffusible guiding substance. However, the visual observation of an encounter\nbetween a cell and a target does not necessarily indicate the presence of a\nchemotactic approach mechanism, as even a blindly migrating cell can come\nacross a target by chance. To distinguish between the chemotactic approach and\nblind migration, we present an objective method that is based on the analysis\nof time-lapse recorded cell migration trajectories. First, we validate our\nmethod with simulated data, demonstrating that it reliably detects the presence\nor absence of remote cell-cell interactions. In a second step, we apply the\nmethod to data from three-dimensional collagen gels, interspersed with highly\nmigratory natural killer (NK) cells that were derived from two different human\ndonors. We find for one of the donors an attractive interaction between the NK\ncells, pointing to a cooperative behavior of these immune cells. When adding\nnearly stationary K562 tumor cells to the system, we find a repulsive\ninteraction between K562 and NK cells for one of the donors. By contrast, we\nfind attractive interactions between NK cells and an IL-15-secreting variant of\nK562 tumor cells. We therefore speculate that NK cells find wild-type tumor\ncells only by chance, but are programmed to leave a target quickly after a\nclose encounter. We provide a freely available Python implementation of our\np-value method that can serve as a general tool for detecting long-range\ninteractions in collective systems of self-driven agents."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Contaminants removal and bacterial activity enhancement along the flow\n  path of constructed wetland microbial fuel cells"}, {"role": "assistant", "content": "Microbial fuel cells implemented in constructed wetlands (CW-MFCs), albeit a\nrelatively new technology still under study, have shown to improve treatment\nefficiency of urban wastewater. So far the vast majority of CW-MFC systems\ninvestigated were designed as lab-scale systems working under rather\nunrealistic hydraulic conditions using synthetic wastewater. The main objective\nof this work was to quantify CW-MFCs performance operated under different\nconditions in a more realistic setup using meso-scale systems with horizontal\nflow fed with real urban wastewater. Operational conditions tested were organic\nloading rate (4.9+-1.6, 6.7+-1.4 and 13.6+-3.2 g COD/m2.day) and hydraulic\nregime (continuous vs intermittent feeding) as well as different electrical\nconnections: CW control (conventional CW without electrodes), open-circuit\nCW-MFC (external circuit between anode and cathode not connected) and\nclosed-circuit CW-MFC (external circuit connected). Eight horizontal subsurface\nflow CWs were operated for about four months. Each wetland consisted of a PVC\nreservoir of 0.193 m2 filled with 4/8 mm granitic riverine gravel. All wetlands\nhad intermediate sampling points for gravel and interstitial liquid sampling.\nThe CW-MFCs were designed as three MFCs incorporated one after the other along\nthe flow path of the CWs. Results showed no significant differences between\ntested organic loading rates, hydraulic regimes or electrical connections,\nhowever, on average, systems operated in closed-circuit CW-MFC mode under\ncontinuous flow outperformed the other experimental conditions. Closed-circuit\nCW-MFC compared to conventional CW control systems showed around 5% and 22%\nhigher COD and ammonium removal, respectively. Correspondingly, overall\nbacteria activity, as measured by the fluorescein diacetate technique, was\nhigher (4% to 34%) in closed-circuit systems when compared to CW control\nsystems."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: aPCoA: Covariate Adjusted Principal Coordinates Analysis"}, {"role": "assistant", "content": "In fields such as ecology, microbiology, and genomics, non-Euclidean\ndistances are widely applied to describe pairwise dissimilarity between\nsamples. Given these pairwise distances, principal coordinates analysis (PCoA)\nis commonly used to construct a visualization of the data. However, confounding\ncovariates can make patterns related to the scientific question of interest\ndifficult to observe. We provide aPCoA as an easy-to-use tool, available as\nboth an R package and a Shiny app, to improve data visualization in this\ncontext, enabling enhanced presentation of the effects of interest."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Comparison of different spike train synchrony measures regarding their\n  robustness to erroneous data from bicuculline induced epileptiform activity"}, {"role": "assistant", "content": "As synchronized activity is associated with basic brain functions and\npathological states, spike train synchrony has become an important measure to\nanalyze experimental neuronal data. Many different measures of spike train\nsynchrony have been proposed, but there is no gold standard allowing for\ncomparison of results between different experiments. This work aims to provide\nguidance on which synchrony measure is best suitable to quantify the effect of\nepileptiform inducing substances (e.g. bicuculline (BIC)) in in vitro neuronal\nspike train data. Spike train data from recordings are likely to suffer from\nerroneous spike detection, such as missed spikes (false negative) or noise\n(false positive). Therefore, different time-scale dependent (cross-correlation,\nmutual information, spike time tiling coefficient) and time-scale independent\n(Spike-contrast, phase synchronization, A-SPIKE-synchronization,\nA-ISI-distance, ARI-SPIKE-distance) synchrony measures were compared in terms\nof their robustness to erroneous spike trains. As a result of the in silico\nmanipulated data, Spike-contrast was the only measure being robust to false\nnegative as well as false-positive spikes. Analyzing the experimental data set\nrevealed that all measures were able to capture the effect of BIC in a\nstatistically significant way, with Spike-contrast showing the highest\nstatistical significance even at low spike detection thresholds. In summary, we\nsuggest the usage of Spike-contrast to complement established synchrony\nmeasures, as it is time scale independent and robust to erroneous spike trains."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: PROSPECT-PRO for estimating content of nitrogen-containing leaf proteins\n  and other carbon-based constituents"}, {"role": "assistant", "content": "Models of radiative transfer (RT) are important tools for remote sensing of\nvegetation, as they facilitate forward simulations of remotely sensed data as\nwell as inverse estimation of biophysical and biochemical properties from\nvegetation optical properties. The remote sensing estimation of foliar protein\ncontent is a key to monitoring the nitrogen cycle in terrestrial ecosystems in\nparticular to better understand photosynthetic capacity of plants and improve\nnitrogen management in agriculture. However, no physically based leaf RT model\ncurrently allows for proper decomposition of leaf dry matter into\nnitrogen-based proteins and carbon-based constituents (CBC), estimated from\noptical properties of fresh or dry foliage. We developed a new version of the\nPROSPECT model, named PROSPECT-PRO, which separates nitrogen-based constituents\n(proteins) from CBC (including cellulose, lignin, hemicellulose and starch).\nPROSPECT-PRO was calibrated and validated on subsets of the LOPEX dataset,\naccounting for both fresh and dry broadleaf and grass samples. We applied an\niterative model inversion optimization algorithm to identify optimal spectral\nsubdomains for retrieval of leaf protein and CBC contents, with 2125-2174 nm\noptimal for proteins and 2025-2349 nm optimal for CBCs. PROSPECT-PRO inversions\nrevealed a better performance in estimating proteins from optical properties of\nfresh than dry leaves. We further tested the ability of PROSPECT-PRO to\nestimate leaf mass per area (LMA) as the sum of proteins and CBC using\nindependent datasets acquired for numerous plant species. Results showed that\nPROSPECT-PRO is fully compatible and comparable with its predecessor PROSPECT-D\nin indirect estimation of LMA. We can conclude from findings of this study that\nPROSPECT-PRO has a high potential in establishing the carbon-to-nitrogen ratio\nbased on the retrieved CBC-to-proteins ratio."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Stochastic single-particle based simulations of cellular signaling\n  embedded into computational models of cellular morphology"}, {"role": "assistant", "content": "Cells exhibit a wide variety of different shapes. This diversity poses a\nchallenge for computational approaches that attempt to shed light on the role\ncell geometry plays in regulating cell physiology and behavior. The simulation\nplatform Simmune is capable of embedding the computational representation of\nsignaling pathways into realistic models of cellular morphology. However,\nSimmune's current approach to account for the cell geometry is limited to\ndeterministic models of reaction-diffusion processes, thus providing a\ncoarse-grained description that ignores stochastic local fluctuations. Here we\npresent an extension of Simmune that removes these limitations by employing an\nalternative computational representation of cellular geometry that is smooth\nand grid-free. These features make it possible to incorporate a fully\nstochastic, spatially resolved description of the cellular biochemistry. The\nalternative computational representation is compatible with Simmune's current\napproach for specifying molecular interactions. This means that a modeler using\nthe approach needs to create a model of cellular biochemistry and morphology\nonly once to be able to use it for both, deterministic and stochastic\nsimulations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: MFC-based biosensor for domestic wastewater COD assessment in\n  constructed wetlands"}, {"role": "assistant", "content": "In the context of natural-based wastewater treatment technologies (such as\nconstructed wetlands - CW) the use of a low-cost, continuous-like biosensor\ntool for the assessment of operational conditions is of key importance for\nplant management optimization. The objective of the present study was to assess\nthe potential use of constructed wetland microbial fuel cells (CW-MFC) as a\ndomestic wastewater COD assessment tool. For the purpose of this work four\nlab-scale CW-MFCs were set up and fed with pre-settled domestic wastewater at\ndifferent COD concentrations. Under laboratory conditions two different anodic\nmaterials were tested (graphite rods and gravel). Furthermore, a pilot-plant\nbased experiment was also conducted to confirm the findings previously recorded\nfor lab-scale experiments. Results showed that in spite of the low coulombic\nefficiencies recorded, either gravel or graphite-based anodes were suitable for\nthe purposes of domestic wastewater COD assessment. Significant linear\nrelationships could be established between inlet COD concentrations and CW-MFC\nEcell whenever contact time was above 10 hours. Results also showed that the\naccuracy of the CW-MFC was greatly compromised after several weeks of\noperation. Pilot experiments showed that CW-MFC presents a good bio-indication\nresponse between week 3 and 7 of operation (equivalent to an accumulated\norganic loading between 100 and 200 g COD/m2, respectively). Main conclusion of\nthis work is that of CW-MFC could be used as an \"alarm-tool\" for qualitative\ncontinuous influent water quality assessment rather than a precise COD\nassessment tool due to a loss of precision after several weeks of operation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: PEtab -- interoperable specification of parameter estimation problems in\n  systems biology"}, {"role": "assistant", "content": "Reproducibility and reusability of the results of data-based modeling studies\nare essential. Yet, there has been -- so far -- no broadly supported format for\nthe specification of parameter estimation problems in systems biology. Here, we\nintroduce PEtab, a format which facilitates the specification of parameter\nestimation problems using Systems Biology Markup Language (SBML) models and a\nset of tab-separated value files describing the observation model and\nexperimental data as well as parameters to be estimated. We already implemented\nPEtab support into eight well-established model simulation and parameter\nestimation toolboxes with hundreds of users in total. We provide a Python\nlibrary for validation and modification of a PEtab problem and currently 20\nexample parameter estimation problems based on recent studies. Specifications\nof PEtab, the PEtab Python library, as well as links to examples, and all\nsupporting software tools are available at https://github.com/PEtab-dev/PEtab,\na snapshot is available at https://doi.org/10.5281/zenodo.3732958. All original\ncontent is available under permissive licenses."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Analyzing the spatial distribution of acute coronary syndrome cases\n  using synthesized data on arterial hypertension prevalence"}, {"role": "assistant", "content": "In the current study, the authors demonstrate the method aimed at analyzing\nthe distribution of acute coronary syndrome (ACS) cases in Saint Petersburg\nusing the synthetic population approach and a statistical model for arterial\nhypertension prevalence. The cumulative number of emergency services calls in a\nseparate geographical area (a grid cell of a map) associated with ACS is\nmatched with the assessed number of dwellers and individuals with arterial\nhypertension, which makes it possible to find locations with excessive ACS\nincidence. The proposed method is implemented in Python programming language,\nthe visualization results are shown using QGIS open software. Three categories\nof locations are proposed based on the analysis results. The demonstrated\nmethod might be applied for using the statistical assessments of hidden health\nconditions in the population to categorize spatial distributions of their\nvisible consequences."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Cross-Country Age Disparities in COVID-19 Cases with Hospitalization,\n  ICU Usage, and Morbidity"}, {"role": "assistant", "content": "In this paper, we examine cross-country differences, in terms of the age\ndistribution of symptomatic cases, hospitalizations, intensive care unit (ICU)\ncases, and fatalities due to the novel COVID-19. By calculating conditional\nprobabilities, we bridge country-level incidence data gathered from different\ncountries and attribute the variability in data to country demographics. We\nthen provide case, hospitalization, ICU, and fatality estimates for a\ncomprehensive list of countries using the existing data from a variety of\ncountries."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Towards defining reference materials for extracellular vesicle size,\n  concentration, refractive index and epitope abundance"}, {"role": "assistant", "content": "Accurate characterization of extracellular vesicles (EVs) is critical to\nexplore their diagnostic and therapeutic applications. As the EV research field\nhas developed, so too have the techniques used to characterize them. The\ndevelopment of reference materials is required for the standardization of these\ntechniques. This work, initiated from the ISEV 2017 Biomarker Workshop in\nBirmingham, UK, and with further discussion during the ISEV 2019\nStandardization Workshop in Ghent, Belgium, sets out to elucidate which\nreference materials are required and which are currently available to\nstandardize commonly used analysis platforms for characterizing EV size,\nconcentration, refractive index, and epitope expression. Due to their\npredominant use, a particular focus is placed on the optical methods\nnanoparticle tracking analysis and flow cytometry."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Machine Learning Method to Control and Observe for Treatment and\n  Monitoring of Hepatitis B Virus"}, {"role": "assistant", "content": "Hepatitis type B is one of the most common infectious disease worldwide that\ncan pose severe threats to human health up to the point that may contribute to\nsevere liver damage or cancer. Over the past two decades a large number of\ndynamic models have been presented based on experimental data to predict the\nHBV infection behavior. Besides, several kinds of controllers have been\nemployed to obtain effective solutions from the HBV treatment. In this essay we\nconsider the nonlinear HBV dynamic model which subjected to both parametric and\nnon-parametric uncertainties without using any linearization. In previous\ncontrol methods three HBV dynamic states should be measured virus safe, and\ninfected cells. However in most of the biological systems, the amount of virus\nis experimentally measured. Accordingly, the necessity to seek a method that\ncan estimate the amount of required drug by receiving the virus data emerges.\nAn ANFIS method is developed in this work to provide an intelligent controller\nfor the drug dosage based on the number of viruses together with an estimator\nfor the amount of infected and uninfected cells. This controller is trained\nfirst using the data provided from a previous adaptive control strategy. After\nthat to improve the closed-loop system capabilities two unmeasured state\nvariables of fundamental dynamics are estimated through the training phase of\nthe ANFIS observer. The results of simulations demonstrated that the accuracy\nof the proposed intelligent controller is high in the tracking of the desired\ndescending virus population."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Combining multi-site Magnetic Resonance Imaging with machine learning\n  predicts survival in paediatric brain tumours"}, {"role": "assistant", "content": "Background Brain tumours represent the highest cause of mortality in the\npaediatric oncological population. Diagnosis is commonly performed with\nmagnetic resonance imaging and spectroscopy. Survival biomarkers are\nchallenging to identify due to the relatively low numbers of individual tumour\ntypes, especially for rare tumour types such as atypical rhabdoid tumours.\n  Methods 69 children with biopsy-confirmed brain tumours were recruited into\nthis study. All participants had both perfusion and diffusion weighted imaging\nperformed at diagnosis. Data were processed using conventional methods, and a\nBayesian survival analysis performed. Unsupervised and supervised machine\nlearning were performed with the survival features, to determine novel\nsub-groups related to survival. Sub-group analysis was undertaken to understand\ndifferences in imaging features, which pertain to survival.\n  Findings Survival analysis showed that a combination of diffusion and\nperfusion imaging were able to determine two novel sub-groups of brain tumours\nwith different survival characteristics (p <0.01), which were subsequently\nclassified with high accuracy (98%) by a neural network. Further analysis of\nhigh-grade tumours showed a marked difference in survival (p=0.029) between the\ntwo clusters with high risk and low risk imaging features.\n  Interpretation This study has developed a novel model of survival for\npaediatric brain tumours, with an implementation ready for integration into\nclinical practice. Results show that tumour perfusion plays a key role in\ndetermining survival in brain tumours and should be considered as a high\npriority for future imaging protocols."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: ivis Dimensionality Reduction Framework for Biomacromolecular\n  Simulations"}, {"role": "assistant", "content": "Molecular dynamics (MD) simulations have been widely applied to study\nmacromolecules including proteins. However, high-dimensionality of the datasets\nproduced by simulations makes it difficult for thorough analysis, and further\nhinders a deeper understanding of biomacromolecules. To gain more insights into\nthe protein structure-function relations, appropriate dimensionality reduction\nmethods are needed to project simulations onto low-dimensional spaces. Linear\ndimensionality reduction methods, such as principal component analysis (PCA)\nand time-structure based independent component analysis (t-ICA), could not\npreserve sufficient structural information. Though better than linear methods,\nnonlinear methods, such as t-distributed stochastic neighbor embedding (t-SNE),\nstill suffer from the limitations in avoiding system noise and keeping\ninter-cluster relations. ivis is a novel deep learning-based dimensionality\nreduction method originally developed for single-cell datasets. Here we applied\nthis framework for the study of light, oxygen and voltage (LOV) domain of\ndiatom Phaeodactylum tricornutum aureochrome 1a (PtAu1a). Compared with other\nmethods, ivis is shown to be superior in constructing Markov state model (MSM),\npreserving information of both local and global distances and maintaining\nsimilarity between high dimension and low dimension with the least information\nloss. Moreover, ivis framework is capable of providing new prospective for\ndeciphering residue-level protein allostery through the feature weights in the\nneural network. Overall, ivis is a promising member in the analysis toolbox for\nproteins."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Maternal education and offspring birthweight for gestational age: the\n  mediating effect of smoking during pregnancy"}, {"role": "assistant", "content": "Background Small for gestational age (SGA) birthweight, a risk factor of\ninfant mortality and delayed child development, is associated with maternal\neducational attainment. Maternal tobacco smoking during pregnancy could\ncontribute to this association. We aimed to quantify the contribution of\nmaternal smoking during pregnancy to social inequalities in child birthweight\nfor gestational age (GA). Methods Data come from the French nation-wide ELFE\ncohort study, which included 17,155 singletons. Birthweights for GA were\ncalculated using z-scores. Associations between maternal educational\nattainment, tobacco smoking during pregnancy and child birthweight for GA were\nascertained using mediation analysis. Mediation analyses were also stratified\nby maternal pre-pregnancy body mass index.Results Low maternal educational\nattainment was associated with an increased odd of tobacco smoking during\npregnancy (adjusted OR (ORa)=2.58 [95% CI 2.34, 2.84]) as well as a decrease in\nchild birthweight for GA (RRa=0.94 [95% 0.91, 0.98]). Tobacco smoking during\npregnancy was associated with a decrease in offspring birthweight for GA\n(RRa=0.73 [95% CI 0.70, 0.76]). Mediation analysis suggests that 39% of the\neffect of low maternal educational attainment on offspring birthweight for GA\nwas mediated by smoking during pregnancy. A more important direct effect of\nmaternal educational attainment on child birthweight for GA was observed among\nunderweight women (RRa=0.82 [95%CI 0.72, 0.93]).Conclusions The relationship\nbetween maternal educational attainment and child birthweight for GA is\nstrongly mediated by smoking during pregnancy. Reducing maternal smoking could\nlessen the occurrence of infant SGA and decrease socioeconomic inequalities in\nbirthweight for GA.Keywords Birthweight, educational attainment, tobacco\nsmoking, pregnancy, mediation analysis, health inequalities"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Partner support during pregnancy mediates social inequalities in\n  maternal postpartum depression for non-migrant and first generation migrant\n  women"}, {"role": "assistant", "content": "Background An advantaged socioeconomic position (SEP) and satisfying social\nsupport during pregnancy (SSP) have been found to be protective factors of\nmaternal postpartum depression (PDD). An advantaged SEP is also associated with\nsatisfying SSP, making SSP a potential mediator of social inequalities in PPD.\nSEP, SSP and PPD are associated with migrant status. The aim of this study was\nto quantify the mediating role of SSP in social inequalities in PPD regarding\nmother's migrant status. Methods A sub-sample of 15,000 mothers from the French\nnationally-representative ELFE cohort study was used for the present analyses.\nSEP was constructed as a latent variable measured with educational attainment,\noccupational grade, employment, financial difficulties and household income.\nSSP was characterized as perceived support from partner (good relation,\nsatisfying support and paternal leave) and actual support from midwives\n(psychosocial risk factors assessment and antenatal education). Mediation\nanalyses with multiple mediators, stratified by migrant status were conducted.\nResults Study population included 76% of non-migrant women, 12% of second and\n12% of first generation migrant. SEP was positively associated with support\nfrom partner, regardless of migrant status. Satisfying partner support was\nassociated with a 8 (non-migrant women) to 11% (first generation migrant women)\nreduction in PPD score. Limitations History of depression was not\nreported.Conclusions Partner support could reduce social inequalities in PPD.\nThis work supports the need of interventions, longitudinal and qualitative\nstudies including fathers and adapted to women at risk of PPD to better\nunderstand the role of SSP in social inequalities in PPD. Keywords social\nsupport, postpartum depression, epidemiology, social inequalities, pregnancy,\nmediation analysis"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Variation of positiveness to enhance testing of specimens during an\n  epidemic"}, {"role": "assistant", "content": "Rapid testing of appropriate specimens from patients suspected for a disease\nduring an epidemic, such as the current Coronavirus outbreak, is of a great\nimportance for the disease management and control. We propose a method to\nenhance processing large amounts of collected samples. The method is based on\nmixing samples in testing tubes in a specific configuration, as opposed to\ntesting single samples in each tube, and accounting for natural virus amounts\nin infected patients from variation of positiveness in test tubes. To\nillustrate the efficiency of the suggested method we carry out numerical tests\nfor actual scenarios under various tests. Applying the proposed method enhances\nthe number of tests by order of magnitudes, where all positives are identified\nwith no false negatives, and the effective testing time can be reduced\ndrastically even when the uncertainty in the test is relatively high."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Low-rank representation of head impact kinematics: A data-driven\n  emulator"}, {"role": "assistant", "content": "Head motion induced by impacts has been deemed as one of the most important\nmeasures in brain injury prediction, given that the majority of brain injury\nmetrics use head kinematics as input. Recently, researchers have focused on\nusing fast approaches, such as machine learning, to approximate brain\ndeformation in real-time for early brain injury diagnosis. However, those\nrequires large number of kinematic measurements, and therefore data\naugmentation is required given the limited on-field measured data available. In\nthis study we present a principal component analysis-based method that emulates\nan empirical low-rank substitution for head impact kinematics, while requiring\nlow computational cost. In characterizing our existing data set of 537 head\nimpacts, consisting of 6 degrees of freedom measurements, we found that only a\nfew modes, e.g. 15 in the case of angular velocity, is sufficient for accurate\nreconstruction of the entire data set. Furthermore, these modes are\npredominantly low frequency since over 70% to 90% of the angular velocity\nresponse can be captured by modes that have frequencies under 40Hz. We compared\nour proposed method against existing impact parametrization methods and showed\nsignificantly better performance in injury prediction using a range of\nkinematic-based metrics -- such as head injury criterion and rotational injury\ncriterion (RIC) -- and brain tissue deformation-metrics -- such as brain angle\nmetric, maximum principal strain (MPS) and axonal fiber strains (FS). In all\ncases, our approach reproduced injury metrics similar to the ground truth\nmeasurements with no significant difference, whereas the existing methods\nobtained significantly different (p<0.01) values as well as poor injury\nclassification sensitivity and specificity. This emulator will enable us to\nprovide the necessary data augmentation to build a head impact kinematic data\nset of any size."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Customised fragment libraries for ab initio protein structure prediction\n  using a structural alphabet"}, {"role": "assistant", "content": "Motivation: Computational protein structure prediction has taken over the\nstructural community in past few decades, mostly focusing on the development of\nTemplate-Free modelling (TFM) or ab initio modelling protocols. Fragment-based\nassembly (FBA), falls under this category and is by far the most popular\napproach to solve the spatial arrangements of proteins. FBA approaches usually\nrely on sequence based profile comparison to generate fragments from a\nrepresentative structural database. Here we report the use of Protein Blocks\n(PBs), a structural alphabet (SA) to perform such sequence comparison and to\nbuild customised fragment libraries for TFM. Results: We demonstrate that\npredicted PB sequences for a query protein can be used to search for high\nquality fragments that overall cover above 90% of the query. The fragments\ngenerated are of minimum length of 11 residues, and fragments that cover more\nthan 30% of the query length were often obtained. Our work shows that PBs can\nserve as a good way to extract structurally similar fragments from a database\nof representatives of non-homologous structures and of the proteins that\ncontain less ordered regions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Antimicrobial Peptide Prediction Using Ensemble Learning Algorithm"}, {"role": "assistant", "content": "Recently, Antimicrobial peptides (AMPs) have been an area of interest in the\nresearches, as the first line of defense against the bacteria. They are raising\nattention as an efficient way of fighting multidrug resistance. Discovering and\nidentification of AMPs in the wet labs are challenging, expensive, and\ntime-consuming. Therefore, using computational methods for AMP predictions have\ngrown attention as they are more efficient approaches. In this paper, we\ndeveloped a promising ensemble learning algorithm that integrates well-known\nlearning models to predict AMPs. First, we extracted the optimal features from\nthe physicochemical, evolutionary, and secondary structure properties of the\npeptide sequences. Our ensemble algorithm then trains the data using\nconventional algorithms. Finally, the proposed ensemble algorithm has improved\nthe performance of the prediction by about 10% comparing to the traditional\nlearning algorithms"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Modeling in the Time of COVID-19: Statistical and Rule-based Mesoscale\n  Models"}, {"role": "assistant", "content": "We present a new technique for rapid modeling and construction of\nscientifically accurate mesoscale biological models. Resulting 3D models are\nbased on few 2D microscopy scans and the latest knowledge about the biological\nentity represented as a set of geometric relationships. Our new technique is\nbased on statistical and rule-based modeling approaches that are rapid to\nauthor, fast to construct, and easy to revise. From a few 2D microscopy scans,\nwe learn statistical properties of various structural aspects, such as the\nouter membrane shape, spatial properties and distribution characteristics of\nthe macromolecular elements on the membrane. This information is utilized in 3D\nmodel construction. Once all imaging evidence is incorporated in the model,\nadditional information can be incorporated by interactively defining rules that\nspatially characterize the rest of the biological entity, such as mutual\ninteractions among macromolecules, their distances and orientations to other\nstructures. These rules are defined through an intuitive 3D interactive\nvisualization and modeling feedback loop. We demonstrate the utility of our\napproach on a use case of the modeling procedure of the SARS-CoV-2 virus\nparticle ultrastructure. Its first complete atomistic model, which we present\nhere, can steer biological research to new promising directions in fighting\nspread of the virus."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Effects of rearing density on growth, digestive conditions, welfare\n  indicators and gut bacterial community of gilthead sea bream (Sparus aurata,\n  L. 1758) fed different fishmeal and fish oil dietary levels"}, {"role": "assistant", "content": "In Mediterranean aquaculture little research has examined the interaction\nbetween rearing density and dietary composition on main key performance\nindicators, physiological processes and gut bacterial community. A study was\nundertaken, therefore to assess growth response, digestive enzyme activity,\nhumoral immunity on skin mucus, plasma biochemistry and gut microbiota of\ngilthead sea bream (Sparus aurata, L. 1758) reared at high (HD) and low (LD)\nfinal stocking densities and fed high (FM30FO15, 30 % fishmeal FM, 15 % fish\noil, FO) and low (FM10FO3; 10 % FM and 3 % FO) FM and FO levels. Isonitrogenous\nand isolipidic extruded diets were fed to triplicate fish groups (initial\nweight: 96.2 g) to overfeeding over 98 days. The densities tested had no major\neffects on overall growth and feed efficiency of sea bream reared at high or\nlow FM and FO dietary level. Results of digestive enzyme activity indicated a\ncomparable digestive efficiency among rearing densities and within each dietary\ntreatment. Plasma parameters related to nutritional and physiological\nconditions were not affected by rearing densities under both nutritional\nconditions a similar observation was also achieved through the study of\nlysozyme, protease, antiprotease and total protein determination in skin mucus,\nFor the first time on this species, the effect of rearing density on gut\nbacterial community was studied. Different response in relation to dietary\ntreatment under HD and LD were detected. Low FM-FO diet maintained steady the\nbiodiversity of the gut bacterial community between LD and HD conditions while\nfish fed high FM-FO level showed a reduced biodiversity at HD. According to the\nresults, it seems feasible to rear gilthead sea bream at the on-growing phase\nat a density up to 36-44 kg m3 with low or high FM-FO diet without negatively\naffecting growth, feed efficiency, welfare condition and gut bacterial\ncommunity."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Equaliza\\c{c}\\~ao das escalas NESSCA e SARA utilizando a Teoria da\n  Resposta ao Item na avalia\\c{c}\\~ao do comprometimento pela doen\\c{c}a de\n  Machado-Joseph"}, {"role": "assistant", "content": "Background: Scale equating is a statistical technique used to establish\nequivalence relations between different scales. Its use is quite popular in\neducational evaluation, however, unusual in the health area, where scales of\nmeasures are tools that integrate clinical practice. With the use of different\nscales, there is a difficulty in comparing scientific results, such as NESSCA\nand SARA scales, tools for assessing the commitment to Machado-Joseph disease\n(SCA3/MJD). Objective: Explore the method of scale equating and demonstrate its\napplication through NESSCA and SARA scales, using the Item Response Theory\n(IRT) approach in assessing SCA3/MJD commitment. Methods: Data came from 227\npatients from the Hospital de Cl\\'inicas de Porto Alegre with SCA3/MJD who have\ncomplete measures for NESSCA and/or SARA scales. The equating design used is\nthat of non-equivalent groups with common items, with separate calibration. The\nIRT model used in the estimation of the parameters was the generalized partial\ncredit, for NESSCA and SARA. The linear transformation was performed using the\nMean/Mean, Mean/Sigma, Haebara and StokingLord methods and the equation of the\ntrue score was applied to obtain an estimated relationship between the scores\nof the scales. Results: Difference between NESSCA score estimated by SARA and\nobserved NESSCA score has shown median of 0.82 points, by Mean/Sigma method.\nThis was the best method of linear transformation among the tested.\nConclusions: This study extended the use of scale equating under IRT approach\nto health outcomes and established an equivalence relationship between NESSCA\nand SARA scores, making the comparison between patients and scientific results\nfeasible."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Alchemical Transformations for Concerted Hydration Free Energy\n  Estimation with Explicit Solvation"}, {"role": "assistant", "content": "We present a family of alchemical perturbation potentials that enable the\ncalculation of hydration free energies of small to medium-sized molecules in a\nconcerted single alchemical coupling step instead of the commonly used sequence\nof two distinct coupling steps for Lennard-Jones and electrostatic\ninteractions. The perturbation potentials are based on the softplus function of\nthe solute-solvent interaction energy designed to focus sampling near entropic\nbottlenecks along the alchemical pathway. We present a general framework to\noptimize the parameters of alchemical perturbation potentials of this kind. The\noptimization procedure is based on the $\\lambda$-function formalism and the\nmaximum-likelihood parameter estimation procedure we developed earlier to avoid\nthe occurrence of multi-modal distributions of the coupling energy along the\nalchemical path. A novel soft-core function applied to the overall\nsolute-solvent interaction energy rather than individual interatomic pair\npotentials critical for this result is also presented. Because it does not\nrequire modifications of core force and energy routines, the soft-core\nformulation can be easily deployed in molecular dynamics simulation codes. We\nillustrate the method by applying it to the estimation of the hydration free\nenergy in water droplets of compounds of varying size and complexity. In each\ncase, we show that convergence of the hydration free energy is achieved\nrapidly. This work paves the way for the ongoing development of more\nstreamlined algorithms to estimate free energies of molecular binding with\nexplicit solvation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Compressed Sensing Approach to Pooled RT-PCR Testing for COVID-19\n  Detection"}, {"role": "assistant", "content": "We propose `Tapestry', a novel approach to pooled testing with application to\nCOVID-19 testing with quantitative Reverse Transcription Polymerase Chain\nReaction (RT-PCR) that can result in shorter testing time and conservation of\nreagents and testing kits. Tapestry combines ideas from compressed sensing and\ncombinatorial group testing with a novel noise model for RT-PCR used for\ngeneration of synthetic data. Unlike Boolean group testing algorithms, the\ninput is a quantitative readout from each test and the output is a list of\nviral loads for each sample relative to the pool with the highest viral load.\nWhile other pooling techniques require a second confirmatory assay, Tapestry\nobtains individual sample-level results in a single round of testing, at\nclinically acceptable false positive or false negative rates. We also propose\ndesigns for pooling matrices that facilitate good prediction of the infected\nsamples while remaining practically viable. When testing $n$ samples out of\nwhich $k \\ll n$ are infected, our method needs only $O(k \\log n)$ tests when\nusing random binary pooling matrices, with high probability. However, we also\nuse deterministic binary pooling matrices based on combinatorial design ideas\nof Kirkman Triple Systems to balance between good reconstruction properties and\nmatrix sparsity for ease of pooling. In practice, we have observed the need for\nfewer tests with such matrices than with random pooling matrices. This makes\nTapestry capable of very large savings at low prevalence rates, while\nsimultaneously remaining viable even at prevalence rates as high as 9.5\\%.\nEmpirically we find that single-round Tapestry pooling improves over two-round\nDorfman pooling by almost a factor of 2 in the number of tests required. We\nvalidate Tapestry in simulations and wet lab experiments with oligomers in\nquantitative RT-PCR assays. Lastly, we describe use-case scenarios for\ndeployment."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Survey of Pathways for Mechano-Electric Coupling in the Atria"}, {"role": "assistant", "content": "Mechano-electric coupling (MEC) in atrial tissue has received sparse\ninvestigation to date, despite the well-known association between chronic\natrial dilation and atrial fibrillation (AF). Of note, no fewer than six\ndifferent mechanisms pertaining to stretch-activated channels, cellular\ncapacitance and geometric effects have been identified in the literature as\npotential players. In this mini review, we briefly survey each of these\npathways to MEC. We then perform computational simulations using single cell\nand tissue models in presence of various stretch regimes and MEC pathways. This\nallows us to assess the relative significance of each pathway in determining\naction potential duration, conduction velocity and rotor stability. For chronic\natrial stretch, we find that stretch-induced alterations in membrane\ncapacitance decrease conduction velocity and increase action potential\nduration, in agreement with experimental findings. In the presence of\ntime-dependent passive atrial stretch, stretch-activated channels play the\nlargest role, leading to after-depolarizations and rotor hypermeandering. These\nfindings suggest that physiological atrial stretches, such as passive stretch\nduring the atrial reservoir phase, may play an important part in the mechanisms\nof atrial arrhythmogenesis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Learning Equations from Biological Data with Limited Time Samples"}, {"role": "assistant", "content": "Equation learning methods present a promising tool to aid scientists in the\nmodeling process for biological data. Previous equation learning studies have\ndemonstrated that these methods can infer models from rich datasets, however,\nthe performance of these methods in the presence of common challenges from\nbiological data has not been thoroughly explored. We present an equation\nlearning methodology comprised of data denoising, equation learning, model\nselection and post-processing steps that infers a dynamical systems model from\nnoisy spatiotemporal data. The performance of this methodology is thoroughly\ninvestigated in the face of several common challenges presented by biological\ndata, namely, sparse data sampling, large noise levels, and heterogeneity\nbetween datasets. We find that this methodology can accurately infer the\ncorrect underlying equation and predict unobserved system dynamics from a small\nnumber of time samples when the data is sampled over a time interval exhibiting\nboth linear and nonlinear dynamics. Our findings suggest that equation learning\nmethods can be used for model discovery and selection in many areas of biology\nwhen an informative dataset is used. We focus on glioblastoma multiforme\nmodeling as a case study in this work to highlight how these results are\ninformative for data-driven modeling-based tumor invasion predictions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Absolute ethanol intake drives ethanol preference in Drosophila"}, {"role": "assistant", "content": "Factors that mediate ethanol preference in Drosophila melanogaster are not\nwell understood. A major confound has been the use of diverse methods to\nestimate ethanol consumption. We measured fly consumptive ethanol preference on\nbase diets varying in nutrients, taste, and ethanol concentration. Both sexes\nshowed ethanol preference that was abolished on high nutrient concentration\ndiets. Additionally, manipulating total food intake without altering the\nnutritive value of the base diet or the ethanol concentration was sufficient to\nevoke or eliminate ethanol preference. Absolute ethanol intake and food volume\nconsumed were stronger predictors of ethanol preference than caloric intake or\nthe dietary caloric content. Our findings suggest that the effect of the base\ndiet on ethanol preference is largely mediated by total consumption associated\nwith the delivery medium, which ultimately determines the level of ethanol\nintake. We speculate that a physiologically relevant threshold for ethanol\nintake is essential for preferential ethanol consumption."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Lyra -- containerized microservices for browsing shared biomedical data"}, {"role": "assistant", "content": "Research papers in the biomedical field come with large and complex data sets\nthat are shared with the scientific community as unstructured data files via\npublic data repositories. Examples are sequencing, microarray, and mass\nspectroscopy data. The papers discuss and visualize only a small part of the\ndata, the part that is in its research focus. For labs with similar but not\nidentical research interests different parts of the data might be important.\nThey can thus download the full data, preprocess it, integrate it with data\nfrom other publications and browse those parts that they are most interested\nin. This requires substantial work as well as programming and analysis\nexpertise that only few biological labs have on board. In contrast, providing\naccess to published data over web browsers makes all data visible, allows for\neasy interaction with it, and lowers the barrier to working with data from\nothers."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Towards in vivo g-ratio mapping using MRI: unifying myelin and diffusion\n  imaging"}, {"role": "assistant", "content": "The g-ratio, quantifying the comparative thickness of the myelin sheath\nencasing an axon, is a geometrical invariant that has high functional relevance\nbecause of its importance in determining neuronal conduction velocity. Advances\nin MRI data acquisition and signal modelling have put in vivo mapping of the\ng-ratio, across the entire white matter, within our reach. This capacity would\ngreatly increase our knowledge of the nervous system: how it functions, and how\nit is impacted by disease. This is the second review on the topic of g-ratio\nmapping using MRI. As such, it summarizes the most recent developments in the\nfield, while also providing methodological background pertinent to aggregate\ng-ratio weighted mapping, and discussing pitfalls associated with these\napproaches. Using simulations based on recently published data, this review\ndemonstrates the relevance of the calibration step for three myelin-markers\n(macromolecular tissue volume, myelin water fraction, and bound pool fraction).\nIt highlights the need to estimate both the slope and offset of the\nrelationship between these MRI-based markers and the true myelin volume\nfraction if we are really to achieve the goal of precise, high sensitivity\ng-ratio mapping in vivo. Other challenges discussed in this review further\nevidence the need for gold standard measurements of human brain tissue from ex\nvivo histology. We conclude that the quest to find the most appropriate MRI\nbiomarkers to enable in vivo g-ratio mapping is ongoing, with the potential of\nmany novel techniques yet to be investigated."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Efficient adaptive designs for clinical trials of interventions for\n  COVID-19"}, {"role": "assistant", "content": "The COVID-19 pandemic has led to an unprecedented response in terms of\nclinical research activity. An important part of this research has been focused\non randomized controlled clinical trials to evaluate potential therapies for\nCOVID-19. The results from this research need to be obtained as rapidly as\npossible. This presents a number of challenges associated with considerable\nuncertainty over the natural history of the disease and the number and\ncharacteristics of patients affected, and the emergence of new potential\ntherapies. These challenges make adaptive designs for clinical trials a\nparticularly attractive option. Such designs allow a trial to be modified on\nthe basis of interim analysis data or stopped as soon as sufficiently strong\nevidence has been observed to answer the research question, without\ncompromising the trial's scientific validity or integrity. In this paper we\ndescribe some of the adaptive design approaches that are available and discuss\nparticular issues and challenges associated with their use in the pandemic\nsetting. Our discussion is illustrated by details of four ongoing COVID-19\ntrials that have used adaptive designs."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: COVID-19 Related Mobility Reduction: Heterogenous Effects on Sleep and\n  Physical Activity Rhythms"}, {"role": "assistant", "content": "Mobility restrictions imposed to suppress coronavirus transmission can alter\nphysical activity (PA) and sleep patterns. Characterization of response\nheterogeneity and their underlying reasons may assist in tailoring customized\ninterventions. We obtained wearable data covering baseline, incremental\nmovement restriction and lockdown periods from 1824 city-dwelling, working\nadults aged 21 to 40 years, incorporating 206,381 nights of sleep and 334,038\ndays of PA. Four distinct rest activity rhythms (RARs) were identified using\nk-means clustering of participants' temporally distributed step counts.\nHierarchical clustering of the proportion of time spent in each of these RAR\nrevealed 4 groups who expressed different mixtures of RAR profiles before and\nduring the lockdown. Substantial but asymmetric delays in bedtime and waketime\nresulted in a 24 min increase in weekday sleep duration with no loss in sleep\nefficiency. Resting heart rate declined 2 bpm. PA dropped an average of 38%. 4\ngroups with different compositions of RAR profiles were found. Three were\nbetter able to maintain PA and weekday/weekend differentiation during lockdown.\nThe least active group comprising 51 percent of the sample, were younger and\npredominantly singles. Habitually less active already, this group showed the\ngreatest reduction in PA during lockdown with little weekday/weekend\ndifferences. Among different mobility restrictions, removal of habitual social\ncues by lockdown had the largest effect on PA and sleep. Sleep and resting\nheart rate unexpectedly improved. RAR evaluation uncovered heterogeneity of\nresponses to lockdown and can identify characteristics of persons at risk of\ndecline in health and wellbeing."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Reducing greenhouse gas emissions and grain arsenic and lead levels\n  without compromising yield in organically produced rice"}, {"role": "assistant", "content": "Flooded rice production is crucial to global food security, but there are\nassociated environmental concerns. In particular, it is a significant source of\nmethane and nitrous oxide emissions and a large consumer of water resources,\nwhile arsenic, cadmium and lead levels in the grain are a serious health\nconcern. There is also a tendency to use more organic fertilisers to close\nnutrient cycles, posing a threat of even higher greenhouse gas emissions and\ngrain arsenic levels. It has been shown that alternate wetting and drying (AWD)\nwater management reduces both water use and greenhouse gas emissions, but\nsuccess at maintaining yields varies. This study tested the effect of early AWD\n(e-AWD) versus continuous flooding (CF) water management practices on grain\nyields, greenhouse gas emissions and grain arsenic, cadmium and lead levels in\na split plot field experiment with organic fertilisers under organic\nmanagement. The e-AWD water regime showed no difference in yield for the\norganic treatments. Yields significantly increased by 5 to 16 percent in the\ncombination treatments. Root biomass and root length increased in the e-AWD\ntreatments up to 72 and 41 percent, respectively. The e-AWD water regime\nreduced seasonal methane emissions by 71 to 85 percent for organic treatments\nand by 51 to 76 percent for combination treatments; this was linked to a 15 to\n47 percent reduction in dissolved organic carbon. Nitrous oxide emissions\nincreased by 23 to 305 percent but accounted for less than 20 percent of global\nwarming potential. Area and yield scaled global warming potentials were reduced\nby 67 to 83 percent. The e-AWD regime altered soil redox potentials, resulting\nin a reduction in grain arsenic and lead concentrations of up to 66 % and 73 %\nrespectively. Grain cadmium levels were also reduced up to 33 % in organic\ntreatments."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: High-sensitivity COVID-19 group testing by digital PCR"}, {"role": "assistant", "content": "Background: Worldwide demand for SARS-CoV-2 RT-PCR testing is increasing as\nmore countries are impacted by COVID-19 and as testing remains central to\ncontain the spread of the disease, both in countries where the disease is\nemerging and in countries that are past the first wave but exposed to\nre-emergence. Group testing has been proposed as a solution to expand testing\ncapabilities but sensitivity concerns have limited its impact on the management\nof the pandemic. Digital PCR (RT-dPCR) has been shown to be more sensitive than\nRT-PCR and could help in this context.\n  Methods: We implemented RT-dPCR based COVID-19 group testing on commercially\navailable system and assay (Naica System from Stilla Technologies) and\ninvestigated the sensitivity of the method in real life conditions of a\nuniversity hospital in Paris, France, in May 2020. We tested the protocol in a\ndirect comparison with reference RT-PCR testing on 448 samples split into\ngroups of 3 sizes for RT-dPCR analysis: 56 groups of 8 samples, 28 groups of 16\nsamples and 14 groups of 32 samples.\n  Results: Individual RT-PCR testing identified 25 positive samples. Using\ngroups of 8, testing by RT-dPCR identified 23 groups as positive, corresponding\nto 26 true positive samples including 2 samples not initially detected by\nindividual RT-PCR but confirmed positive by further RT-PCR and RT-dPCR\ninvestigation. For groups of 16, 15 groups tested positive, corresponding to 25\ntrue positive samples identified. 100% concordance is found for groups of 32\nbut with limited data points."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Ecological notes on the Annulated Treeboa (Corallus annulatus) from a\n  Costa Rican Lowland Tropical Wet Forest"}, {"role": "assistant", "content": "The Annulated Treeboa (Corallus annulatus) is one of nine currently\nrecognized species in the boid genus Corallus. Its disjunct range extends from\neastern Guatemala into northern Honduras, southeastern Nicaragua, northeastern\nCosta Rica, and southwestern Panama to northern Colombia west of the Andes. It\nis the only species of Corallus found on the Caribbean versant of Costa Rica,\nwhere it occurs at elevations to at least 650m and perhaps as high as 1,000m.\nCorallus annulatus occurs mostly in primary and secondary lowland tropical wet\nand moist rainforest and it appears to be genuinely rare. Besides C. cropanii\nand C. blombergi (the latter closely related to C. annulatus), it is the rarest\nmember of the genus. Aside from information on habitat and activity, little is\nknown regarding its natural history."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Pycro-manager: open-source software for integrated microscopy hardware\n  control and image processing"}, {"role": "assistant", "content": "{\\mu}Manager, an open-source microscopy acquisition software, has been an\nessential tool for many microscopy experiments over the past 15 years, but is\nnot easy to use for experiments in which image acquisition and analysis are\nclosely coupled. This is because {\\mu}Manager libraries are written in C++ and\nJava, whereas image processing is increasingly carried out with data science\nand machine learning tools most easily accessible through the Python\nprogramming language. We present Pycro-Manager, a tool that enables rapid\ndevelopment of such experiments, while also providing access to the wealth of\nexisting tools within {\\mu}Manager through Python."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Metabolomic measures of altered energy metabolism mediate the\n  relationship of inflammatory miRNAs to motor control in collegiate football\n  athletes"}, {"role": "assistant", "content": "Recent research has shown there can be detrimental neurological effects of\nshort- and long-term exposure to contact sports. In the present study,\nmetabolomic profiling was combined with inflammatory miRNA quantification,\ncomputational behavior with virtual reality (VR) testing of motor control, and\nhead collision event monitoring to explore trans-omic and collision effects on\nhuman behavior across a season of players on a collegiate American football\nteam. We integrated permutation-based statistics with mediation analyses to\ntest complex, directional relationships between miRNAs, metabolites, and VR\ntask performance. Fourteen significant mediations (metabolite = mediator; miRNA\n= independent variable; VR score = dependent variable) were discovered at\npreseason (N=6) and across season (N=8) with Sobel p-values less than or equal\nto 0.05 and with total effects at or exceeding 50%. The majority of mediation\nfindings involved long to medium chain fatty acids (2-HG, 8-HOA, UND, sebacate,\nsuberate, and heptanoate). In parallel, TCA metabolites were found to be\nsignificantly decreased at postseason relative to preseason. HAEs were\nassociated with metabolomic measures and miRNA levels across-season. Together,\nthese observations suggest a state of chronic HAE-induced neuroinflammation (as\nevidence by elevated miRNAs) and mitochondrial dysfunction (as observed by\nabnormal FAs and TCA metabolites) that together produce subtle changes in\nneurological function (as observed by impaired motor control behavior). These\nfindings point to a shift in mitochondrial metabolism, away from mitochondria\nfunction, consistent with other illnesses classified as mitochondrial\ndisorders, suggesting a plausible mechanism underlying HAEs in contact sports\nand potential avenue for treatment intervention."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A metabolomic measure of energy metabolism moderates how an inflammatory\n  miRNA relates to rs-fMRI network and motor control in football athletes"}, {"role": "assistant", "content": "Collision sports athletes experience many head acceleration events (HAEs) per\nseason. The effects of these subconcussive events are largely understudied\nsince HAEs may produce no overt symptoms, and are likely to diffusely manifest\nacross multiple scales of study (e.g., molecular, cellular network, and\nbehavior). This study integrated resting-state fMRI with metabolome,\ntranscriptome and computational virtual reality (VR) behavior measures to\nassess the effects of exposure to HAEs on players in a collegiate American\nfootball team. Permutation-based mediation and moderation analysis was used to\ninvestigate relationships between network fingerprint, changes in omic measures\nand VR metrics over the season. Change in an energy cycle fatty acid,\ntridecenedioate, moderated the relationship between 1) miR-505 and DMN\nfingerprint and 2) the relationship between DMN fingerprint and worsening VR\nBalance measures (all p less than or equal to 0.05). In addition, the\nsimilarity in DMN over the season was negatively related to cumulative number\nof HAEs above 80G, and DMN fingerprint was less similar across the season in\nathletes relative to age-matched non-athletes. miR-505 was also positively\nrelated to average number of HAEs above 25G per session. It is important to\nnote that tridecenedioate has a double bond making it a candidate for ROS\nscavenging. These findings between a candidate ROS-related metabolite,\ninflammatory miRNA, altered brain imaging and diminished behavioral performance\nsuggests that impact athletes may experience chronic neuroinflammation. The\nrigorous permutation-based mediation/moderation may provide a methodology for\ninvestigating complex multi-scale biological data within humans alone and thus\nassist study of other functional brain problems."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Polymerase/nicking enzyme powered dual-template multi-cycled G-triplex\n  machine for HIV-1 determination"}, {"role": "assistant", "content": "We proposed a dual-template multi-cycled DNA nanomachine driven by polymerase\nnicking enzyme with high efficiency. The reaction system simply consists of two\ntemplates (T1, T2) and two enzymes (KF polymerase, Nb.BbvCI). The two templates\nare similar in structure (X-X-Y, Y-Y-C): primer recognition region, primer\nanalogue generation region, output region (3 to 5), and there is a nicking site\nbetween each two regions. Output of T1 is the primer of T2 and G-rich fragment\n(G3) is designed as the final products. In the presence of HIV-1, numerous of\nG3 were generated owing to the multi-cycled amplification strategy and formed\ninto G-triplex ThT complex after the addition of thioflavin T (ThT), which\ngreatly enhanced the fluorescence intensity as signal reporter in the\nlabel-free sensing strategy. A dynamic response range of 50 fM-2 nM for HIV-1\ngene detection can be achieved through this multi-cycled G-triplex machine, and\nbenefit from the high efficiency amplification strategy, enzymatic reaction can\nbe completed within 45 minutes followed by fluorescence measurement. In\naddition, analysis of other targets can be achieved by replacing the template\nsequence. Thus there is a certain application potential for trace biomarker\nanalysis in this strategy."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Integrative Data Analytic Framework to Enhance Cancer Precision Medicine"}, {"role": "assistant", "content": "With the advancement of high-throughput biotechnologies, we increasingly\naccumulate biomedical data about diseases, especially cancer. There is a need\nfor computational models and methods to sift through, integrate, and extract\nnew knowledge from the diverse available data to improve the mechanistic\nunderstanding of diseases and patient care. To uncover molecular mechanisms and\ndrug indications for specific cancer types, we develop an integrative framework\nable to harness a wide range of diverse molecular and pan-cancer data. We show\nthat our approach outperforms competing methods and can identify new\nassociations. Furthermore, through the joint integration of data sources, our\nframework can also uncover links between cancer types and molecular entities\nfor which no prior knowledge is available. Our new framework is flexible and\ncan be easily reformulated to study any biomedical problems."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Calibration of Biophysical Models for tau-Protein Spreading in\n  Alzheimer's Disease from PET-MRI"}, {"role": "assistant", "content": "Aggregates of misfolded tau proteins (or just 'tau' for brevity) play a\ncrucial role in the progression of Alzheimer's disease (AD) as they correlate\nwith cell death and accelerated tissue atrophy. Longitudinal positron emission\ntomography (PET) scans can be used quantify the extend of abnormal tau spread.\nSuch PET-based image biomarkers are a promising technology for AD diagnosis and\nprognosis. Here, we propose to calibrate an organ-scale biophysical\nmathematical model using longitudinal PET scans to extract characteristic\ngrowth patterns and spreading of tau. The biophysical model is a\nreaction-advection-diffusion partial differential equation (PDE) with only two\nscalar unknown parameters, one representing the spreading (the diffusion part\nof the PDE) and the other one the growth of tau (the reaction part of the PDE).\nThe advection term captures tissue atrophy and is obtained from diffeomorphic\nregistration of longitudinal magnetic resonance imaging (MRI) scans. We\ndescribe the method, present a numerical scheme for the calibration of the\ngrowth and spreading parameters, perform a sensitivity study using synthetic\ndata, and we perform a preliminary evaluation on clinical scans from the ADNI\ndataset. We study whether such model calibration is possible and investigate\nthe sensitivity of such calibration to the time between consecutive scans and\nthe presence of atrophy. Our findings show that despite using only two\ncalibration parameters, the model can reconstruct clinical scans quite\naccurately. We discovered that small time intervals between scans and the\npresence of background noise create difficulties. Our reconstructed model fits\nthe data well, yet the study on clinical data also reveals shortcomings of the\nsimplistic model. Interestingly, the parameters show significant variability\nacross patients, an indication that these parameters could be useful\nbiomarkers."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A computational approach to aid clinicians in selecting anti-viral drugs\n  for COVID-19 trials"}, {"role": "assistant", "content": "COVID-19 has fast-paced drug re-positioning for its treatment. This work\nbuilds computational models for the same. The aim is to assist clinicians with\na tool for selecting prospective antiviral treatments. Since the virus is known\nto mutate fast, the tool is likely to help clinicians in selecting the right\nset of antivirals for the mutated isolate.\n  The main contribution of this work is a manually curated database publicly\nshared, comprising of existing associations between viruses and their\ncorresponding antivirals. The database gathers similarity information using the\nchemical structure of drugs and the genomic structure of viruses. Along with\nthis database, we make available a set of state-of-the-art computational drug\nre-positioning tools based on matrix completion. The tools are first analysed\non a standard set of experimental protocols for drug target interactions. The\nbest performing ones are applied for the task of re-positioning antivirals for\nCOVID-19. These tools select six drugs out of which four are currently under\nvarious stages of trial, namely Remdesivir (as a cure), Ribavarin (in\ncombination with others for cure), Umifenovir (as a prophylactic and cure) and\nSofosbuvir (as a cure). Another unanimous prediction is Tenofovir alafenamide,\nwhich is a novel tenofovir prodrug developed in order to improve renal safety\nwhen compared to the counterpart tenofovir disoproxil. Both are under trail,\nthe former as a cure and the latter as a prophylactic. These results establish\nthat the computational methods are in sync with the state-of-practice. We also\ndemonstrate how the selected drugs change as the SARS-Cov-2 mutates over time,\nsuggesting the importance of such a tool in drug prediction.\n  The dataset and software is available publicly at\nhttps://github.com/aanchalMongia/DVA and the prediction tool with a\nuser-friendly interface is available at http://dva.salsa.iiitd.edu.in."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: BioStatFlow -Statistical Analysis Workflow for \"Omics\" Data"}, {"role": "assistant", "content": "BioStatFlow is a free web application, useful to facilitate the performance\nof statistical analyses of \"omics\", including metabolomics, data using R\npackages. It is a fast and easy on-line tool for biologists who are not experts\nin univariate and multivariate statistics, do not have time to learn R\nlanguage, and only have basic notions in biostatistics. It guides the biologist\nthrough the different steps of a statistical workflow, from data normalization\nand imputation of missing data to univariate and multivariate analyses. It also\nincludes tools to reconstruct and visualize networks based on correlations. All\noutputs are easily saved in a session or downloaded. New analytical modules can\nbe easily included upon request. BioStatFlow is available online:\nhttp://biostatflow.org"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Efficacy of Hydroxychloroquine as Prophylaxis for Covid-19"}, {"role": "assistant", "content": "Limitations in the design of the experiment of Boulware et al[1] are\nconsidered in Cohen[2]. They are not subject to correction but they are\nreported for readers' consideration. However, they made an analysis for the\nincidence based on Fisher's hypothesis test for means while they published\ndetailed time dependent data which were not analyzed, disregarding an important\ninformation. Here we make the analyses with this time dependent data adopting a\nsimple regression analysis.\n  We conclude their randomized, double-blind, placebo-controlled trial presents\nstatistical evidence, at 99% confidence level, that the treatment of Covid-19\npatients with hydroxychloroquine is effective in reducing the appearance of\nsymptoms if used before or right after exposure to the virus. For 0 to 2 days\nafter exposure to virus, the estimated relative reduction in symptomatic\noutcomes is 72% after 0 days, 48.9% after 1 day and 29.3% after 2 days. For 3\ndays after exposure, the estimated relative reduction is 15.7% but results are\nnot statistically conclusive and for 4 or more days after exposure there is no\nstatistical evidence that hydroxychloroquine is effective in reducing the\nappearance of symptoms.\n  Our results show that the time elapsed between infection and the beginning of\ntreatment is crucial for the efficacy of hydroxychloroquine as a treatment to\nCovid-19."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Challenges in constructing genetic instruments for pharmacologic\n  therapies"}, {"role": "assistant", "content": "The genes that encode the targets of most therapies do not have rare variants\nwith large-effect or common variants with moderate effects on the biomarker\nreflecting the pharmacologic action of the corresponding therapy. Therefore,\nproviding genetic target validation for most therapies is challenging. Novel\nmethods are being developed to combine multiple variants in the gene encoding\nthe target of a therapy that are weakly associated with the biomarker\nreflecting the pharmacologic action of that therapy into a genetic score that\ncan be used as an adequate instrumental variable. We describe one approach to\nsolve this important problem."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Network resilience"}, {"role": "assistant", "content": "Many systems on our planet are known to shift abruptly and irreversibly from\none state to another when they are forced across a \"tipping point,\" such as\nmass extinctions in ecological networks, cascading failures in infrastructure\nsystems, and social convention changes in human and animal networks. Such a\nregime shift demonstrates a system's resilience that characterizes the ability\nof a system to adjust its activity to retain its basic functionality in the\nface of internal disturbances or external environmental changes. In the past 50\nyears, attention was almost exclusively given to low dimensional systems and\ncalibration of their resilience functions and indicators of early warning\nsignals without considerations for the interactions between the components.\nOnly in recent years, taking advantages of the network theory and lavish real\ndata sets, network scientists have directed their interest to the real-world\ncomplex networked multidimensional systems and their resilience function and\nearly warning indicators. This report is devoted to a comprehensive review of\nresilience function and regime shift of complex systems in different domains,\nsuch as ecology, biology, social systems and infrastructure. We cover the\nrelated research about empirical observations, experimental studies,\nmathematical modeling, and theoretical analysis. We also discuss some ambiguous\ndefinitions, such as robustness, resilience, and stability."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Artificial neural networks for disease trajectory prediction in the\n  context of sepsis"}, {"role": "assistant", "content": "The disease trajectory for clinical sepsis, in terms of temporal cytokine and\nphenotypic dynamics, can be interpreted as a random dynamical system. The\nability to make accurate predictions about patient state from clinical\nmeasurements has eluded the biomedical community, primarily due to the paucity\nof relevant and high-resolution data. We have utilized two distinct neural\nnetwork architectures, Long Short-Term Memory and Multi-Layer Perceptron, to\ntake a time sequence of five measurements of eleven simulated serum cytokine\nconcentrations as input and to return both the future cytokine trajectories as\nwell as an aggregate metric representing the patient's state of health. The\nneural networks converged within 50 epochs for cytokine trajectory predictions\nand health-metric regressions, with the expected amount of error (due to\nstochasticity in the simulation). The mapping from a specific cytokine profile\nto a state-of-health is not unique, and increased levels of inflammation result\nin less accurate predictions. Due to the propagation of machine learning error\ncombined with computational model stochasticity over time, the network should\nbe re-grounded in reality daily as predictions can diverge from the true model\ntrajectory as the system evolves towards a probabilistic basin of attraction.\nThis work serves as a proof-of-concept for the use of artificial neural\nnetworks to predict disease progression in sepsis. This work is not intended to\nreplace a trained clinician, rather the goal is to augment intuition with\nquantifiable statistical information to help them make the best decisions. We\nnote that this relies on a valid computational model of the system in question\nas there does not exist sufficient data to inform a machine-learning trained,\nartificially intelligent, controller."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Screening and evaluation of potential clinically significant HIV drug\n  combinations against SARS-CoV-2 virus"}, {"role": "assistant", "content": "In this study, we investigated the inhibition of SARS-CoV-2 spike\nglycoprotein with HIV drugs and their combinations. This glycoprotein is\nessential for the reproduction of the SARS-COV-2 virus, so its inhibition opens\nnew avenues for the treatment of patients with COVID-19 disease. In doing so,\nwe used the VINI in silico model of cancer, whose high accuracy in finding\neffective drugs and their combinations was confirmed in vitro by comparison\nwith existing results from NCI-60 bases, and in vivo by comparison with\nexisting clinical trial results. In the first step, the VINI model calculated\nthe inhibition efficiency of SARS-CoV-2 spike glycoprotein with 44 FDA-approved\nantiviral drugs. Of these drugs, HIV drugs have been shown to be effective,\nwhile others mainly have shown weak or no efficiency. Subsequently, the VINI\nmodel calculated the inhibition efficiency of all possible double and triple\nHIV drug combinations, and among them identified ten with the highest\ninhibition efficiency. These ten combinations were analyzed by Medscape\ndrug-drug interaction software and LexiComp Drug Interactions. All combinations\nexcept the combination of cobicistat_abacavir_rilpivirine appear to have\nserious interactions (risk rating category D) when dosage\nadjustments/reductions are required for possible toxicity. Finally, the VINI\nmodel compared the inhibition efficiency of cobicistat_abacivir_rilpivirine\ncombination with cocktails and individual drugs already used or planned to be\ntested against SARS-CoV-2. Combination cobicistat_abacivir_rilpivirine\ndemonstrated the highest inhibition of SARS-CoV-2 spike glycoprotein over\nothers. Thus, this combination seems to be a promising candidate for the\nfurther in vitro testing and clinical trials."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: scGNN: scRNA-seq Dropout Imputation via Induced Hierarchical Cell\n  Similarity Graph"}, {"role": "assistant", "content": "Single-cell RNA sequencing provides tremendous insights to understand\nbiological systems. However, the noise from dropout can corrupt the downstream\nbiological analysis. Hence, it is desirable to impute the dropouts accurately.\nIn this work, we propose a simple and powerful dropout imputation method\n(scGNN) by applying a bottlenecked Graph Convolutional Neural Network on an\ninduced hierarchical cell similarity graph. We show scGNN has competitive\nperformance against state-of-the-art baselines across three datasets and can\nimprove downstream analysis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Inferring phenomenological models of first passage processes"}, {"role": "assistant", "content": "Biochemical processes in cells are governed by complex networks of many\nchemical species interacting stochastically in diverse ways and on different\ntime scales. Constructing microscopically accurate models of such networks is\noften infeasible. Instead, here we propose a systematic framework for building\nphenomenological models of such networks from experimental data, focusing on\naccurately approximating the time it takes to complete the process, the First\nPassage (FP) time. Our phenomenological models are mixtures of Gamma\ndistributions, which have a natural biophysical interpretation. The complexity\nof the models is adapted automatically to account for the amount of available\ndata and its temporal resolution. The framework can be used for predicting the\nbehavior of various FP systems under varying external conditions. To\ndemonstrate the utility of the approach, we build models for the distribution\nof inter-spike intervals of a morphologically complex neuron, a Purkinje cell,\nfrom experimental and simulated data. We demonstrate that the developed models\ncan not only fit the data but also make nontrivial predictions. We demonstrate\nthat our coarse-grained models provide constraints on more mechanistically\naccurate models of the involved phenomena."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Tutorial of numerical continuation and bifurcation theory for systems\n  and synthetic biology"}, {"role": "assistant", "content": "Mathematical modelling allows us to concisely describe fundamental principles\nin biology. Analysis of models can help to both explain known phenomena, and\npredict the existence of new, unseen behaviours. Model analysis is often a\ncomplex task, such that we have little choice but to approach the problem with\ncomputational methods. Numerical continuation is a computational method for\nanalysing the dynamics of nonlinear models by algorithmically detecting\nbifurcations. Here we aim to promote the use of numerical continuation tools by\nproviding an introduction to nonlinear dynamics and numerical bifurcation\nanalysis. Many numerical continuation packages are available, covering a wide\nrange of system classes; a review of these packages is provided, to help both\nnew and experienced practitioners in choosing the appropriate software tools\nfor their needs."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Gait complexity assessed by detrended fluctuation analysis is sensitive\n  to inconsistencies in stride time series: A modeling study"}, {"role": "assistant", "content": "Background: Human gait exhibits complex fractal fluctuations among\nconsecutive strides. The time series of gait parameters are long-range\ncorrelated (statistical persistence). In contrast, when gait is synchronized\nwith external rhythmic cues, the fluctuation regime is modified to stochastic\noscillations around the target frequency (statistical anti-persistence). To\nhighlight these two fluctuation modes, the prevalent methodology is the\ndetrended fluctuation analysis (DFA). The DFA outcome is the scaling exponent,\nwhich lies between 0.5 and 1 if the time series exhibit long-range\ncorrelations, and below 0.5 if the time series is anti-correlated. A\nfundamental assumption for applying DFA is that the analyzed time series\nresults from a time-invariant generating process. However, a gait time series\nmay be constituted by an ensemble of sub-segments with distinct fluctuation\nregimes (e.g., correlated and anti-correlated). Methods: Several proportions of\ncorrelated and anti-correlated time series were mixed together and then\nanalyzed through DFA. The original (before mixing) time series were generated\nvia autoregressive fractionally integrated moving average (ARFIMA) modelling or\nactual gait data. Results: Results evidenced a nonlinear sensitivity of DFA to\nthe mix of correlated and anti-correlated series. Notably, adding a small\nproportion of correlated segments into an anti-correlated time series had\nstronger effects than the reverse. Significance: In case of changes in gait\ncontrol during a walking trial, the resulting time series may be a patchy\nensemble of several fluctuation regimes. When applying DFA, the scaling\nexponent may be misinterpreted. Cued walking studies may be most at risk of\nsuffering this issue in cases of sporadic synchronization with external cues."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Prevalence and incidence of postpartum depression and environmental\n  factors: the IGEDEPP cohort"}, {"role": "assistant", "content": "Background: IGEDEPP (Interaction of Gene and Environment of Depression during\nPostPartum) is a prospective multicenter cohort study of 3,310 Caucasian women\nwho gave birth between 2011 and 2016, with follow-up until one year postpartum.\nThe aim of the current study is to describe the cohort and estimate the\nprevalence and cumulative incidence of early and late postpartum depression\n(PPD). Methods: Socio-demographic data, personal and family psychiatric\nhistory, as well as stressful life events during childhood and pregnancy were\nevaluated at baseline. Early and late PPD were assessed at 8 weeks and 1 year\npostpartum respectively, using DSM-5 criteria. Results: The prevalence of early\nPPD was 8.3% (95%CI 7.3-9.3), and late PPD 12.9% (95%CI 11.5-14.2), resulting\nin an 8-week cumulative incidence of 8.5% (95%CI 7.4-9.6) and a one-year\ncumulative incidence of PPD of 18.1% (95%CI: 17.1-19.2). Nearly half of the\ncohort (N=1571, 47.5%) had a history of at least one psychiatric or addictive\ndisorder, primarily depressive disorder (35%). Almost 300 women in the cohort\n(9.0%) reported childhood trauma. During pregnancy, 47.7% women experienced a\nstressful event, 30.2% in the first 8 weeks and 43.9% between 8 weeks and one\nyear postpartum. Nearly one in five women reported at least one stressful\npostpartum event at 8 weeks. Conclusion: Incident depressive episodes affected\nnearly one in five women during the first year postpartum. Most women had\nstressful perinatal events. Further IGEDEPP studies will aim to disentangle the\nimpact of childhood and pregnancy-related stressful events on postpartum mental\ndisorders."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Understanding and Modelling the Complexity of the Immune System: Systems\n  Biology for Integration and Dynamical Reconstruction of Lymphocyte\n  Multi-Scale Dynamics"}, {"role": "assistant", "content": "Understanding and modelling the complexity of the immune system is a\nchallenge that is shared by the ImmunoComplexiT$^1$ thematic network from the\nRNSC. The immune system is a complex biological, adaptive, highly diversified,\nself-organized and degenerative cognitive network of entities, allowing for a\nrobust and resilient system with emergent properties such as anamnestic\nresponses and regulation. The adaptive immune system has evolved into a complex\nsystem of billions of highly diversified lymphocytes all interacting as a\nconnective dynamic, multi-scale organised and distributed system, in order to\ncollectively insure body and species preservation. The immune system is\ncharacterized by complexity at different levels: network organisation through\nfluid cell populations with inter-and intra-cell signalling, lymphocyte\nreceptor diversity, cell clonotype selection and competition at cell level,\nmigration and interaction inside the immunological tissues and fluid\ndissemination through the organism, homeostatic regulation while rapid\nadaptation to a changing environment."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Parametric dynamic causal modelling"}, {"role": "assistant", "content": "This technical note introduces parametric dynamic causal modelling, a method\nfor inferring slow changes in biophysical parameters that control fluctuations\nof fast neuronal states. The application domain we have in mind is inferring\nslow changes in variables (e.g., extracellular ion concentrations or synaptic\nefficacy) that underlie phase transitions in brain activity (e.g., paroxysmal\nseizure activity). The scheme is efficient and yet retains a biophysical\ninterpretation, in virtue of being based on established neural mass models that\nare equipped with a slow dynamic on the parameters (such as synaptic rate\nconstants or effective connectivity). In brief, we use an adiabatic\napproximation to summarise fast fluctuations in hidden neuronal states (and\ntheir expression in sensors) in terms of their second order statistics; namely,\ntheir complex cross spectra. This allows one to specify and compare models of\nslowly changing parameters (using Bayesian model reduction) that generate a\nsequence of empirical cross spectra of electrophysiological recordings.\nCrucially, we use the slow fluctuations in the spectral power of neuronal\nactivity as empirical priors on changes in synaptic parameters. This introduces\na circular causality, in which synaptic parameters underwrite fast neuronal\nactivity that, in turn, induces activity-dependent plasticity in synaptic\nparameters. In this foundational paper, we describe the underlying model,\nestablish its face validity using simulations and provide an illustrative\napplication to a chemoconvulsant animal model of seizure activity."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Utilization of 3D segmentation for measurement of pediatric brain tumor\n  outcomes after treatment: review of available free tools, step-by-step\n  instructions, and applications to clinical practice"}, {"role": "assistant", "content": "Volumetric measurements are known to provide more information when it comes\nto segmenting tumors, in comparison to one- and two-dimensional measurements,\nand thus can lead to better informed therapy. In this work, we review the free\nand easily accessible computer platforms available for conducting these 3D\nmeasurements, such as Horos and 3D Slicer and compare the segmentations to\ncommercial Visage software. We compare the time for 3D segmentation of tumors\nand demonstrate how to use a novel plugin that we developed in 3D slicer for\nthe efficient and accurate segmentation of the cystic component of a tumor."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Data Mining and Analytical Models to Predict and Identify Adverse\n  Drug-drug Interactions"}, {"role": "assistant", "content": "The use of multiple drugs accounts for almost 30% of all hospital admission\nand is the 5th leading cause of death in America. Since over 30% of all adverse\ndrug events (ADEs) are thought to be caused by drug-drug interactions (DDI),\nbetter identification and prediction of administration of known DDIs in primary\nand secondary care could reduce the number of patients seeking urgent care in\nhospitals, resulting in substantial savings for health systems worldwide along\nwith better public health. However, current DDI prediction models are prone to\nconfounding biases along with either inaccurate or a lack of access to\nlongitudinal data from Electronic Health Records (EHR) and other drug\ninformation such as FDA Adverse Event Reporting System (FAERS) which continue\nto be the main barriers in measuring the prevalence of DDI and characterizing\nthe phenomenon in medical care. In this review, analytical models including\nLabel Propagation using drug side effect data and Supervised Learning DDI\nPrediction model using Drug-Gene interactions (DGIs) data are discussed.\nImproved identification of DDIs in both of these models compared to previous\nversions are highlighted while limitations that include bias, inaccuracy, and\ninsufficient data are also assessed. A case study of Psoriasis DDI prediction\nby DGI data using Random Forest Classifier was studied. Transfer Matrix\nRecurrent Neural Networks (TM-RNN) that address the above limitations are\ndiscussed in future works."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: GNN-PT: Enhanced Prediction of Compound-protein Interactions by\n  Integrating Protein Transformer"}, {"role": "assistant", "content": "The prediction of protein interactions (CPIs) is crucial for the in-silico\nscreening step in drug discovery. Recently, many end-to-end representation\nlearning methods using deep neural networks have achieved significantly better\nperformance than traditional machine learning algorithms. Much effort has\nfocused on the compound representation or the information extraction from the\ncompound-protein interaction to improve the model capability by taking the\nadvantage of the neural attention mechanism. However, previous studies have\npaid little attention to representing the protein sequences, in which the\nlong-range interactions of residue pairs are essential for characterizing the\nstructural properties arising from the protein folding. We incorporate the\nself-attention mechanism into the protein representation module for CPI\nmodeling, which aims at capturing the long-range interaction information within\nproteins. The proposed module concerning protein representation, called Protein\nTransformer, with an integration with an existing CPI model, has shown a\nsignificant improvement in the prediction performance when compared with\nseveral existing CPI models."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Computation Of Microbial Ecosystems in Time and Space (COMETS): An open\n  source collaborative platform for modeling ecosystems metabolism"}, {"role": "assistant", "content": "Genome-scale stoichiometric modeling of metabolism has become a standard\nsystems biology tool for modeling cellular physiology and growth. Extensions of\nthis approach are also emerging as a valuable avenue for predicting,\nunderstanding and designing microbial communities. COMETS (Computation Of\nMicrobial Ecosystems in Time and Space) was initially developed as an extension\nof dynamic flux balance analysis, which incorporates cellular and molecular\ndiffusion, enabling simulations of multiple microbial species in spatially\nstructured environments. Here we describe how to best use and apply the most\nrecent version of this platform, COMETS 2, which incorporates a more accurate\nbiophysical model of microbial biomass expansion upon growth, as well as\nseveral new biological simulation modules, including evolutionary dynamics and\nextracellular enzyme activity. COMETS 2 provides user-friendly Python and\nMATLAB interfaces compatible with the well-established COBRA models and\nmethods, and comprehensive documentation and tutorials, facilitating the use of\nCOMETS for researchers at all levels of expertise with metabolic simulations.\nThis protocol provides a detailed guideline for installing, testing and\napplying COMETS 2 to different scenarios, with broad applicability to microbial\ncommunities across biomes and scales."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Cox-nnet v2.0: improved neural-network based survival prediction\n  extended to large-scale EMR dataset"}, {"role": "assistant", "content": "Cox-nnet is a neural-network based prognosis prediction method, originally\napplied to genomics data. Here we propose the version 2 of Cox-nnet, with\nsignificant improvement on efficiency and interpretability, making it suitable\nto predict prognosis based on large-scale electronic medical records (EMR)\ndatasets. We also add permutation-based feature importance scores and the\ndirection of feature coefficients. Applying on an EMR dataset of OPTN kidney\ntransplantation, Cox-nnet v2.0 reduces the training time of Cox-nnet up to 32\nfolds (n=10,000) and achieves better prediction accuracy than Cox-PH (p<0.05).\nAvailability and implementation: Cox-nnet v2.0 is freely available to the\npublic at https://github.com/lanagarmire/Cox-nnet-v2.0"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Enhanced Algal Photosynthetic Photon Efficiency by Pulsed Light"}, {"role": "assistant", "content": "We present experimental results demonstrating that, relative to continuous\nillumination, an increase of a factor of 3-10 in the photon efficiency of algal\nphoto-synthesis is attainable via the judicious application of pulsed light for\nlight intensities of practical interest (e.g., average-to-peak solar photon\nflux). We also propose a simple model that can account for all the\nmeasurements. The model (1) reflects the essential rate-limiting elements in\nbio-productivity, (2) incorporates the impact of photon arrival-time statistics\nand (3) accounts for how the enhancement in photon efficiency depends on the\ntimescales of light pulsing and photon flux density. The key is avoiding\nclogging of the photosynthetic pathway by properly timing the light-dark cycles\nexperienced by algal cells. We show how this can be realized with pulsed light\nsources, or by producing pulsed-light effects from continuous illumination via\nturbulent mixing in dense algal cultures in thin photo-bioreactors."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: New mixture models for decoy-free false discovery rate estimation in\n  mass-spectrometry proteomics"}, {"role": "assistant", "content": "Motivation: Accurate estimation of false discovery rate (FDR) of spectral\nidentification is a central problem in mass spectrometry-based proteomics. Over\nthe past two decades, target decoy approaches (TDAs) and decoy-free approaches\n(DFAs), have been widely used to estimate FDR. TDAs use a database of decoy\nspecies to faithfully model score distributions of incorrect peptide-spectrum\nmatches (PSMs). DFAs, on the other hand, fit two-component mixture models to\nlearn the parameters of correct and incorrect PSM score distributions. While\nconceptually straightforward, both approaches lead to problems in practice,\nparticularly in experiments that push instrumentation to the limit and generate\nlow fragmentation-efficiency and low signal-to-noise-ratio spectra. Results: We\nintroduce a new decoy-free framework for FDR estimation that generalizes\npresent DFAs while exploiting more search data in a manner similar to TDAs. Our\napproach relies on multi-component mixtures, in which score distributions\ncorresponding to the correct PSMs, best incorrect PSMs, and second-best\nincorrect PSMs are modeled by the skew normal family. We derive EM algorithms\nto estimate parameters of these distributions from the scores of best and\nsecond-best PSMs associated with each experimental spectrum. We evaluate our\nmodels on multiple proteomics datasets and a HeLa cell digest case study\nconsisting of more than a million spectra in total. We provide evidence of\nimproved performance over existing DFAs and improved stability and speed over\nTDAs without any performance degradation. We propose that the new strategy has\nthe potential to extend beyond peptide identification and reduce the need for\nTDA on all analytical platforms."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: DiviK: Divisive intelligent K-Means for hands-free unsupervised\n  clustering in big biological data"}, {"role": "assistant", "content": "Investigating molecular heterogeneity provides insights about tumor origin\nand metabolomics. The increasing amount of data gathered makes manual analyses\ninfeasible - therefore, automated unsupervised learning approaches are utilized\nfor discovering heterogeneity. However, automated unsupervised analyses require\na lot of experience with setting their hyperparameters and usually an upfront\nknowledge about the number of expected substructures. Moreover, numerous\nmeasured molecules require an additional step of feature engineering to provide\nvaluable results. In this work, we propose DiviK: a scalable stepwise algorithm\nwith local data-driven feature space adaptation for the segmentation of\nhigh-dimensional datasets. The combination of three quality indices: Dice\nIndex, Rand Index and EXIMS score are used to assess the quality of\nunsupervised analyses in 3D space. DiviK was validated on two separate\nhigh-throughput datasets acquired by Mass Spectrometry Imaging in 2D and 3D.\nDiviK could be one of the default choices to consider during the initial\nexploration of Mass Spectrometry Imaging data. It provides a trade-off between\nabsolute heterogeneity detection and focus on biologically plausible\nstructures, and does not require specifying the number of expected structures\nbefore the analysis. With its unique local feature space adaptation, it is\nrobust against dominating global patterns when focusing on the detail. Finally,\ndue to its simplicity, DiviK is easily generalizable to an even more flexible\nframework, useful for other '-omics' data, or tabular data in general\n(including medical images after appropriate embedding). A generic\nimplementation is freely available under Apache 2.0 license at\nhttps://github.com/gmrukwa/divik."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Identifying and Analyzing Sepsis States: A Retrospective Study on\n  Patients with Sepsis in ICUs"}, {"role": "assistant", "content": "Sepsis accounts for more than 50% of hospital deaths, and the associated cost\nranks the highest among hospital admissions in the US. Improved understanding\nof disease states, severity, and clinical markers has the potential to\nsignificantly improve patient outcomes and reduce cost. We develop a\ncomputational framework that identifies disease states in sepsis using clinical\nvariables and samples in the MIMIC-III database. We identify six distinct\npatient states in sepsis, each associated with different manifestations of\norgan dysfunction. We find that patients in different sepsis states are\nstatistically significantly composed of distinct populations with disparate\ndemographic and comorbidity profiles. Collectively, our framework provides a\nholistic view of sepsis, and our findings provide the basis for future\ndevelopment of clinical trials and therapeutic strategies for sepsis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Deep learning for peptide identification from metaproteomics datasets"}, {"role": "assistant", "content": "Metaproteomics are becoming widely used in microbiome research for gaining\ninsights into the functional state of the microbial community. Current\nmetaproteomics studies are generally based on high-throughput tandem mass\nspectrometry (MS/MS) coupled with liquid chromatography. The identification of\npeptides and proteins from MS data involves the computational procedure of\nsearching MS/MS spectra against a predefined protein sequence database and\nassigning top-scored peptides to spectra. Existing computational tools are\nstill far from being able to extract all the information out of large MS/MS\ndatasets acquired from metaproteome samples. In this paper, we proposed a\ndeep-learning-based algorithm, called DeepFilter, for improving the rate of\nconfident peptide identifications from a collection of tandem mass spectra.\nCompared with other post-processing tools, including Percolator, Q-ranker,\nPeptideProphet, and Iprophet, DeepFilter identified 20% and 10% more\npeptide-spectrum-matches and proteins, respectively, on marine microbial and\nsoil microbial metaproteome samples with false discovery rate at 1%."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Clustering methods and Bayesian inference for the analysis of the\n  evolution of immune disorders"}, {"role": "assistant", "content": "Choosing appropriate hyperparameters for unsupervised clustering algorithms\nin an optimal way depending on the problem under study is a long standing\nchallenge, which we tackle while adapting clustering algorithms for immune\ndisorder diagnoses. We compare the potential ability of unsupervised clustering\nalgorithms to detect disease flares and remission periods through analysis of\nlaboratory data from systemic lupus erythematosus patients records with\ndifferent hyperparameter choices. To determine which clustering strategy is the\nbest one we resort to a Bayesian analysis based on the Plackett-Luce model\napplied to rankings. This analysis quantifies the uncertainty in the choice of\nclustering methods for a given problem"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The MetaSUB Microbiome Core Analysis Pipeline Enables Large Scale\n  Metagenomic Analysis"}, {"role": "assistant", "content": "Motivation: Accurate data analysis and quality control is critical for\nmetagenomic studies. Though many tools exist to analyze metagenomic data there\nis no consistent framework to integrate and run these tools across projects.\nCurrently, computational analysis of metagenomes is time consuming, often\nmisses potentially interesting results, and is difficult to reproduce. Further,\ncomparison between metagenomic studies is hampered by inconsistencies in tools\nand databases.\n  Results: We present the MetaSUB Core Analysis Pipeline (CAP) a comprehensive\ntool to analyze metagenomes and summarize the results of a project. The CAP is\ndesigned in a bottom up fashion to perform QC, preprocessing, analysis and even\nto build relevant databases and install necessary tools.\n  Availability and Implementation: The CAP is available under an MIT License on\nGitHub at https://github.com/MetaSUB/CAP2 and on the Python Package Index.\nDocumentation and examples are available on GitHub."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Deep learning-based i-EEG classification with convolutional neural\n  networks for drug-target interaction prediction"}, {"role": "assistant", "content": "Drug-target interaction (DTI) prediction has become a foundational task in\ndrug repositioning, polypharmacology, drug discovery, as well as drug\nresistance and side-effect prediction. DTI identification using machine\nlearning is gaining popularity in these research areas. Through the years,\nnumerous deep learning methods have been proposed for DTI prediction.\nNevertheless, prediction accuracy and efficiency remain key challenges.\nPharmaco-electroencephalogram (pharmaco-EEG) is considered valuable in the\ndevelopment of central nervous system-active drugs. Quantitative EEG analysis\ndemonstrates high reliability in studying the effects of drugs on the brain.\nEarlier preclinical pharmaco-EEG studies showed that different types of drugs\ncan be classified according to their mechanism of action on neural activity.\nHere, we propose a convolutional neural network for EEG-mediated DTI\nprediction. This new approach can explain the mechanisms underlying complicated\ndrug actions, as it allows the identification of similarities in the mechanisms\nof action and effects of psychotropic drugs."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: HIV transmission in men who have sex with men in England: on track for\n  elimination by 2030?"}, {"role": "assistant", "content": "Background: After a decade of a treatment as prevention (TasP) strategy based\non progressive HIV testing scale-up and earlier treatment, a reduction in the\nestimated number of new infections in men-who-have-sex-with-men (MSM) in\nEngland had yet to be identified by 2010. To achieve internationally agreed\ntargets for HIV control and elimination, test-and-treat prevention efforts have\nbeen dramatically intensified over the period 2010-2015, and, from 2016,\nfurther strengthened by pre-exposure prophylaxis (PrEP).\n  Methods: Application of a novel age-stratified back-calculation approach to\ndata on new HIV diagnoses and CD4 count-at-diagnosis, enabled age-specific\nestimation of HIV incidence, undiagnosed infections and mean time-to-diagnosis\nacross both the 2010-2015 and 2016-2018 periods. Estimated incidence trends\nwere then extrapolated, to quantify the likelihood of achieving HIV elimination\nby 2030.\n  Findings: A fall in HIV incidence in MSM is estimated to have started in\n2012/3, eighteen months before the observed fall in new diagnoses. A steep\ndecrease from 2,770 annual infections (95% credible interval 2.490-3,040) in\n2013 to 1,740 (1,500-2,010) in 2015 is estimated, followed by steady decline\nfrom 2016, reaching 854 (441-1,540) infections in 2018. A decline is\nconsistently estimated in all age groups, with a fall particularly marked in\nthe 24-35 age group, and slowest in the 45+ group. Comparable declines are\nestimated in the number of undiagnosed infections.\n  Interpretation: The peak and subsequent sharp decline in HIV incidence\noccurred prior to the phase-in of PrEP. Definining elimination as a public\nhealth threat to be < 50 new infections (1.1 infections per 10,000 at risk),\n40% of incidence projections hit this threshold by 2030. In practice, targeted\npolicies will be required, particularly among the 45+y where STIs are\nincreasing most rapidly."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Global analysis of more than 50,000 SARS-Cov-2 genomes reveals epistasis\n  between 8 viral genes"}, {"role": "assistant", "content": "Genome-wide epistasis analysis is a powerful tool to infer gene interactions,\nwhich can guide drug and vaccine development and lead to a deeper understanding\nof microbial pathogenesis. We have considered all complete SARS-CoV-2 genomes\ndeposited in the GISAID repository until \\textbf{four} different cut-off dates,\nand used Direct Coupling Analysis together with an assumption of Quasi-Linkage\nEquilibrium to infer epistatic contributions to fitness from polymorphic loci.\nWe find \\textbf{eight} interactions, of which three between pairs where one\nlocus lies in gene ORF3a, both loci holding non-synonymous mutations. We also\nfind interactions between two loci in gene nsp13, both holding non-synonymous\nmutations, and four interactions involving one locus holding a synonymous\nmutation. Altogether we infer interactions between loci in viral genes ORF3a\nand nsp2, nsp12 and nsp6, between ORF8 and nsp4, and between loci in genes\nnsp2, nsp13 and nsp14. The paper opens the prospect to use prominent\nepistatically linked pairs as a starting point to search for combinatorial\nweaknesses of recombinant viral pathogens."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Injury risk increases minimally over a large range of changes in\n  activity level in children"}, {"role": "assistant", "content": "Background: Limited research exists on the association between changes in\nphysical activity levels and injury in children. Objective: To assess how well\ndifferent variations of the acute:chronic workload ratio (ACWR), a measure of\nchange in activity, predict injury in children. Methods: We conducted a\nprospective cohort study using data from 1670 Danish schoolchildren measured\nover 5.5 years (2008 to 2014). Coupled 4-week, uncoupled 4-week, and uncoupled\n5-week ACWRs were calculated using activity frequency in the past week as the\nacute load (numerator), and average weekly activity frequency in the past 4 or\n5 weeks as the chronic load (denominator). We modelled the relationship between\ndifferent ACWR variations and injury using generalized linear and generalized\nadditive models, with and without accounting for repeated measures. Results:\nThe prognostic relationship between the ACWR and injury risk was best\nrepresented using a generalized additive mixed model for the uncoupled 5-week\nACWR. It predicted an injury risk of ~3% for ACWRs between 0.8 (activity level\ndecreased by 20%) and 1.5 (activity level increased by 50%). When activity\ndecreased by more than 20% (ACWR< 0.8), injury risk was lower (minimum of 1.5%\nat ACWR=0). When activity increased by more than 50% (ACWR > 1.5), injury risk\nwas higher (maximum of 6% at ACWR = 5). Girls were at significantly higher risk\nof injury than boys. Conclusion: Increases in physical activity in children are\nassociated with much lower injury risks compared to previous results in adults."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Parameter estimation in FACS-seq enables high-throughput\n  characterization of phenotypic heterogeneity"}, {"role": "assistant", "content": "Phenotypic heterogeneity is a most fascinating property of a population of\ncells, which shows the differences among individuals even with the same genetic\nbackground and extracellular environmental conditions. However, the lack of\nhigh-throughput analysis of phenotypic diversity has limited our research\nprogress. To deal with it, we constructed a novel parameter estimation method\nin FACS-seq, a commonly used experimental framework, to achieve simultaneous\ncharacterization of thousands of variants in a library. We further demonstrated\nthe model's ability in estimating the expression properties of each variant,\nwhich we believe can help to decipher the mechanisms of phenotypic\nheterogeneity."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Nanopores -- a Versatile Tool to Study Protein Dynamics"}, {"role": "assistant", "content": "Proteins are the active working horses in our body. These biomolecules\nperform all vital cellular functions from DNA replication and general\nbiosynthesis to metabolic signaling and environmental sensing. While static 3D\nstructures are now readily available, observing the functional cycle of\nproteins - involving conformational changes and interactions - remains very\nchallenging, e.g., due to ensemble averaging. However, time-resolved\ninformation is crucial to gain a mechanistic understanding of protein function.\nSingle-molecule techniques such as FRET and force spectroscopies provide\nanswers but can be limited by the required labelling, a narrow time bandwidth,\nand more. Here, we describe electrical nanopore detection as a tool for probing\nprotein dynamics. With a time bandwidth ranging from microseconds to hours, it\ncovers an exceptionally wide range of timescales that is very relevant for\nprotein function. First, we discuss the working principle of label-free\nnanopore experiments, various pore designs, instrumentation, and the\ncharacteristics of nanopore signals. In the second part, we review a few\nnanopore experiments that solved research questions in protein science, and we\ncompare nanopores to other single-molecule techniques. We hope to make\nelectrical nanopore sensing more accessible to the biochemical community, and\nto inspire new creative solutions to resolve a variety of protein dynamics -\none molecule at a time."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: EIC (Expert Information Criterion) not AIC: the cautious biologist's\n  guide to model selection"}, {"role": "assistant", "content": "1.A goal of many research programs in biology is to extract meaningful\ninsights from large, complex data sets. Researchers in Ecology, Evolution and\nBehavior (EEB) often grapple with long-term, observational data sets from which\nthey construct models to address fundamental questions about biology.\nSimilarly, epidemiologists analyze large, complex observational data sets to\nunderstand the distribution and determinants of human health and disease. A key\ndifference in the analytical workflows for these two distinct areas of biology\nis delineation of data analysis tasks and explicit use of causal inference\nmethods, widely adopted by epidemiologists. 2.Here, we review the most recent\ncausal inference literature and describe an analytical workflow that has direct\napplications for EEB researchers. 3.The first half of this commentary defines\nfour distinct analytical tasks (description, prediction, association, and\ncausal inference), and the corresponding approaches to data analysis and model\nselection. The latter half is dedicated to walking the reader through the steps\nof casual inference, focusing on examples from EEB. 4.Given increasing interest\nin causal inference and common misperceptions regarding the task of causal\ninference, we aim to facilitate an exchange of ideas between disciplinary silos\nand provide a framework for analyses of all data, though particularly relevant\nfor observational data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Comparison of surface thermal patterns of horses and donkeys in IRT\n  images"}, {"role": "assistant", "content": "Infrared thermography (IRT) is a valuable diagnostic tool in equine\nveterinary medicine however, little is known about its application in donkeys.\nThe aim was to find patterns in thermal images of donkeys and horses, and\ndetermine if these patterns share similarities. The study was carried out on 18\ndonkeys and 16 horses. All equids underwent thermal imaging with an infrared\ncamera and measuring the skin thickness and hair coat length. On the class maps\nof each thermal image, 15 regions of interest (ROIs) were annotated and then\ncombined into 10 groups of ROIs (GORs). The existence of statistically\nsignificant differences between surface temperatures in GORs was tested both\n`globally' for all animals of a given species and `locally' for each animal.\nTwo special cases of animals that differ from the rest were also discussed. Our\nresults indicated that the majority of thermal patterns are similar for both\nspecies however, average surface temperatures in horses are higher than in\ndonkeys. It may be related to differences in the skin and hair coat. We\nconcluded, the patterns of both species are associated with GORs, rather than\nan individual ROI, with higher uniformity of donkeys patterns."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Integrating microbial electrochemical technologies with anaerobic\n  digestion to accelerate propionate degradation"}, {"role": "assistant", "content": "The aim of this study is to evaluate the integration of microbial\nelectrochemical technologies (MET) with anaerobic digestion (AD) to overcome AD\nlimitations caused by propionate accumulation. The study focuses on\nunderstanding to what extent the inoculum impacts on the behaviour of the\nintegrated systems (AD-MET) from the perspective of propionate degradation,\nmethane production and microbial population dynamics. Three different inocula\nwere used: two from environmental sources (anaerobic sludge and river sediment)\nand another one from a pre-enriched electroactive consortium adapted to\npropionate degradation. Contrary to expectations, the reactor inoculated with\nthe pre-enriched consortium was not able to maintain its initial good\nperformance in the long run, and the bioelectrochemical activity collapsed\nafter three months of operation. In contrast, the reactor inoculated with\nanaerobic sludge, although it required a relatively longer time to produce any\nobservable current, was able to maintain the electrogenic activity operation\n(0.8 A.m-2) as well as the positive contribution of AD-MET integration to\ntackle propionate accumulation and to enhance methane yield (338 mL.gCOD-1).\nHowever, it must also be highlighted that from a purely energetic point of view\nthe AD-MET was not favorable."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A damaged-informed lung model for ventilator waveforms"}, {"role": "assistant", "content": "The acute respiratory distress syndrome (ARDS) is characterized by the acute\ndevelopment of diffuse alveolar damage (DAD) resulting in increased vascular\npermeability and decreased alveolar gas exchange. Mechanical ventilation is a\npotentially lifesaving intervention to improve oxygen exchange but has the\npotential to cause ventilator-induced lung injury (VILI). A general strategy to\nreduce VILI is to use low tidal volume and low-pressure ventilation, but\noptimal ventilator settings for an individual patient are difficult for the\nbedside physician to determine and mortality from ARDS remains unacceptably\nhigh. Motivated by the need to minimize VILI, scientists have developed models\nof varying complexity to understand diseased pulmonary physiology. However,\nsimple models often fail to capture real-world injury while complex models tend\nto not be estimable with clinical data, limiting the clinical utility of\nexisting models. To address this gap, we present a physiologically anchored\ndata-driven model to better model lung injury. Our approach relies on using\nclinically relevant features in the ventilator waveform data that contain\ninformation about pulmonary physiology, patients-ventilator interaction and\nventilator settings. Our lung model can reproduce essential physiology and\npathophysiology dynamics of differently damaged lungs for both controlled mouse\nmodel data and uncontrolled human ICU data. The estimated parameters values\nthat are correlated with a known measure of lung physiology agree with the\nobserved lung damage. In future endeavors, this model could be used to\nphenotype ventilator waveforms and serve as a basis for predicting the course\nof ARDS and improving patient care."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Describing the movement of molecules in reduced-dimension models"}, {"role": "assistant", "content": "When addressing spatial biological questions using mathematical models,\nsymmetries within the system are often exploited to simplify the problem by\nreducing its physical dimension. In a reduced-dimension model molecular\nmovement is restricted to the reduced dimension, changing the nature of\nmolecular movement. This change in molecular movement can lead to\nquantitatively and even qualitatively different results in the full and reduced\nsystems. Within this manuscript we discuss the condition under which restricted\nmolecular movement in reduced-dimension models accurately approximates\nmolecular movement in the full system. For those systems which do not satisfy\nthe condition, we present a general method for approximating unrestricted\nmolecular movement in reduced-dimension models. We will derive a mathematically\nrobust, finite difference method for solving the 2D diffusion equation within a\n1D reduced-dimension model. The methods described here can be used to improve\nthe accuracy of many reduced-dimension models while retaining benefits of\nsystem simplification."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Imaging the Beating Heart with Macroscopic Phase Stamping"}, {"role": "assistant", "content": "We present a novel approach for imaging the beating embryonic heart, based on\ncombining two independent imaging channels to capture the full spatio-temporal\ninformation of the moving 3D structure. High-resolution, optically-sectioned\nimage recording is accompanied by simultaneous acquisition of low-resolution,\nwhole-heart recording, allowing the latter to be used in post-acquisition\nprocessing to determine the macroscopic spatio-temporal phase of the heart\nbeating cycle. Once determined, or 'stamped', the phase information common to\nboth imaging channels is used to reconstruct the 3D beating heart. We\ndemonstrated our approach in imaging the beating heart of the zebrafish embryo,\ncapturing the entire heart over its full beating cycle, and characterizing\ncellular dynamic behavior with sub-cellular resolution."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Transformer Based Molecule Encoding for Property Prediction"}, {"role": "assistant", "content": "Neural methods of molecule property prediction require efficient encoding of\nstructure and property relationship to be accurate. Recent work using graph\nalgorithms shows limited generalization in the latent molecule encoding space.\nWe build a Transformer-based molecule encoder and property predictor network\nwith novel input featurization that performs significantly better than existing\nmethods. We adapt our model to semi-supervised learning to further perform well\non the limited experimental data usually available in practice."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Tree species effects on topsoil carbon stock and concentration are\n  mediated by tree species type, mycorrhizal association, and N-fixing ability\n  at the global scale"}, {"role": "assistant", "content": "Selection of appropriate tree species is an important forest management\ndecision that may affect sequestration of carbon (C) in soil. However,\ninformation about tree species effects on soil C stocks at the global scale\nremains unclear. Here, we quantitatively synthesized 850 observations from\nfield studies that were conducted in a common garden or monoculture plantations\nto assess how tree species type (broadleaf vs. conifer), mycorrhizal\nassociation (arbuscular mycorrhizal (AM) vs. ectomycorrhizal (ECM)), and\nN-fixing ability (N-fixing vs. non-N-fixing), directly and indirectly, affect\ntopsoil (with a median depth of 10 cm) C concentration and stock, and how such\neffects were influenced by environmental factors such as geographical location\nand climate. We found that (1) tree species type, mycorrhizal association, and\nN-fixing ability were all important factors affecting soil C, with lower forest\nfloor C stocks under broadleaved (44%), AM (39%), or N-fixing (28%) trees\nrespectively, but higher mineral soil C concentration (11%, 22%, and 156%) and\nstock (9%, 10%, and 6%) under broadleaved, AM, and N-fixing trees respectively;\n(2) tree species type, mycorrhizal association, and N-fixing ability affected\nforest floor C stock and mineral soil C concentration and stock directly or\nindirectly through impacting soil properties such as microbial biomass C and\nnitrogen; (3) tree species effects on mineral soil C concentration and stock\nwere mediated by latitude, MAT, MAP, and forest stand age. These results reveal\nhow tree species and their specific traits influence forest floor C stock and\nmineral soil C concentration and stock at a global scale. Insights into the\nunderlying mechanisms of tree species effects found in our study would be\nuseful to inform tree species selection in forest management or afforestation\naiming to sequester more atmospheric C in soil for mitigation of climate\nchange."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Label-free Raman spectroscopy and machine learning enables sensitive\n  evaluation of differential response to immunotherapy"}, {"role": "assistant", "content": "Cancer immunotherapy provides durable clinical benefit in only a small\nfraction of patients, particularly due to a lack of reliable biomarkers for\naccurate prediction of treatment outcomes and evaluation of response. Here, we\ndemonstrate the first application of label-free Raman spectroscopy for\nelucidating biochemical changes induced by immunotherapy in the tumor\nmicroenvironment. We used CT26 murine colorectal cancer cells to grow tumor\nxenografts and subjected them to treatment with anti-CTLA-4 and anti-PD-L1\nantibodies. Multivariate curve resolution - alternating least squares (MCR-ALS)\ndecomposition of Raman spectral dataset obtained from the treated and control\ntumors revealed subtle differences in lipid, nucleic acid, and collagen content\ndue to therapy. Our supervised classification analysis using support vector\nmachines and random forests provided excellent prediction accuracies for both\nimmune checkpoint inhibitors and delineated important spectral markers specific\nto each therapy, consistent with their differential mechanisms of action. Our\nfindings pave the way for in vivo studies of response to immunotherapy in\nclinical patients using label-free Raman spectroscopy and machine learning."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Lamotrigine Therapy for Bipolar Depression: Analysis of Self-Reported\n  Patient Data"}, {"role": "assistant", "content": "Background: Depression in people with bipolar disorder is a major cause of\nlong-term disability, possibly leading to early mortality and currently,\nlimited safe and effective therapies exist. A double-blinded randomized\nplacebo-controlled trial (CEQUEL study) was conducted to evaluate the efficacy\nof Lamotrigine plus Quetiapine versus Quetiapine monotherapy in patients with\nbipolar type I or type II disorders.\n  Objective: The objective of our study was to reanalyze CEQUEL data and\ndetermine an unbiased classification accuracy for active lamotrigine versus\nplacebo. We also wanted to establish the time it took for the drug to provide\nstatistically significant outcomes.\n  Methods: Between October 21, 2008 and April 27, 2012, 202 participants from\n27 sites in United Kingdom were randomly assigned to two treatments; 101:\nlamotrigine, 101: placebo. The primary variable used for estimating depressive\nsymptoms was based on the Quick Inventory of Depressive Symptomatology-self\nreport version 16 (QIDS-SR16). We analyze the data using feature engineering\nand simple classifiers.\n  Results: From weeks 10 to 14, the mean difference in QIDS-SR16 ratings\nbetween the groups was -1.6317 (P=.09; sample size=81, 77; 95% CI -0.2403 to\n3.5036). From weeks 48 to 52, the mean difference was -2.0032 (P=.09; sample\nsize=54, 48; 95% CI -0.3433 to 4.3497). The coefficient of variation and\ndetrended fluctuation analysis (DFA) exponent alpha had the greatest\nexplanatory power. The out-of-sample classification accuracy for the 138\nparticipants who reported more than 10 times after week 12 was 62%. A\nconsistent classification accuracy higher than the no-information benchmark was\nobtained in week 44.\n  Conclusions: Lamotrigine plus Quetiapine treatment decreased depressive\nsymptoms in patients, but with substantial temporal instability. A trial of at\nleast 44 weeks was required to achieve consistent results."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Effectiveness Of Sesame Oil For The Prevention Of Pressure Ulcer In\n  Patients With Bed Rest Undergoing Hospitalization"}, {"role": "assistant", "content": "Pressure Ulcer is one of the most problems in patients with bed rest.\nReposition and skin care are deterrent against the incidence of pressure ulcer.\nObjective: This study aimed to analyze the effectiveness of sesame oil for the\nprevention of pressure ulcer in patients with bed rest undergoing\nhospitalization. Method: This study used a randomized controlled trial design.\nForty samples were divided groups: control and intervention groups. This study\nwas analysed using Chi Square. Results: The results showed that there was a\nsignificant difference between two group (p=0,04). Conclusions: Skin care with\nsesame oil can prevention of pressure ulcers. These results recommended that\nsesame oil can be used for nursing intervention for the prevention of pressure\nulcers."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: THCluster: herb supplements categorization for precision traditional\n  Chinese medicine"}, {"role": "assistant", "content": "There has been a continuing demand for traditional and complementary medicine\nworldwide. A fundamental and important topic in Traditional Chinese Medicine\n(TCM) is to optimize the prescription and to detect herb regularities from TCM\ndata. In this paper, we propose a novel clustering model to solve this general\nproblem of herb categorization, a pivotal task of prescription optimization and\nherb regularities. The model utilizes Random Walks method, Bayesian rules and\nExpectation Maximization(EM) models to complete a clustering analysis\neffectively on a heterogeneous information network. We performed extensive\nexperiments on the real-world datasets and compared our method with other\nalgorithms and experts. Experimental results have demonstrated the\neffectiveness of the proposed model for discovering useful categorization of\nherbs and its potential clinical manifestations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Microalgae-based bioremediation of water contaminated by pesticides in\n  peri-urban agricultural areas"}, {"role": "assistant", "content": "The present study evaluated the capacity of a semi-closed, tubular horizontal\nphotobioreactor (PBR) to remove pesticides from agricultural run-off. The study\nwas carried out in July to study its efficiency under the best conditions\n(highest solar irradiation). A total of 51 pesticides, including 10\ntransformation products, were selected and investigated based on their\nconsumption rate and environmental relevance. Sixteen of them were detected in\nthe agricultural run-off, and the estimated removal efficiencies ranged from\nnegative values, obtained for 3 compounds, namely terbutryn, diuron, and\nimidacloprid, to 100%, achieved for 10 compounds. The acidic herbicide MCPA was\nremoved by 88% on average, and the insecticides 2,4-D and diazinon showed\nvariable removals, between 100% and negative values. The environmental risk\nassociated with the compounds still present in the effluent of the PBR was\nevaluated using hazard quotients (HQs), calculated using the average and\nhighest measured concentrations of the compounds. HQ values > 10 (meaning high\nrisk) were obtained for imidacloprid (21), between 1 and 10 (meaning moderate\nrisk) for 2,4-D (2.8), diazinon (4.6) and terbutryn (1.5), and < 1 (meaning low\nrisk) for the remaining compounds diuron, linuron, and MCPA. The PBR treatment\nyielded variable removals depending on the compound, similar to conventional\nwastewater treatment plants. This study provides new data on the capacity of\nicroalgae-based treatment systems to eliminate a wide range of priority\npesticides under real/environmental conditions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Fungal bioremediation of diuron-contaminated waters: evaluation of its\n  degradation and the effect of amendable factors on its removal in a\n  trickle-bed reactor under non-sterile conditions"}, {"role": "assistant", "content": "The occurrence of the extensively used herbicide diuron in the environment\nposes a severe threat to the ecosystem and human health. Four different\nligninolytic fungi were studied as biodegradation candidates for the removal of\ndiuron. Among them, T. versicolor was the most effective species, degrading\nrapidly not only diuron (83%) but also the major metabolite 3,4-dichloroaniline\n(100%), after 7-day incubation. During diuron degradation, five transformation\nproducts (TPs) were found to be formed and the structures for three of them are\ntentatively proposed. According to the identified TPs, a hydroxylated\nintermediate 3-(3,4-dichlorophenyl)-1-hydroxymethyl-1-methylurea (DCPHMU) was\nfurther metabolized into the N-dealkylated compounds\n3-(3,4-dichlorophenyl)-1-methylurea (DCPMU) and 3,4-dichlorophenylurea (DCPU).\nThe discovery of DCPHMU suggests a relevant role of hydroxylation for\nsubsequent N-demethylation, helping to better understand the main reaction\nmechanisms of diuron detoxification. Experiments also evidenced that\ndegradation reactions may occur intracellularly and be catalyzed by the\ncytochrome P450 system. A response surface method, established by central\ncomposite design, assisted in evaluating the effect of operational variables in\na trickle-bed bioreactor immobilized with T. versicolor on diuron removal. The\nbest performance was obtained at low recycling ratios and influent flow rates.\nFurthermore, results indicate that the contact time between the contaminant and\nimmobilized fungi plays a crucial role in diuron removal. This study represents\na pioneering step forward amid techniques for bioremediation of\npesticides-contaminated waters using fungal reactors at a real scale."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A method to predict location of non-coup brain injuries"}, {"role": "assistant", "content": "Brain injuries are a major reason for mortality and morbidity following\ntrauma in sports, work and traffic. Apart from the trauma at the site of impact\n(coup injury), other regions of the brain remote from the impact locations\n(non-coup) are commonly affected. We show that a screw theory-based method can\nbe used to account for the combined effect of head rotational and linear\naccelerations in causing brain injuries. A scalar measure obtained from the\ninner product of the motion screw and the impact screw is shown to be a\npredictor of the severity and the location of non-coup brain injuries under an\nimpact. The predictions are consistent with head impact experiments conducted\nwith non-human primates. The methodology is proved using finite element\nsimulations and already published experimental results"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Discovering novel cancer bio-markers in acquired lapatinib resistance\n  using Bayesian methods"}, {"role": "assistant", "content": "Genes/Proteins do not work alone within our body, rather as a group they\nperform certain activities indicated as pathways. Signalling transduction\npathways (STPs) are some of the important pathways that transmit biological\nsignals from protein-to-protein controlling several cellular activities.\nHowever, many diseases such as cancer target some of these signalling pathways\nfor their growth and malignance, but demystifying their underlying mechanisms\nare a very complicated tasks. In this study, we use a fully Bayesian approach\nto develop methodologies in discovering novel driver bio-markers in aberrant\nSTPs given two-conditional high-throughput gene expression data. This project,\nnamely PathTurbEr (Pathway Perturbation Driver), is applied on a global gene\nexpression dataset derived from the lapatinib (an EGFR/HER dual inhibitor)\nsensitive and resistant samples from breast cancer cell lines (SKBR3).\nDifferential expression analysis revealed 512 differentially expressed genes\n(DEGs) and their signalling pathway enrichment analysis revealed 22 singalling\npathways as aberrated including PI3K-AKT, Hippo, Chemokine, and TGF-beta\nsingalling pathway as highly dysregulated in lapatinib resistance. Next, we\nmodel the aberrant activities in TGF-beta STP as a causal Bayesian network (BN)\nfrom given observational datasets using three Markov Chain Monte Carlo (MCMC)\nsampling methods, i.e. Neighbourhood sampler (NS) and Hit-and-Run (HAR)\nsampler, which has already proven to have more robust inference with lower\nchances of getting stuck at local optima and faster convergence compared to\nother state-of-art methods. Next, we examined the structural features of the\noptimal BN as a statistical process that generates the global structure using,\n$p_1$-model, a special class of Exponential Random Graph Models (ERGMs) and\nMCMC methods for their hyper-parameter sampling...."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Dynamics-based peptide-MHC binding optimization by a convolutional\n  variational autoencoder: a use-case model for CASTELO"}, {"role": "assistant", "content": "An unsolved challenge in the development of antigen specific immunotherapies\nis determining the optimal antigens to target. Comprehension of antigen-MHC\nbinding is paramount towards achieving this goal. Here, we present CASTELO, a\ncombined machine learning-molecular dynamics (ML-MD) approach to design novel\nantigens of increased MHC binding affinity for a Type 1 diabetes\n(T1D)-implicated system. We build upon a small molecule lead optimization\nalgorithm by training a convolutional variational autoencoder (CVAE) on MD\ntrajectories of 48 different systems across 4 antigens and 4 HLA serotypes. We\ndevelop several new machine learning metrics including a structure-based anchor\nresidue classification model as well as cluster comparison scores. ML-MD\npredictions agree well with experimental binding results and free energy\nperturbation-predicted binding affinities. Moreover, ML-MD metrics are\nindependent of traditional MD stability metrics such as contact area and RMSF,\nwhich do not reflect binding affinity data. Our work supports the role of\nstructure-based deep learning techniques in antigen specific immunotherapy\ndesign."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: SimAEN -- Simulated Automated Exposure Notification"}, {"role": "assistant", "content": "Mitigation strategies that remove infectious individuals from the greater\npopulation have to balance their efficacy with the economic effects associated\nwith quarantine and have to contend with the limited resources available to the\npublic health authorities. Prior strategies have relied on testing and contact\ntracing to find individuals before they become infectious and in order to limit\ntheir interactions with others until after their infectious period has passed.\nManual contact tracing is a public health intervention where individuals\ntesting positive are interviewed to identify other members of the community who\nthey may have come into contact with. These interviews can take a significant\namount of time that has to be tallied in the overall accounting of the outbreak\ncost. The concept of contact tracing has been expanded recently into Automated\nExposure Notification whereby cellphones can be used as sensor platforms to log\nclose contacts and notify the owner in the event that one of their close\ncontacts tests positive. The intention is that this notification will prompt\nthe person to be tested and then restrict their interactions with others until\ntheir status is determined. In this paper we describe our efforts to\ninvestigate the effectiveness of contact tracing interventions on controlling\nan outbreak. This is accomplished by creating a model of disease spread and\nthen observing the impact that simulated tracing and testing have on the number\nof infected individuals. Model parameters are explored to identify critical\ntransition points where interventions become effective. We estimate the\nbenefits as well as costs in order to offer insight to public health officials\nas they select courses of action."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Markov chain Monte Carlo methods for hierarchical clustering of dynamic\n  causal models"}, {"role": "assistant", "content": "In this paper, we address technical difficulties that arise when applying\nMarkov chain Monte Carlo (MCMC) to hierarchical models designed to perform\nclustering in the space of latent parameters of subject-wise generative models.\nSpecifically, we focus on the case where the subject-wise generative model is a\ndynamic causal model (DCM) for fMRI and clusters are defined in terms of\neffective brain connectivity. While an attractive approach for detecting\nmechanistically interpretable subgroups in heterogeneous populations, inverting\nsuch a hierarchical model represents a particularly challenging case, since DCM\nis often characterized by high posterior correlations between its parameters.\nIn this context, standard MCMC schemes exhibit poor performance and extremely\nslow convergence. In this paper, we investigate the properties of hierarchical\nclustering which lead to the observed failure of standard MCMC schemes and\npropose a solution designed to improve convergence but preserve computational\ncomplexity. Specifically, we introduce a class of proposal distributions which\naims to capture the interdependencies between the parameters of the clustering\nand subject-wise generative models and helps to reduce random walk behaviour of\nthe MCMC scheme. Critically, these proposal distributions only introduce a\nsingle hyperparameter that needs to be tuned to achieve good performance. For\nvalidation, we apply our proposed solution to synthetic and real-world datasets\nand also compare it, in terms of computational complexity and performance, to\nHamiltonian Monte Carlo (HMC), a state-of-the-art Monte Carlo. Our results\nindicate that, for the specific application domain considered here, our\nproposed solution shows good convergence performance and superior runtime\ncompared to HMC."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Novel Tool for the Accurate and Affordable Early Diagnosis of\n  Pancreatic Cancer via Machine Learning and Bioinformatics"}, {"role": "assistant", "content": "Pancreatic cancer (PC) is the fourth leading cause of cancer death in the\nUnited States due to its five-year survival rate of 10%. Late diagnosis,\naffiliated with the asymptomatic nature in early stages and the location of the\ncancer with respect to the pancreas, makes current widely-accepted screening\nmethods unavailable. Prior studies have achieved low (70-75%) diagnostic\naccuracy, possibly because 80% of PC cases are associated with diabetes,\nleading to misdiagnosis. To address the problems of frequent late diagnosis and\nmisdiagnosis, we developed an accessible, accurate and affordable diagnostic\ntool for PC, by analyzing the expression of nineteen genes in PC and diabetes.\nFirst, machine learning algorithms were trained on four groups of subjects,\ndepending on the occurrence of PC and Diabetes. The models were analyzed with\n400 PC subjects at varying stages to ensure validity. Naive Bayes, Neural\nNetwork and K-Nearest Neighbors models achieved the highest testing accuracy of\naround 92.6%. Second, the biological implication of the nineteen genes was\ninvestigated using bioinformatics tools. It was found that these genes were\nsignificantly involved in regulating the cytoplasm, cytoskeleton and nuclear\nreceptor activity in the pancreas, specifically in acinar and ductal cells. Our\nnovel tool is the first in the literature that achieves a PC diagnostic\naccuracy of above 90%, having the potential to significantly improve the\ndetection of PC in the background of diabetes and increase the five-year\nsurvival rate."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: AMICI: High-Performance Sensitivity Analysis for Large Ordinary\n  Differential Equation Models"}, {"role": "assistant", "content": "Ordinary differential equation models facilitate the understanding of\ncellular signal transduction and other biological processes. However, for large\nand comprehensive models, the computational cost of simulating or calibrating\ncan be limiting. AMICI is a modular toolbox implemented in C++/Python/MATLAB\nthat provides efficient simulation and sensitivity analysis routines tailored\nfor scalable, gradient-based parameter estimation and uncertainty\nquantification.\n  AMICI is published under the permissive BSD-3-Clause license with source code\npublicly available on https://github.com/AMICI-dev/AMICI. Citeable releases are\narchived on Zenodo."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Neural network fast-classifies biological images using features selected\n  after their random-forests-importance to power smart microscopy"}, {"role": "assistant", "content": "Artificial intelligence is nowadays used for cell detection and\nclassification in optical microscopy, during post-acquisition analysis. The\nmicroscopes are now fully automated and next expected to be smart, to make\nacquisition decisions based on the images. It calls for analysing them on the\nfly. Biology further imposes training on a reduced dataset due to cost and time\nto prepare the samples and have the datasets annotated by experts. We propose\nhere a real-time image processing, compliant with these specifications by\nbalancing accurate detection and execution performance. We characterised the\nimages using a generic, high-dimensional feature extractor. We then classified\nthe images using machine learning for the sake of understanding the\ncontribution of each feature in decision and execution time. We found that the\nnon-linear-classifier random forests outperformed Fisher's linear discriminant.\nMore importantly, the most discriminant and time-consuming features could be\nexcluded without any significant loss in accuracy, offering a substantial gain\nin execution time. It suggests a feature-group redundancy likely related to the\nbiology of the observed cells. We offer a method to select fast and\ndiscriminant features. In our assay, a 79.6 $\\pm$ 2.4 % accurate classification\nof a cell took 68.7 $\\pm$ 3.5 ms (mean $\\pm$ SD, 5-fold cross-validation nested\nin 10 bootstrap repeats), corresponding to 14 cells per second, dispatched into\n8 phases of the cell cycle using 12 feature-groups and operating a consumer\nmarket ARM-based embedded system. Interestingly, a simple neural network\noffered similar performances paving the way to faster training and\nclassification, using parallel execution on a general-purpose graphic\nprocessing unit. Finally, this strategy is also usable for deep neural networks\npaving the way to optimising these algorithms for smart microscopy."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Incorporating domain growth into hybrid methods for reaction-diffusion\n  systems"}, {"role": "assistant", "content": "Reaction--diffusion mechanism are a robust paradigm that can be used to\nrepresent many biological and physical phenomena over multiple spatial scales.\nApplications include intracellular dynamics, the migration of cells and the\npatterns formed by vegetation in semi-arid landscapes. Moreover, domain growth\nis an important process for embryonic growth and wound healing. There are many\nnumerical modelling frameworks capable of simulating such systems on growing\ndomains, however each of these may be well suited to different spatial scales\nand particle numbers. Recently, spatially extended hybrid methods on static\ndomains have been produced in order to bridge the gap between these different\nmodelling paradigms in order to represent multiscale phenomena. However, such\nmethods have not been developed with domain growth in mind. In this paper, we\ndevelop three hybrid methods on growing domains, extending three of the\nprominent static domain hybrid methods. We also provide detailed algorithms to\nallow others to employ them. We demonstrate that the methods are able to\naccurately model three representative reaction-diffusion systems accurately and\nwithout bias."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: UMAP-assisted $K$-means clustering of large-scale SARS-CoV-2 mutation\n  datasets"}, {"role": "assistant", "content": "Coronavirus disease 2019 (COVID-19) caused by severe acute respiratory\nsyndrome coronavirus 2 (SARS-CoV-2) has a worldwide devastating effect. The\nunderstanding of evolution and transmission of SARS-CoV-2 is of paramount\nimportance for the COVID-19 control, combating, and prevention. Due to the\nrapid growth of both the number of SARS-CoV-2 genome sequences and the number\nof unique mutations, the phylogenetic analysis of SARS-CoV-2 genome isolates\nfaces an emergent large-data challenge. We introduce a dimension-reduced\n$k$-means clustering strategy to tackle this challenge. We examine the\nperformance and effectiveness of three dimension-reduction algorithms:\nprincipal component analysis (PCA), t-distributed stochastic neighbor embedding\n(t-SNE), and uniform manifold approximation and projection (UMAP). By using\nfour benchmark datasets, we found that UMAP is the best-suited technique due to\nits stable, reliable, and efficient performance, its ability to improve\nclustering accuracy, especially for large Jaccard distanced-based datasets, and\nits superior clustering visualization. The UMAP-assisted $k$-means clustering\nenables us to shed light on increasingly large datasets from SARS-CoV-2 genome\nisolates."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Indirect Measurement of Hepatic Drug Clearance by Fitting Dynamical\n  Models"}, {"role": "assistant", "content": "We present an indirect signal processing-based measurement method for\nbiological quantities in humans that cannot be directly measured. We develop\nthe method by focusing on estimating hepatic enzyme and drug transporter\nactivity through breath-biopsy samples clinically obtained via the erythromycin\nbreath test (EBT): a small dose of radio-labeled drug is injected and the\nsubsequent content of radio-labeled CO$_2$ is measured repeatedly in exhaled\nbreath; the resulting time series is analyzed. To model EBT we developed a\n14-variable non-linear reduced order dynamical model that describes the\nbehavior of the drug and its metabolites in the human body well enough to\ncapture all biological phenomena of interest. Based on this system of coupled\nnon-linear ordinary differential equations (ODEs) we treat the measurement\nproblem as inverse problem: we estimate the ODE parameters of individual\npatients from the measured EBT time series. These estimates then provide a\nmeasurement of the liver activity of interest. The parameters are hard to\nestimate as the ODEs are stiff and the problem needs to be regularized to\nensure stable convergence. We develop a formal operator framework to capture\nand treat the specific non-linearities present, and perform perturbation\nanalysis to establish properties of the estimation procedure and its solution.\nDevelopment of the method required 150,000 CPU hours at a supercomputing\ncenter, and a single production run takes CPU 24 hours. We introduce and\nanalyze the method in the context of future precision dosing of drugs for\nvulnerable patients (e.g., oncology, nephrology, or pediatrics) to eventually\nensure efficacy and avoid toxicity."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Topological data analysis distinguishes parameter regimes in the\n  Anderson-Chaplain model of angiogenesis"}, {"role": "assistant", "content": "Angiogenesis is the process by which blood vessels form from pre-existing\nvessels. It plays a key role in many biological processes, including embryonic\ndevelopment and wound healing, and contributes to many diseases including\ncancer and rheumatoid arthritis. The structure of the resulting vessel networks\ndetermines their ability to deliver nutrients and remove waste products from\nbiological tissues. Here we simulate the Anderson-Chaplain model of\nangiogenesis at different parameter values and quantify the vessel\narchitectures of the resulting synthetic data. Specifically, we propose a\ntopological data analysis (TDA) pipeline for systematic analysis of the model.\nTDA is a vibrant and relatively new field of computational mathematics for\nstudying the shape of data. We compute topological and standard descriptors of\nmodel simulations generated by different parameter values. We show that TDA of\nmodel simulation data stratifies parameter space into regions with similar\nvessel morphology. The methodologies proposed here are widely applicable to\nother synthetic and experimental data including wound healing, development, and\nplant biology."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Bee Cluster 3D: A system to monitor the temperature in a hive over time"}, {"role": "assistant", "content": "A new system, Bee Cluster 3D, allowing the study of the time evolution of the\n3D temperature distribution in a bee hive is presented. This system can be used\nto evaluate the cluster size and the location of the queen during winter. In\nsummer, the device can be used to quantify the size of the brood nest and the\nbreeding activity of the queen. The system does not disturb the activity of the\ncolony and can be used on any hive. This electronic system was developed to be\nnon-intrusive, miniaturized, and energy autonomous."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Cloud connected NO2 and Ozone Sensor System for Personalized Pediatric\n  Asthma Research and Management"}, {"role": "assistant", "content": "This paper presents a cloud-connected indoor air quality sensor system that\ncan be deployed to patients' homes to study personal microenvironmental\nexposure for asthma research and management. The system consists of multiple\ncompact sensor units that can measure residential NO2, ozone, humidity, and\ntemperature at one minute resolution and a cloud based informatic system that\nacquires, stores, and visualizes the microenvironmental data in real time. The\nsensor hardware can measure NO2 as low as 10 ppb and ozone at 15 ppb. The cloud\ninformatic system is implemented using open-source software on Amazon Web\nService for easy deployment and scalability. This system was successfully\ndeployed to pediatric asthma patients' homes in a pilot study. In this study,\nwe discovered that some families can have short term NO2 exposure higher than\nEPA's one hour exposure limit (100 ppb), and NO2 micropollution episodes often\narise from natural gas appliance usage such as gas stove burning during\ncooking. By combining the personalized air pollutant exposure measurements with\nthe physiological responses from a patient diary and medical record, this\nsystem can enable novel asthma research and personalized asthma management."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Detecting seasonal episodic-like spatiotemporal memory patterns using\n  animal movement modelling"}, {"role": "assistant", "content": "1. Spatial memory plays a role in the way animals perceive their\nenvironments, resulting in memory-informed movement patterns that are\nobservable to ecologists. Developing mathematical techniques to understand how\nanimals use memory in their environments allows for an increased understanding\nof animal cognition. 2. Here we describe a model that accounts for the memory\nof seasonal or ephemeral qualities of an animal's environment. The model\ncaptures multiple behaviors at once by allowing for resource selection in the\npresent time as well as long-distance navigations to previously visited\nlocations within an animal's home range. 3. We performed a set of analyses on\nsimulated data to test our model, determining that it can provide informative\nresults from as little as one year of discrete-time location data. We also show\nthat the accuracy of model selection and parameter estimation increases with\nmore location data. 4. This model has potential to identify a specific\nmechanism in which animals use memory to optimize their foraging, by revisiting\ntemporally and predictably variable resources at consistent time lags."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Systematic Review of the Efforts and Hindrances of Modeling and\n  Simulation of CAR T-cell Therapy"}, {"role": "assistant", "content": "Chimeric Antigen Receptor (CAR) T-cell therapy is an immunotherapy that has\nrecently become highly instrumental in the fight against life-threatening\ndiseases. A variety of modeling and computational simulation efforts have\naddressed different aspects of CAR T therapy, including T-cell activation, T-\nand malignant cell population dynamics, therapeutic cost-effectiveness\nstrategies, and patient survival analyses. In this article, we present a\nsystematic review of those efforts, including mathematical, statistical, and\nstochastic models employing a wide range of algorithms, from differential\nequations to machine learning. To the best of our knowledge, this is the first\nreview of all such models studying CAR T therapy. In this review, we provide a\ndetailed summary of the strengths, limitations, methodology, data used, and\ndata lacking in current published models. This information may help in\ndesigning and building better models for enhanced prediction and assessment of\nthe benefit-risk balance associated with novel CAR T therapies, as well as with\nthe data collection essential for building such models."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Constructed wetlands operated as bioelectrochemical systems for the\n  removal of organic micropollutants"}, {"role": "assistant", "content": "The removal of organic micropollutants (OMPs) has been investigated in\nconstructed wetlands (CWs) operated as bioelectrochemical systems (BES). The\noperation of CWs as BES (CW-BES), either in the form of microbial fuel cells\n(MFC) or microbial electrolysis cells (MEC), has only been investigated in\nrecent years. The presented experiment used CW meso-scale systems applying a\nrealistic horizontal flow regime and continuous feeding of real urban\nwastewater spiked with four OMPs (pharmaceuticals), namely carbamazepine (CBZ),\ndiclofenac (DCF), ibuprofen (IBU) and naproxen (NPX). The study evaluated the\nremoval efficiency of conventional CW systems (CW-control) as well as CW\nsystems operated as closed-circuit MFCs (CW-MFCs) and MECs (CW-MECs). Although\na few positive trends were identified for the CW-BES compared to the CW-control\n(higher average CBZ, DCF and NPX removal by 10-17% in CW-MEC and 5% in CW-MFC),\nthese proved to be not statistically significantly different. Mesoscale\nexperiments with real wastewater could thus not confirm earlier positive\neffects of CW-BES found under strictly controlled laboratory conditions with\nsynthetic wastewaters."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Parameter inference in a computational model of hemodynamics in\n  pulmonary hypertension"}, {"role": "assistant", "content": "Pulmonary hypertension (PH), defined by a mean pulmonary arterial pressure\n(mPAP) $>$ 20 mmHg, is characterized by increased pulmonary vascular resistance\nand decreased pulmonary arterial compliance. There are few measurable\nbiomarkers of PH progression, but a conclusive diagnosis of the disease\nrequires invasive right heart catheterization (RHC). Patient-specific\ncomputational models of the cardiovascular system are a potential noninvasive\ntool for determining additional indicators of disease severity. Using\ncomputational modeling, this study quantifies physiological parameters\nindicative of disease severity in nine PH patients. The model includes all four\nheart chambers and the pulmonary and systemic circulations. We consider two\nsets of calibration data: static (systolic \\& diastolic values) RHC data and a\ncombination of static and continuous, time-series waveform data. We determine a\nsubset of identifiable parameters for model calibration using sensitivity\nanalyses and multistart inference, and carry out uncertainty quantification\npost-inference. Results show that additional waveform data enables accurate\ncalibration of the right atrial reservoir and pump function across the PH\ncohort. Model outcomes, including stroke work and pulmonary\nresistance-compliance relations, reflect typical right heart dynamics in PH\nphenotypes. Lastly, we show that estimated parameters agree with previous,\nnon-modeling studies, supporting this type of analysis in translational PH\nresearch."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: SPRISS: Approximating Frequent $k$-mers by Sampling Reads, and\n  Applications"}, {"role": "assistant", "content": "The extraction of $k$-mers is a fundamental component in many complex\nanalyses of large next-generation sequencing datasets, including reads\nclassification in genomics and the characterization of RNA-seq datasets. The\nextraction of all $k$-mers and their frequencies is extremely demanding in\nterms of running time and memory, owing to the size of the data and to the\nexponential number of $k$-mers to be considered. However, in several\napplications, only frequent $k$-mers, which are $k$-mers appearing in a\nrelatively high proportion of the data, are required by the analysis. In this\nwork we present SPRISS, a new efficient algorithm to approximate frequent\n$k$-mers and their frequencies in next-generation sequencing data. SPRISS\nemploys a simple yet powerful reads sampling scheme, which allows to extract a\nrepresentative subset of the dataset that can be used, in combination with any\n$k$-mer counting algorithm, to perform downstream analyses in a fraction of the\ntime required by the analysis of the whole data, while obtaining comparable\nanswers. Our extensive experimental evaluation demonstrates the efficiency and\naccuracy of SPRISS in approximating frequent $k$-mers, and shows that it can be\nused in various scenarios, such as the comparison of metagenomic datasets and\nthe identification of discriminative $k$-mers, to extract insights in a\nfraction of the time required by the analysis of the whole dataset."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Automatic prediction of cognitive and functional decline can\n  significantly decrease the number of subjects required for clinical trials in\n  early Alzheimer's disease"}, {"role": "assistant", "content": "INTRODUCTION: Heterogeneity in the progression of Alzheimer's disease makes\nit challenging to predict the rate of cognitive and functional decline for\nindividual patients. Tools for short-term prediction could help enrich clinical\ntrial designs and focus prevention strategies on the most at-risk patients.\nMETHOD: We built a prognostic model using baseline cognitive scores and\nMRI-based features to determine which subjects with mild cognitive impairment\nremained stable and which functionally declined (measured by a two-point\nincrease in CDR-SB) over 2 and 3-year follow-up periods, periods typical of the\nlength of clinical trials. RESULTS: Combining both sets of features yields 77%\naccuracy (81% sensitivity and 75% specificity) to predict cognitive decline at\n2 years (74% accuracy at 3 years with 75% sensitivity and 73% specificity).\nUsing this tool to select trial participants yields a 3.8-fold decrease in the\nrequired sample size for a 2-year study (2.8-fold decrease for a 3-year study)\nfor a hypothesized 25% treatment effect to reduce cognitive decline.\nDISCUSSION: This cohort enrichment tool could accelerate treatment development\nby increasing power in clinical trials."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Time to revisit the endpoint dilution assay and to replace TCID$_{50}$\n  and PFU as measures of a virus sample's infection concentration"}, {"role": "assistant", "content": "The infectivity of a virus sample is measured by the infections it causes,\nvia a plaque or focus forming assay (PFU or FFU) or an endpoint dilution (ED)\nassay (TCID$_{50}$, CCID$_{50}$, EID$_{50}$, etc., hereafter collectively\nID$_{50}$). The counting of plaques or foci at a given dilution intuitively and\ndirectly provides the concentration of infectious doses in the undiluted\nsample. However, it has many technical and experimental limitations. For\nexample, it relies on one's judgement in distinguishing between two merged\nplaques and a larger one, or between small plaques and staining artifacts. In\nthis regard, ED assays are more robust because one need only determine whether\ninfection occurred. The output of the ED assay, the 50% infectious dose\n(ID$_{50}$), is calculated using either the Spearman-Karber (SK, 1908,1931) or\nReed-Muench (RM, 1938) mathematical approximations. However, these are often\nmiscalculated and their ID$_{50}$ approximation is biased. We propose that the\nPFU and FFU assays be abandoned, and that the measured output of the ED assay,\nthe ID$_{50}$, be replaced by a more useful measure we coined Specific\nINfections (SIN). We introduce a free, open-source web-application, midSIN,\nthat computes the SIN concentration in a virus sample from a standard ED assay,\nrequiring no changes to current experimental protocols. We demonstrate that the\nSIN/mL of a sample reliably corresponds to the number of infections the sample\nwill cause per unit volume, and directly relates to the multiplicity of\ninfection. midSIN estimates are shown to be more accurate and robust than those\nusing the RM and SK approximations. The impact of ED plate design choices\n(dilution factor, replicates per dilution) on measurement accuracy is also\nexplored. The simplicity of SIN as a measure and the greater accuracy of midSIN\nmake them an easy, superior replacement for the PFU, FFU, and ID$_{50}$\nmeasures."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Comment on \"A compilation and bioenergetic evaluation of syntrophic\n  microbial growth yields in anaerobic digestion\" by Pat\\'on, M. and\n  Rodr\\'iguez, J. [Water Research 162 (2019), 516-517]"}, {"role": "assistant", "content": "Recent efforts have focused on providing a systematic analysis of syntrophic\nmicrobial growth yields. These biokinetic parameters are key to developing an\naccurate mathematical description of the anaerobic digestion process. The\nagreement between experimentally determined growth yields and those obtained\nfrom bioenergetic estimations is therefore of great interest. Considering five\nimportant syntrophic groups, including acetoclastic and hydrogenotrophic\nmethanogens, as well as propionate, butyrate and lactate oxidizers, previous\nfindings suggest that measured and estimated growth yields were consistent only\nfor acetoclastic methanogens. A re-analysis revealed that data are also\nconsistent for lactate oxidizers and hydrogenotrophic methanogens, whereas the\nlimited data available for propionate and butyrate oxidizers are unsupportive\nof firm conclusions. These results highlight pertinent challenges in the\nanalysis of microbial syntrophy and encourage more accurate measurements of\nsyntrophic microbial growth yields in the future."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Benchmarking real-time monitoring strategies for ethanol production from\n  lignocellulosic biomass"}, {"role": "assistant", "content": "The goal of this paper is to review and critically assess different methods\nto monitor key process variables for ethanol production from lignocellulosic\nbiomass. Because cellulose-based biofuels cannot yet compete with\nnon-cellulosic biofuels, process control and optimization are of importance to\nlower the production costs. This study reviews different monitoring schemes, to\nindicate what the added value of real-time monitoring is for process control.\nFurthermore, a comparison is made on different monitoring techniques to measure\nthe off-gas, the concentrations of dissolved components in the inlet to the\nprocess, the concentrations of dissolved components in the reactor, and the\nbiomass concentration. Finally, soft sensor techniques and available models are\ndiscussed, to give an overview of modeling techniques that analyze data, with\nthe aim of coupling the soft sensor predictions to the control and optimization\nof cellulose to ethanol fermentation. The paper ends with a discussion of\nfuture needs and developments."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Pathogenesis, Symptomatology, and Transmission of SARS-CoV-2 through\n  Analysis of Viral Genomics and Structure"}, {"role": "assistant", "content": "The novel coronavirus SARS-CoV-2, which emerged in late 2019, has since\nspread around the world and infected hundreds of millions of people with\ncoronavirus disease 2019 (COVID-19). While this viral species was unknown prior\nto January 2020, its similarity to other coronaviruses that infect humans has\nallowed for rapid insight into the mechanisms that it uses to infect human\nhosts, as well as the ways in which the human immune system can respond. Here,\nwe contextualize SARS-CoV-2 among other coronaviruses and identify what is\nknown and what can be inferred about its behavior once inside a human host.\nBecause the genomic content of coronaviruses, which specifies the virus's\nstructure, is highly conserved, early genomic analysis provided a significant\nhead start in predicting viral pathogenesis and in understanding potential\ndifferences among variants. The pathogenesis of the virus offers insights into\nsymptomatology, transmission, and individual susceptibility. Additionally,\nprior research into interactions between the human immune system and\ncoronaviruses has identified how these viruses can evade the immune system's\nprotective mechanisms. We also explore systems-level research into the\nregulatory and proteomic effects of SARS-CoV-2 infection and the immune\nresponse. Understanding the structure and behavior of the virus serves to\ncontextualize the many facets of the COVID-19 pandemic and can influence\nefforts to control the virus and treat the disease."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Effect of stress on cardiorespiratory synchronization of Ironmen\n  athletes"}, {"role": "assistant", "content": "The aim of this paper is to investigate the cardiorespiratory synchronization\nin athletes subjected to extreme physical stress combined with a cognitive\nstress tasks. ECG and respiration were measured in 14 athletes before and after\nthe Ironmen competition. Stroop test was applied between the measurements\nbefore and after the Ironmen competition to induce cognitive stress.\nSynchrogram and empirical mode decomposition analysis were used for the first\ntime to investigate the effects of physical stress, induced by the Ironmen\ncompetition, on the phase synchronization of the cardiac and respiratory\nsystems of Ironmen athletes before and after the competition. A cognitive\nstress task (Stroop test) was performed both pre- and post-Ironman event in\norder to prevent the athletes from cognitively controlling their breathing\nrates. Our analysis showed that cardiorespiratory synchronization increased\npost-Ironman race compared to pre-Ironman. The results suggest that the amount\nof stress the athletes are recovering from post-competition is greater than the\neffects of the Stroop test. This indicates that the recovery phase after the\ncompetition is more important for restoring and maintaining homeostasis, which\ncould be another reason for stronger synchronization."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Dietary Supplements and Nutraceuticals Under Investigation for COVID-19\n  Prevention and Treatment"}, {"role": "assistant", "content": "Coronavirus disease 2019 (COVID-19) has caused global disruption and a\nsignificant loss of life. Existing treatments that can be repurposed as\nprophylactic and therapeutic agents could reduce the pandemic's devastation.\nEmerging evidence of potential applications in other therapeutic contexts has\nled to the investigation of dietary supplements and nutraceuticals for\nCOVID-19. Such products include vitamin C, vitamin D, omega 3 polyunsaturated\nfatty acids, probiotics, and zinc, all of which are currently under clinical\ninvestigation. In this review, we critically appraise the evidence surrounding\ndietary supplements and nutraceuticals for the prophylaxis and treatment of\nCOVID-19. Overall, further study is required before evidence-based\nrecommendations can be formulated, but nutritional status plays a significant\nrole in patient outcomes, and these products could help alleviate deficiencies.\nFor example, evidence indicates that vitamin D deficiency may be associated\nwith greater incidence of infection and severity of COVID-19, suggesting that\nvitamin D supplementation may hold prophylactic or therapeutic value. A growing\nnumber of scientific organizations are now considering recommending vitamin D\nsupplementation to those at high risk of COVID-19. Because research in vitamin\nD and other nutraceuticals and supplements is preliminary, here we evaluate the\nextent to which these nutraceutical and dietary supplements hold potential in\nthe COVID-19 crisis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Rate-dependent effects of lidocaine on cardiac dynamics: Development and\n  analysis of a low-dimensional drug-channel interaction model"}, {"role": "assistant", "content": "State-dependent Na+ channel blockers are often prescribed to treat cardiac\narrhythmias, but many Na+ channel blockers are known to have pro-arrhythmic\nside effects. While the anti and proarrhythmic potential of a Na+ channel\nblocker is thought to depend on the characteristics of its rate-dependent\nblock, the mechanisms linking these two attributes are unclear. Furthermore,\nhow specific properties of rate-dependent block arise from the binding kinetics\nof a particular drug is poorly understood. Here, we examine the rate-dependent\neffects of the Na+ channel blocker lidocaine by constructing and analyzing a\nnovel drug-channel interaction model. First, we identify the predominant mode\nof lidocaine binding in a 24 variable Markov model for lidocaine-Na+ channel\ninteraction by Moreno et al. We then develop a novel 3-variable lidocaine-Na+\nchannel interaction model that incorporates only the predominant mode of drug\nbinding. Our low-dimensional model replicates the extensive voltage-clamp data\nused to parameterize the Moreno et al. model. Furthermore, the effects of\nlidocaine on action potential upstroke velocity and conduction velocity in our\nmodel are similar to those predicted by the Moreno et al. model. By exploiting\nthe low-dimensionality of our model, we derive an algebraic expression for\nlevel of rate-dependent block as a function of pacing frequency, restitution\nproperties, diastolic and plateau potentials, and drug binding rate constants.\nOur model predicts that the level of rate-dependent block is sensitive to\nalterations in restitution properties and increases in diastolic potential, but\nit is insensitive to variations in the shape of the action potential waveform\nand lidocaine binding rates."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Sarc-Graph: Automated segmentation, tracking, and analysis of sarcomeres\n  in hiPSC-derived cardiomyocytes"}, {"role": "assistant", "content": "A better fundamental understanding of human induced pluripotent stem\ncell-derived cardiomyocytes (hiPSC-CMs) has the potential to advance\napplications ranging from drug discovery to cardiac repair. Automated\nquantitative analysis of beating hiPSC-CMs is an important and fast developing\ncomponent of the hiPSC-CM research pipeline. Here we introduce \"Sarc-Graph,\" a\ncomputational framework to segment, track, and analyze sarcomeres in\nfluorescently tagged hiPSC-CMs. Our framework includes functions to segment\nz-discs and sarcomeres, track z-discs and sarcomeres in beating cells, and\nperform automated spatiotemporal analysis and data visualization. In addition\nto reporting good performance for sarcomere segmentation and tracking with\nlittle to no parameter tuning and a short runtime, we introduce two novel\nanalysis approaches. First, we construct spatial graphs where z-discs\ncorrespond to nodes and sarcomeres correspond to edges. This makes measuring\nthe network distance between each sarcomere (i.e., the number of connecting\nsarcomeres separating each sarcomere pair) straightforward. Second, we treat\ntracked and segmented components as fiducial markers and use them to compute\nthe approximate deformation gradient of the entire tracked population. This\nrepresents a new quantitative descriptor of hiPSC-CM function. We showcase and\nvalidate our approach with both synthetic and experimental movies of beating\nhiPSC-CMs. By publishing Sarc-Graph, we aim to make automated quantitative\nanalysis of hiPSC-CM behavior more accessible to the broader research\ncommunity."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Fine-tuning neural excitation/inhibition for tailored ketamine use in\n  treatment-resistant depression"}, {"role": "assistant", "content": "The glutamatergic modulator ketamine has been shown to rapidly reduce\ndepressive symptoms in patients with treatment-resistant major depressive\ndisorder (TRD). Although its mechanisms of action are not fully understood,\nchanges in cortical excitation/inhibition (E/I) following ketamine\nadministration are well documented in animal models and could represent a\npotential biomarker of treatment response. Here, we analyse neuromagnetic\nvirtual electrode timeseries collected from the primary somatosensory cortex in\n18 unmedicated patients with TRD and in an equal number of age-matched healthy\ncontrols during a somatosensory 'airpuff' stimulation task. These two groups\nwere scanned as part of a clinical trial of ketamine efficacy under three\nconditions: a) baseline; b) 6-9 hours following subanesthetic ketamine\ninfusion; and c) 6-9 hours following placebo-saline infusion. We obtained\nestimates of E/I interaction strengths by using Dynamic Causal Modelling (DCM)\non the timeseries, thereby allowing us to pinpoint, under each scanning\ncondition, where each subject's dynamics lie within the Poincar\\'e diagram - as\ndefined in dynamical systems theory. We demonstrate that the Poincar\\'e diagram\noffers classification capability for TRD patients, in that the further the\npatients' coordinates were shifted (by virtue of ketamine) toward the stable\n(top-left) quadrant of the Poincar\\'e diagram, the more their depressive\nsymptoms improved. The same relationship was not observed by virtue of a\nplacebo effect - thereby verifying the drug-specific nature of the results. We\nshow that the shift in neural dynamics required for symptom improvement\nnecessitates an increase in both excitatory and inhibitory coupling. We present\naccompanying MATLAB code made available in a public repository, thereby\nallowing for future studies to assess individually-tailored treatments of TRD."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: An overview of continuous and discrete phasor analysis of binned or\n  time-gated periodic decays"}, {"role": "assistant", "content": "Time-resolved analysis of periodically excited luminescence decays by the\nphasor method in the presence of time-gating or binning is revisited.\nAnalytical expressions for discrete configurations of square gates are derived\nand the locus of the phasors of such modified periodic single-exponential\ndecays is compared to the canonical universal semicircle. The effects of IRF\noffset, decay truncation and gate shape are also discussed. Finally, modified\nexpressions for the phase and modulus lifetimes are provided for some simple\ncases. A discussion of a modified phasor calibration approach is presented."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: GC-MS Profile of Diodella sarmentosa (SW) Bacigalupo El Cabral ex\n  Borhidi Ethanol Leaf Extract and its Total Dehydrogenase Inhibitory Potential"}, {"role": "assistant", "content": "Phytochemical composition of ethanol leaf extract of Diodella sarmentosa was\nprofiled with GC-MS and the inhibitory property of the extract against total\nmicrobial dehydrogenases were assessed. The major constituents of the extract\nwere squalene (29.50%), Phytol (24.68%), phenol, 3-pentadecyl- (18.58%),\n1-Butanol, 3-methyl- (9.09%) and n-Hexadecanoic acid (7.78%). The minimum\ninhibitory concentration (MIC) of the extract against broad spectrum of\nmicrobial population was assessed. Bacillus subtilis, Candidas spp, and\nPenicillium spp were more sensitive to the treatment and thus; were further\ninvestigated using Dehydrogenase activity assay method. Total dehydrogenase\nactivities of Bacillus subtilis, Candidas spp, and Penicillium spp at the\nextract concentration range of 0 to 2000mg/ml were progressively inhibited at\nincreasing extract concentrations. The threshold inhibitory concentrations\n(IC50) of the extracts against Candidas spp, Penicillium spp and Bacillus\nsubtilis were 275micro. g/ml, 322 micro. g/ml and 411 micro. g/ml respectively.\nOur findings suggested the extract as a useful source of antimicrobial\nphytochemicals for pharmaceutical use."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Unmasking the mask studies: why the effectiveness of surgical masks in\n  preventing respiratory infections has been underestimated"}, {"role": "assistant", "content": "Face masks have been widely used as a protective measure against COVID-19.\nHowever, pre-pandemic empirical studies have produced mixed statistical results\non the effectiveness of masks against respiratory viruses. The implications of\nthe studies' recognized limitations have not been quantitatively and\nstatistically analyzed, leading to confusion regarding the effectiveness of\nmasks. Such confusion may have contributed to organizations such as the WHO and\nCDC initially not recommending that the general public wear masks. Here we show\nthat when the adherence to mask-usage guidelines is taken into account, the\nempirical evidence indicates that masks prevent disease transmission: all\nstudies we analyzed that did not find surgical masks to be effective were\nunder-powered to such an extent that even if masks were 100% effective, the\nstudies in question would still have been unlikely to find a statistically\nsignificant effect. We also provide a framework for understanding the effect of\nmasks on the probability of infection for single and repeated exposures. The\nframework demonstrates that more frequently wearing a mask provides\nsuper-linearly compounding protection, as does both the susceptible and\ninfected individual wearing a mask. This work shows (1) that both theoretical\nand empirical evidence is consistent with masks protecting against respiratory\ninfections and (2) that nonlinear effects and statistical considerations\nregarding the percentage of exposures for which masks are worn must be taken\ninto account when designing empirical studies and interpreting their results."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Evaluation of the Penetration Process of Fluorescent Collagenase\n  Nanocapsules in a 3D Collagen Gel"}, {"role": "assistant", "content": "One of the major limitations of nanomedicine is the scarce penetration of\nnanoparticles in tumoral tissues. These constrains have been tried to be solved\nby different strategies, such as the employ of polyethyleneglycol (PEG) to\navoid the opsonization or reducing the extracellular matrix (ECM) density. Our\nresearch group has developed some strategies to overcome these limitations such\nas the employ of pH-sensitive collagenase nanocapsules for the digestion of the\ncollagen-rich extracellular matrix present in most of tumoral tissues. However,\na deeper understanding of physicochemical kinetics involved in the nanocapsules\ndegradation process is needed to understand the nanocapsule framework\ndegradation process produced during the penetration in the tissue. For this, in\nthis work it has been employed a double-fluorescent labelling strategy of the\npolymeric enzyme nanocapsule as a crucial chemical tool which allowed the\nanalysis of nanocapsules and free collagenase during the diffusion process\nthroughout a tumour-like collagen matrix. This extrinsic label strategy\nprovides far greater advantages for observing biological processes. For the\ndetection of enzyme, collagenase has been labelled with fluorescein\nIsothiocyanate (FITC), whereas the nanocapsule surface was labelled with\nrhodamine Isothiocyanate (RITC). Thus, it has been possible to monitor the\nhydrolysis of nanocapsules and their diffusion throughout a thick 3D Collagen\ngel during the time, obtaining a detailed temporal evaluation of the\npH-sensitive collagenase nanocapsule behaviour. These collagenase nanocapsules\ndisplayed a high enzymatic activity in low concentrations at acidic pH, and\ntheir efficiency to penetrate into tissue models pave the way to a wide range\nof possible nanomedical applications, especially in cancer therapy."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: From sleep medicine to medicine during sleep: A clinical perspective"}, {"role": "assistant", "content": "Sleep has a profound influence on the physiology of body systems and\nbiological processes. Molecular studies have shown circadian-regulated shifts\nin protein expression patterns across human tissues, further emphasizing the\nunique functional, behavioral and pharmacokinetic landscape of sleep. Thus,\nmany pathological processes are also expected to exhibit sleep-specific\nmanifestations. Nevertheless, sleep is seldom utilized for the study, detection\nand treatment of non-sleep-specific pathologies. Modern advances in biosensor\ntechnologies have enabled remote, non-invasive recording of a growing number of\nphysiologic parameters and biomarkers. Sleep is an ideal time frame for the\ncollection of long and clean physiological time series data which can then be\nanalyzed using data-driven algorithms such as deep learning. In this\nperspective paper, we aim to highlight the potential of sleep as an auspicious\ntime for diagnosis, management and therapy of nonsleep-specific pathologies. We\nintroduce key clinical studies in selected medical fields, which leveraged\nnovel technologies and the advantageous period of sleep to diagnose, monitor\nand treat pathologies. We then discuss possible opportunities to further\nharness this new paradigm and modern technologies to explore human health and\ndisease during sleep and to advance the development of novel clinical\napplications: From sleep medicine to medicine during sleep."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Structural identifiability analysis of PDEs: A case study in continuous\n  age-structured epidemic models"}, {"role": "assistant", "content": "Computational and mathematical models rely heavily on estimated parameter\nvalues for model development. Identifiability analysis determines how well the\nparameters of a model can be estimated from experimental data. Identifiability\nanalysis is crucial for interpreting and determining confidence in model\nparameter values and to provide biologically relevant predictions. Structural\nidentifiability analysis, in which one assumes data to be noiseless and\narbitrarily fine-grained, has been extensively studied in the context of\nordinary differential equation (ODE) models, but has not yet been widely\nexplored for age-structured partial differential equation (PDE) models. These\nmodels present additional difficulties due to increased number of variables and\npartial derivatives as well as the presence of boundary conditions. In this\nwork, we establish a pipeline for structural identifiability analysis of\nage-structured PDE models using a differential algebra framework and derive\nidentifiability results for specific age-structured models. We use epidemic\nmodels to demonstrate this framework because of their wide-spread use in many\ndifferent diseases and for the corresponding parallel work previously done for\nODEs. In our application of the identifiability analysis pipeline, we focus on\na Susceptible-Exposed-Infected model for which we compare identifiability\nresults for a PDE and corresponding ODE system and explore effects of\nage-dependent parameters on identifiability. We also show how practical\nidentifiability analysis can be applied in this example."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Application of Quantitative Systems Pharmacology to guide the optimal\n  dosing of COVID-19 vaccines"}, {"role": "assistant", "content": "Optimal use and distribution of Covid-19 vaccines involves adjustments of\ndosing. Due to the rapidly-evolving pandemic, such adjustments often need to be\nintroduced before full efficacy data are available. As demonstrated in other\nareas of drug development, quantitative systems pharmacology (QSP) is well\nplaced to guide such extrapolation in a rational and timely manner. Here we\npropose for the first time how QSP can be applied real time in the context of\nCOVID-19 vaccine development."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Prediction of Influenza A virus infections in humans using an Artificial\n  Neural Network learning approach"}, {"role": "assistant", "content": "The Influenza type A virus can be considered as one of the most severe\nviruses that can infect multiple species with often fatal consequences to the\nhosts. The Haemagglutinin (HA) gene of the virus has the potential to be a\ntarget for antiviral drug development realised through accurate identification\nof its sub-types and possible the targeted hosts. In this paper, to accurately\npredict if an Influenza type A virus has the capability to infect human hosts,\nby using only the HA gene, is therefore developed and tested. The predictive\nmodel follows three main steps; (i) decoding the protein sequences into\nnumerical signals using EIIP amino acid scale, (ii) analysing these sequences\nby using Discrete Fourier Transform (DFT) and extracting DFT-based features,\n(iii) using a predictive model, based on Artificial Neural Networks and using\nthe features generated by DFT. In this analysis, from the Influenza Research\nDatabase, 30724, 18236 and 8157 HA protein sequences were collected for Human,\nAvian and Swine, respectively. Given this set of the proteins, the proposed\nmethod yielded 97.36% (+- 0.04%), 97.26% (+- 0.26%), 0.978 (+- 0.004), 0.963\n(+- 0.005) and 0.945 (+- 0.005) for the training accuracy validation accuracy,\nprecision, recall and Mathews Correlation Coefficient (MCC) respectively, based\non a 10-fold cross-validation. The classification model generated by using one\nof the largest dataset, if not the largest, yields promising results that could\nlead to early detection of such species and help develop precautionary\nmeasurements for possible human infections."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The effects of temperature acclimation on swimming performance in the\n  pelagic Mahi-mahi (Coryphaena hippurus)"}, {"role": "assistant", "content": "Mahi-mahi (Coryphaena hippurus) are a highly migratory pelagic fish, but\nlittle is known about what environmental factors drive their broad\ndistribution. This study examined how temperature influences aerobic scope and\nswimming performance in mahi. Mahi were acclimated to four temperatures\nspanning their natural range (20, 24, 28, and 32{\\deg}C; 5-27 days) and\ncritical swimming speed (Ucrit), metabolic rates, aerobic scope, and optimal\nswim speed were measured. Aerobic scope and Ucrit were highest in\n28{\\deg}C-acclimated fish. 20{\\deg}C-acclimated mahi experienced significantly\ndecreased aerobic scope and Ucrit relative to 28{\\deg}C-acclimated fish (57 and\n28% declines, respectively). 32{\\deg}C-acclimated mahi experienced increased\nmortality and a significant 23% decline in Ucrit, and a trend for a 26% decline\nin factorial aerobic scope relative to 28{\\deg}C-acclimated fish. Absolute\naerobic scope showed a similar pattern to factorial aerobic scope. Our results\nare generally in agreement with previously observed distribution patterns for\nwild fish. Although thermal performance can vary across life stages, the\nhighest tested swim performance and aerobic scope found in the present study\n(28{\\deg}C), aligns with recently observed habitat utilization patterns for\nwild mahi and could be relevant for climate change predictions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Metabolic alterations caused by smoking: the use of 1H-NMR in blood\n  plasma analysis to unravel underlying mechanisms of lung cancers leading risk\n  factor"}, {"role": "assistant", "content": "Nowadays, the screening methods for the early detection of lung cancer\nstruggle with several limitations such as many false positive results and low\nsensitivity. The detection of specific biomarkers is of high interest to\ncomplement these conventional screening methods. The objective of this study is\nto prove the power of 1H-NMR in metabolomics for the detection of smoking\nbehavior, which is the leading risk factor for lung cancer, and as such gain\nmore insights in the metabolic alterations that are caused by smoking. In this\nresearch, 1H-NMR spectra of human blood plasma samples were divided in 110\nintegration regions, from which the integration values were used to train an\nOPLS-DA classification model that underwent further data reduction. Results\nshow that a classification model could discriminate between individuals based\non their smoking status with a sensitivity of 96 percent and a specificity of\n94 percent. This study also demonstrates that by performing a pathway-specific\nvariable reduction of almost 50 percent, the sensitivity and specificity of the\nmodel almost remains the same. To conclude, 1H-NMR analyses show that the\nbloods metabolic profile of a smoker is altered compared to that of a\nnon-smoker. Also, pathway-specific variable reduction shows great potential to\nperform overall data reduction. This workflow could be interesting to apply in\nthe identification of lung cancer, to potentially detect specific biomarkers."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Interpretation of the Area Under the ROC Curve for Risk Prediction\n  Models"}, {"role": "assistant", "content": "The area under the curve (AUC) of the receiver operating characteristics\ncurve (ROC) evaluates the separation between patients and nonpatients or\ndiscrimination. For risk prediction models these risk distributions can be\nderived from the population risk distribution so are not independent as in\ndiagnosis. A ROC curve AUC formula based on the underlying population risk\ndistribution clarifies how discrimination is defined mathematically and that\ngeneration of the equivalent c-statistic effects a Monte Carlo integration of\nthe formula. For a selection of continuous risk distributions, exact analytic\nformulas or numerical results for the ROC curve AUC and overlap measure are\npresented and demonstrate a linear or near-linear dependence on their standard\ndeviation. The ROC curve AUC is also shown to be highly dependent on the mean\npopulation risk, a distinction from the independence from disease prevalence\nfor diagnostic tests. The converse of discrimination, overlap, has been\nquantified by the overlap measure, which appears to provide equivalent\ninformation. As achieving wider population risk distributions is the goal of\nrisk prediction modeling for clinical risk stratification, interpreting the ROC\ncurve AUC as a measure of dispersion, rather than discrimination, when\ncomparing risk prediction models may be more relevant."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Bayesian uncertainty quantification for data-driven equation learning"}, {"role": "assistant", "content": "Equation learning aims to infer differential equation models from data. While\na number of studies have shown that differential equation models can be\nsuccessfully identified when the data are sufficiently detailed and corrupted\nwith relatively small amounts of noise, the relationship between observation\nnoise and uncertainty in the learned differential equation models remains\nunexplored. We demonstrate that for noisy data sets there exists great\nvariation in both the structure of the learned differential equation models as\nwell as the parameter values. We explore how to combine data sets to quantify\nuncertainty in the learned models, and at the same time draw mechanistic\nconclusions about the target differential equations. We generate noisy data\nusing a stochastic agent-based model and combine equation learning methods with\napproximate Bayesian computation (ABC) to show that the correct differential\nequation model can be successfully learned from data, while a quantification of\nuncertainty is given by a posterior distribution in parameter space."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The tipping effect of delayed interventions on the evolution of COVID-19\n  incidence"}, {"role": "assistant", "content": "We combine infectious disease transmission and the non-pharmaceutical\nintervention (NPI) response to disease incidence into one closed model\nconsisting of two coupled delay differential equations for the incidence rate\nand the time-dependent reproduction number. The model contains three free\nparameters, the initial reproduction number, the intervention strength, and the\nresponse delay relative to the time of infection. The NPI response is modeled\nby assuming that the rate of change of the reproduction number is proportional\nto the negative deviation of the incidence rate from an intervention threshold.\nThis delay dynamical system exhibits damped oscillations in one part of the\nparameter space, and growing oscillations in another, and these are separated\nby a surface where the solution is a strictly periodic nonlinear oscillation.\nFor parameters relevant for the COVID-19 pandemic, the tipping transition from\ndamped to growing oscillations occurs for response delays of the order of one\nweek, and suggests that effective control and mitigation of successive epidemic\nwaves cannot be achieved unless NPIs are implemented in a precautionary manner,\nrather than merely as a response to the present incidence rate."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Verification of an agent-based disease model of human mycobacterium\n  tuberculosis infection"}, {"role": "assistant", "content": "Agent-Based Models are a powerful class of computational models widely used\nto simulate complex phenomena in many different application areas. However, one\nof the most critical aspects, poorly investigated in the literature, regards an\nimportant step of the model credibility assessment: solution verification. This\nstudy overcomes this limitation by proposing a general verification framework\nfor Agent-Based Models that aims at evaluating the numerical errors associated\nwith the model. A step-by-step procedure, which consists of two main\nverification studies (deterministic and stochastic model verification), is\ndescribed in detail and applied to a specific mission critical scenario: the\nquantification of the numerical approximation error for UISS-TB, an ABM of the\nhuman immune system developed to predict the progression of pulmonary\ntuberculosis. Results provide indications on the possibility to use the\nproposed model verification workflow to systematically identify and quantify\nnumerical approximation errors associated with UISS-TB and, in general, with\nany other ABMs."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Absolute quantification of real-time PCR data with stage signal\n  difference analysis"}, {"role": "assistant", "content": "Real-time PCR, or Real-time Quantitative PCR (qPCR) is an effective approach\nto quantify nucleic acid samples. Given the complicated reaction system along\nwith thermal cycles, there has been long-term confusion on accurately\ncalculating the initial nucleic acid amounts from the fluorescence signals.\nAlthough many improved algorithms had been proposed, the classical threshold\nmethod is still the primary choice in the routine application. In this study,\nwe will first illustrate the origin of the linear relationship between the\nthreshold value and logarithm of the initial nucleic acid amount by\nreconstructing the PCR reaction process with stochastic simulations. We then\ndevelop a new method for the absolute quantification of nucleic acid samples\nwith qPCR. By monitoring the fluorescence signal changes in every stage of the\nthermal cycle, we are able to calculate a representation of the step-wise\nefficiency change. This is the first work calculated PCR efficiency change\ndirectly from the fluorescence signal, without fitting or sophisticated\nanalysis. Our results revealed that the efficiency change during the PCR\nprocess is complicated and can not be modeled simply by monotone function\nmodel. Based on the calculated efficiency, we illustrate a new absolute qPCR\nanalysis method for accurately determining nucleic acid amount. The efficiency\nproblem is completely avoided in this new method."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Betti Curves of Rank One Symmetric Matrices"}, {"role": "assistant", "content": "Betti curves of symmetric matrices were introduced in (Giusti et. al., 2015)\nas a new class of matrix invariants that depend only on the relative ordering\nof matrix entries. These invariants are computed using persistent homology, and\ncan be used to detect underlying structure in biological data that may\notherwise be obscured by monotone nonlinearities. Here we prove three theorems\nthat fully characterize the Betti curves of rank 1 symmetric matrices. We then\nillustrate how these Betti curve signatures arise in natural data obtained from\ncalcium imaging of neural activity in zebrafish."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Beat-to-Beat Fetal Heart Rate Analysis Using Portable Medical Device and\n  Wavelet Transformation Technique"}, {"role": "assistant", "content": "A beat-to-beat Tele-fetal Monitoring and comparison with clinical data are\nstudied with a wavelet transformation approach. Tele-fetal monitoring is a big\nprogress toward a wearable medical device for a pregnant woman capable of\nobtaining prenatal care at home. We apply a wavelet transformation algorithm\nfor fetal cardiac monitoring using a portable fetal Doppler medical device.\nChoosing an appropriate mother wavelet, 85 different mother wavelets are\ninvestigated. The efficiency of the proposed method is evaluated using two data\nsets including public and clinical. From publicly available data on PhysioBank,\nand simultaneous clinical measurement, we prove that the comparison between\nobtained fetal heart rate by the algorithm and the baselines yields a promising\naccuracy beyond 95%. Finally, we conclude that the proposed algorithm would be\na robust technique for any similar tele-fetal monitoring approach."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Identification and Development of Therapeutics for COVID-19"}, {"role": "assistant", "content": "After emerging in China in late 2019, the novel Severe acute respiratory\nsyndrome-like coronavirus 2 (SARS-CoV-2) spread worldwide and as of early 2021,\ncontinues to significantly impact most countries. Only a small number of\ncoronaviruses are known to infect humans, and only two are associated with the\nsevere outcomes associated with SARS-CoV-2: Severe acute respiratory\nsyndrome-related coronavirus, a closely related species of SARS-CoV-2 that\nemerged in 2002, and Middle East respiratory syndrome-related coronavirus,\nwhich emerged in 2012. Both of these previous epidemics were controlled fairly\nrapidly through public health measures, and no vaccines or robust therapeutic\ninterventions were identified. However, previous insights into the immune\nresponse to coronaviruses gained during the outbreaks of severe acute\nrespiratory syndrome (SARS) and Middle East respiratory syndrome (MERS) have\nproved beneficial to identifying approaches to the treatment and prophylaxis of\nnovel coronavirus disease 2019 (COVID-19). A number of potential therapeutics\nagainst SARS-CoV-2 and the resultant COVID-19 illness were rapidly identified,\nleading to a large number of clinical trials investigating a variety of\npossible therapeutic approaches being initiated early on in the pandemic. As a\nresult, a small number of therapeutics have already been authorized by\nregulatory agencies such as the Food and Drug Administration (FDA) in the\nUnited States, and many other therapeutics remain under investigation. Here, we\ndescribe a range of approaches for the treatment of COVID-19, along with their\nproposed mechanisms of action and the current status of clinical investigation\ninto each candidate. The status of these investigations will continue to\nevolve, and this review will be updated as progress is made."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Amino acid frequency and domain features serve well for random forest\n  based classification of thermophilic and mesophilic protein; a case study on\n  serine proteases"}, {"role": "assistant", "content": "Thermostability is an important prerequisite for enzymes employed for\nindustrial applications. Several machine learning based models have thus been\nformulated for protein classification based on this particular trait. These\nmodels have employed features derived from sequences, structures or both\nresulting in a >93% accuracy based on a 10-fold cross-validation. Besides using\nvarious proteins from a wide range of organisms, such studies also rely on\nhundreds of features. In the present study, an enzyme specific classification\nmodel was created using significantly less number of features that provides a\nsimilar accuracy of classification for thermophilic and non-thermophilic enzyme\nserine proteases. For building the classifier, 219 thermophilic and 200\nmesophilic bacterial genomes were mined for their respective serine protease\nsequences. Features were extracted for 800 sequences followed by feature\nselection. We deployed a random forest based classifier that identified\nthermophilic and non-thermophilic serine proteases with an accuracy of 95.71%.\nKnowledge of thermostability along with amino acid positional shifts can be\nvital for downstream protein engineering techniques. Thus, to emphasize the\nreal time application of the enzyme specific classification model, a web\nplatform has been designed. Combining the sequence data and the classification\nmodel, this prototype can allow users to align their query serine protease\nsequence against the custom database and identify its thermophilic nature."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantitative predictions of neoadjuvant chemotherapy effects in breast\n  cancer by individual patient data assimililation"}, {"role": "assistant", "content": "Neoadjuvant chemotherapy has been used for breast cancer aiming at\ndowngrading before surgery. In this article we propose a new quantitative\nanalysis of the effects of the neoadjuvant therapy to obtain numerical,\npersonalized, predictions on the shrinkage of the tumor size after the drug\ndoses, by data assimilation of the individual patient. The algorithm has been\nvalidated by a sample of 37 patients with histological diagnosis of locally\nadvanced primary breast carcinoma. The biopsy specimen, the initial tumor size\nand its reduction after each treatment were known for all patients. We find\nthat: a) the measure of tumor size at the diagnosis and after the first dose\npermits to predict the size reduction for the follow up; b) the results are in\nagreement with our data sample, within 10-20 %, for about 90% of the patients.\nThe quantitative indications suggest the best time for surgery. The analysis is\npatient oriented, weakly model dependent and can be applied to other cancer\nphenotypes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Sleep quality, chronotype and social jet lag of adolescents from a\n  population with a very late chronotype"}, {"role": "assistant", "content": "Sleep disorders can be a negative factor both for learning as for the mental\nand physical development of adolescents. It has been shown that, in many\npopulations, adolescents tend to have a poor sleep quality, and a very late\nchronotype. Furthermore, these features peak at adolescence, in the sense that\nadults tend to sleep better and have an earlier chronotype. But what happens\nwhen we consider adolescents in a population where already adults have poor\nsleep quality and a very late chronotype? We have conducted two non-clinical\nstudies in the city of Bariloche, Argentina aimed at measuring sleep quality,\nchronotype, and social jet lag, using the Pittsburgh and Munich questionnaires.\nThese were administered individually to groups of high school students, as well\nas to smaller samples of adults and preadolescents, in order to study\ndifferences between adolescents and these groups. The results show that in this\npopulation sleep quality is much poorer than in most other healthy populations\nrecorded elsewhere. Furthermore, sleep quality is consistently worse for\nadolescents than for the other groups. The difference with adults seems to be\ndue mainly to increased daytime sleepiness and sleep latency, whereas the\ndifference with preadolescents seems to be due mainly to shorter sleep\nduration. We also found that the chronotypes of all the groups are very late,\nwith a peak at an age between 18 and 24 ys. Social jet lag and sleep onset\nlatency are also large, and they peak at adolescence, which suggests that they\nmight be closely related to the large prevalence of poor sleep quality that we\nfind in adolescents."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Development and evaluation of copper-containing mesoporous bioactive\n  glasses for bone defects therapy"}, {"role": "assistant", "content": "Mesoporous bioactive glasses, MBG, are gaining increasing interest in the\ndesign of new biomaterials for bone defects treatment. An important research\ntrend to enhance their biological behavior is the inclusion of moderate amounts\nof oxides with therapeutical action such as CuO. In this paper, MBG with\ncomposition were synthesized, investigating the influence of the CuO content\nand some synthesis parameters in their properties. Two batch were developed;\nfirst one using HCl as catalyst and chlorides as CaO and CuO precursors, second\none, using HNO3 and nitrates. MBG of chlorides batch exhibited calcium/copper\nphosphate nanoparticles, between 10 and 20 nm. Nevertheless, CuO- containing\nMBG of nitrates batch showed nuclei of metallic copper nanoparticles larger\nthan 50 nm and quicker in vitro bioactive responses. Thus, they were coated by\nan apatite-like layer after 24 h soaked in simulated body fluid, a remarkably\nshort period for MBG containing up to 5 % of CuO. A model, focused in the\ncopper location in the glass network, was proposed to relate nanostructure and\nin vitro behaviour. Moreover, after 24 h in MEM or THB culture media, all the\nMBG released therapeutic amounts of Ca2+ and Cu2+ ions. Because the quick\nbioactive response in SBF, the capacity to host biomolecules in their pores and\nto release therapeutic concentrations of Ca2+ and Cu2+ ions, MBG of the nitrate\nbatch are considered as excellent biomaterials for bone regeneration."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: OnionNet-2: A Convolutional Neural Network Model for Predicting\n  Protein-Ligand Binding Affinity based on Residue-Atom Contacting Shells"}, {"role": "assistant", "content": "One key task in virtual screening is to accurately predict the binding\naffinity ($\\triangle$$G$) of protein-ligand complexes. Recently, deep learning\n(DL) has significantly increased the predicting accuracy of scoring functions\ndue to the extraordinary ability of DL to extract useful features from raw\ndata. Nevertheless, more efforts still need to be paid in many aspects, for the\naim of increasing prediction accuracy and decreasing computational cost. In\nthis study, we proposed a simple scoring function (called OnionNet-2) based on\nconvolutional neural network to predict $\\triangle$$G$. The protein-ligand\ninteractions are characterized by the number of contacts between protein\nresidues and ligand atoms in multiple distance shells. Compared to published\nmodels, the efficacy of OnionNet-2 is demonstrated to be the best for two\nwidely used datasets CASF-2016 and CASF-2013 benchmarks. The OnionNet-2 model\nwas further verified by non-experimental decoy structures from docking program\nand the CSAR NRC-HiQ data set (a high-quality data set provided by CSAR), which\nshowed great success. Thus, our study provides a simple but efficient scoring\nfunction for predicting protein-ligand binding free energy."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multifunctional antibiotic- and zinc-containing mesoporous bioactive\n  glass scaffolds to fight bone infection"}, {"role": "assistant", "content": "Bone regeneration is a clinical challenge that requires multiple approaches.\nSometimes, it also includes the development of new osteogenic and antibacterial\nbiomaterials to treat the occurrence of possible infection processes derived\nfrom surgery. This study evaluates the antibacterial properties of\nmeso-macroporous scaffolds coated with gelatin and based on a bioactive glass\nand after being doped with 4% ZnO (4ZN-GE) and loaded with saturated and\nminimally inhibitory concentrations of one of the antibiotics levofloxacin\n(LEVO), vancomycin (VANCO), rifampicin (RIFAM) or gentamicin (GENTA). After the\nphysicochemical characterization of the materials, inorganic ion and antibiotic\nrelease studies were performed from the scaffolds. In addition, molecular\nmodeling allowed the determination of electrostatic potential density maps and\nhydrogen bonds of the antibiotics and the glass matrix. In vitro antibacterial\nstudies (in plankton, inhibition halos and biofilm destruction) with S. aureus\nand E. coli as model bacteria showed a synergistic effect of zinc ions and\nantibiotics. The effect was especially noticeable in planktonic cultures of S.\naureus with 4ZN-GE scaffolds loaded with VANCO, LEVO or RIFAM and in cultures\nof E. coli with LEVO or GENTA. Furthermore, S. aureus biofilms were completely\ndestroyed by 4ZN-GE scaffolds loaded with VANCO, LEVO or RIFAM and total\ndestruction of E. coli biofilm was achieved with 4ZN-GE scaffolds loaded with\nGENTA or LEVO. This approach could be an important step in the fight against\nmicrobial resistance and provide much needed options for the treatment of bone\ninfection."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Putting the dynamic pathosome in practice: a novel way of analyzing\n  longitudinal data"}, {"role": "assistant", "content": "Previously we have developed the concept of the dynamic pathosome, which\nsuggests that individual patterns of phenotype development, i.e., phenotypic\ntrajectories, contain more information than is commonly appreciated and that a\nphenotype's past trajectory predicts its future development. In this article,\nwe present a pathosome-inspired approach to analyzing longitudinal data by\nfunctional linear models. We demonstrate how to use this approach and compare\nit with classical linear models on data from the Czech section of the European\nLongitudinal Study of Pregnancy and Childhood (ELSPAC). Our results show that\nfunctional linear models explain more observed variance in age at menarche from\nheight and weight data than the commonly used approaches. Furthermore, we\ndemonstrate that functional linear models can be used to identify crucial time\npoints that can be used to create linear models achieving almost the same\nperformance as functional linear models. In addition, we use data from the\nBerkeley growth study (BGS) to demonstrate that growth trajectories from birth\nto 15 years can be used to explain 97% of observed variance of height at 18\nyears, thus supporting the notion that a phenotype's past trajectory affects\nits future course. Overall, this article presents experimental support for the\nconcept of the dynamic pathosome and presents a method that can be used as a\npowerful tool for analyzing quantitative longitudinal data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Inferring, comparing and exploring ecological networks from time-series\n  data through R packages constructnet, disgraph and dynet"}, {"role": "assistant", "content": "Network inference is a major field of interest for the ecological community,\nespecially in light of the high cost and difficulty of manual observation, and\neasy availability of remote, long term monitoring data. In addition, comparing\nacross similar network structures, especially with spatial, environmental, or\ntemporal variability and, simulating processes on networks to create toy models\nand hypotheses - are topics of considerable interest to the researchers. A\nlarge number of methods are being developed in the network science community to\nachieve these objectives but either don't have their code available or an\nimplementation in R, the language preferred by ecologists and other biologists.\nWe provide a suite of three packages which will provide a central suite of\nstandardized network inference methods from time-series data (constructnet),\ndistance metrics (disgraph) and (process) simulation models (dynet) to the\ngrowing R network analysis environment and would help ecologists and biologists\nto perform and compare methods under one roof. These packages are implemented\nin a coherent, consistent framework - making comparisons across methods and\nmetrics easier. We hope that these tools in R will help increase the\naccessibility of network tools to ecologists and other biologists, who the\nlanguage for most of their analysis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Neural Representations of Cryo-EM Maps and a Graph-Based Interpretation"}, {"role": "assistant", "content": "Advances in imagery at atomic and near-atomic resolution, such as cryogenic\nelectron microscopy (cryo-EM), have led to an influx of high resolution images\nof proteins and other macromolecular structures to data banks worldwide.\nProducing a protein structure from the discrete voxel grid data of cryo-EM maps\ninvolves interpolation into the continuous spatial domain. We present a novel\ndata format called the neural cryo-EM map, which is formed from a set of neural\nnetworks that accurately parameterize cryo-EM maps and provide native,\nspatially continuous data for density and gradient. As a case study of this\ndata format, we create graph-based interpretations of high resolution\nexperimental cryo-EM maps. Normalized cryo-EM map values interpolated using the\nnon-linear neural cryo-EM format are more accurate, consistently scoring less\nthan 0.01 mean absolute error, than a conventional tri-linear interpolation,\nwhich scores up to 0.12 mean absolute error. Our graph-based interpretations of\n115 experimental cryo-EM maps from 1.15 to 4.0 Angstrom resolution provide high\ncoverage of the underlying amino acid residue locations, while accuracy of\nnodes is correlated with resolution. The nodes of graphs created from atomic\nresolution maps (higher than 1.6 Angstroms) provide greater than 99% residue\ncoverage as well as 85% full atomic coverage with a mean of than 0.19 Angstrom\nroot mean squared deviation (RMSD). Other graphs have a mean 84% residue\ncoverage with less specificity of the nodes due to experimental noise and\ndifferences of density context at lower resolutions. This work may be\ngeneralized for transforming any 3D grid-based data format into non-linear,\ncontinuous, and differentiable format for the downstream geometric deep\nlearning applications."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Finding Nano-\\\"Otzi: Semi-Supervised Volume Visualization for\n  Cryo-Electron Tomography"}, {"role": "assistant", "content": "Cryo-Electron Tomography (cryo-ET) is a new 3D imaging technique with\nunprecedented potential for resolving submicron structural detail. Existing\nvolume visualization methods, however, cannot cope with its very low\nsignal-to-noise ratio. In order to design more powerful transfer functions, we\npropose to leverage soft segmentation as an explicit component of visualization\nfor noisy volumes. Our technical realization is based on semi-supervised\nlearning where we combine the advantages of two segmentation algorithms. A\nfirst weak segmentation algorithm provides good results for propagating sparse\nuser provided labels to other voxels in the same volume. This weak segmentation\nalgorithm is used to generate dense pseudo labels. A second powerful\ndeep-learning based segmentation algorithm can learn from these pseudo labels\nto generalize the segmentation to other unseen volumes, a task that the weak\nsegmentation algorithm fails at completely. The proposed volume visualization\nuses the deep-learning based segmentation as a component for segmentation-aware\ntransfer function design. Appropriate ramp parameters can be suggested\nautomatically through histogram analysis. Finally, our visualization uses\ngradient-free ambient occlusion shading to further suppress visual presence of\nnoise, and to give structural detail desired prominence. The cryo-ET data\nstudied throughout our technical experiments is based on the highest-quality\ntilted series of intact SARS-CoV-2 virions. Our technique shows the high impact\nin target sciences for visual data analysis of very noisy volumes that cannot\nbe visualized with existing techniques."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Mesoporous silica nanoparticles containing silver as novel\n  antimycobacterial agents against Mycobacterium tuberculosis"}, {"role": "assistant", "content": "Tuberculosis remains today a major public health issue with a total of 9\nmillion new cases and 2 million deaths annually. The lack of an effective\nvaccine and the increasing emergence of new strains of Mycobacterium\ntuberculosis (Mtb) highly resistant to antibiotics, anticipate a complicated\nscenario in the near future. The use of nanoparticles features as an\nalternative to antibiotics in tackling this problem due to their potential\neffectiveness in resistant bacterial strains. In this context, silver\nnanoparticles have demonstrated high bactericidal efficacy, although their use\nis limited by their relatively high toxicity, which calls for the design of\nnanocarriers that allow silver based nanoparticles to be safely delivered to\nthe target cells or tissues. In this work mesoporous silica nanoparticles are\nused as carriers of silver based nanoparticles as antimycobacterial agent\nagainst Mtb. Two different synthetic approaches have been used to afford, on\nthe one hand, a 2D hexagonal mesoporous silica nanosystem which contains silver\nbromide nanoparticles distributed all through the silica network and, on the\nother hand, a core@shell nanosystem with metallic silver nanoparticles as core\nand mesoporous silica shell in a radial mesoporous rearrangement. Both\nmaterials have demonstrated good antimycobacterial capacity in in vitro test\nusing Mtb, being lower the minimum inhibitory concentration for the nanosystem\nwhich contains silver bromide. Therefore, the interaction of this material with\nthe mycobacterial cell has been studied by cryo-electron microscopy,\nestablishing a direct connection between the antimycobactericidal effect\nobserved and the damage induced in the cell envelope."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Utilizing a Mathematical Model to Estimate Abortion Decline Scenario"}, {"role": "assistant", "content": "Abortion is one of the biggest causes of maternal deaths, accounting for 15%\nof maternal deaths in Southeast Asia. The increase in and effectiveness of\nusing contraception are still considered to be the effective method to reduce\nabortion rate. Data pertaining to abortion incidence and effective efforts to\nreduce abortion rate in Indonesia is limited and difficult to access. Meanwhile\nsuch supporting information is necessary to enable the planning and evaluation\nof abortion control programs. This paper exemplifies the use of a mathematical\nmodel to explain an abortion decline scenario. The model employs determinants\nproposed by Bongaarts, which include average reproductive period, contraceptive\nprevalence and effectiveness, total fertility rate (TFR), and intended total\nfertility rate (ITFR), as well as birth and abortion intervals. The data used\nis from the 1991-2007 Indonesian Demography and Health Survey (Survei Demografi\ndan Kesehatan Indonesia/SDKI), and the unit of analysis is women who had been\nmarried and aged 15-49 years old. Based on the current contraceptive prevalence\nlevel in Indonesia at 59-61%, the estimated total abortion rate is 1.9-2.2.\nBased on the plot of this total abortion rate, an abortion decline scenario can\nbe estimated. At the current TFR level of 2.6, the required contraceptive\nprevalence is 69% (9% increase) for a decrease of one abortion case per woman.\nWith a delay of one year in the age of the first marriage and a birth interval\nof three years, it is estimated that the abortion rate will decline from 3.05\nto 0.69 case per woman throughout her reproductive period. Based on the\nassumption of contraceptive prevalence growth at 1-1.4%, it can be estimated\nthat abortion rate will reach nearly 0 between 2018 and 2022."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Machine Learning Model for Nowcasting Epidemic Incidence"}, {"role": "assistant", "content": "Due to delay in reporting, the daily national and statewide COVID-19\nincidence counts are often unreliable and need to be estimated from recent\ndata. This process is known in economics as nowcasting. We describe in this\npaper a simple random forest statistical model for nowcasting the COVID - 19\ndaily new infection counts based on historic data along with a set of simple\ncovariates, such as the currently reported infection counts, day of the week,\nand time since first reporting. We apply the model to adjust the daily\ninfection counts in Ohio, and show that the predictions from this simple\ndata-driven method compare favorably both in quality and computational burden\nto those obtained from the state-of-the-art hierarchical Bayesian model\nemploying a complex statistical algorithm."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Conductance-based Dynamic Causal Modeling: A mathematical review of its\n  application to cross-power spectral densities"}, {"role": "assistant", "content": "Dynamic Causal Modeling (DCM) is a Bayesian framework for inferring on hidden\n(latent) neuronal states, based on measurements of brain activity. Since its\nintroduction in 2003 for functional magnetic resonance imaging data, DCM has\nbeen extended to electrophysiological data, and several variants have been\ndeveloped. Their biophysically motivated formulations make these models\npromising candidates for providing a mechanistic understanding of human brain\ndynamics, both in health and disease. However, due to their complexity and\nreliance on concepts from several fields, fully understanding the mathematical\nand conceptual basis behind certain variants of DCM can be challenging. At the\nsame time, a solid theoretical knowledge of the models is crucial to avoid\npitfalls in the application of these models and interpretation of their\nresults. In this paper, we focus on one of the most advanced formulations of\nDCM, i.e. conductance-based DCM for cross-spectral densities, whose components\nare described across multiple technical papers. The aim of the present article\nis to provide an accessible exposition of the mathematical background, together\nwith an illustration of the model's behavior. To this end, we include\nstep-by-step derivations of the model equations, point to important aspects in\nthe software implementation of those models, and use simulations to provide an\nintuitive understanding of the type of responses that can be generated and the\nrole that specific parameters play in the model. Furthermore, all code utilized\nfor our simulations is made publicly available alongside the manuscript to\nallow readers an easy hands-on experience with conductance-based DCM."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Light-weight sleep monitoring: electrode distance matters more than\n  placement for automatic scoring"}, {"role": "assistant", "content": "Modern sleep monitoring development is shifting towards the use of\nunobtrusive sensors combined with algorithms for automatic sleep scoring. Many\ndifferent combinations of wet and dry electrodes, ear-centered,\nforehead-mounted or headband-inspired designs have been proposed, alongside an\never growing variety of machine learning algorithms for automatic sleep\nscoring. In this paper, we compare 13 different, realistic sensor setups\nderived from the same data set and analysed with the same pipeline. We find\nthat all setups which include both a lateral and an EOG derivation show\nsimilar, state-of-the-art performance, with average Cohen's kappa values of at\nleast 0.80. This indicates that electrode distance, rather than position, is\nimportant for accurate sleep scoring. Finally, based on the results presented,\nwe argue that with the current competitive performance of automated staging\napproaches, there is an urgent need for establishing an improved benchmark\nbeyond current single human rater scoring."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Tree species, crown cover, and age as determinants of the vertical\n  distribution of airborne LiDAR returns"}, {"role": "assistant", "content": "Light detection and ranging (LiDAR) provides information on the vertical\nstructure of forest stands enabling detailed and extensive ecosystem study. The\nvertical structure is often summarized by scalar features and data-reduction\ntechniques that limit the interpretation of results. Instead, we quantified the\ninfluence of three variables, species, crown cover, and age, on the vertical\ndistribution of airborne LiDAR returns from forest stands. We studied 5,428\nregular, even-aged stands in Quebec (Canada) with five dominant species: balsam\nfir (Abies balsamea (L.) Mill.), paper birch (Betula papyrifera Marsh), black\nspruce (Picea mariana (Mill.) BSP), white spruce (Picea glauca Moench) and\naspen (Populus tremuloides Michx.). We modeled the vertical distribution\nagainst the three variables using a functional general linear model and a novel\nnonparametric graphical test of significance. Results indicate that LiDAR\nreturns from aspen stands had the most uniform vertical distribution. Balsam\nfir and white birch distributions were similar and centered at around 50% of\nthe stand height, and black spruce and white spruce distributions were skewed\nto below 30% of stand height (p<0.001). Increased crown cover concentrated the\ndistributions around 50% of stand height. Increasing age gradually shifted the\ndistributions higher in the stand for stands younger than 70-years, before\nplateauing and slowly declining at 90-120 years. Results suggest that the\nvertical distributions of LiDAR returns depend on the three variables studied."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Optimization of Sequential Microwave-Ultrasound-Assisted Extraction for\n  Maximum Recovery of Quercetin and Total Flavonoids from Red Onion (Allium\n  cepa L.) Skin Wastes"}, {"role": "assistant", "content": "This study aimed to optimize the extraction conditions in order to maximize\nthe recovery yields of quercetin and total flavonoids from red onion skin\nwastes using sequential microwave-ultrasound-assisted extraction. Five\neffective factors on quercetin extraction yield were investigated using\nresponse surface methodology. The method was successfully performed under\noptimal conditions of 60 s microwave irradiation followed by 15 min sonication\nat 70 {\\deg}C, 70% ethanol with solvent to solid ratio of 30 mL/g. Based on the\noptimization results, ultrasound temperature was found to be a highly\nsignificant and influential factor for the recovery. The maximum recovery\nyields of quercetin and total flavonoids from red onion skin were estimated to\nbe 10.32 and 12.52%, respectively. The predicted values for quercetin (10.05%)\nand total flavonoids (12.72%) were very close to the experimental results. The\nrecovery yields obtained from different extraction methods were as follows:\nultrasound-microwave-assisted extraction (7.66% quercetin and 10.18% total\nflavonoids), ultrasound-assisted extraction (5.36% quercetin and 8.34% total\nflavonoids), and microwave-assisted extraction (5.03% quercetin and 7.91 %\ntotal flavonoids). The validity of the projected model was examined by the\nobtained experimental data; in which, the validated model was suitable for the\nrecovery of the valuable products from onion skin wastes for further scale-up\nin the food processes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Mixed-horizon optimal feedback control as a model of human movement"}, {"role": "assistant", "content": "Computational optimal feedback control (OFC) models in the sensorimotor\ncontrol literature span a vast range of different implementations. Among the\npopular algorithms, finite-horizon, receding-horizon or infinite-horizon\nlinear-quadratic regulators (LQR) have been broadly used to model human\nreaching movements. While these different implementations have their unique\nmerits, all three have limitations in simulating the temporal evolution of\nvisuomotor feedback responses. Here we propose a novel approach - a\nmixed-horizon OFC - by combining the strengths of the traditional\nfinite-horizon and the infinite-horizon controllers to address their individual\nlimitations. Specifically, we use the infinite-horizon OFC to generate\ndurations of the movements, which are then fed into the finite-horizon\ncontroller to generate control gains. We then demonstrate the stability of our\nmodel by performing extensive sensitivity analysis of both re-optimisation and\ndifferent cost functions. Finally, we use our model to provide a fresh look to\npreviously published studies by reinforcing the previous results, providing\nalternative explanations to previous studies, or generating new predictive\nresults for prior experiments."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Classifying herbal medicine origins by temporal and spectral data mining\n  of electronic nose"}, {"role": "assistant", "content": "The origins of herbal medicines are important for their treatment effect,\nwhich could be potentially distinguished by electronic nose system. As the odor\nfingerprint of herbal medicines from different origins can be tiny, the\ndiscrimination of origins can be much harder than that of different categories.\nBetter feature extraction methods are significant for this task to be more\naccurately done, but there lacks systematic studies on different feature\nextraction methods. In this study, we classified different origins of three\ncategories of herbal medicines with different feature extraction methods:\nmanual feature extraction, mathematical transformation, deep learning\nalgorithms. With 50 repetitive experiments with bootstrapping, we compared the\neffectiveness of the extractions with a two-layer neural network w/o\ndimensionality reduction methods (principal component analysis, linear\ndiscriminant analysis) as the three base classifiers. Compared with the\nconventional aggregated features, the Fast Fourier Transform method and our\nnovel approach (longitudinal-information-in-a-line) showed an significant\naccuracy improvement(p < 0.05) on all 3 base classifiers and all three herbal\nmedicine categories. Two of the deep learning algorithm we applied also showed\npartially significant improvement: one-dimensional convolution neural\nnetwork(1D-CNN) and a novel graph pooling based framework - multivariate time\npooling(MTPool)."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Prospector: a mobile app for high-throughput NIRS phenotyping"}, {"role": "assistant", "content": "Quality traits are some of the most important and time-consuming phenotypes\nto evaluate in plant breeding programs. These traits are often evaluated late\nin the breeding pipeline due to their cost, resulting in the potential\nadvancement of many lines that are not suitable for release. Near-infrared\nspectroscopy (NIRS) is a non-destructive tool that can rapidly increase the\nspeed at which quality traits are evaluated. However, most spectrometers are\nnon-portable or prohibitively expensive. Recent advancements have led to the\ndevelopment of consumer-targeted, inexpensive spectrometers with demonstrated\npotential for breeding applications. Unfortunately, the mobile applications for\nthese spectrometers are not designed to rapidly collect organized samples at\nthe scale necessary for breeding programs. To that end, we developed\nProspector, a mobile application that connects with LinkSquare portable NIR\nspectrometers and allows breeders to efficiently capture NIR data. In this\nreport, we outline the core functionality of the app and how it can easily be\nintegrated into breeding workflows as well as the opportunities for further\ndevelopment. Prospector and other high throughput phenotyping tools and\ntechnologies are required for plant breeders to develop the next generation of\nimproved varieties necessary to feed a growing global population."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A cross-study analysis of drug response prediction in cancer cell lines"}, {"role": "assistant", "content": "To enable personalized cancer treatment, machine learning models have been\ndeveloped to predict drug response as a function of tumor and drug features.\nHowever, most algorithm development efforts have relied on cross validation\nwithin a single study to assess model accuracy. While an essential first step,\ncross validation within a biological data set typically provides an overly\noptimistic estimate of the prediction performance on independent test sets. To\nprovide a more rigorous assessment of model generalizability between different\nstudies, we use machine learning to analyze five publicly available cell\nline-based data sets: NCI60, CTRP, GDSC, CCLE and gCSI. Based on observed\nexperimental variability across studies, we explore estimates of prediction\nupper bounds. We report performance results of a variety of machine learning\nmodels, with a multitasking deep neural network achieving the best cross-study\ngeneralizability. By multiple measures, models trained on CTRP yield the most\naccurate predictions on the remaining testing data, and gCSI is the most\npredictable among the cell line data sets included in this study. With these\nexperiments and further simulations on partial data, two lessons emerge: (1)\ndifferences in viability assays can limit model generalizability across\nstudies, and (2) drug diversity, more than tumor diversity, is crucial for\nraising model generalizability in preclinical screening."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantitative mapping of the brain's structural connectivity using\n  diffusion MRI tractography: a review"}, {"role": "assistant", "content": "Diffusion magnetic resonance imaging (dMRI) tractography is an advanced\nimaging technique that enables in vivo mapping of the brain's white matter\nconnections at macro scale. Over the last two decades, the study of brain\nconnectivity using dMRI tractography has played a prominent role in the\nneuroimaging research landscape. In this paper, we provide a high-level\noverview of how tractography is used to enable quantitative analysis of the\nbrain's structural connectivity in health and disease. We first provide a\nreview of methodology involved in three main processing steps that are common\nacross most approaches for quantitative analysis of tractography, including\nmethods for tractography correction, segmentation and quantification. For each\nstep, we aim to describe methodological choices, their popularity, and\npotential pros and cons. We then review studies that have used quantitative\ntractography approaches to study the brain's white matter, focusing on\napplications in neurodevelopment, aging, neurological disorders, mental\ndisorders, and neurosurgery. We conclude that, while there have been\nconsiderable advancements in methodological technologies and breadth of\napplications, there nevertheless remains no consensus about the \"best\"\nmethodology in quantitative analysis of tractography, and researchers should\nremain cautious when interpreting results in research and clinical\napplications."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A scalable solver for a stochastic, hybrid cellular automaton model of\n  personalized breast cancer therapy"}, {"role": "assistant", "content": "Mathematical modeling and simulation is a promising approach to personalized\ncancer medicine. Yet, the complexity, heterogeneity and multi-scale nature of\ncancer pose significant computational challenges. Coupling discrete cell-based\nmodels with continuous models using hybrid cellular automata is a powerful\napproach for mimicking biological complexity and describing the dynamical\nexchange of information across different scales. However, when clinically\nrelevant cancer portions are taken into account, such models become\ncomputationally very expensive. While efficient parallelization techniques for\ncontinuous models exist, their coupling with discrete models, particularly\ncellular automata, necessitates more elaborate solutions. Building upon FEniCS,\na popular and powerful scientific computing platform for solving partial\ndifferential equations, we developed parallel algorithms to link stochastic\ncellular automata with differential equations (\nhttps://bitbucket.org/HTasken/cansim ). The algorithms minimize the\ncommunication between processes that share cellular automata neighborhood\nvalues while also allowing for reproducibility during stochastic updates. We\ndemonstrated the potential of our solution on a complex hybrid cellular\nautomaton model of breast cancer treated with combination chemotherapy. On a\nsingle-core processor, we obtained nearly linear scaling with an increasing\nproblem size, whereas weak parallel scaling showed moderate growth in solving\ntime relative to increase in problem size. Finally we applied the algorithm to\na problem that is 500 times larger than previous work, allowing us to run\npersonalized therapy simulations based on heterogeneous cell density and tumor\nperfusion conditions estimated from magnetic resonance imaging data on an\nunprecedented scale."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Rough Set Microbiome Characterisation"}, {"role": "assistant", "content": "Microbiota profiles measure the structure of microbial communities in a\ndefined environment (known as microbiomes). In the past decade, microbiome\nresearch has focused on health applications as a result of which the gut\nmicrobiome has been implicated in the development of a broad range of diseases\nsuch as obesity, inflammatory bowel disease, and major depressive disorder. A\nkey goal of many microbiome experiments is to characterise or describe the\nmicrobial community. High-throughput sequencing is used to generate microbiota\nprofiles, but data gathered via this method are extremely challenging to\nanalyse, as the data violate multiple strong assumptions of standard models.\nRough Set Theory (RST) has weak assumptions that are less likely to be\nviolated, and offers a range of attractive tools for extracting knowledge from\ncomplex data. In this paper we present the first application of RST for\ncharacterising microbiomes. We begin with a demonstrative benchmark microbiota\nprofile and extend the approach to gut microbiomes gathered from depressed\nsubjects to enable knowledge discovery. We find that RST is capable of\nexcellent characterisation of the gut microbiomes in depressed subjects and\nidentifying previously undescribed alterations to the microbiome-gut-brain\naxis. An important aspect of the application of RST is that it provides a\npossible solution to an open research question regarding the search for an\noptimal normalisation approach for microbiome census data, as one does not\ncurrently exist."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A modified two-leaf light use efficiency model for improving the\n  simulation of GPP using a radiation scalar"}, {"role": "assistant", "content": "A TL-LUE model modified with a radiation scalar (RTL-LUE) is developed in\nthis paper. The same maximum LUE is used for both sunlit and shaded leaves, and\nthe difference in LUE between sunlit and shaded leaf groups is determined by\nthe same radiation scalar. The RTL-LUE model was calibrated and validated at\nglobal 169 FLUXNET eddy covariance (EC) sites. Results indicate that although\nGPP simulations from the TL-LUE model match well with the EC GPP, the RTL-LUE\nmodel can further improve the simulation, for half-hour, 8-day, and yearly time\nscales. The TL-LUE model tends to overestimate GPP under conditions of high\nincoming photosynthetically active radiation (PAR), because the\nradiation-independent LUE values for both sunlit and shaded leaves are only\nsuitable for low-medium (e.g. average) incoming PAR conditions. The errors in\nthe RTL-LUE model show lower sensitivity to PAR, and its GPP simulations can\nbetter track the diurnal and seasonal variations of EC GPP by alleviating the\noverestimation at noon and growing seasons associated with the TL-LUE model.\nThis study demonstrates the necessity of considering a radiation scalar in GPP\nsimulation in LUE models even if the first-order effect of radiation is already\nconsidered through differentiating sunlit and shaded leaves. The simple RTL-LUE\ndeveloped in this study would be a useful alternative to complex process-based\nmodels for global carbon cycle research."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Dynamical models for metabolomics data integration"}, {"role": "assistant", "content": "As metabolomics datasets are becoming larger and more complex, there is an\nincreasing need for model-based data integration and analysis to optimally\nleverage these data. Dynamical models of metabolism allow for the integration\nof heterogeneous data and the analysis of dynamical phenotypes. Here, we review\nrecent efforts in using dynamical metabolic models for data integration,\nfocusing on approaches that are not restricted to steady-state measurements or\nthat require flux distributions as inputs. Furthermore, we discuss recent\nadvances and current challenges. We conclude that much progress has been made\nin various areas, such as the development of scalable simulation tools, and\nthat, although challenges remain, dynamical modeling is a powerful tool for\nmetabolomics data analysis that is not yet living up to its full potential."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Centralizing data to unlock whole-cell models"}, {"role": "assistant", "content": "Despite substantial potential to transform bioscience, medicine, and\nbioengineering, whole-cell models remain elusive. One of the biggest challenges\nto whole-cell models is assembling the large and diverse array of data needed\nto model an entire cell. Thanks to rapid advances in experimentation, much of\nthe necessary data is becoming available. Furthermore, investigators are\nincreasingly sharing their data due to increased emphasis on reproducibility.\nHowever, the scattered organization of this data continues to hamper modeling.\nToward more predictive models, we highlight the challenges to assembling the\ndata needed for whole-cell modeling and outline how we can overcome these\nchallenges by working together to build a central data warehouse."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A protocol for dynamic model calibration"}, {"role": "assistant", "content": "Ordinary differential equation models are nowadays widely used for the\nmechanistic description of biological processes and their temporal evolution.\nThese models typically have many unknown and non-measurable parameters, which\nhave to be determined by fitting the model to experimental data. In order to\nperform this task, known as parameter estimation or model calibration, the\nmodeller faces challenges such as poor parameter identifiability, lack of\nsufficiently informative experimental data, and the existence of local minima\nin the objective function landscape. These issues tend to worsen with larger\nmodel sizes, increasing the computational complexity and the number of unknown\nparameters. An incorrectly calibrated model is problematic because it may\nresult in inaccurate predictions and misleading conclusions. For non-expert\nusers, there are a large number of potential pitfalls. Here, we provide a\nprotocol that guides the user through all the steps involved in the calibration\nof dynamic models. We illustrate the methodology with two models, and provide\nall the code required to reproduce the results and perform the same analysis on\nnew models. Our protocol provides practitioners and researchers in biological\nmodelling with a one-stop guide that is at the same time compact and\nsufficiently comprehensive to cover all aspects of the problem."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Optimizing the location of vaccination sites to stop a zoonotic epidemic"}, {"role": "assistant", "content": "The mainstay of canine rabies control is fixed point mass dog vaccination\ncampaigns (MDVC). However, in some regions, ideal vaccination coverage in dogs\nis not obtained due to low participation in the MDVC. Travel distance to the\nvaccination sites has been identified as an important barrier to participation.\nWe aim to increase MDVC participation by optimally placing fixed point\nvaccination locations to minimize walking distance to the nearest vaccination\nlocation. We quantified participation probability based on walking distance to\nthe nearest vaccination point using a Poisson regression model. The regression\nwas fit with survey data collected from 2016-2019. We then used a computational\nrecursive interchange technique to solve the facility location problem to find\na set of optimal placements of fixed point vaccination locations. Finally, we\ncompared predicted participation of optimally placed vaccination sites to\nhistorical participation data from surveys collected from 2016-2019. We\nidentified the p-median algorithm to solve the facility location problem as\nideal for fixed point vaccination placement. We found a predicted increase in\nMDVC participation if vaccination locations are placed optimally. We also found\na more even vaccination coverage with optimized vaccination sites; however, the\nworkload in some optimized locations increased significantly. We developed a\ndata-driven computational algorithm to combat an ongoing rabies epidemic by\noptimally using limited resources to maximize vaccination coverage. The main\npositive effects we expect if this algorithm is to be implemented would be\nincreased overall vaccination coverage and increased spatial evenness of\ncoverage. A potential negative effect could be the presence of long waiting\nlines as participation increases."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Prenatal stress perturbs fetal iron homeostasis in a sex-specific manner"}, {"role": "assistant", "content": "What is the influence of chronic maternal prenatal stress (PS) on fetal iron\nhomeostasis? In a prospective case-control study in 164 pregnant women, we show\nthat cord blood transferrin saturation is lower in male stressed neonates. The\ntotal effect of PS exposure on fetal ferritin revealed a decrease of 15.4%\ncompared with controls. Electrocardiogram-based Fetal Stress Index (FSI)\nidentified affected fetuses non-invasively during the third trimester of\ngestation. FSI-based timely detection of fetuses affected by PS can support\nearly individualized iron supplementation and neurodevelopmental follow-up to\nprevent long-term sequelae due to PS-exacerbated impairment of the iron\nhomeostasis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Network embedding unveils the hidden interactions in the mammalian\n  virome"}, {"role": "assistant", "content": "At most 1-2% of the global virome has been sampled to date. Recent work has\nshown that predicting which host-virus interactions are possible but\nundiscovered or unrealized is, fundamentally, a network science problem. Here,\nwe develop a novel method that combines a coarse recommender system (Linear\nFiltering; LF) with an imputation algorithm based on low-rank graph embedding\n(Singular Value Decomposition; SVD) to infer host-virus associations. This\ncombination of techniques results in informed initial guesses based on directly\nmeasurable network properties (density, degree distribution) that are refined\nthrough SVD (which is able to leverage emerging features). Using this method,\nwe recovered highly plausible undiscovered interactions with a strong signal of\nviral coevolutionary history, and revealed a global hotspot of unusually unique\nbut unsampled (or unrealized) host-virus interactions in the Amazon rainforest.\nWe develop several tests for quantifying the bias and realism of these\npredictions, and show that the LF-SVD method is robust in each aspect. We\nfinally show that graph embedding of the imputed network can be used to improve\npredictions of human infection from viral genome features, showing that the\nglobal structure of the mammal-virus network provides additional insights into\nhuman disease emergence."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Stochastic filtering for multiscale stochastic reaction networks based\n  on hybrid approximations"}, {"role": "assistant", "content": "In the past few decades, the development of fluorescent technologies and\nmicroscopic techniques has greatly improved scientists' ability to observe\nreal-time single-cell activities. In this paper, we consider the filtering\nproblem associate with these advanced technologies, i.e., how to estimate\nlatent dynamic states of an intracellular multiscale stochastic reaction\nnetwork from time-course measurements of fluorescent reporters. A good solution\nto this problem can further improve scientists' ability to extract information\nabout intracellular systems from time-course experiments.\n  A straightforward approach to this filtering problem is to use a particle\nfilter where particles are generated by simulation of the full model and\nweighted according to observations. However, the exact simulation of the full\ndynamic model usually takes an impractical amount of computational time and\nprevents this type of particle filters from being used for real-time\napplications, such as transcription regulation networks. Inspired by the recent\ndevelopment of hybrid approximations to multiscale chemical reaction networks,\nwe approach the filtering problem in an alternative way. We first prove that\naccurate solutions to the filtering problem can be constructed by solving the\nfiltering problem for a reduced model that represents the dynamics as a hybrid\nprocess. The model reduction is based on exploiting the time-scale separations\nin the original network and, therefore, can greatly reduce the computational\neffort required to simulate the dynamics. As a result, we are able to develop\nefficient particle filters to solve the filtering problem for the original\nmodel by applying particle filters to the reduced model. We illustrate the\naccuracy and the computational efficiency of our approach using several\nnumerical examples."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Mortality Analysis of Early COVID-19 Cases in the Philippines Based on\n  Observed Demographic and Clinical Characteristics"}, {"role": "assistant", "content": "This study aims to determine the demographic, epidemiologic, and clinical\ncharacteristics of COVID-19 cases that are highly susceptible to COVID-19\ninfection, with longer hospitalization and at higher risk of mortality and to\nprovide insights that may be useful to assess the vaccination priority program\nand allocate hospital resources. Methods that were used include descriptive\nstatistics, nonparametric analysis, and survival analysis. Results of the study\nreveal that women are more susceptible to infection while men are at risk of\nlonger hospitalization and higher mortality. Significant risk factors to\nCOVID-19 mortality are older age, male sex, difficulty breathing, and\ncomorbidities like hypertension and diabetes. Patients with these combined\nsymptoms should be considered for admission to the COVID-19 facility for proper\nmanagement and care. Also, there is a significant delay in the testing and\ndiagnosis of those who died, implying that timeliness in the testing and\ndiagnosis of patients is crucial in patient survival."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Interpretable machine learning applied to on-farm biosecurity and\n  porcine reproductive and respiratory syndrome virus"}, {"role": "assistant", "content": "Effective biosecurity practices in swine production are key in preventing the\nintroduction and dissemination of infectious pathogens. Ideally, biosecurity\npractices should be chosen by their impact on bio-containment and\nbio-exclusion, however quantitative supporting evidence is often unavailable.\nTherefore, the development of methodologies capable of quantifying and ranking\nbiosecurity practices according to their efficacy in reducing risk have the\npotential to facilitate better informed choices. Using survey data on\nbiosecurity practices, farm demographics, and previous outbreaks from 139\nherds, a set of machine learning algorithms were trained to classify farms by\nporcine reproductive and respiratory syndrome virus status, depending on their\nbiosecurity practices, to produce a predicted outbreak risk. A novel\ninterpretable machine learning toolkit, MrIML-biosecurity, was developed to\nbenchmark farms and production systems by predicted risk, and quantify the\nimpact of biosecurity practices on disease risk at individual farms.\nQuantifying the variable impact on predicted risk 50% of 42 variables were\nassociated with fomite spread while 31% were associated with local\ntransmission. Results from machine learning interpretations identified similar\nresults, finding substantial contribution to predicted outbreak risk from\nbiosecurity practices relating to: the turnover and number of employees; the\nsurrounding density of swine premises and pigs; the sharing of trailers;\ndistance from the public road; and production type. In addition, the\ndevelopment of individualized biosecurity assessments provides the opportunity\nto guide biosecurity implementation on a case-by-case basis. Finally, the\nflexibility of the MrIML-biosecurity toolkit gives it potential to be applied\nto wider areas of biosecurity benchmarking, to address weaknesses in other\nlivestock systems and industry relevant diseases."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Language for Modeling And Optimizing Experimental Biological Protocols"}, {"role": "assistant", "content": "Automation is becoming ubiquitous in all laboratory activities, leading\ntowards precisely defined and codified laboratory protocols. However, the\nintegration between laboratory protocols and mathematical models is still\nlacking. Models describe physical processes, while protocols define the steps\ncarried out during an experiment: neither cover the domain of the other,\nalthough they both attempt to characterize the same phenomena. We should\nideally start from an integrated description of both the model and the steps\ncarried out to test it, to concurrently analyze uncertainties in model\nparameters, equipment tolerances, and data collection. To this end, we present\na language to model and optimize experimental biochemical protocols that\nfacilitates such an integrated description, and that can be combined with\nexperimental data. We provide a probabilistic semantics for our language based\non a Bayesian interpretation that formally characterizes the uncertainties in\nboth the data collection, the underlying model, and the protocol operations. On\na set of case studies we illustrate how the resulting framework allows for\nautomated analysis and optimization of experimental protocols, including Gibson\nassembly protocols."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Learning to predict target location with turbulent odor plumes"}, {"role": "assistant", "content": "Animal behavior and neural recordings show that the brain is able to measure\nboth the intensity of an odor and the timing of odor encounters. However,\nwhether intensity or timing of odor detections is more informative for\nolfactory-driven behavior is not understood. To tackle this question, we\nconsider the problem of locating a target using the odor it releases. We ask\nwhether the position of a target is best predicted by measures of timing\nintensity of its odor, sampled for a short period of time. To answer this\nquestion, we feed data from accurate numerical simulations of odor transport to\nmachine learning algorithms that learn how to connect odor to target location.\nWe find that both intensity and timing can separately predict target location\neven from a distance of several meters; however their efficacy varies with the\ndilution of the odor in space. Thus organisms that use olfaction from different\nranges may have to switch among different modalities. This has implications on\nhow the brain should represent odors as the target is approached. We\ndemonstrate simple strategies to improve accuracy and robustness of the\nprediction by modifying odor sampling and appropriately combining distinct\nmeasures together. To test the predictions, animal behavior and odor\nrepresentation should be monitored as the animal moves relative to the target,\nor in virtual conditions that mimic concentrated dilute environments."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Unsupervised classification of cell imaging data using the quantization\n  error in a Self Organizing Map"}, {"role": "assistant", "content": "This study exploits previously demonstrated properties such as sensitivity to\nthe spatial extent and the intensity of local image contrast of the\nquantization error in the output of a Self Organizing Map (SOM QE). Here, the\nSOM QE is applied to double color staining based cell viability data in 96\nimage simulations. The results show that the SOM QE consistently and in only a\nfew seconds detects fine regular spatial increases in relative amounts of RED\nor GREEN pixel staining across the test images, reflecting small, systematic\nincreases or decreases in the percentage of theoretical cell viability below\nthe critical threshold. Such small changes may carry clinical significance, but\nare almost impossible to detect by human vision. Moreover, we demonstrate a\nclear sensitivity of the SOM QE to differences in the relative physical\nluminance (Y) of the colors, which here translates into a RED GREEN color\nselectivity. Across differences in relative luminance, the SOM QE exhibits\nconsistently greater sensitivity to the smallest spatial increases in RED image\npixels compared with smallest increases of identical spatial extents in GREEN\nimage pixels. Further selective color contrast studies on simulations of\nbiological imaging data will allow generating increasingly larger benchmark\ndatasets and, ultimately, unravel the full potential of fast, economic, and\nunprecedentedly precise biological data analysis using the SOM QE."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Fluctuating ecological networks: a synthesis of maximum-entropy\n  approaches for pattern detection and process inference"}, {"role": "assistant", "content": "Ecological networks such as plant-pollinator systems and food webs vary in\nspace and time. This variability includes fluctuations in global network\nproperties such as total number and intensity of interactions but also in the\nlocal properties of individual nodes such as the number and intensity of\nspecies-level interactions. Fluctuations of species properties can\nsignificantly affect higher-order network features, e.g. robustness and\nnestedness. Local fluctuations should therefore be controlled for in\napplications that rely on null models, especially pattern and perturbation\ndetection. By contrast, most randomization methods for null models used by\necologists treat node-level local properties as hard constraints that cannot\nfluctuate. Here, we synthesise a set of methods that resolves the limit of hard\nconstraints and is based on statistical mechanics. We illustrate the methods\nwith some practical examples making available open source computer codes. We\nclarify how this approach can be used by experimental ecologists to detect\nnon-random network patterns with null models that not only rewire but also\nredistribute interaction strengths by allowing fluctuations in the null model\nconstraints (soft constraints). Null modelling of species heterogeneity through\nlocal fluctuations around typical topological and quantitative constraints\noffers a statistically robust and expanded (e.g. quantitative null models) set\nof tools to understand the assembly and resilience of ecological networks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Harnessing the Benefits of Open Electronics in Science"}, {"role": "assistant", "content": "Freely and openly shared low-cost electronic applications, known as open\nelectronics, have sparked a new open-source movement, with much un-tapped\npotential to advance scientific research. Initially designed to appeal to\nelectronic hobbyists, open electronics have formed a global community of\n\"makers\" and inventors and are increasingly used in science and industry. Here,\nwe review the current benefits of open electronics for scientific research and\nguide academics to enter this emerging field. We discuss how electronic\napplications, from the experimental to the theoretical sciences, can help (I)\nindividual researchers by increasing the customization, efficiency, and\nscalability of experiments, while improving data quantity and quality; (II)\nscientific institutions by improving access and maintenance of high-end\ntechnologies, visibility and interdisciplinary collaboration potential; and\n(III) the scientific community by improving transparency and reproducibility,\nhelping decouple research capacity from funding, increasing innovation, and\nimproving collaboration potential among researchers and the public. Open\nelectronics are powerful tools to increase creativity, democratization, and\nreproducibility of research and thus offer practical solutions to overcome\nsignificant barriers in science."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Compiling Elementary Mathematical Functions into Finite Chemical\n  Reaction Networks via a Polynomialization Algorithm for ODEs"}, {"role": "assistant", "content": "The Turing completeness result for continuous chemical reaction networks\n(CRN) shows that any computable function over the real numbers can be computed\nby a CRN over a finite set of formal molecular species using at most\nbimolecular reactions with mass action law kinetics. The proof uses a previous\nresult of Turing completeness for functions defined by polynomial ordinary\ndifferential equations (PODE), the dualrail encoding of real variables by the\ndifference of concentration between two molecular species, and a back-end\nquadratization transformation to restrict to elementary reactions with at most\ntwo reactants. In this paper, we present a polynomialization algorithm of\nquadratic time complexity to transform a system of elementary differential\nequations in PODE. This algorithm is used as a front-end transformation to\ncompile any elementary mathematical function, either of time or of some input\nspecies, into a finite CRN. We illustrate the performance of our compiler on a\nbenchmark of elementary functions relevant to CRN design problems in synthetic\nbiology specified by mathematical functions. In particular, the abstract CRN\nobtained by compilation of the Hill function of order 5 is compared to the\nnatural CRN structure of MAPK signalling networks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Uncertainty quantification of a thrombosis model considering the\n  clotting assay PFA-100"}, {"role": "assistant", "content": "Mathematical models of thrombosis are currently used to study clinical\nscenarios of pathological thrombus formation. Most of these models involve\ninherent uncertainties that must be assessed to increase the confidence in\nmodel predictions and identify avenues of improvement for both thrombosis\nmodeling and anti-platelet therapies. In this work, an uncertainty\nquantification analysis of a multi-constituent thrombosis model is performed\nconsidering a common assay for platelet function (PFA-100). The analysis is\nperformed using a polynomial chaos expansion as a parametric surrogate for the\nthrombosis model. The polynomial approximation is validated and used to perform\na global sensitivity analysis via computation of Sobol' coefficients. Six out\nof fifteen parameters were found to be influential in the simulation\nvariability considering only individual effects. Nonetheless, parameter\ninteractions are highlighted when considering the total Sobol' indices. In\naddition to the sensitivity analysis, the surrogate model was used to compute\nthe PFA-100 closure times of 300,000 virtual cases that align well with\nclinical data. The current methodology could be used including common\nanti-platelet therapies to identify scenarios that preserve the hematological\nbalance."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Vestibular Drop Attacks and Meniere's Disease as Results of Otolithic\n  Membrane Damage -- A Numerical Model"}, {"role": "assistant", "content": "BACKGROUND: Meniere's Disease (MD) is a condition of the inner ear with\nsymptoms affecting both vestibular and hearing functions. Some patients with MD\nexperience vestibular drop attacks (VDAs), which are violent falls caused by\nspurious vestibular signals from the utricle and/or saccule. Recent surgical\nwork has shown that patients who experience VDAs also show distrupted utricular\notolithic membranes. OBJECTIVE: The objective of this study is to determine if\notolithic membrane damage alone is sufficient to induce spurious vestibular\nsignals, thus potentially eliciting VDAs and the vestibular dysfunction seen in\npatients with MD. METHODS: We use a previously developed numerical model to\ndescribe the nonlinear dynamics of an array of active, elastically coupled hair\ncells. We then reduce the coupling strength of a selected region of the\nmembrane to model the effects of tissue damage. RESULTS: As we reduce the\ncoupling strength, we observe large and abrupt spikes in hair bundle position.\nAs bundle displacements from the equilibrium position have been shown to lead\nto depolarization of the hair-cell soma and hence trigger neural activity, this\nspontaneous activity could elicit false detection of a vestibular signal.\nCONCLUSIONS: The results of this numerical model suggest that otolithic\nmembrane damage alone may be sufficient to induce VDAs and the vestibular\ndysfunction seen in patients with MD. Future experimental work is needed to\nconfirm these results in vitro."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: In vitro reconstitution of microtubule dynamics and severing imaged by\n  label-free interference reflection microscopy"}, {"role": "assistant", "content": "The dynamic architecture of the microtubule cytoskeleton is crucial for cell\ndivision, motility and morphogenesis. The dynamic properties of microtubules -\ngrowth, shrinkage, nucleation and severing - are regulated by an arsenal of\nmicrotubule-associated proteins (MAPs). The activities of many of these MAPs\nhave been reconstituted in vitro using microscope assays. As an alternative to\nfluorescence microscopy, interference-reflection microscopy (IRM) has been\nintroduced as an easy-to-use, wide-field imaging technique that allows\nlabel-free visualization of microtubules with high contrast and speed. IRM\ncircumvents several problems associated with fluorescence microscopy including\nthe high concentrations of tubulin required for fluorescent labeling, the\npotential perturbation of function caused by the fluorophores, and the risks of\nphotodamage. IRM can be implemented on a standard epifluorescence microscope at\nlow cost and can be combined with fluorescence techniques like\ntotal-internal-reflection-fluorescence (TIRF) microscopy. Here we describe the\nexperimental procedure to image microtubule dynamics and severing using IRM,\nproviding practical tips and guidelines to resolve possible experimental\nhurdles."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Effect of high PM2.5 concentrations on cardiovascular disease: A South\n  Korean cohort study"}, {"role": "assistant", "content": "Background: Many studies have analyzed the relationship between average\nparticulate matter less than 2.5{\\mu}m in diameter (PM2.5) exposure and the\nhuman health, but few studies have focused on the effect of the freqnecy of\nPM2.5 concentration. The main purpose of this study is to analyze the\nrelationship between the first occurrence of hospitalization for cardiovascular\ndisease (CVD) and PM2.5 exposure, considering average PM2.5 concentration and\nthe frequency of high PM2.5 concentration simultaneously. Methods: We used\nlarge-scale cohort data from the National Health Insurance Service of Korea\nfrom 2002 to 2018, which includes a study population of 3,147,595. We estimated\nhazard ratios (HR) and 95% confidence intervals (CI) using the Cox\nproportional-hazards model with time-dependent covariates, including annual\naverage PM2.5 and the annual hours of PM2.5 concentration exceeding 55.5\n{\\mu}g/m3 (FH55), considering the individual residential moving. Results: We\nfound that the risk was elevated by 6.7% (95% CI, 6.2-7.3) for all CVD, by 7.1%\n(95% CI, 5.9-8.4) for ischemic heart disease (IHD), and by 7.5% (95% CI,\n6.0-9.1) for stroke per 1{\\mu}g/m3 increase of average PM2.5. Interestingly,\nthe 10-hour increase of FH55 decreased the risk of all CVD, IHD, and stroke by\n7.0% (95% CI: 7.0-7.1), 7.3% (95% CI: 7.1-7.4), and 7.4% (95% CI: 7.2-7.6),\nrespectively. This is due to people checking real-time or daily PM2.5\nconcentration information and voluntarily avoiding outdoor activities and\nexposure to high PM2.5 concentrations. Conclusions: Based on the results, we\nconclude that accurate forecasts, information disclosure, and timely warning of\nhigh concentrations of PM2.5 at the national level have the potential to reduce\nthe risk of CVD occurrence."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Intercross: An Android app for plant breeding and genetics cross\n  management"}, {"role": "assistant", "content": "Plant breeding is fundamentally comprised of three cyclic activities: 1)\nintermating lines to generate novel allelic combinations, 2) evaluation of new\nplant cultivars in distinct environments, and 3) selection of superior\nindividuals to be used as parents in the next breeding cycle. While digital\ntechnologies and tools are commonly utilized for the latter two stages, many\nplant research programs still rely on manual annotation and paper tags to track\nthe crosses that constitute the basis of a plant breeding program. This\npresence of analog data is a crack in the foundation of a digital breeding\necosystem and a significant occasion for errors to be introduced that will\npropagate through the entire breeding program. However, implementing digital\ncross tracking into breeding programs is difficult due to the non-standardized\nworkflows that different breeders have adopted. Intercross, an open-source\nAndroid app, aims to provide scientists with a robust and simple solution for\nplanning, tracking, and managing the crosses being made each season and aims to\nserve as the primary tool to digitize crossing data for breeding programs. The\nsimplicity and flexibility of Intercross allows rapid and broad adoption by\ndiverse breeding programs and will solidify the concepts of a digital breeding\necosystem."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Characterising mosquito biting behaviour at high resolution"}, {"role": "assistant", "content": "Blood feeding represents a critical event in the life cycle of female\nmosquitoes. In addition to providing nutrients to the mosquito, blood feeding\nfacilitates the transmission of parasites and viruses to hosts, potentially\nhaving devastating health consequences. Despite this, our understanding of\nthese short, yet important bouts of behaviour is incomplete. How and where a\nmosquito decides to feed and the success of feeding can influence the\ntransmission of pathogens, while a more thorough understanding may allow\ninterventions to reduce or prevent infections. Recent advances in machine\nvision and automated tracking presents the opportunity to observe and\nunderstand blood feeding behaviour of mosquitoes at unprecedented spatial and\ntemporal resolution. Here, we combine these technologies with novel designs for\nbehavioural arenas and controllable artificial host cues to enable detailed\nobservations of biting behaviour using relatively inexpensive and readily\navailable materials. Combined with a workflow for quantitative image analysis,\nwe are able to describe nuanced, high resolution biting behaviour under tightly\ncontrolled conditions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A new method of carbon budget analysis with application to present and\n  paleo atmospheric concentration data sets"}, {"role": "assistant", "content": "We introduce a new method for analyzing the carbon budget using box models\nand a mass balance approach. The method describes the net flow of carbon\nbetween the atmosphere and other reservoirs. The method assumes that the data\ncan be explained by having the carbon move in and out of the atmosphere through\ntwo reservoirs, one consisting of isotopically light carbon (biotic) and the\nother consisting of isotopically heavy carbon (abiotic). The systems are\nunderdetermined from the data, so the Occam's razor approach is to assume that\nthe least amount of carbon moves between the atmosphere and the reservoirs. As\ndata from known sources and sinks are added to the model, one can determine the\nconstraints on the unknown sources and sinks. To illustrate the method, we\nanalyze data from the Mauna Loa Observatory and data from Antarctic ice cores."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Three-way Mixed Effect ANOVA to Estimate MRMC Limits of Agreement"}, {"role": "assistant", "content": "When evaluating the clinical performance of a medical imaging device, a\nmulti-reader multi-case (MRMC) analysis is usually applied to account for both\ncase and reader variability. For a clinical task that equates to a quantitative\nmeasurement, an agreement analysis such as a limits of agreement (LOA) method\ncan be used to compare different measurement methods. In this work, we\nintroduce four types of comparisons; these types differ depending on whether\nthe measurements are within or between readers and within or between\nmodalities. A three-way mixed effect ANOVA model is applied to estimate the\nvariances of individual differences, which is an essential step for estimating\nLOA. To verify the estimates of LOA, we propose a hierarchical model to\nsimulate quantitative MRMC data. Two simulation studies were conducted to\nvalidate both the simulation and the LOA variance estimates. From the\nsimulation results, we can conclude that our estimate of variance is unbiased,\nand the uncertainty of the estimation drops as the number of readers and cases\nincreases and rises as the value of true variance increases."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: FANCA: In-Silico deleterious mutation analysis for early prediction of\n  leukemia"}, {"role": "assistant", "content": "As a novel biomarker from the Fanconi anemia complementation group (FANC)\nfamily, FANCA is antigens to Leukemia cancer. The overexpression of FANCA has\npredicted the second most common cancer in the world that is responsible for\ncancer-related deaths. Non-synonymous SNPs are an essential group of SNPs that\nlead to alterations in encoded polypeptides. Changes in the amino acid\nsequences of gene products lead to Leukemia. First, we study individual SNPs in\nthe coding region of FANCA and computational tools like PROVEAN, PolyPhen2,\nMuPro, and PANTHER to compute deleterious mutation scores. The\nthree-dimensional structural and functional prediction conducted using\nI-TASSER. Further, the predicted structure refined using the GlaxyWeb tool. In\nthe study, the proteomic data has been retrieved from the UniProtKB. The coding\nregion of the dataset contains 100 non-synonymous single nucleotide\npolymorphisms (nsSNPs), and 24 missense SNPs have been determined as\ndeleterious by all analyses. In this work, six well-known computational tools\nwere employed to study Leukemia-associated nsSNPs. It is inferred that these\nnsSNPs could play their role in the up-regulation of FANCA, which further leads\nto provoke leukemia advancement. The current research would benefit researchers\nand practitioners in handling cancer-associated diseases related to FANCA. The\nproposed study would also help to develop precision medicine in the field of\ndrug discovery."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multiple species animal movements: network properties, disease dynamic\n  and the impact of targeted control actions"}, {"role": "assistant", "content": "Infectious diseases in livestock are well-known to infect multiple hosts and\npersist through the combination of within- and between-host transmission\npathways. Uncertainty remains about the epidemic consequences of the disease\nbeing introduced on farms with more than one susceptible host. Here we describe\nmulti-host contact networks to elucidate the potential of disease spread among\nfarms with multiple species. Four years of between-farm animal movement data of\nbovine, swine, small ruminants, and multi-host, were described through both\nstatic and time-series networks; the in-going and out-going contact chains were\nalso calculated. We use the proposed stochastic multilevel model to simulate\nscenarios in which infection was seeded into a single host and multi-hosts\nfarms, to estimate epidemic trajectories and simulate network-based control\nactions to assess the reduction of secondarily infected farms. Our analysis\nshowed that the swine network was more connected than cattle and small\nruminants in the temporal network view. The small ruminants network was shown\ndisconnected, however, allowing the interaction among networks with different\nhosts enabling the spread of disease throughout the network. Independently from\nthe initial infected host, secondary infections were observed crossing overall\nspecies. We showed that targeting the top 3.25% of the farms ranked by degree\ncould reduce the total number of infected farms below 70% at the end of the\nsimulation period. In conclusion, we demonstrated the potential of the\nmulti-host network in disease propagation, therefore, it becomes important to\nconsider the observed multi-host movement dynamics while designing surveillance\nand preparedness control strategies."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Clinica: an open source software platform for reproducible clinical\n  neuroscience studies"}, {"role": "assistant", "content": "We present Clinica (www.clinica.run), an open-source software platform\ndesigned to make clinical neuroscience studies easier and more reproducible.\nClinica aims for researchers to i) spend less time on data management and\nprocessing, ii) perform reproducible evaluations of their methods, and iii)\neasily share data and results within their institution and with external\ncollaborators. The core of Clinica is a set of automatic pipelines for\nprocessing and analysis of multimodal neuroimaging data (currently, T1-weighted\nMRI, diffusion MRI and PET data), as well as tools for statistics, machine\nlearning and deep learning. It relies on the brain imaging data structure\n(BIDS) for the organization of raw neuroimaging datasets and on established\ntools written by the community to build its pipelines. It also provides\nconverters of public neuroimaging datasets to BIDS (currently ADNI, AIBL, OASIS\nand NIFD). Processed data include image-valued scalar fields (e.g. tissue\nprobability maps), meshes, surface-based scalar fields (e.g. cortical thickness\nmaps) or scalar outputs (e.g. regional averages). These data follow the ClinicA\nProcessed Structure (CAPS) format which shares the same philosophy as BIDS.\nConsistent organization of raw and processed neuroimaging files facilitates the\nexecution of single pipelines and of sequences of pipelines, as well as the\nintegration of processed data into statistics or machine learning frameworks.\nThe target audience of Clinica is neuroscientists or clinicians conducting\nclinical neuroscience studies involving multimodal imaging, and researchers\ndeveloping advanced machine learning algorithms applied to neuroimaging data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Characterising menotactic behaviours in movement data using hidden\n  Markov models"}, {"role": "assistant", "content": "1. Movement is the primary means by which animals obtain resources and avoid\nhazards. Most movement exhibits directional bias that is related to\nenvironmental features (taxis), such as the location of food patches,\npredators, ocean currents, or wind. Numerous behaviours with directional bias\ncan be characterized by maintaining orientation at an angle relative to the\nenvironmental stimuli (menotaxis), including navigation relative to sunlight or\nmagnetic fields and energy-conserving flight across wind. However, no\nstatistical methods exist to flexibly classify and characterise such\ndirectional bias. 2. We propose a biased correlated random walk model that can\nidentify menotactic behaviours by predicting turning angle as a trade-off\nbetween directional persistence and directional bias relative to environmental\nstimuli without making a priori assumptions about the angle of bias. We apply\nthe model within the framework of a multi-state hidden Markov model (HMM) and\ndescribe methods to remedy information loss associated with coarse\nenvironmental data to improve the classification and parameterization of\ndirectional bias. 3. Using simulation studies, we illustrate how our method\nmore accurately classifies behavioural states compared to conventional\ncorrelated random walk HMMs that do not incorporate directional bias. We\nillustrate the application of these methods by identifying cross wind olfactory\nforaging and drifting behaviour mediated by wind-driven sea ice drift in polar\nbears (Ursus maritimus) from movement data collected by satellite telemetry. 4.\nThe extensions we propose can be readily applied to movement data to identify\nand characterize behaviours with directional bias toward any angle, and open up\nnew avenues to investigate more mechanistic relationships between animal\nmovement and the environment."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Analysis of complex circadian time series data using wavelets"}, {"role": "assistant", "content": "Experiments that compare rhythmic properties across different genetic\nalterations and entrainment conditions underlie some of the most important\nbreakthroughs in circadian biology. A robust estimation of the rhythmic\nproperties of the circadian signals goes hand in hand with these discoveries.\nWidely applied traditional signal analysis methods such as fitting cosine\nfunctions or Fourier transformations rely on the assumption that oscillation\nperiods do not change over time. However, novel high-resolution recording\ntechniques have shown that, most commonly, circadian signals exhibit\ntime-dependent changes of periods and amplitudes which cannot be captured with\nthe traditional approaches. In this chapter we introduce a method to determine\ntime-dependent properties of oscillatory signals, using the novel open-source\nPython-based Biological Oscillations Analysis Toolkit (pyBOAT). We show with\nexamples how to detect rhythms, compute and interpret high-resolution\ntime-dependent spectral results, analyze the main oscillatory component and to\nsubsequently determine these main components time-dependent instantaneous\nperiod, amplitude and phase. We introduce step-by-step how such an analysis can\nbe done by means of the easy-to-use point-and-click graphical user interface\n(GUI) provided by pyBOAT or executed within a Python programming environment.\nConcepts are explained using simulated signals as well as experimentally\nobtained time series."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Deep Predictive Learning of Carotid Stenosis Severity"}, {"role": "assistant", "content": "Carotid artery stenosis is the narrowing of carotid arteries, which supplies\nblood to the neck and head. In this work, we train a model to predict the\nseverity of the stenosis blockage based on SRUC criteria variables and other\npatient information. We implement classic machine learning methods, decision\ntrees and random forests, used in a previous experiment. In addition, we\nimprove the accuracy through the use of the state-of-art Augmented Neural ODE\ndeep learning method. Through systematic and theory-rooted analysis, we examine\ndifferent parameters to achieve an accuracy of about 77%. These results show\nthe strong potential in applying recently developing deep learning methods,\nwhile simultaneously suggesting that the current data provided by the SRUC\ncriteria may be insufficient to predict stenosis severity at a high performance\nlevel."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: CPSC: Conformal prediction with shrunken centroids for efficient\n  prediction reliability quantification and data augmentation, a case in\n  alternative herbal medicine classification with electronic nose"}, {"role": "assistant", "content": "In machine learning applications, the reliability of predictions is\nsignificant for assisted decision and risk control. As an effective framework\nto quantify the prediction reliability, conformal prediction (CP) was developed\nwith the CPKNN (CP with kNN). However, the conventional CPKNN suffers from high\nvariance and bias and long computational time as the feature dimensionality\nincreases. To address these limitations, a new CP framework-conformal\nprediction with shrunken centroids (CPSC) is proposed. It regularizes the class\ncentroids to attenuate the irrelevant features and shrink the sample space for\npredictions and reliability quantification. To compare CPKNN and CPSC, we\nemployed them in the classification of 12 categories of alternative herbal\nmedicine with electronic nose as a case and assessed them in two tasks: 1)\noffline prediction: the training set was fixed and the accuracy on the testing\nset was evaluated; 2) online prediction with data augmentation: they filtered\nunlabeled data to augment the training data based on the prediction reliability\nand the final accuracy of testing set was compared. The result shows that CPSC\nsignificantly outperformed CPKNN in both two tasks: 1) CPSC reached a\nsignificantly higher accuracy with lower computation cost, and with the same\ncredibility output, CPSC generally achieves a higher accuracy; 2) the data\naugmentation process with CPSC robustly manifested a statistically significant\nimprovement in prediction accuracy with different reliability thresholds, and\nthe augmented data were more balanced in classes. This novel CPSC provides\nhigher prediction accuracy and better reliability quantification, which can be\na reliable assistance in decision support."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Therapeutic Interfering Particles Exploiting Viral Replication and\n  Assembly Mechanisms Show Promising Performance: A Modelling Study"}, {"role": "assistant", "content": "Defective interfering particles arise spontaneously during a viral infection\nas mutants lacking essential parts of the viral genome. Their ability to\nreplicate in the presence of the wild-type (WT) virus (at the expense of viable\nviral particles) is mimicked and exploited by therapeutic interfering\nparticles. We propose a strategy for the design of therapeutic interfering RNAs\n(tiRNAs) against positive-sense single-stranded RNA viruses that assemble via\npackaging signal-mediated assembly. These tiRNAs contain both an optimised\nversion of the virus assembly manual that is encoded by multiple dispersed RNA\npackaging signals and a replication signal for viral polymerase, but lack any\nprotein coding information. We use an intracellular model for hepatitis C viral\n(HCV) infection that captures key aspects of the competition dynamics between\ntiRNAs and viral genomes for virally produced capsid protein and polymerase. We\nshow that only a small increase in the assembly and replication efficiency of\nthe tiRNAs compared with WT virus is required in order to achieve a treatment\nefficacy greater than 99%. This demonstrates that the proposed tiRNA design\ncould be a promising treatment option for RNA viral infections."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: An age-structured model of hepatitis B viral infection highlights the\n  potential of different therapeutic strategies"}, {"role": "assistant", "content": "Hepatitis B virus is a global health threat, and its elimination by 2030 has\nbeen prioritised by the World Health Organisation. Here we present an\nage-structured model for the immune response to an HBV infection, which takes\ninto account contributions from both cell-mediated and humoral immunity. The\nmodel has been validated using published patient data recorded during acute\ninfection. It has been adapted to the scenarios of chronic infection, clearance\nof infection, and flare-ups via variation of the immune response parameters.\nThe impacts of immune response exhaustion and non-infectious subviral particles\non the immune response dynamics are analysed. A comparison of different\ntreatment options in the context of this model reveals that drugs targeting\naspects of the viral life cycle are more effective than exhaustion therapy, a\nform of therapy mitigating immune response exhaustion. Our results suggest that\nantiviral treatment is best started when viral load is declining rather than in\na flare-up. The model suggests that a fast antibody production rate always lead\nto viral clearance, highlighting the promise of antibody therapies currently in\nclinical trials."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: CellProfiler Analyst 3.0: Accessible data exploration and machine\n  learning for image analysis"}, {"role": "assistant", "content": "Image-based experiments can yield many thousands of individual measurements\ndescribing each object of interest, such as cells in microscopy screens.\nCellProfiler Analyst is a free, open-source software package designed for the\nexploration of quantitative image-derived data and the training of machine\nlearning classifiers with an intuitive user interface. We have now released\nCellProfiler Analyst 3.0, which in addition to enhanced performance adds\nsupport for neural network classifiers, identifying rare object subsets, and\ndirect transfer of objects of interest from visualisation tools into the\nClassifier tool for use as training data. This release also increases\ninteroperability with the recently released CellProfiler 4, making it easier\nfor users to detect and measure particular classes of objects in their\nanalyses."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Proteome remodelling during development from blood to insect-form\n  Trypanosoma brucei quantified by SILAC and mass spectrometry"}, {"role": "assistant", "content": "Background: Trypanosoma brucei is the causative agent of human African\nsleeping sickness and Nagana in cattle. In addition to being an important\npathogen T. brucei has developed into a model system in cell biology. Results:\nUsing Stable Isotope Labelling of Amino acids in Cell culture (SILAC) in\ncombination with mass spectrometry we determined the abundance of >1600\nproteins in the long slender (LS), short stumpy (SS) mammalian bloodstream form\nstages relative to the procyclic (PC) insect-form stage. In total we identified\n2645 proteins, corresponding to ~30% of the total proteome and for the first\ntime present a comprehensive overview of relative protein levels in three life\nstages of the parasite. Conclusions: We can show the extent of pre-adaptation\nin the SS cells, especially at the level of the mitochondrial proteome. The\ncomparison to a previously published report on monomorphic in vitro grown\nbloodstream and procyclic T. brucei indicates a loss of stringent regulation\nparticularly of mitochondrial proteins in these cells when compared to the\npleomorphic in vivo situation. In order to better understand the different\nlevels of gene expression regulation in this organism we compared mRNA steady\nstate abundance with the relative protein abundance-changes and detected\nmoderate but significant correlation indicating that trypanosomes possess a\nsignificant repertoire of translational and posttranslational mechanisms to\nregulate protein abundance."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Creative Diversity: Patterns in the Creative Habits of ~10,000 People"}, {"role": "assistant", "content": "Despite popular media interest in uncovering the creative habits of\nsuccessful people, there is a surprising paucity of empirical research on the\ndiversity of tendencies and preferences people have when engaged in creative\nwork. We developed a simple survey that characterized 42 creative habits along\n21 independent dimensions. Data from 9,633 respondents revealed seven 'Creative\nSpecies', or clusters of people with combinations of creative habits that tend\nto co-occur more than expected by chance. These emergent clusters where\nrelatively stable to random subsampling of the population and to variation in\nmodel parameters. The seven Creative Species self-sorted along a primary\ngradient from those characterized by more 'deliberate' creative habits (e.g.,\nMonotasker, Risk Averse, Routine Seeker, Tenacious, Make it Happen) to those\ncharacterized by more 'open' creative habits (e.g. Multitasker, Risk Friendly,\nNovelty Seeker, Reframer, Let it Happen). A weaker second gradient was defined\nby outward and rational vs inward and intuitive creators. For the subset of\nrespondents with data about their broad professional discipline (Art, Science,\nand Business) and gender, some groups were more (or less) common in some\nCreative Species than expected by chance, but the absolute magnitude of these\ndifferences were generally small; and knowing the discipline or gender of a\nperson was not a good single predictor of their creative preferences or\ntendencies. Together these results suggest that independent of discipline or\ngender, people vary widely in the habits, behaviors, and contexts in which they\nfeel most creative. Understanding creative diversity is critical for improving\nthe creative performance of both individuals and collaborative teams."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Automated Tracking of Primate Behavior"}, {"role": "assistant", "content": "Understanding primate behavior is a mission-critical goal of both biology and\nbiomedicine. Despite the importance of behavior, our ability to rigorously\nquantify it has heretofore been limited to low-information measures like\npreference, looking time, and reaction time, or to non-scaleable measures like\nethograms. However, recent technological advances have led to a major\nrevolution in behavioral measurement. Specifically, digital video cameras and\nautomated pose tracking software can provide detailed measures of full body\nposition (i.e., pose) of multiple primates over time (i.e., behavior) with high\nspatial and temporal resolution. Pose-tracking technology in turn can be used\nto detect behavioral states, such as eating, sleeping, and mating. The\navailability of such data has in turn spurred developments in data analysis\ntechniques. Together, these changes are poised to lead to major advances in\nscientific fields that rely on behavioral as a dependent variable. In this\nreview, we situate the tracking revolution in the history of the study of\nbehavior, argue for investment in and development of analytical and research\ntechniques that can profit from the advent of the era of big behavior, and\npropose that zoos will have a central role to play in this era."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Fokker-Planck feedback control framework for optimal personalized\n  therapies in colon cancer-induced angiogenesis"}, {"role": "assistant", "content": "In this paper, a new framework for obtaining personalized optimal treatment\nstrategies in colon cancer-induced angiogenesis is presented. The dynamics of\ncolon cancer is given by a It\\'o stochastic process, which helps in modeling\nthe randomness present in the system. The stochastic dynamics is then\nrepresented by the Fokker-Planck (FP) partial differential equation (PDE) that\ngoverns the evolution of the associated probability density function. The\noptimal therapies are obtained using a three step procedure. First, a finite\ndimensional FP-constrained optimization problem is formulated that takes input\nindividual noisy patient data, and is solved to obtain the unknown parameters\ncorresponding to the individual tumor characteristics. Next, a sensitivity\nanalysis of the optimal parameter set is used to determine the parameters to be\ncontrolled, thus, helping in assessing the types of treatment therapies.\nFinally, a feedback FP control problem is solved to determine the optimal\ncombination therapies. Numerical results with the combination drug, comprising\nof Bevacizumab and Capecitabine, demonstrate the efficiency of the proposed\nframework."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Optimized protocol for DNA extraction from ancient skeletal remains\n  using Chelex-100"}, {"role": "assistant", "content": "PCR-based analysis of skeletonized human remains is a common aspect in both\nforensic human identification as well as Ancient DNA research. In this, both\nareas not merely utilize very similar methodology, but also share the same\nproblems regarding quantity and quality of recovered DNA and presence of\ninhibitory substances in samples from excavated remains. To enable\namplification based analysis of the remains, development of optimized DNA\nextraction procedures is thus a critical factor in both areas. The study here\npresents an optimized protocol for DNA extraction from ancient skeletonized\nremains using Chelex-100, which proved to be effective in yielding amplifiable\nextracts from sample material excavated after centuries in a soil environment,\nwhich consequently have high inhibitor content and overall limited DNA\npreservation. Success of the optimization strategies utilized is shown in\nsignificantly improved amplification outcomes compared to the predecessor\nmethod."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Cyclic attractors of nonexpanding n-ary networks"}, {"role": "assistant", "content": "Discrete dynamical systems in which model components take on categorical\nvalues have been successfully applied to biological networks to study their\nglobal dynamic behavior. Boolean models in particular have been used\nextensively. However, multi-state models have also emerged as effective\ncomputational tools for the analysis of complex mechanisms underlying\nbiological networks. Models in which variables assume more than two discrete\nstates provide greater resolution, but this scheme introduces discontinuities.\nIn particular, variables can increase or decrease by more than one unit in one\ntime step. This can be corrected, without changing fixed points of the system,\nby applying an additional rule to each local activation function. On the other\nhand, if one is interested in cyclic attractors of their system, then this rule\ncan potentially introduce new cyclic attractors that were not observed\npreviously. This article makes some advancements in understanding the state\nspace dynamics of multi-state network models with a synchronous update schedule\nand establishes conditions under which no new cyclic attractors are added to\nnetworks when the additional rule is applied. Our analytical results have the\npotential to be incorporated into modeling software and aid researchers in\ntheir analyses of biological multi-state networks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: HELIX: Data-driven characterization of Brazilian land snails"}, {"role": "assistant", "content": "Decision-support systems benefit from hidden patterns extracted from digital\ninformation. In the specific domain of gastropod characterization,\nmorphometrical measurements support biologists in the identification of land\nsnail specimens. Although snails can be easily identified by their excretory\nand reproductive systems, the after-death mollusk body is commonly inaccessible\nbecause of either soft material deterioration or fossilization. This study aims\nat characterizing Brazilian land snails by morphometrical data features\nmanually taken from the shells. In particular, we examined a dataset of shells\nby using different learning models that labeled snail specimens with a\nprecision up to 97.5% (F1-Score = .975, CKC = .967 and ROC Area = .998). The\nextracted patterns describe similarities and trends among land snail species\nand indicates possible outliers physiologies due to climate traits and\nbreeding. Finally, we show some morphometrical characteristics dominate others\naccording to different feature selection biases. Those data-based patterns can\nbe applied to fast land snail identification whenever their bodies are\nunavailable, as in the recurrent cases of lost shells in nature or private and\nmuseum collections."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: ASGARD: A Single-cell Guided pipeline to Aid Repurposing of Drugs"}, {"role": "assistant", "content": "Intercellular heterogeneity is a major obstacle to successful precision\nmedicine. Single-cell RNA sequencing (scRNA-seq) technology has enabled\nin-depth analysis of intercellular heterogeneity in various diseases. However,\nits full potentials for precision medicine are yet to be reached. Towards this,\nwe propose A Single-cell Guided pipeline to Aid Repurposing of Drugs (ASGARD).\nTo precisely address the intercellular heterogeneity within each patient,\nASGARD defines a novel drug score predicting drugs for multiple cell clusters.\nWe tested ASGARD on three independent datasets, including advanced metastatic\nbreast cancer, acute lymphoblastic leukemia, and coronavirus disease 2019\n(COVID-19). On single-drug therapy, ASGARD shows significantly better average\naccuracy (AUC=0.95) compared to two other single-cell pipelines (AUC 0.69 and\n0.57) and two other bulk-cell-based drug repurposing methods (AUC 0.80 and\n0.75). The top-ranked drugs, such as fulvestrant and neratinib for breast\ncancer, tretinoin and vorinostat for leukemia, and enalapril for severe\nCOVID19, are either approved by FDA or in clinical trials treating\ncorresponding diseases. In conclusion, ASGARD is a promising pipeline guided by\nsingle-cell RNA-seq data, for repurposing drugs towards precision medicine.\nASGARD is free for academic use at https://github.com/lanagarmire/ASGARD."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: How to address cellular heterogeneity by distribution biology"}, {"role": "assistant", "content": "Cellular heterogeneity is an immanent property of biological systems that\ncovers very different aspects of life ranging from genetic diversity to\ncell-to-cell variability driven by stochastic molecular interactions, and noise\ninduced cell differentiation. Here, we review recent developments in\ncharacterizing cellular heterogeneity by distributions and argue that\nunderstanding multicellular life requires the analysis of heterogeneity\ndynamics at single cell resolution by integrative approaches that combine\nmethods from non-equilibrium statistical physics, information theory and omics\nbiology."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Optimization reduces knee-joint forces during walking and squatting:\n  Validating the inverse dynamics approach for full body movements on\n  instrumented knee prostheses"}, {"role": "assistant", "content": "Due to the redundancy of our motor system, movements can be performed in many\nways. While multiple motor control strategies can all lead to the desired\nbehavior, they result in different joint and muscle forces. This creates\nopportunities to explore this redundancy, e.g., for pain avoidance or reducing\nthe risk of further injury. To assess the effect of different motor control\noptimization strategies, a direct measurement of muscle and joint forces is\ndesirable, but problematic for medical and ethical reasons. Computational\nmodeling might provide a solution by calculating approximations of these\nforces. In this study, we used a full-body computational musculoskeletal model\nto (1) predict forces measured in knee prostheses during walking and squatting\nand (2) to study the effect of different motor control strategies (i.e.,\nminimizing joint force vs. muscle activation) on the joint load and prediction\nerror. We found that musculoskeletal models can accurately predict knee joint\nforces with an RMSE of <0.5 BW in the superior direction and about 0.1 BW in\nthe medial and anterior directions. Generally, minimization of joint forces\nproduced the best predictions. Furthermore, minimizing muscle activation\nresulted in maximum knee forces of about 4 BW for walking and 2.5 BW for\nsquatting. Minimizing joint forces resulted in maximum knee forces of 2.25 BW\nand 2.12 BW, i.e., a reduction of 44% and 15%, respectively. Thus, changing the\nmuscular coordination strategy can strongly affect knee joint forces. Patients\nwith a knee prosthesis may adapt their neuromuscular activation to reduce joint\nforces during locomotion."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Julia for Biologists"}, {"role": "assistant", "content": "Increasing emphasis on data and quantitative methods in the biomedical\nsciences is making biological research more computational. Collecting,\ncurating, processing, and analysing large genomic and imaging data sets poses\nmajor computational challenges, as does simulating larger and more realistic\nmodels in systems biology. Here we discuss how a relative newcomer among\ncomputer programming languages -- Julia -- is poised to meet the current and\nemerging demands in the computational biosciences, and beyond. Speed,\nflexibility, a thriving package ecosystem, and readability are major factors\nthat make high-performance computing and data analysis available to an\nunprecedented degree to \"gifted amateurs\". We highlight how Julia's design is\nalready enabling new ways of analysing biological data and systems, and we\nprovide a, necessarily incomplete, list of resources that can facilitate the\ntransition into the Julian way of computing."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Structural optimization of biohydrogen production: Impact of\n  pretreatments on volatile fatty acids and biogas parameters"}, {"role": "assistant", "content": "The present study aims to describe an innovative approach that enables the\nsystem to achieve high yielding for biohydrogen (bio-H$_2$) production using\nxylose as a by-product of lignocellulosic biomass processing. A hybrid\noptimization technique, structural modelling, desirability analysis, and\ngenetic algorithm could determine the optimum input factors to maximize useful\nbiogas parameters, especially bio-H$_2$ and CH$_4$. As found, the input factors\n(pretreatment, digestion time and biogas relative pressure) and volatile fatty\nacids (acetic acid, propionic acid and butyric acid) had indirectly and\nsignificantly impacted the bio-H$_2$ and desirability score. The pretreatment\nfactor had the most effect on bio-H$_2$ and CH$_4$ production among the\nfactors, and after that, were propionic acid and digestion time. The\noptimization method showed that the best pretreatment was acidic pretreatment,\ndigestion time > 20 h, relative pressure in a range of 300-800 mbar, acetic\nacid in a range of 90-200 mg/L, propionic acid in a range of 20-150 mg/L, and\nbutyric acid in a range of 250-420 mg/L. These values caused to produce H$_2$ >\n10.2 mmol/L, CH$_4$ > 3.9 mmol/L, N$_2$ < 15.3 mmol/L, CO$_2$ < 19.5 mmol/L,\ntotal biogas > 0.31 L, produced biogas > 0.10 L, and accumulated biogas > 0.41\nL."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Bayesian hypothesis testing and hierarchical modelling of ivermectin\n  effectiveness in treating Covid-19"}, {"role": "assistant", "content": "Ivermectin is an antiparasitic drug that some have claimed is an effective\ntreatment for reducing Covid-19 deaths. To test this claim, two recent peer\nreviewed papers both conducted a meta-analysis on a similar set of randomized\ncontrolled trials data, applying the same classical statistical approach.\nAlthough the statistical results were similar, one of the papers (Bryant et al,\n2021) concluded that ivermectin was effective for reducing Covid-19 deaths,\nwhile the other (Roman et al, 2021) concluded that there was insufficient\nquality of evidence to support the conclusion Ivermectin was effective. This\npaper applies a Bayesian approach, to a subset of the same trial data, to test\nseveral causal hypotheses linking Covid-19 severity and ivermectin to mortality\nand produce an alternative analysis to the classical approach. Applying diverse\nalternative analysis methods which reach the same conclusions should increase\noverall confidence in the result. We show that there is strong evidence to\nsupport a causal link between ivermectin, Covid-19 severity and mortality, and:\ni) for severe Covid-19 there is a 90.7% probability the risk ratio favours\nivermectin; ii) for mild/moderate Covid-19 there is an 84.1% probability the\nrisk ratio favours ivermectin. To address concerns expressed about the veracity\nof some of the studies we evaluate the sensitivity of the conclusions to any\nsingle study by removing one study at a time. In the worst case, where\n(Elgazzar 2020) is removed, the results remain robust, for both severe and mild\nto moderate Covid-19. The paper also highlights advantages of using Bayesian\nmethods over classical statistical methods for meta-analysis. All studies\nincluded in the analysis were prior to data on the delta variant."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Implementation of a practical Markov chain Monte Carlo sampling\n  algorithm in PyBioNetFit"}, {"role": "assistant", "content": "Bayesian inference in biological modeling commonly relies on Markov chain\nMonte Carlo (MCMC) sampling of a multidimensional and non-Gaussian posterior\ndistribution that is not analytically tractable. Here, we present the\nimplementation of a practical MCMC method in the open-source software package\nPyBioNetFit (PyBNF), which is designed to support parameterization of\nmathematical models for biological systems. The new MCMC method, am,\nincorporates an adaptive move proposal distribution. For warm starts, sampling\ncan be initiated at a specified location in parameter space and with a\nmultivariate Gaussian proposal distribution defined initially by a specified\ncovariance matrix. Multiple chains can be generated in parallel using a\ncomputer cluster. We demonstrate that am can be used to successfully solve\nreal-world Bayesian inference problems, including forecasting of new\nCoronavirus Disease 2019 case detection with Bayesian quantification of\nforecast uncertainty. PyBNF version 1.1.9, the first stable release with am, is\navailable at PyPI and can be installed using the pip package-management system\non platforms that have a working installation of Python 3. PyBNF relies on\nlibRoadRunner and BioNetGen for simulations (e.g., numerical integration of\nordinary differential equations defined in SBML or BNGL files) and\nDask.Distributed for task scheduling on Linux computer clusters."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: MOLUCINATE: A Generative Model for Molecules in 3D Space"}, {"role": "assistant", "content": "Recent advances in machine learning have enabled generative models for both\noptimization and de novo generation of drug candidates with desired properties.\nPrevious generative models have focused on producing SMILES strings or 2D\nmolecular graphs, while attempts at producing molecules in 3D have focused on\nreinforcement learning (RL), distance matrices, and pure atom density grids.\nHere we present MOLUCINATE (MOLecUlar ConvolutIoNal generATive modEl), a novel\narchitecture that simultaneously generates topological and 3D atom position\ninformation. We demonstrate the utility of this method by using it to optimize\nmolecules for desired radius of gyration. In the future, this model can be used\nfor more useful optimization such as binding affinity for a protein target."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Inferring the Localization of White-Matter Tracts using Diffusion Driven\n  Label Fusion"}, {"role": "assistant", "content": "Inferring which pathways are affected by a brain lesion is key for both pre\nand post-treatment planning. However, many disruptive lesions cause changes in\nthe tissue that interrupt tractography algorithms. In such cases, aggregating\ninformation from healthy subjects can provide a solution to inferring the\naffected pathways. In this paper, we introduce a novel label fusion technique\nthat leverages diffusion information to locate brain pathways. Through\nsimulations and experiments in publicly available data we show that our method\nis able to correctly reconstruct brain pathways, even if they are affected by a\nfocal lesion."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: DRP-VEM: Drug repositioning prediction using voting ensemble"}, {"role": "assistant", "content": "Traditional drug discovery methods are costly and time-consuming. Drug\nrepositioning (DR) is a common strategy to overcome these issues. Recently,\nmachine learning methods have been used extensively in DR problem. The\nperformance of these methods depends on the features, representations and\ntraining dataset. In this problem, feature sets include many redundant\nfeatures, which have a negative effect on the performance of methods. Moreover,\nselecting an appropriate training set is influential in the rise of machine\nlearning method accuracy. However, in this problem, we face two obstacles to\nfind the proper training set. First, most methods employ known and unknown\ndrug-disease pairs as positive and negative sets, respectively. While the\nnumber of known pairs is much less than unknowns, it leads to machine learning\nperformance error because of biasing to the majority group. Second, the absence\nof a drug-disease association means this association has not been approved\nexperimentally and may be changed. In this paper, DRP-VEM framework is proposed\nto overcome the challenges. We assess DRP-VEM based on different parameters:\ndisease and drug feature representations, classification methods, and voting\nensemble training approaches. DRP-VEM is evaluated using heterogenous\nevaluation criteria. Moreover, we compare DRP-VEM using the best combination of\nparameters with DisDrugPred."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Weight of Evidence approach to classify nanomaterials according to the\n  EU Classification, Labelling and Packaging regulation criteria"}, {"role": "assistant", "content": "In the context of the EU Horizon 2020 GRACIOUS project, we proposed a\nquantitative Weight of Evidence (WoE) approach for hazard classification of\nnanomaterials (NMs). This approach is based on the requirements of the European\nRegulation on Classification, Labelling and Packaging of Substances and\nMixtures (the CLP Regulation), which implements the United Nations' Globally\nHarmonized System of Classification and Labelling of Chemicals (UN GHS) in the\nEuropean Union. The goal of this WoE methodology is to facilitate\nclassification of NMs according to CLP criteria, following the decision trees\ndefined in ECHA's CLP regulatory guidance. The proposed methodology involves\nthe following stages: (1) collection of data for different NMs related to the\nendpoint of interest: each study related to each NM is referred as a Line of\nEvidence (LoE); (2) computation of weighted scores for each LoE: each LoE is\nweighted by a score calculated based on agreed data quality and completeness\ncriteria defined in the GRACIOUS project; (3) comparison and integration of the\nweighed LoEs for each NM: A Monte Carlo resampling approach is adopted to\nquantitatively and probabilistically integrate the weighted evidence; and (4)\nassignment of each NM to a hazard class: according to the results, each NM is\nassigned to one of the classes defined by the CLP regulation. Furthermore, to\nfacilitate the integration and the classification of the weighted LoEs, an R\ntool was developed. Finally, the approach was tested against an endpoint\nrelevant to CLP (Aquatic Toxicity) using data retrieved from the eNanoMapper\ndatabase, results obtained were consistent to results in ECHA registration\ndossiers and in recent literature"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Ordered Weighted Average Based grouping of nanomaterials with Arsinh and\n  Dose Response similarity models"}, {"role": "assistant", "content": "In the context of the EU GRACIOUS project, we propose a novel procedure for\nsimilarity assessment and grouping of nanomaterials. This methodology is based\non the (1) Arsinh transformation function for scalar properties, (2) full curve\nshape comparison by application of a modified Kolmogorov-Smirnov metric for\nbivariate properties, (3) Ordered Weighted Average (OWA) aggregation-based\ngrouping distance, and (4) hierarchical clustering. The approach allows for\ngrouping of nanomaterials that is not affected by the dataset, so that group\nmembership will not change when new candidates are included in the set of\nassessed materials. To facilitate the application of the proposed methodology,\na software script was developed by using the R programming language which is\ncurrently under migration to a web tool. The presented approach was tested\nagainst a dataset, derived from literature review, related to immobilisation of\nDaphnia magna and reporting information on several nanomaterials."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantification of collective behaviour via movement tracking"}, {"role": "assistant", "content": "Terms such as leader, follower, and oppressed sound equally well in the\ndescription of a pack of wolves, a street protest crowd, or a business team and\nhave very similar meanings. This indicates the presence of some general law or\nstructure that governs collective behaviour. To reveal this, we selected the\nmost common parameter for all levels of the organization -- motion. A causality\nanalysis of distance correlations was performed to obtain follow-up networks\nthat show who follows whom and how strongly. These networks characterize an\nobserved system in general and work as an automation bridge between the\nbiological experiment and the broad field of network analysis. The proposed\nmethod was tested on a school of aquarium fish. The patterns observed in the\nnetwork can be easily interpreted and agree with expected behaviour."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: MAGORINO: Magnitude-only fat fraction and R2* estimation with Rician\n  noise modelling"}, {"role": "assistant", "content": "Purpose: Magnitude-based fitting of chemical shift-encoded data enables\nproton density fat fraction (PDFF) and R2* estimation where complex-based\nmethods fail or when phase data is inaccessible or unreliable, such as in\nmulti-centre studies. However, traditional magnitude-based fitting algorithms\nsuffer from Rician noise-related bias and fat-water swaps. To address these\nissues, we propose an algorithm for Magnitude-Only PDFF and R2* estimation with\nRician Noise modelling (MAGORINO).\n  Methods: Simulations of multi-echo gradient echo signal intensities are used\nto investigate the performance and behavior of MAGORINO over the space of\nclinically plausible PDFF, R2* and SNR values. Fitting performance is assessed\nin terms of parameter bias, precision and fitting error. To gain deeper\ninsights into algorithm behavior, the paths on the likelihood functions are\nvisualized and statistics describing correct optimization are generated.\nMAGORINO is compared against Gaussian noise-based magnitude fitting and complex\nfitting.\n  Results: Simulations show that MAGORINO reduces bias in both PDFF and R2*\nmeasurements compared to Gaussian fitting, through two main mechanisms: (i) a\ngreater chance of selecting the true (non-swapped) optimum, and (ii) a shift in\nthe position of the optima such that the estimates are closer to ground truth\nsolutions, as a result of the correct noise model.\n  Conclusion: MAGORINO reduces fat-water swaps and Rician noise-related bias in\nPDFF and R2* estimation, thus addressing key limitations of traditional\nGaussian noise-based magnitude-only fitting."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Understanding of a brain spatial map based on threshold-free function\n  dendrogramization"}, {"role": "assistant", "content": "Linear matrix factorizations (LMFs) such as independent component analysis\n(ICA), principal component analysis (PCA), and their extensions, have been\nwidely used for finding relevant spatial maps in brain imaging data. The last\nstep of an LMF before interpretation is usually to extract the activated brain\nregions from the map by thresholding. However, it is difficult to determine an\nappropriate threshold level. Thresholding can remove the underlying properties\nof spatial maps and their features imposed by the model. In this study, we\npropose a threshold-free activated region extraction method which involves\nsimplifying a brain spatial map to a dendrogram through Morse filtration. Since\na dendrogram is related to the change of clustering structure in Rips\nfiltration, we first show the relationship between the Rips filtration of a\ngraph and the Morse filtration of a function. Then, we dendrogramize a spatial\nmap in order to visualize the activated brain regions and the range of their\nimportance in a spatial map. The proposed method can be applied to any spatial\nmaps that a user wants to threshold and interpret. In experiments, we applied\nthe proposed method to independent component maps (ICMs) obtained from\nresting-state fMRI data, and the dominant subnetworks obtained by the PCA of a\ncorrelation-based functional connectivity of FDG PET Alzheimer's disease\nneuroimaging initiative (ADNI) data. We found that dendrogramization can help\nto understand a brain spatial map without thresholding."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Microfluidic bioanalytical flow cells for biofilm studies: A review"}, {"role": "assistant", "content": "Bacterial biofilms are among the oldest and most prevalent multicellular life\nforms on Earth and are increasingly relevant in research areas related to\nindustrial fouling, medicine and biotechnology. The main hurdles to obtaining\ndefinitive experimental results include time-varying biofilm properties,\nstructural and chemical heterogeneity, and especially their strong sensitivity\nto environmental cues. Therefore, in addition to judicious choice of\nmeasurement tools, a well-designed biofilm study requires strict control over\nexperimental conditions, more so than most chemical studies. Due to excellent\ncontrol over a host of physiochemical parameters, microfluidic flow cells have\nbecome indispensable in microbiological studies. Not surprisingly, the number\nof lab-on-chip studies focusing on biofilms and other microbiological systems\nwith expanded analytical capabilities has expanded rapidly in the past decade.\nIn this paper, we comprehensively review the current state of microfluidic\nbioanalytical research applied to bacterial biofilms and offer a perspective on\nnew approaches that are expected to drive continued advances in this field."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The correlated variability control problem: a dominant approach"}, {"role": "assistant", "content": "Given a population of interconnected input-output agents repeatedly exposed\nto independent random inputs, we talk of correlated variability when agents'\noutputs are variable (i.e., they change randomly at each input repetition) but\ncorrelated (i.e., they do not vary independently across input repetitions).\nCorrelated variability appears at multiple levels in neuronal systems, from the\nmolecular level of protein expression to the electrical level of neuronal\nexcitability, but its functions and origins are still debated. Motivated by\nadvancing our understanding of correlated variability, we introduce the\n(linear) \"correlated variability control problem\" as the problem of controlling\nsteady-state correlations in a linear dynamical network in which agents receive\nindependent random inputs. Although simple, the chosen setting reveals\nimportant connections between network structure, in particular, the existence\nand the dimension of dominant (i.e., slow) dynamics in the network, and the\nemergence of correlated variability."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Application of Sequence Embedding in Protein Sequence-Based Predictions"}, {"role": "assistant", "content": "In sequence-based predictions, conventionally an input sequence is\nrepresented by a multiple sequence alignment (MSA) or a representation derived\nfrom MSA, such as a position-specific scoring matrix. Recently, inspired by the\ndevelopment in natural language processing, several applications of sequence\nembedding have been observed. Here, we review different approaches of protein\nsequence embeddings and their applications including protein contact\nprediction, secondary structure, prediction, and function prediction."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Convergence of regularized particle filters for stochastic reaction\n  networks"}, {"role": "assistant", "content": "Filtering for stochastic reaction networks (SRNs) is an important problem in\nsystems/synthetic biology aiming to estimate the state of unobserved chemical\nspecies. A good solution to it can provide scientists valuable information\nabout the hidden dynamic state and enable optimal feedback control. Usually,\nthe model parameters need to be inferred simultaneously with state variables,\nand a conventional particle filter can fail to solve this problem accurately\ndue to sample degeneracy. In this case, the regularized particle filter (RPF)\nis preferred to the conventional ones, as the RPF can mitigate sample\ndegeneracy by perturbing particles with artificial noise. However, the\nartificial noise introduces an additional bias to the estimate, and, thus, it\nis questionable whether the RPF can provide reliable results for SRNs. In this\npaper, we aim to identify conditions under which the RPF converges to the exact\nfilter in the filtering problem determined by a bimolecular network. First, we\nestablish computationally efficient RPFs for SRNs on different scales using\ndifferent dynamical models, including the continuous-time Markov process,\ntau-leaping model, and piecewise deterministic process. Then, by parameter\nsensitivity analyses, we show that the established RPFs converge to the exact\nfilters if all reactions leading to an increase of the molecular population\nhave linearly growing propensities and some other mild conditions are satisfied\nsimultaneously. This ensures the performance of the RPF for a large class of\nSRNs, and several numerical examples are presented to illustrate our results."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Control of diffusion-driven pattern formation behind a wave of\n  competency"}, {"role": "assistant", "content": "In certain biological contexts, such as the plumage patterns of birds and\nstripes on certain species of fishes, pattern formation takes place behind a\nso-called \"wave of competency\". Currently, the effects of a wave of competency\non the patterning outcome is not well-understood. In this study, we use\nTuring's diffusion-driven instability model to study pattern formation behind a\nwave of competency, under a range of wave speeds. Numerical simulations show\nthat in one spatial dimension a slower wave speed drives a sequence of peak\nsplittings in the pattern, whereas a higher wave speed leads to peak\ninsertions. In two spatial dimensions, we observe stripes that are either\nperpendicular or parallel to the moving boundary under slow or fast wave\nspeeds, respectively. We argue that there is a correspondence between the one-\nand two-dimensional phenomena, and that pattern formation behind a wave of\ncompetency can account for the pattern organization observed in many biological\nsystems."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Anatomy of a superorganism -- structure and growth dynamics of army ant\n  bivouacs"}, {"role": "assistant", "content": "Beyond unicellular and multicellular organisms, there is a third type of\nstructural complexity in living animals: that of the mechanical self-assembly\nof groups of distinct multicellular organisms into dynamical, functional\nstructures. One of the most striking examples of such structures is the army\nant bivouac, a nest which self-assembles solely from the interconnected bodies\nof hundreds of thousands of individuals. These bivouacs are difficult to study\nbecause they rapidly disassemble when disturbed, and hence little is known\nabout the structure and rules that individuals follow during their formation.\nHere we use a custom-built Computed Tomography scanner to investigate the\ndetails of the internal structure and growth process of army ant bivouacs. We\nshow that bivouacs are heterogeneous structures, which throughout their growth\nmaintain a thick shell surrounding a less dense interior that contains empty\nspaces akin to nest chambers. We find that ants within the bivouac do not carry\nmore than approximately eight times their weight regardless of the size of the\nstructure or their position within it. This observation suggests that bivouac\nsize is not limited by physical constraints of the ants' morphology. This study\nbrings us closer to understanding the rules used by individuals to govern the\nformation of these exceptional superorganismal structures, and provides insight\ninto how to create engineered self-assembling systems with, for instance,\nswarms of robots or active matter."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Deep Learning Model of Dock by Dock Process Significantly Accelerate the\n  Process of Docking-based Virtual Screening"}, {"role": "assistant", "content": "Docking-based virtual screening (VS process) selects ligands with potential\npharmacological activities from millions of molecules using computational\ndocking methods, which greatly could reduce the number of compounds for\nexperimental screening, shorten the research period and save the research cost.\nHowerver, a majority of compouds with low docking scores could waste most of\nthe computational resources. Herein, we report a novel and practical\ndocking-based machine learning method called MLDDM (Machince Learning\nDocking-by-Docking Models). It is composed of a regression model and a\nclassification model that simulates a classical docking by docking protocol\nususally applied in many virtual screening projects. MLDDM could quickly\neliminate compounds with low docking scores and the retained compounds with\npotential high docking scores would be examined for further real docking\nprogram. We demonstrated that MLDDM has a good ability to identify active\ncompounds in the case studies for 10 specific protein targets. Compared to pure\ndocking by docking based VS protocol, the VS process with MLDDM can achieve an\nover 120 times speed increment on average and the consistency rate with\ncorresponding docking by docking VS protocol is above 0.8. Therefore, it would\nbe promising to be used for examing ultra-large compound libraries in the\ncurrent big data era."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Kruskal-Wallis Power Studies Utilizing Bernstein Distributions;\n  preliminary empirical studies using simulations/medical studies"}, {"role": "assistant", "content": "Bernstein fits implemented into R allow another route for Kruskal-Wallis\npower-study tool development. Monte-Carlo Kruskal-Wallis power studies were\ncompared with measured power, with Monte-Carlo ANOVA equivalent and with an\nanalytical method, with or without normalization, using four simulated runs\neach with 60-100 populations (each population with N=30000 from a set of\nPearson-type ranges): random selection gave 6300 samples analysed for\npredictive power. Three medical-study datasets (Dialysis/systolic blood\npressure; Diabetes/sleep-hours; Marital-status/high-density-lipoprotein\ncholesterol) were also analysed. In three from four simulated runs (run_one,\nrun_one_relaxed, and run_three) with Pearson types pooled, Monte-Carlo\nKruskal-Wallis gave predicted sample sizes significantly slightly lower than\nmeasured but more accurate than with ANOVA methods; the latter gave high\nsample-size predictions. Populations (run_one_relaxed) with ANOVA assumptions\ninvalid gave Kruskal-Wallis predictions similar to those measured. In two from\nthree medical studies, Kruskal-Wallis predictions (Dialysis: similar\npredictions; Marital: higher than measured) were more accurate than ANOVA (both\nhigher than measured) but in one (Diabetes) the reverse was found\n(Kruskal-Wallis: lower; Monte-Carlo ANOVA: similar to measured). These\npreliminary studies appear to show that Monte-Carlo Kruskal-Wallis power\nstudies based on Bernstein fits might perform better than ANOVA equivalents in\nmany settings (and provide reasonable results when ANOVA cannot be used); and\nboth Monte-Carlo methods appeared considerably more accurate than the analysed\nanalytical version."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Predictive factors associated with survival rate of cervical cancer\n  patients in Brunei Darussalam"}, {"role": "assistant", "content": "Introduction: Cervical cancer is the third most prevalent cancer among women\nin Brunei Darussalam. This study aims to report the overall survival rates and\nassociated factors of patients diagnosed with malignant cervical cancer in\nBrunei Darussalam. Methods: A retrospective study of patients diagnosed with\ncervical cancer from 2007 to 2017 in Brunei Darussalam. The data were obtained\nfrom the population-based cancer registry in Brunei Darussalam. Kaplan- Meier\nsurvival analysis was used to estimate the overall survival rates at 1-, 3- and\n5-year intervals while the log-rank test was used to assess differences in\nsurvival between groups. Cox Proportional Hazard (PH) regression analysis was\nused to examine the association of demographic and clinical factors on the\nsurvival of cervical cancer patients. Results: A total of 329 registered\nmalignant cervical cancer cases were analyzed. The mean age at diagnosis of\npatients with cervical cancer was 46.7 years. There were 28.6% deaths and the\noverall survival rates at 1, 3 and 5 years were 85.4%, 72.6% and 68.6%\nrespectively. Age at diagnosis, cancer stage and histology types were\nsignificant predictive factors for overall survival of the patients diagnosed\nwith cervical cancers when analysed on both log rank tests and Cox PH model.\nConclusion: Age at diagnosis, cancer stage and histology types were\nsignificantly associated with the overall survival rates of cervical cancer\npatients in Brunei Darussalam. Early detection and management of cervical\ncancer at early stages should be prioritized to improve the survival rate and\nquality of cancer care."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Learning physics confers pose-sensitivity in structure-based virtual\n  screening"}, {"role": "assistant", "content": "In drug discovery, structure-based virtual high-throughput screening (vHTS)\ncampaigns aim to identify bioactive ligands or \"hits\" for therapeutic protein\ntargets from docked poses at specific binding sites. However, while generally\nsuccessful at this task, many deep learning methods are known to be insensitive\nto protein-ligand interactions, decreasing the reliability of hit detection and\nhindering discovery at novel binding sites. Here, we overcome this limitation\nby introducing a class of models with two key features: 1) we condition\nbioactivity on pose quality score, and 2) we present poor poses of true binders\nto the model as negative examples. The conditioning forces the model to learn\ndetails of physical interactions. We evaluate these models on a new benchmark\ndesigned to detect pose-sensitivity."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Spectra of Reduced Fractals and their Applications in Biology"}, {"role": "assistant", "content": "Reduced fractals, with different levels of self-similarity and magnification,\nare defined and used to introduce discrete spectra of reduced fractals. To\njustify the concept of reduced fractals and their spectra, some specific\napplications to biological systems, such as green algae, are performed and it\nis demonstrated how these spectra can be used to classify biological systems.\nThe ranges of these spectra for the considered systems are determined and their\nextension to other natural science systems is suggested."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A group theoretic approach to model comparison with simplicial\n  representations"}, {"role": "assistant", "content": "The complexity of biological systems, and the increasingly large amount of\nassociated experimental data, necessitates that we develop mathematical models\nto further our understanding of these systems. As biological systems are\ngenerally not well understood, most mathematical models of these systems are\nbased on experimental data, resulting in a seemingly heterogeneous collection\nof models that ostensibly represent the same system. To understand the system\nwe therefore need to know how the different models are related, with a view to\nobtaining a unified mathematical description. This goal is complicated by the\nfact that distinct mathematical formalisms may be used to represent the same\nsystem, making direct comparison of the models very difficult. In previous work\nwe developed an appropriate framework for model comparison where we represent\nmodels as labelled simplicial complexes and compare them with two general\nmethodologies: comparison by distance or equivalence. In this article we\ncontinue the development of our model comparison methodology in two directions.\nFirst, we present a rigorous and automatable methodology for the core process\nof comparison by equivalence, namely determining the vertices in a simplicial\nrepresentation, corresponding to model components, that are conceptually\nrelated and the identification of these vertices via simplicial operations. Our\nmethodology is based on considerations of vertex symmetry in the simplicial\nrepresentation, for which we develop the required mathematical theory of group\nactions on simplicial complexes. This methodology greatly simplifies and\nexpedites the process of determining model equivalence. Second, we provide an\nalternative mathematical framework for our model-comparison methodology by\nrepresenting models as groups, which allows for the direct application of\ngroup-theoretic techniques within our model-comparison methodology."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: An Open-Source Web App for Creating and Scoring Qualtrics-based Implicit\n  Association Test"}, {"role": "assistant", "content": "The Implicit Association Test (IAT) is a common behavioral paradigm to assess\nimplicit attitudes in various research contexts. In recent years, researchers\nhave sought to collect IAT data remotely using online applications. Compared to\nlaboratory-based assessments, online IAT experiments have several advantages,\nincluding widespread administration outside of artificial (i.e., laboratory)\nenvironments. Use of survey-software platforms (e.g., Qualtrics) represents an\ninnovative and cost-effective approach that allows researchers to prepare\nonline IAT experiments without any programming expertise. However, there are\nsome drawbacks with the existing survey-software as well as other online IAT\npreparation tools, such as limited mobile device compatibility and lack of\nhelper functionalities for easy adaptation. To address these issues, we\ndeveloped an open-source web app (GitHub page:\nhttps://github.com/ycui1-mda/qualtrics_iat) for creating mobile-compatible\nQualtrics-based IAT experiments and scoring the collected responses. The\npresent study demonstrates the key functionalities of this web app and\ndescribes feasibility data that were collected and scored using the app to show\nthe tool's validity. We show that the web app provides a complete and\neasy-to-adapt toolset for researchers to construct Qualtrics-based IAT\nexperiments and process the derived IAT data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: 4Dia: A tool for automated 4D microscope image alignment"}, {"role": "assistant", "content": "Recent advances in microscopy enable three-dimensional live imaging at a high\nresolution. Long-term live imaging of a multicellular organism requires\nimmobilization of the organism under stable physiological conditions. Despite\nproper immobilization, challenges remain within live imaging data analysis due\nto other intrinsic and extrinsic dynamics, which can result in misalignments of\nan image series over time. 4Dia, an ImageJ/Fiji macro script, aligns 3D\ntimelapse images through Z-stacks as well as over time using any user selected\nchannel. 4Dia can be used for essentially any tissue sample with no limit on\nthe size of Z-stack or the number of timepoints."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Prediction of cognitive decline for enrichment of Alzheimer's disease\n  clinical trials"}, {"role": "assistant", "content": "A key issue to Alzheimer's disease clinical trial failures is poor\nparticipant selection. Participants have heterogeneous cognitive trajectories\nand many do not decline during trials, which reduces a study's power to detect\ntreatment effects. Trials need enrichment strategies to enroll individuals who\nwill decline. We developed machine learning models to predict cognitive\ntrajectories in participants with early Alzheimer's disease (n=1342) and\npresymptomatic individuals (n=756) over 24 and 48 months respectively. Baseline\nmagnetic resonance imaging, cognitive tests, demographics, and APOE genotype\nwere used to classify decliners, measured by an increase in CDR-Sum of Boxes,\nand non-decliners with up to 79% area under the curve (cross-validated and\nout-of-sample). Using these prognostic models to recruit enriched cohorts of\ndecliners can reduce required sample sizes by as much as 51%, while maintaining\nthe same detection power, and thus may improve trial quality, derisk endpoint\nfailures, and accelerate therapeutic development in Alzheimer's disease."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Bone Adaptation as a Geometric Flow"}, {"role": "assistant", "content": "This paper presents bone adaptation as a geometric flow. The proposed method\nis based on two assumptions: first, that the bone surface is smooth (not\nfractal) permitting the definition of a tangent plane and, second, that the\ninterface between marrow and bone tissue phases is orientable. This permits the\nanalysis of bone adaptation using the well-developed mathematics of geometric\nflows and the numerical techniques of the level set method. Most importantly,\ntopological changes such as holes forming in plates and rods disconnecting can\nbe treated formally and simulated naturally. First, the relationship between\nbiological theories of bone adaptation and the mathematical object describing\ngeometric flow is described. This is termed the adaptation function, $F$, and\nis the multi-scale link described by Frost's Utah paradigm between cellular\ndynamics and bone structure. Second, a model of age-related bone loss termed\ncurvature-based bone adaptation is presented. Using previous literature, it is\nshown that curvature-based bone adaptation is the limiting continuous equation\nof simulated bone atrophy, a discrete model of bone aging. Interestingly, the\nparameters of the model can be defined in such a way that the flow is\nvolume-preserving. This implies that bone health can in principle change in\nways that fundamentally cannot be measured by areal or volumetric bone mineral\ndensity, requiring structure-level imaging. Third, a numerical method is\ndescribed and two in silico experiments are performed demonstrating the\nnon-volume-preserving and volume-preserving cases. Taken together, recognition\nof bone adaptation as a geometric flow permits the recruitment of mathematical\nand numerical developments over the last 50 years to understanding and\ndescribing the complex surface of bone."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A new radiomics feature: image frequency analysis"}, {"role": "assistant", "content": "Radiomics is a promising technology that focuses on improvements of image\nanalysis, using an automated high-throughput extraction of quantitative\nfeatures. However, the character of lesion is affected by the surrounding\ntissue. A lesion on medical image should be characterized from the\ninter-relation between lesion and surrounding tissue as well as property of the\nlesion itself. The aim of this study is to introduce a new radiomics feature\nwhich quantitatively analyze the inter-relation between lesion and surrounding\ntissue focusing on the value change of rows and columns in a medical image."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Interpreting BERT architecture predictions for peptide presentation by\n  MHC class I proteins"}, {"role": "assistant", "content": "The major histocompatibility complex (MHC) class-I pathway supports the\ndetection of cancer and viruses by the immune system. It presents parts of\nproteins (peptides) from inside a cell on its membrane surface enabling\nvisiting immune cells that detect non-self peptides to terminate the cell. The\nability to predict whether a peptide will get presented on MHC Class I\nmolecules helps in designing vaccines so they can activate the immune system to\ndestroy the invading disease protein. We designed a prediction model using a\nBERT-based architecture (ImmunoBERT) that takes as input a peptide and its\nsurrounding regions (N and C-terminals) along with a set of MHC class I (MHC-I)\nmolecules. We present a novel application of well known interpretability\ntechniques, SHAP and LIME, to this domain and we use these results along with\n3D structure visualizations and amino acid frequencies to understand and\nidentify the most influential parts of the input amino acid sequences\ncontributing to the output. In particular, we find that amino acids close to\nthe peptides' N- and C-terminals are highly relevant. Additionally, some\npositions within the MHC proteins (in particular in the A, B and F pockets) are\noften assigned a high importance ranking - which confirms biological studies\nand the distances in the structure visualizations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Integrative Data Semantics through a Model-enabled Data Stewardship"}, {"role": "assistant", "content": "Motivation: The importance of clinical data in understanding the\npathophysiology of complex disorders has prompted the launch of multiple\ninitiatives designed to generate patient-level data from various modalities.\nWhile these studies can reveal important findings relevant to the disease, each\nstudy captures different yet complementary aspects and modalities which, when\ncombined, generate a more comprehensive picture of disease aetiology. However,\nachieving this requires a global integration of data across studies, which\nproves to be challenging given the lack of interoperability of cohort datasets.\nResults: Here, we present the Data Steward Tool (DST), an application that\nallows for semi-automatic semantic integration of clinical data into ontologies\nand global data models and data standards. We demonstrate the applicability of\nthe tool in the field of dementia research by establishing a Clinical Data\nModel (CDM) in this domain. The CDM currently consists of 277 common variables\ncovering demographics (e.g. age and gender), diagnostics, neuropsychological\ntests, and biomarker measurements. The DST combined with this disease-specific\ndata model shows how interoperability between multiple, heterogeneous dementia\ndatasets can be achieved."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Development and Validation of MicrobEx: an Open-Source Package for\n  Microbiology Culture Concept Extraction"}, {"role": "assistant", "content": "Microbiology culture reports contain critical information for important\nclinical and public health applications. However, microbiology reports often\nhave complex, semi-structured, free-text data that present a barrier for\nsecondary use. Here we present the development and validation of an open-source\npackage designed to ingest free-text microbiology reports, determine whether\nthe culture is positive, and return a list of SNOMED-CT mapped bacteria. Our\nrule-based natural language processing algorithm was developed using\nmicrobiology reports from two different electronic health record systems in a\nlarge healthcare organization, and then externally validated on the reports of\ntwo other institutions with manually-extracted results as a benchmark. Our\nalgorithm achieved F-1 scores >0.95 on all classification tasks across both\nvalidation sets. Our concept extraction Python package, MicrobEx, is designed\nto be reused and adapted to individual institutions as an upstream process for\nother clinical applications, such as machine learning studies, clinical\ndecision support, and disease surveillance systems."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Nonlinear Multi-Objective Flux Balance Analysis of the Warburg Effect"}, {"role": "assistant", "content": "Due to its implication in cancer treatment, the Warburg Effect has received\nextensive in silico investigation. Flux Balance Analysis (FBA), based on\nconstrained optimization, was successfully applied in the Warburg Effect\nmodelling. Yet, the assumption that cell types have one invariant cellular\nobjective severely limits the applicability of the previous FBA models.\nMeanwhile, we note that cell types with different objectives show different\nextents of the Warburg Effect. To extend the applicability of the previous\nmodel and model the disparate cellular pathway preferences in different cell\ntypes, we built a Nonlinear Multi-Objective FBA (NLMOFBA) model by including\nthree key objective terms (ATP production rate, lactate generation rate and ATP\nyield) into one objective function through linear scalarization. By\nconstructing a cellular objective map and iteratively varying the objective\nweights, we showed disparate cellular pathway preferences manifested by\ndifferent cell types driven by their unique cellular objectives, and we gained\ninsights about the causal relationship between cellular objectives and the\nWarburg Effect. In addition, we obtained other biologically consistent results\nby using our NLMOFBA model. For example, augmented with the constraint\nassociated with inefficient mitochondria function or limited substrate, NLMOFBA\npredicts cellular pathways supported by the biology literature. Collectively,\nNLMOFBA can help build a complete understanding towards the Warburg Effect in\ndifferent cell types."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: NanoFrame: A web-based DNA wireframe design tool for 3D structures"}, {"role": "assistant", "content": "The rapid development of the DNA nanotechnology field has been facilitated by\nadvances in CAD software. However, as more complex concepts arose, the lag\nbetween the needs and software capabilities appeared. Further derailed by\nmanual installation and software incompatibility across different platforms and\noften tedious library management issues, the software has become hard-to-use\nfor many.\n  Here we present NanoFrame, a web-based DNA wireframe design tool for making\n3D nanostructures from a single scaffold. Within this software, we devised\nalgorithms for DNA routing, staple breaking, and wireframe cage opening which,\nwhile modeled for cuboid structure, can be generalized to a variety of platonic\nand Archimedean shapes. In addition, NanoFrame provides a platform for editing\nauto-generated staple sequences and saving work online."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Prediction of H-Bond Rotations from Protein H-Bond Topology"}, {"role": "assistant", "content": "H-bonds are known to play an important role in the folding of proteins into\nthree-dimensional structures, which in turn determine their diverse functions.\nThe conformations around H-bonds are important, in that they can be non-local\nalong the backbone and are therefore not captured by the methods such as\nRamachandran plots. We study the relationship between the geometry of H-bonds\nin proteins, expressed as a spatial rotation between the two bonded peptide\nunits, and their topology, expressed as a subgraph of the protein fatgraph. We\ndescribe two experiments to predict H-bond rotations from their corresponding\nsubgraphs. The first method is based on sequence alignment between sequences of\nthe signed lengths of H-bonds measured along the backbone. The second method is\nbased on finding an exact match between the descriptions of subgraphs around\nH-bonds. We find that 88.14% of the predictions lie inside the ball, centred\naround the true rotation, occupying just 1% of the volume of the rotation space\nSO(3)."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A universal framework to efficiently share material and process\n  resources in the DNA construction world"}, {"role": "assistant", "content": "DNA constructs and their annotated sequence maps have been rapidly\naccumulating with the advancement of DNA cloning, synthesis, and assembly\nmethods. Such a resource has the potential to be optimally utilized in an\nautonomous DNA building platform. However, most DNA design processes today\nremain manually operated with the assistance of graphical user interface (GUI)\nsoftware. Furthermore, as seen commonly in the life sciences, reproducibility\nof DNA construction process descriptions is usually not guaranteed, and\nutilization of previously developed materials and protocols is not\nappropriately credited. Here, we developed an open-source process description\nand resource sharing framework QUEEN (a framework to generate quinable and\nefficiently editable nucleotide sequence resources) to resolve these issues in\nbuilding DNA. QUEEN enables the flexible design of new DNA by using existing\nDNA resource files and recoding the construction process in an output file\n(GenBank file format). The GenBank files generated by QUEEN are able to\nregenerate the process codes that perfectly clone themselves and bequeath the\ndesign history to successive DNA constructs that recycle their partial\nresources. QUEEN-generated GenBank files are compatible with the existing DNA\nrepository services and software. We propose QUEEN as a solution to start\nsignificantly advancing our material and protocol sharing of DNA resources."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Omicron (B.1.1.529): Infectivity, vaccine breakthrough, and antibody\n  resistance"}, {"role": "assistant", "content": "The latest severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)\nvariant Omicron (B.1.1.529) has ushered panic responses around the world due to\nits contagious and vaccine escape mutations. The essential infectivity and\nantibody resistance of the SARS-CoV-2 variant are determined by its mutations\non the spike (S) protein receptor-binding domain (RBD). However, a complete\nexperimental evaluation of Omicron might take weeks or even months. Here, we\npresent a comprehensive quantitative analysis of Omicron's infectivity,\nvaccine-breakthrough, and antibody resistance. An artificial intelligence (AI)\nmodel, which has been trained with tens of thousands of experimental data\npoints and extensively validated by experimental data on SARS-CoV-2, reveals\nthat Omicron may be over ten times more contagious than the original virus or\nabout twice as infectious as the Delta variant. Based on 132 three-dimensional\n(3D) structures of antibody-RBD complexes, we unveil that Omicron may be twice\nmore likely to escape current vaccines than the Delta variant. The Food and\nDrug Administration (FDA)-approved monoclonal antibodies (mAbs) from Eli Lilly\nmay be seriously compromised. Omicron may also diminish the efficacy of mAbs\nfrom Celltrion and Rockefeller University. However, its impact on Regeneron mAb\ncocktail appears to be mild."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Artificial Intelligence-driven Image Analysis of Bacterial Cells and\n  Biofilms"}, {"role": "assistant", "content": "The current study explores an artificial intelligence framework for measuring\nthe structural features from microscopy images of the bacterial biofilms.\nDesulfovibrio alaskensis G20 (DA-G20) grown on mild steel surfaces is used as a\nmodel for sulfate reducing bacteria that are implicated in microbiologically\ninfluenced corrosion problems. Our goal is to automate the process of\nextracting the geometrical properties of the DA-G20 cells from the scanning\nelectron microscopy (SEM) images, which is otherwise a laborious and costly\nprocess. These geometric properties are a biofilm phenotype that allow us to\nunderstand how the biofilm structurally adapts to the surface properties of the\nunderlying metals, which can lead to better corrosion prevention solutions. We\nadapt two deep learning models: (a) a deep convolutional neural network (DCNN)\nmodel to achieve semantic segmentation of the cells, (d) a mask\nregion-convolutional neural network (Mask R-CNN) model to achieve instance\nsegmentation of the cells. These models are then integrated with moment\ninvariants approach to measure the geometric characteristics of the segmented\ncells. Our numerical studies confirm that the Mask-RCNN and DCNN methods are\n227x and 70x faster respectively, compared to the traditional method of manual\nidentification and measurement of the cell geometric properties by the domain\nexperts."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: AIS Explorer: Prioritization for watercraft inspections-A\n  decision-support tool for aquatic invasive species management"}, {"role": "assistant", "content": "Invasions of aquatic invasive species have imposed significant economic and\necological damage to global aquatic ecosystems. Once an invasive population has\nestablished in a new habitat, eradication can be financially and logistically\nimpossible, motivating management strategies to rely heavily upon prevention\nmeasures aimed at reducing the introduction and spread. To be productive,\non-the-ground management of aquatic invasive species requires effective\ndecision-making surrounding the allocation of limited resources. Watercraft\ninspections play an important role in managing aquatic invasive species by\npreventing the overland transport of invasive species between waterbodies and\nproviding education to boaters. In this study, we developed and tested an\ninteractive web-based decision-support tool, AIS Explorer: Prioritization for\nWatercraft Inspections, to guide AIS managers in developing efficient\nwatercraft inspection plans. The decision-support tool is informed by a novel\nnetwork model that maximized the number of inspected watercraft that move from\nAIS-infested to uninfested waterbodies, within and outside of counties in\nMinnesota, USA. It was iteratively built with stakeholder feedback, including\nconsultations with county managers, beta-testing of the web-based application,\nand workshops to educate and train end-users. The co-development and\nimplementation of data-driven decision support tools demonstrate how\ninterdisciplinary methods can be used to connect science and management to\nsupport decision-making. The AIS Explorer: Prioritization for Watercraft\nInspections application makes optimized research outputs accessible in multiple\ndynamic forms that maintain pace with the identification of new infestations\nand local needs. In addition, the decision support tool has supported improved\nand closer communication between AIS managers and researchers on this topic."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Cross Entropy test allows quantitative statistical comparison of t-SNE\n  and UMAP representations"}, {"role": "assistant", "content": "The advent of high dimensional single cell data in the biomedical sciences\nhas necessitated the development of dimensionality-reduction tools. t-SNE and\nUMAP are the two most frequently used approaches, allowing clear visualisation\nof highly complex single cell datasets. Despite the ubiquity of these\napproaches and the clear need for quantitative comparison of single cell\ndatasets, t-SNE and UMAP have largely remained data visualisation tools due to\nthe lack of robust statistical approaches available. Here, we have derived a\nstatistical test for evaluating the difference between dimensionality-reduced\ndatasets, using the Kolmogorov-Smirnov test on the distributions of cross\nentropy of single cells within each dataset. As the approach uses the\ninterrelationship of single cells for comparison, the resulting statistic is\nrobust and capable of distinguishing between true biological variation and\nrotational symmetry generation during dimensionality reduction. Further, the\ntest provides a valid distance between single cell datasets, allowing the\norganisation of multiple samples into a dendrogram for quantitative comparison\nof complex datasets. These results demonstrate the largely untapped potential\nof dimensionality-reduction tools for biomedical data analysis beyond\nvisualisation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Impact of Weight Loss on Brain Age: Improved Brain Health Following\n  Bariatric Surgery"}, {"role": "assistant", "content": "Overweight and obese individuals tend to have increased brain age, reflecting\npoorer brain health likely due to grey and white matter atrophy related to\nobesity. However, it is unclear if older brain age associated with obesity can\nbe reversed following weight loss and cardiometabolic health improvement. The\naim of this study was to assess the impact of weight loss and cardiometabolic\nimprovement following bariatric surgery on brain health, as measured by change\nin brain age estimated based on voxel-based morphometry (VBM). We used three\ndatasets: 1) CamCAN to train the brain age prediction model, 2) Human\nConnectome Project to investigate whether individuals with obesity have greater\nbrain age than individuals with normal weight, and 3) pre-surgery, as well as\n4, 12, and 24 month post-surgery data from participants (n=87) who underwent a\nbariatric surgery to investigate whether weight loss and cardiometabolic\nimprovement as a result of bariatric surgery lowers the brain age. Our results\nfrom the HCP dataset showed a higher brain age for individuals with obesity\ncompared to individuals with normal weight (p<0.0001). We also found\nsignificant improvement in brain health, indicated by a decrease of 2.9 and 5.6\nyears in adjusted delta age at 12 and 24 months following bariatric surgery\ncompared to baseline (p<0.0005). While the overall effect seemed to be driven\nby a global change across all brain regions and not from a specific region, our\nexploratory analysis showed lower delta age in certain brain regions at 24\nmonths. This reduced age was also associated with post-surgery improvements in\nBMI, systolic/diastolic blood pressure, and HOMA-IR (p<0.05). In conclusion,\nthese results suggest that obesity-related brain health abnormalities might be\nreversed by bariatric surgery-induced weight loss and widespread improvements\nin cardiometabolic alterations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Model predictive control guided with optimal experimental design for\n  pulse-based parallel cultivation"}, {"role": "assistant", "content": "Optimal experimental design for parameter precision attempts to maximize the\ninformation content in experimental data for a most effective identification of\nparametric model. With the recent developments in miniaturization and\nparallelization of cultivation platforms for high-throughput screening of\noptimal growth conditions massive amounts of informative data can be generated\nwith few experiments. Increasing the quantity of the data means to increase the\nnumber of parameters and experimental design variables which might deteriorate\nthe identifiability and hamper the online computation of optimal inputs. To\nreduce the problem complexity, in this work, we introduce an auxiliary\ncontroller at a lower level that tracks the optimal feeding strategy computed\nby a high-level optimizer in an online fashion. The hierarchical framework is\nespecially interesting for the operation under constraints. The key aspect of\nthis method are discussed together with an in silico study considering parallel\nglucose limited bacterial fed batch cultivations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: pyscreener: A Python Wrapper for Computational Docking Software"}, {"role": "assistant", "content": "pyscreener is a Python library that seeks to alleviate the challenges of\nlarge-scale structure-based design using computational docking. It provides a\nsimple and uniform interface that is agnostic to the backend docking engine\nwith which to calculate the docking score of a given molecule in a specified\nactive site. Additionally, pyscreener features first-class support for task\ndistribution, allowing users to seamlessly scale their code from a local,\nmulti-core setup to a large, heterogeneous resource allocation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: An adaptively optimized algorithm for counting nuclei in X-ray micro-CT\n  scans of whole organisms"}, {"role": "assistant", "content": "Living organisms are primarily made of cells. Identifying them and\ncharacterizing their geometry and spatial distribution is a first step towards\nbuilding multi-scale models of these biomaterials. We propose a method to count\ncells using nuclei in an X-ray microtomographic scan of a zebrafish. To account\nfor scanning artifacts and partial volume effect, the method is adaptively\ncalibrated using parameters approximated from the manifold of manually selected\nand optimized special cases. The methodology is tested on nuclei in the eyes of\nzebrafish larvae of different ages."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Evaluation of diagnostic test procedures for SARS-CoV-2 using latent\n  class models: comparison of antigen test kits and sampling for PCR testing\n  based on Danish national data registries"}, {"role": "assistant", "content": "Antigen test kits have been used extensively as a screening tool during the\nworldwide pandemic of coronavirus (SARS-CoV-2). While it is generally expected\nthat taking samples for analysis with PCR testing gives more reliable results\nthan using antigen test kits, the overall sensitivity and specificity of the\ntwo protocols in the field have not yet been estimated without assuming that\nthe PCR test constitutes a gold standard. We use latent class models to\nestimate the in situ performance of both PCR and antigen testing, using data\nfrom the Danish national registries. The results are based on 240,000 paired\ntests results sub-selected from the 55 million test results that were obtained\nin Denmark during the period from February 2021 until June 2021.\n  We found that the specificity of both tests is very high in our data sample\n(>99.7%), while the sensitivity of PCR sampling was estimated to be 95.7% (95%\nCI: 92.8-98.4%) and that of the antigen test kits used in Denmark over the\nstudy period was estimated at 53.8% (95% CI: 49.8-57.9%). Our findings can be\nused as supplementary information for consideration when implementing serial\ntesting strategies that employ a confirmatory PCR sample following a positive\nresult from an antigen test kit, such as the policy used in Denmark. We note\nthat while this strategy reduces the number of false positives associated with\nantigen test screening, it also increases the false negatives. We demonstrate\nthat the balance of trading false positives for false negatives only favours\nthe use of serial testing when the expected true prevalence is low. Our results\ncontain substantial uncertainty in the estimates for sensitivity due to the\nrelatively small number of positive test results over this period: validation\nof our findings in a population with higher prevalence would therefore be\nhighly relevant for future work."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The utility of wearable devices in assessing ambulatory impairments of\n  people with multiple sclerosis in free-living conditions"}, {"role": "assistant", "content": "Multiple sclerosis (MS) is a progressive inflammatory and neurodegenerative\ndisease of the central nervous system affecting over 2.5 million people\nglobally. In-clinic six-minute walk test (6MWT) is a widely used objective\nmeasure to evaluate the progression of MS. Yet, it has limitations such as the\nneed for a clinical visit and a proper walkway. The widespread use of wearable\ndevices capable of depicting patients activity profiles has the potential to\nassess the level of MS-induced disability in free-living conditions. In this\nwork, we extracted 96 activity features in different temporal granularities\n(from minute-level to day-level) and explored their utility in estimating 6MWT\nscores in a European (Italy, Spain, and Denmark) MS cohort of 337 participants\nover an average of 10-month duration. We combined these features with\nparticipant demographics using three regression models including elastic net,\ngradient boosted trees and random forest. In addition, we quantified the\nindividual feature contribution using feature importance in these regression\nmodels, linear mixed-effects models, generalized estimating equations, and\ncorrelation-based feature selection (CFS). The results showed promising\nestimation performance with R2 of 0.30, which was derived using random forest\nafter CFS. This model was able to distinguish the participants with low\ndisability from those with high disability. Furthermore, we observed that the\nminute-level (no longer than 8 minutes) step count, particularly those\ncapturing the upper end of the step count distribution, had a stronger\nassociation with 6MWT. The use of a walking aid was indicative of ambulatory\nfunction measured through 6MWT. This study provides a basis for future\ninvestigation into the clinical relevance and utility of wearables in assessing\nMS progression in free-living conditions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Mathematical Properties of Incremental Effect Additivity and Other\n  Synergy Theories"}, {"role": "assistant", "content": "Synergy theories for multi-component agent mixtures use 1-agent dose-effect\nrelations, assumed known from analyzing previous 1-agent experiments, to\ncalculate baseline Neither-Synergy-Nor-Antagonism mixture dose-effect\nrelations. The most commonly used synergy theory, Simple Effect Additivity, is\nnot self-consistent mathematically. Many nonlinear alternatives have been\nsuggested, almost all of which require an assumption that effects increase\nmonotonically as dose increases. We here emphasize the recently introduced\nIncremental Effect Additivity synergy theory and briefly discuss Loewe\nAdditivity. By utilizing the fact that, when dose increments approach zero,\ndose-effect relations approach linearity, Incremental Effect Additivity theory\nto some extent circumvents the non-linearity of dose-effect relations that\nplague Simple Effect Additivity calculations. We study mathematical properties\nof Incremental Effect Additivity that are relevant to practical implementation\nof this synergy theory and hold whatever particular area of biology, medicine,\ntoxicology or pharmacology is involved. However, as yet Incremental Effect\nAdditivity synergy theory has only been applied to mixture experiments\nsimulating the toxic galactic cosmic ray mixture encountered during voyages in\ninterplanetary space. Our main results are theorems, propositions, examples and\ncounterexamples revealing various properties of Incremental Effect Additivity\nsynergy theory including whether or not Neither-Synergy-Nor-Antagonism\ndose-effect relations lie between 1-agent dose-effect relations. These results\nare amply illustrated with figures."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Un nouvel algorithme pour la detection des transferts horizontaux de\n  genes partiels entre les especes et pour la classification des transferts\n  inferes"}, {"role": "assistant", "content": "In this article we are describing a new algorithm for detecting and\nvalidating partial horizontal gene transfers (HGT). The presented algorithm is\nbased on a sliding window procedure which analyzes fragments of the given\nmultiple sequence alignment. A bootstrap procedure incorporated in our method\ncan be used to estimate the support of each inferred partial HGT. The new\nalgorithm can be also applied to confirm or discard complete (i.e.,\ntraditional) horizontal gene transfers detected by any HGT inferring algorithm.\nWhile working on a full-genome scale, the introduced algorithm can be used to\nassess the level of mosaicism of the whole species genomes as well as the rates\nof complete and partial HGT underlying the evolution of the considered set of\nspecies."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Probabilistic Models of k-mer Frequencies (Extended Abstract)"}, {"role": "assistant", "content": "In this article, we review existing probabilistic models for modeling\nabundance of fixed-length strings (k-mers) in DNA sequencing data. These models\ncapture dependence of the abundance on various phenomena, such as the size and\nrepeat content of the genome, heterozygosity levels, and sequencing error rate.\nThis in turn allows to estimate these properties from k-mer abundance\nhistograms observed in real data. We also briefly discuss the issue of\ncomparing k-mer abundance between related sequencing samples and meaningfully\nsummarizing the results."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Phenotypic correlation between external and internal egg quality\n  characteristics in 85-week-old laying hens"}, {"role": "assistant", "content": "Background and Objective: Several studies confirm that the age of hens has a\ntremendous impact on external and internal egg quality characteristics. Egg\nproduction could be at serious risk if egg quality characteristics and age of\nhens are not seriously considered. This study was conducted to analyze the\nphenotypic correlations between some internal and external egg quality\ncharacteristics in old laying hens. Materials and Methods: A total of 288 eggs\nof 85-week-old Hy-Line Brown laying hens were collected during 3 weeks and\ntheir internal and external egg characteristics were evaluated. Results:\nPhenotypic correlations between egg quality characteristics in old laying hens\nindicate a negative impact on shell and albumen quality but not affected yolk\nquality characteristics. Conclusion: This study helps to understand that\nraising laying hens above 80 weeks would have a negative impact on egg quality\ncharacteristics."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Egg shell quality and bone status as affected by environmental\n  temperature, Ca and non-phytate P intake and in vitro limestone solubility in\n  Single-Comb White Leghorn hens"}, {"role": "assistant", "content": "Environmental temperature (ET) often changes the nutrient intake/output for\nlayers. Changing feed formulations based on ET may need to be utilized to\nobtain optimum performance, shell quality and bone status. This study was\nconducted to investigate the effects of temperature, Ca intake, non-phytate P\n(NPP) intake and in vitro limestone solubility (LS) on egg-shell quality and\nbone status in commercial White Leghorn hens. Egg mass and shell weight per\nunit surface area (SWUSA) decreased with increasing ET (p lower than 0.05),\nespecially when ET was 29.7 C (cycling mean ET)or a constant ET was 32.2 C.\nFeeding layers a low soluble larger particle size limestone instead of a highly\nsoluble limestone produced beneficial effects for SWUSA at the thermoneutral ET\n(21.1 C) but the beneficial effect was less or disappeared when ET was higher\nthan 26.6 C in EXP 1 and 2. Feeding layers 245 and 353 mg NPP/h/d supported\nsatisfactory bone status at 21.1 C, however layers housed at higher than 30 C\nneeded an additional intake of 50 mg NPP/h/d to support bone integrity. Results\nof EXP 1 and 2 indicates that 48 week old layers housed in thermoneutral or\nwarmer ET require a minimum of 4.2 g Ca/h/d for maintaining optimum shell\nquality and bone integrity. Feeding low LS (34.1% in vitro solubility) improved\negg shell quality only for hens housed in thermoneutral ET (21.1 C) and did not\nimprove egg shell quality at higher ET (constant or cycling). Daily NPP intake\nof 245 and 353 mg/h/d supported optimum egg production and bone status at 21.1\nC, respectively. A higher NPP and Ca intake may be required for bone status\ncompared to egg production, especially in older hens."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Pruning deep neural networks generates a sparse, bio-inspired nonlinear\n  controller for insect flight"}, {"role": "assistant", "content": "Insect flight is a strongly nonlinear and actuated dynamical system. As such,\nstrategies for understanding its control have typically relied on either\nmodel-based methods or linearizations thereof. Here we develop a framework that\ncombines model predictive control on an established flight dynamics model and\ndeep neural networks (DNN) to create an efficient method for solving the\ninverse problem of flight control. We turn to natural systems for inspiration\nsince they inherently demonstrate network pruning with the consequence of\nyielding more efficient networks for a specific set of tasks. This bio-inspired\napproach allows us to leverage network pruning to optimally sparsify a DNN\narchitecture in order to perform flight tasks with as few neural connections as\npossible, however, there are limits to sparsification. Specifically, as the\nnumber of connections falls below a critical threshold, flight performance\ndrops considerably. We develop sparsification paradigms and explore their\nlimits for control tasks. Monte Carlo simulations also quantify the statistical\ndistribution of network weights during pruning given initial random weights of\nthe DNNs. We demonstrate that on average, the network can be pruned to retain\napproximately 7% of the original network weights, with statistical\ndistributions quantified at each layer of the network. Overall, this work shows\nthat sparsely connected DNNs are capable of predicting the forces required to\nfollow flight trajectories. Additionally, sparsification has sharp performance\nlimits."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A simple model describing evolution of genomic GC content with random\n  perturbations in asexually reproducing organisms"}, {"role": "assistant", "content": "A model is presented relating the evolution of genomic GC content over time\nto AT$\\rightarrow$GC and GC$\\rightarrow$AT mutation rates. By employing It\\^o\ncalculus it is shown that if mutation rates in asexually reproducing organisms\nare subject to random perturbations that can vary over time several\nimplications follow. For instance, an extra Brownian motion term appears\ninfluencing nucleotide variability; the greater the variability of the random\nperturbations on the mutation rates the stronger the impact of the Brownian\nmotion term. Reducing the influence of the random perturbations, to limit\nfitness decreasing and deleterious mutations, will likely imply divesting\nresources to genomic repair systems. The stable mutation rates seen in many\norganisms could thus be an evolved strategy to reduce the influence of the\nBrownian motion term. Furthermore, if change to genomic GC content, i.e. the GC\ncontent of variable sites or single nucleotide polymorphisms (SNPs), is just as\nlikely to increase as to decrease, something that resembles knockout of repair\nenzymes and removal of selective pressures seen in evolutionary laboratory\nexperiments, the species genome will likely decay unless infinite resources are\navailable. These implications are solely a consequence of allowing random\nperturbations affect AT- and GC mutation rates and not obtainable using\nstandard non-stochastic methodology. Finally, a connection between the model\nfor genomic GC content evolution and the classical Luria-Delbr\\\"uck mutation\nmodel is presented in a stochastic setting."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Continuous-Time Probabilistic Models for Longitudinal Electronic Health\n  Records"}, {"role": "assistant", "content": "Analysis of longitudinal Electronic Health Record (EHR) data is an important\ngoal for precision medicine. Difficulty in applying Machine Learning (ML)\nmethods, either predictive or unsupervised, stems in part from the\nheterogeneity and irregular sampling of EHR data. We present an unsupervised\nprobabilistic model that captures nonlinear relationships between variables\nover continuous-time. This method works with arbitrary sampling patterns and\ncaptures the joint probability distribution between variable measurements and\nthe time intervals between them. Inference algorithms are derived that can be\nused to evaluate the likelihood of future using under a trained model. As an\nexample, we consider data from the United States Veterans Health Administration\n(VHA) in the areas of diabetes and depression. Likelihood ratio maps are\nproduced showing the likelihood of risk for moderate-severe vs minimal\ndepression as measured by the Patient Health Questionnaire-9 (PHQ-9)."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Detailed Balance for Particle Models of Reversible Reactions in Bounded\n  Domains"}, {"role": "assistant", "content": "In particle-based stochastic reaction-diffusion models, reaction rate and\nplacement kernels are used to decide the probability per time a reaction can\noccur between reactant particles, and to decide where product particles should\nbe placed. When choosing kernels to use in reversible reactions, a key\nconstraint is to ensure that detailed balance of spatial reaction-fluxes holds\nat all points at equilibrium. In this work we formulate a general\npartial-integral differential equation model that encompasses several of the\ncommonly used contact reactivity (e.g. Smoluchowski-Collins-Kimball) and volume\nreactivity (e.g. Doi) particle models. From these equations we derive a\ndetailed balance condition for the reversible $\\textrm{A} + \\textrm{B}\n\\leftrightarrows \\textrm{C}$ reaction. In bounded domains with no-flux boundary\nconditions, when choosing unbinding kernels consistent with several commonly\nused binding kernels, we show that preserving detailed balance of spatial\nreaction-fluxes at all points requires spatially varying unbinding rate\nfunctions near the domain boundary. Brownian Dynamics simulation algorithms can\nrealize such varying rates through ignoring domain boundaries during unbinding\nand rejecting unbinding events that result in product particles being placed\noutside the domain."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Inferring characteristics of bacterial swimming in biofilm matrix from\n  time-lapse confocal laser scanning microscopy"}, {"role": "assistant", "content": "Biofilms are spatially organized microorganism colonies embedded in a\nself-produced matrix, conferring to the microbial community resistance to\nenvironmental stresses. Motile bacteria have been observed swimming in the\nmatrix of pathogenic exogeneous host biofilms. This observation opened new\npromising routes for deleterious biofilms biocontrol: these bacterial swimmers\nenhance biofilm vascularization for chemical treatment or could deliver\nbiocontrol agent by microbial hitchhiking or local synthesis.\n%\\cite{muok2021microbial,yu2020hitchhiking,samad2017swimming}. Hence,\ncharacterizing swimmer trajectories in the biofilm matrix is of particular\ninterest to understand and optimize its biocontrol.In this study, a new\nmethodology is developed to analyze time-lapse confocal laser scanning images\nto describe and compare the swimming trajectories of bacterial swimmers\npopulations and their adaptations to the biofilm structure. The method is based\non the inference of a kinetic model of swimmer population including mechanistic\ninteractions with the host biofilm. After validation on synthetic data, the\nmethodology is implemented on images of three different motile {Bacillus\nspecies swimming in a Staphylococcus aureus biofilm. The fitted model allows to\nstratify the swimmer populations by their swimming behavior and provides\ninsights into the mechanisms deployed by the micro-swimmers to adapt their\nswimming traits to the biofilm matrix."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantifying yeast colony morphologies with feature engineering from\n  time-lapse photography"}, {"role": "assistant", "content": "Baker's yeast (Saccharomyces cerevisiae) is a model organism for studying the\nmorphology that emerges at the scale of multi-cell colonies. To look at how\nmorphology develops, we collect a dataset of time-lapse photographs of the\ngrowth of different strains of S. cerevisiae. We discuss the general\nstatistical challenges that arise when using time-lapse photographs to extract\ntime-dependent features. In particular, we show how texture-based feature\nengineering and representative clustering can be successfully applied to\ncategorize the development of yeast colony morphology using our dataset. The\nlocal binary pattern (LBP) from image processing is used to score the surface\ntexture of colonies. This texture score develops along a smooth trajectory\nduring growth. The path taken depends on how the morphology emerges. A\nhierarchical clustering of the colonies is performed according to their texture\ndevelopment trajectories. The clustering method is designed for practical\ninterpretability; it obtains the best representative colony image for any\nhierarchical sub-cluster."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A simple, sensitive and quantitative FACS-based test for SARS-CoV-2\n  serology in humans and animals"}, {"role": "assistant", "content": "Serological tests are important for understanding the physiopathology and\nfollowing the evolution of the Covid-19 pandemic. Assays based on flow\ncytometry (FACS) of tissue culture cells expressing the spike (S) protein of\nSARS-CoV-2 have repeatedly proven to perform slightly better than the\nplate-based assays ELISA and CLIA (chemiluminescent immuno-assay), and markedly\nbetter than lateral flow immuno-assays (LFIA). Here, we describe an optimized\nand very simple FACS assay based on staining a mix of two Jurkat cell lines,\nexpressing either high levels of the S protein (Jurkat-S) or a fluorescent\nprotein (Jurkat-R expressing m-Cherry, or Jurkat-G, expressing GFP, which serve\nas an internal negative control). We show that the Jurkat-S\\&R-flow test has a\nmuch broader dynamic range than a commercial ELISA test and performs at least\nas well in terms of sensitivity and specificity. Also, it is more sensitive and\nquantitative than the hemagglutination-based test HAT, which we described\nrecently. The Jurkat-flow test requires only a few microliters of blood; thus,\nit can be used to quantify various Ig isotypes in capillary blood collected\nfrom a finger prick. It can be used also to evaluate serological responses in\nmice, hamsters, cats and dogs. FACS tests offer a very attractive solution for\nlaboratories with access to tissue culture and flow cytometry who want to\nmonitor serological responses in humans or in animals, and how these relate to\nsusceptibility to infection, or re-infection, by the virus, and to protection\nagainst Covid-19."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Systematic analysis reveals key microRNAs as diagnostic and prognostic\n  factors in progressive stages of lung cancer"}, {"role": "assistant", "content": "MicroRNAs play an indispensable role in numerous biological processes ranging\nfrom organismic development to tumor progression.In oncology,these microRNAs\nconstitute a fundamental regulation role in the pathology of cancer that\nprovides the basis for probing into the influences on clinical features through\ntranscriptome data. Previous work focused on machine learning (ML) for\nsearching biomarkers in different cancer databases, but the functions of these\nbiomarkers are fully not clear. Taking lung cancer as a prototype case of\nstudy. Through integrating clinical information into the transcripts expression\ndata, we systematically analyzed the effect of microRNA on diagnostic and\nprognostic factors at deteriorative lung adenocarcinoma (LUAD). After dimension\nreduction, unsupervised hierarchical clustering was used to find the diagnostic\nfactors which represent the unique expression patterns of microRNA at various\npatient's stages. In addition, we developed a classification framework, Light\nGradient Boosting Machine (LightGBM) and SHAPley Additive explanation (SHAP)\nalgorithm, to screen out the prognostic factors. Enrichment analyses show that\nthe diagnostic and prognostic factors are not only enriched in cancer-related\nathways, but also involved in many vital cellular signaling transduction and\nimmune responses. These key microRNAs also impact the survival risk of LUAD\npatients at all (or a specific) stage(s) and some of them target some important\nTranscription Factors (TF).The key finding is that five microRNAs\n(hsa-mir-196b, hsa-mir-31, hsa-mir-891a, hsa-mir-34c, and hsa-mir-653) can then\nserve as not only potential diagnostic factors but also prognostic tools in the\nmonitoring of lung cancer."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Developing a data analysis pipeline for automated protein profiling in\n  immunology"}, {"role": "assistant", "content": "Accurate information about protein content in the organism is instrumental\nfor a better understanding of human biology and disease mechanisms. While the\npresence of certain types of proteins can be life-threatening, the abundance of\nothers is an essential condition for an individual's overall well-being.\nProtein microarray is a technology that enables the quantification of thousands\nof proteins in hundreds of human samples in a parallel manner. In a series of\nstudies involving protein microarrays, we have explored and implemented various\ndata science methods for all-around analysing of these data. This analysis has\nenabled the identification and characterisation of proteins targeted by the\nautoimmune reaction in patients with the APS1 condition. We have also assessed\nthe utility of applying machine learning methods alongside statistical tests in\na study based on protein expression data to evaluate potential biomarkers for\nendometriosis. The keystone of this work is a web-tool PAWER. PAWER implements\nrelevant computational methods, and provides a semi-automatic way to run the\nanalysis of protein microarray data online in a drag-and-drop and\nclick-and-play style. The source code of the tool is publicly available. The\nwork that laid the foundation of this thesis has been instrumental for a number\nof subsequent studies of human disease and also inspired a contribution to\nrefining standards for validation of machine learning methods in biology."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The influence of spatial configuration in collective transitions: the\n  importance of being sorted"}, {"role": "assistant", "content": "We studied the effects of spatial configuration on collective dynamics in a\nnearest-neighbour and diffusively coupled lattice of heterogeneous nodes. The\nnetworks contained nodes from two populations, which differed in their\nintrinsic excitability. Initially, these populations were uniformly and\nrandomly distributed throughout the lattice. We then developed an iterative\nalgorithm for perturbing the arrangement of the network such that nodes from\nthe same population were increasingly likely to be adjacent to one another. We\nfound that the global input strength, or network drive, necessary to transition\nthe network from a state of quiescence to a state of synchronised and\noscillatory activity was decreased as network sortedness was increased.\nMoreover, for weak coupling, we found that regimes of partial synchronisation\nexist (i.e., 2:1 resonance in the activity of the two populations), which were\ndependent both on network drive (sometimes in a non-monotonic fashion) and\nnetwork sortedness."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Efficient Sampling-Based Bayesian Active Learning for synaptic\n  characterization"}, {"role": "assistant", "content": "Bayesian Active Learning (BAL) is an efficient framework for learning the\nparameters of a model, in which input stimuli are selected to maximize the\nmutual information between the observations and the unknown parameters.\nHowever, the applicability of BAL to experiments is limited as it requires\nperforming high-dimensional integrations and optimizations in real time:\ncurrent methods are either too time consuming, or only applicable to specific\nmodels. Here, we propose an Efficient Sampling-Based Bayesian Active Learning\n(ESB-BAL) framework, which is efficient enough to be used in real-time\nbiological experiments. We apply our method to the problem of estimating the\nparameters of a chemical synapse from the postsynaptic responses to evoked\npresynaptic action potentials. Using synthetic data and synaptic whole-cell\npatch-clamp recordings, we show that our method can improve the precision of\nmodel-based inferences, thereby paving the way towards more systematic and\nefficient experimental designs in physiology."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Evaluating and predicting the Efficiency Index for Stereotactic\n  Radiosurgery Plans using RapidMiner GO(JAVA) Based Artificial Intelligence\n  Algorithms"}, {"role": "assistant", "content": "Evaluation the prediction of Efficiency index by DVH parameter for SRS\ntreatment plans using Supervised Machine learning and the performance of\npredictive model algorithms of RapidMiner GO in the parameter prediction are\ninvestigated. Dose volume histogram (DVH) based Efficiency index was calculated\nfor 100 clinical SRS plans generated by Leksell Gamma plan, and the results\nwere compared to predicted values produced by machine learning toolbox of\nRapidMiner Go, algorithms are namely, Generalized linear model (GLR), Decision\nTree Model, Support Vector Machine (SVM), Gradient Boosted Trees (GBT), Random\nForest (RF) and Deep learning Model (DL). Root mean square error (RMSE),\nAverage absolute error, Absolute relative error, squared correlation and model\nbuilding time were determined to evaluate the performance of each algorithm.\nThe GLR algorithm model had square correlation of 0.974 with the smallest RMSE\nof 0.01, relatively high prediction speed, and fast model building time with\n2.812 s, according to the results. The RMSE values for all models were between\n0.01 upto 0.021, all algorithms performed well. The RMSE of the Gradient\nBoosted Tree, Random Forest, and Decision Tree regression algorithms was found\nto be greater than 0.01, suggesting that they are not appropriate for\npredicting EI in this analysis. RapidMiner GO machine learning models can be\nused to predict DVH parameters like EI in SRS treatment planning QA. To\neffectively evaluate the parameter, it is necessary to choose a suitable\nmachine learning algorithm."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Symbiotic bacterial network structure involved in carbon and nitrogen\n  metabolism of wood-utilizing insect larvae"}, {"role": "assistant", "content": "Effective biological utilization of wood biomass is necessary worldwide.\nSince several insect larvae can use wood biomass as a nutrient source, studies\non their digestive mechanism are expected to speculate a novel rule in wood\nbiomass processing. Here, the relationships of inhabitant bacteria involved in\ncarbon and nitrogen metabolism in the intestine of beetle larvae, an insect\nmodel, are investigated. Bacterial analysis of larval feces showed enrichment\nof members of which could include candidates for plant growth promotion,\nnitrogen cycle modulation, and/or environmental protection. The abundances of\nthese bacteria were not necessarily positively correlated with the abundance in\nthe habitat, suggesting that they might be selectively enriched in the\nintestines of larvae. Further association analysis predicted that carbon and\nnitrogen metabolism in the intestine was affected by the presence of the other\ncommon bacteria, the populations of which were not remarkably altered in the\nhabitat and feces. Based on hypotheses targeting these selected bacterial\ngroups, structural estimation modeling analyses statistically suggested that\ntheir metabolism of carbon and nitrogen and their stable isotopes, {\\delta}13C\nand {\\delta}15N, may be associated with fecal enriched bacteria and other\ncommon bacteria. In addition, other causal inference analyses, such as causal\nmediation analysis, linear non-Gaussian acyclic model (LiNGAM), and\nBayesLiNGAM, did not necessarily affirm the existence of prominent bacteria\ninvolved in metabolism, implying its importance as the bacterial groups for\nmetabolism rather than a remarkable bacterium. Thus, these observations\nhighlight a multifaceted view of symbiotic bacterial groups utilizing carbon\nand nitrogen from wood biomass in insect larvae as a cultivator of potentially\nenvironmentally beneficial bacteria."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Using unsupervised machine learning to quantify physical activity from\n  accelerometry in a diverse and rapidly changing population"}, {"role": "assistant", "content": "Accelerometers are widely used to measure physical activity behaviour,\nincluding in children. The traditional method for processing acceleration data\nuses cut points to define physical activity intensity, relying on calibration\nstudies that relate the magnitude of acceleration to energy expenditure.\nHowever, these relationships do not generalise across diverse populations and\nhence they must be parametrised for each subpopulation (e.g., age groups) which\nis costly and makes studies across diverse populations and over time difficult.\nA data driven approach that allows physical activity intensity states to emerge\nfrom the data, without relying on parameters derived from external populations,\nand offers a new perspective on this problem and potentially improved results.\nWe applied an unsupervised machine learning approach, namely a hidden semi\nMarkov model, to segment and cluster the accelerometer data recorded from 279\nchildren (9 to 38 months old) with a diverse range of physical and\nsocial-cognitive abilities (measured using the Paediatric Evaluation of\nDisability Inventory). We benchmarked this analysis with the cut points\napproach calculated using the best available thresholds for the population.\nTime spent active as measured by this unsupervised approach correlated more\nstrongly with measures of the childs mobility, social-cognitive capacity,\nindependence, daily activity, and age than that measured using the cut points\napproach. Unsupervised machine learning offers the potential to provide a more\nsensitive, appropriate, and cost-effective approach to quantifying physical\nactivity behaviour in diverse populations, compared to the current cut points\napproach. This, in turn, supports research that is more inclusive of diverse or\nrapidly changing populations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A novel sustainable role of compost as a universal protective substitute\n  for fish, chicken, pig, and cattle, and its estimation by structural equation\n  modeling"}, {"role": "assistant", "content": "Natural decomposition of organic matter is essential in food systems, and\ncompost is used worldwide as an organic fermented fertilizer. However, as a\nfeature of the ecosystem, its effects on the animals are poorly understood.\nHere we show that oral administration of compost and/or its derived\nthermophilic Bacillaceae, i.e., Caldibacillus hisashii and Weizmannia\ncoagulans, can modulate the prophylactic activities of various industrial\nanimals. The fecal omics analyses in the modulatory process showed an improving\ntrend dependent upon animal species, environmental conditions, and\nadministration. However, structural equation modeling (SEM) estimated the\ngrouping candidates of bacteria and metabolites as standard key components\nbeyond the animal species. In particular, the SEM model implied a strong\nrelationship among partly digesting fecal amino acids, increasing genus\nLactobacillus as inhabitant beneficial bacteria and 2-aminoisobutyric acid\ninvolved in lantibiotics. These results highlight the potential role of compost\nfor sustainable protective control in agriculture, fishery, and livestock\nindustries."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Repetition and reproduction of preclinical medical studies: taking a\n  leaf from the plant sciences with consideration of generalised systematic\n  errors"}, {"role": "assistant", "content": "Reproduction of pre-clinical results has a high failure rate. The fundamental\nmethodology including replication (\"protocol\") for hypothesis\ntesting/validation to a state allowing inference, varies within medical and\nplant sciences with little justification. Here, five protocols are\ndistinguished which deal differently with systematic/random errors and vary\nconsiderably in result veracity. Aim: to compare prevalence of protocols\n(defined in text). Medical/plant science articles from 2017/2019 were surveyed:\n713 random articles assessed for eligibility for counts: first (with p-values):\n1) non-replicated; 2) global; 3) triple-result protocols; second: 4)\nreplication-error protocol; 5) meta-analyses. Inclusion criteria:\nhuman/plant/fungal studies with categorical groups. Exclusion criteria: phased\nclinical trials, pilot studies, cases, reviews, technology, rare subjects,\n-omic studies. Abbreviated PICOS question: which protocol was evident for a\nmain result with categorically distinct group difference(s) ? Electronic\nsources: Journal Citation Reports 2017/2019, Google. Triplication prevalence\ndiffered dramatically between sciences (both years p<10-16; cluster-adjusted\nchi-squared tests): From 320 studies (80/science/year): in 2017, 53 (66%, 95%\nconfidence interval (C.I.) 56%:77%) and in 2019, 48 (60%, C.I. 49%:71%) plant\nstudies had triple-result or triplicated global protocols, compared with, in\nboth years, 4 (5%, C.I. 0.19%:9.8%) medical studies. Plant sciences had a\nhigher prevalence of protocols more likely to counter generalised systematic\nerrors (the most likely cause of false positives) and random error than\nnon-replicated protocols, without suffering from serious flaws found with\nrandom-Institutes protocols. It is suggested that a triple-result\n(organised-reproduction) protocol, with Institute consortia, is likely to solve\nmost problems connected with the replicability crisis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Gate-based Quantum Computing for Protein Design"}, {"role": "assistant", "content": "Protein design is a technique to engineer proteins by modifying their\nsequence to obtain novel functionalities. In this method, amino acids in the\nsequence are permutated to find the low energy states satisfying the\nconfiguration. However, exploring all possible combinations of amino acids is\ngenerally impossible to achieve on conventional computers due to the\nexponential growth of possibilities with the number of designable sites. Thus,\nsampling methods are currently used as a conventional approach to address the\nprotein design problems. Recently, quantum computation methods have shown the\npotential to solve similar types of problems. In the present work, we use the\ngeneral idea of Grover's algorithm, a pure quantum computation method, to\ndesign circuits at the gate-based level and address the protein design problem.\nIn our quantum algorithms, we use custom pair-wise energy tables consisting of\neight different amino acids. Also, the distance reciprocals between designable\nsites are included in calculating energies in the circuits. Due to the noisy\nstate of current quantum computers, we mainly use quantum computer simulators\nfor this study. However, a very simple version of our circuits is implemented\non real quantum devices to examine their capabilities to run these algorithms.\nOur results show that using $\\mathcal{O}(\\sqrt N)$ iterations, the circuits\nfind the correct results among all $N$ possibilities, providing the expected\nquadratic speed up of Grover's algorithm over classical methods."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Associations between depression symptom severity and daily-life gait\n  characteristics derived from long-term acceleration signals in real-world\n  settings"}, {"role": "assistant", "content": "Gait is an essential manifestation of depression. Laboratory gait\ncharacteristics have been found to be closely associated with depression.\nHowever, the gait characteristics of daily walking in real-world scenarios and\ntheir relationships with depression are yet to be fully explored. This study\naimed to explore associations between depression symptom severity and\ndaily-life gait characteristics derived from acceleration signals in real-world\nsettings. In this study, we used two ambulatory datasets: a public dataset with\n71 elder adults' 3-day acceleration signals collected by a wearable device, and\na subset of an EU longitudinal depression study with 215 participants and their\nphone-collected acceleration signals (average 463 hours per participant). We\ndetected participants' gait cycles and force from acceleration signals and\nextracted 20 statistics-based daily-life gait features to describe the\ndistribution and variance of gait cadence and force over a long-term period\ncorresponding to the self-reported depression score. The gait cadence of faster\nsteps (75th percentile) over a long-term period has a significant negative\nassociation with the depression symptom severity of this period in both\ndatasets. Daily-life gait features could significantly improve the goodness of\nfit of evaluating depression severity relative to laboratory gait patterns and\ndemographics, which was assessed by likelihood-ratio tests in both datasets.\nThis study indicated that the significant links between daily-life walking\ncharacteristics and depression symptom severity could be captured by both\nwearable devices and mobile phones. The gait cadence of faster steps in\ndaily-life walking has the potential to be a biomarker for evaluating\ndepression severity, which may contribute to clinical tools to remotely monitor\nmental health in real-world settings."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The Impact of Vaccination on the Infection rate and the Severity of\n  Covid-19"}, {"role": "assistant", "content": "This study aims to statistically assess the effectiveness of vaccination\nagainst SARS-CoV-2. It is indispensable to investigate the relationship between\nCovid-19 deadliness and vaccination in order to study the impact of vaccine in\nreal-world. We studied rates of infection and death due to Covid-19 in\ndifferent countries with respect to their levels of vaccination. People who\nreceived the required dose of vaccination were considered as fully vaccinated\nin this study. Based on the percentage of fully vaccinated population,\ncountries were categorized into several groups. Though a high-level study on\nthe vaccine effectiveness may not provide much insight for individual level\ndifferences, a global analysis is imperative to infer the influence of\nvaccination as a controlling measure of the pandemic."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Deep Learning-based Assessment of Hepatic Steatosis on chest CT"}, {"role": "assistant", "content": "Purpose: Automatic methods are required for the early detection of hepatic\nsteatosis to avoid progression to cirrhosis and cancer. Here, we developed a\nfully automated deep learning pipeline to quantify hepatic steatosis on\nnon-contrast enhanced chest computed tomography (CT) scans. Materials and\nMethods: We developed and evaluated our pipeline on chest CT images of 1,431\nrandomly selected National Lung Screening Trial (NLST) participants. A dataset\nof 451 CT scans with volumetric liver segmentations of expert readers was used\nfor training a deep learning model. For testing, in an independent dataset of\n980 CT scans hepatic attenuation was manually measured by an expert reader on\nthree cross-sectional images at different hepatic levels by selecting three\ncircular regions of interest. Additionally, 100 randomly selected cases of the\ntest set were volumetrically segmented by expert readers. Hepatic steatosis on\nthe test set was defined as mean hepatic attenuation of < 40 Hounsfield unit.\nSpearman correlation was conducted to analyze liver fat quantification accuracy\nand the Cohen's Kappa coefficient was calculated for hepatic steatosis\nprediction reliability. Results: Our pipeline demonstrated strong performance\nand achieved a mean dice score of 0.970 for the volumetric liver segmentation.\nThe spearman correlation of the liver fat quantification was 0.954 (P <0.0001)\nbetween the automated and expert reader measurements. The cohen's kappa\ncoefficient was 0.875 for automatic assessment of hepatic steatosis.\nConclusion: We developed a fully automatic deep learning-based pipeline for the\nassessment of hepatic steatosis in chest CT images. With the fast and cheap\nscreening of hepatic steatosis, our pipeline has the potential to help initiate\npreventive measures to avoid progression to cirrhosis and cancer."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Agricultural quality matrix-based multiomics structural analysis of\n  carrots in soils fertilized with thermophile-fermented compost"}, {"role": "assistant", "content": "Compost is used worldwide as a soil conditioner for crops, but its functions\nhave still been explored. Here, the omics profiles of carrots were\ninvestigated, as a root vegetable plant model, in a field amended with compost\nfermented with thermophilic Bacillaceae for growth and quality indices.\nExposure to compost significantly increased the productivity, antioxidant\nactivity, red color, and taste of the carrot root and altered the soil\nbacterial composition with the levels of characteristic metabolites of the\nleaf, root, and soil. Based on the data, structural equation modeling (SEM)\nestimated that L-2-aminoadipate, phenylalanine, flavonoids and / or carotenoids\nin plants were optimally linked by exposure to compost. The SEM of the soil\nestimated that the genus Paenibacillus, L-2-aminoadipate and nicotinamide, and\nS-methyl L-cysteine were optimally involved during exposure. These estimates\ndid not show a contradiction between the whole genomic analysis of\ncompost-derived Paenibacillus isolates and the bioactivity data, inferring the\npresence of a complex cascade of plant growth-promoting effects and modulation\nof the nitrogen cycle by compost itself. These observations have provided\ninformation on the qualitative indicators of compost in complex soil-plant\ninteractions and offer a new perspective for chemically independent sustainable\nagriculture through the efficient use of natural nitrogen."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Novel prediction methods for virtual drug screening"}, {"role": "assistant", "content": "Drug development is an expensive and time-consuming process where thousands\nof chemical compounds are being tested in order to find those possessing\ndrug-like properties while being safe and effective. One of key parts of the\nearly drug discovery process has become virtual drug screening -- a method used\nto narrow down search for potential drugs by running computer simulations of\ndrug-target interactions. As these methods are known to demand huge amounts of\ncomputational power to get accurate results, prediction models based on machine\nlearning techniques became a popular solution requiring less computational\npower as well as offering the ability to generate novel chemical structures for\nfurther research. Deep learning is to stay in drug discovery but has a long way\nto go. Only in the past few years with increases in computing power have\nresearchers really started to embrace the potential of neural networks in\nvarious stages of the drug discovery process. While prediction methods promise\ngreat perspective in the future development of drug discovery they open new\nquestions and challenges that still have to be solved."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Queueing Model of Patient Flow for Stroke Networks to Estimate Acute\n  Stroke Transfer Capacity"}, {"role": "assistant", "content": "Background: Most acute stroke (AS) patients in the United States are\ninitially evaluated at a primary stroke center (PSC) and a significant\nproportion requires transfer to a comprehensive stroke center (CSC) for\nadvanced treatment. A CSC typically accepts patients from multiple PSCs in its\nnetwork, leading to capacity limits. This study uses a queueing model to\nestimate impacts on CSC capacity due to transfers from PSCs.\n  Methods: The model assumes that the number of AS patients arriving at each\nPSC, proportion of AS patients transferred, and length of stay in the CSC\nNeurologic Intensive Care Unit (Neuro-ICU) by type of AS are random, while the\ntransfer rates of ischemic and hemorrhagic AS patients are control variables.\nThe main outcome measure is the \"overflow\" probability, namely, the probability\nof a CSC not having capacity (unavailability of a Neuro-ICU bed) to accept a\ntransfer. Data simulations of the model, using a base case and an expanded\ncase, were performed to illustrate the effects of changing key parameters, such\nas transfer rates from PSCs and CSC Neuro-ICU capacity on overflow capacity.\n  Results: Data simulations of the model using a base case show that an\nincrease of a PSC's ischemic stroke transfer rate from 15% to 55% raises the\noverflow probability from 30.62% to 36.13%. Further simulations of the expanded\ncase show that to maintain an a priori CSC overflow probability of 30.62% when\nadding a PSC with a AS transfer rate of 15% to the network, other PSCs would\nneed to decrease their transfer rate by 12.5% or the CSC Neuro-ICU would need\nto add 2 beds.\n  Discussion: A queuing model can be used to estimate the effects of change in\nthe size of a PSC-CSC network, change in AS transfer rates, or change in number\nof CSC Neuro-ICU beds of a CSC on its capacity on the overflow probability in\nthe CSC."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: AutoClassWeb: a simple web interface for Bayesian clustering"}, {"role": "assistant", "content": "Objective: Data clustering is a common exploration step in the omics era,\nnotably in genomics and proteomics where many genes or proteins can\nbequantified from one or more experiments. Bayesian clustering is a powerful\nalgorithm that can classify several thousands of genes or proteins. AutoClass\nC, its original implementation, handles missing data, automatically determines\nthe best number of clusters but is not user-friendly.Results: We developed an\nonline tool called AutoClassWeb, which provides an easy-to-use web interface\nfor Bayesian clustering with AutoClass. Input data are entered as TSV files.\nResults are provided in formats that ease further analyses with spreadsheet\nprograms or with programming languages, such as Python or R. AutoClassWeb is\nimplemented in Python and is published under the 3-Clauses BSD license. The\nsource code is available athttps://github.com/pierrepo/autoclassweb along with\na detailed documentation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Uncovering the dynamic effects of DEX treatment on lung cancer by\n  integrating bioinformatic inference and multiscale modeling of scRNA-seq and\n  proteomics data"}, {"role": "assistant", "content": "Motivation: Lung cancer is one of the leading causes for cancer-related\ndeath, with a five-year survival rate of 18%. It is a priority for us to\nunderstand the underlying mechanisms that affect the implementation and\neffectiveness of lung cancer therapeutics. In this study, we combine the power\nof Bioinformatics and Systems Biology to comprehensively uncover functional and\nsignaling pathways of drug treatment using bioinformatics inference and\nmultiscale modeling of both scRNA-seq data and proteomics data. The innovative\nand cross-disciplinary approach can be further applied to other computational\nstudies in tumorigenesis and oncotherapy. Results: A time series of lung\nadenocarcinoma-derived A549 cells after DEX treatment were analysed. (1) We\nfirst discovered the differentially expressed genes in those lung cancer cells.\nThen through the interrogation of their regulatory network, we identified key\nhub genes including TGF-\\b{eta}, MYC, and SMAD3 varied underlie DEX treatment.\nFurther enrichment analysis revealed the TGF-\\b{eta} signaling pathway as the\ntop enriched term. Those genes involved in the TGF-\\b{eta} pathway and their\ncrosstalk with the ERBB pathway presented a strong survival prognosis in\nclinical lung cancer samples. (2) Based on biological validation and further\ncuration, a multiscale model of tumor regulation centered on both\nTGF-\\b{eta}-induced and ERBB-amplified signaling pathways was developed to\ncharacterize the dynamics effects of DEX therapy on lung cancer cells. Our\nsimulation results were well matched to available data of SMAD2, FOXO3,\nTGF\\b{eta}1, and TGF\\b{eta}R1 over the time course. Moreover, we provided\npredictions of different doses to illustrate the trend and therapeutic\npotential of DEX treatment."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Structural features of microvascular networks trigger blood-flow\n  oscillations"}, {"role": "assistant", "content": "We analyse mathematical models in order to understand how microstructural\nfeatures of vascular networks may affect blood-flow dynamics, and to identify\nparticular characteristics that promote the onset of self-sustained\noscillations. By focusing on a simple three-node motif, we predict that network\n\"redundancy\", in the form of a redundant vessel connecting two main\nflow-branches, together with differences in haemodynamic resistance in the\nbranches, can promote the emergence of oscillatory dynamics. We use existing\nmathematical descriptions for blood rheology and haematocrit splitting at\nvessel branch-points to construct our flow model; we combine numerical\nsimulations and stability analysis to study the dynamics of the three-node\nnetwork and its relation to the system's multiple steady-state solutions.\nWhile, for the case of equal inlet-pressure conditions, a \"trivial\" equilibrium\nsolution with no flow in the redundant vessel always exists, we find that it is\nnot stable when other, stable, steady-state attractors exist. In turn, these\n\"nontrivial\" steady-state solutions may undergo a Hopf bifurcation into an\noscillatory state. We use the branch diameter ratio, together with the inlet\nhaematocrit rate, to construct a two-parameter stability diagram that\ndelineates regimes in which such oscillatory dynamics exist. We show that flow\noscillations in this network geometry are only possible when the branch\ndiameters are sufficiently different to allow for a sufficiently large flow in\nthe redundant vessel, which acts as the driving force of the oscillations.\nThese microstructural properties, which were found to promote oscillatory\ndynamics, could be used to explore sources of flow instability in biological\nmicrovascular networks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Greedy Optimization of Electrode Arrangement for Epiretinal Prostheses"}, {"role": "assistant", "content": "Visual neuroprostheses are the only FDA-approved technology for the treatment\nof retinal degenerative blindness. Although recent work has demonstrated a\nsystematic relationship between electrode location and the shape of the\nelicited visual percept, this knowledge has yet to be incorporated into retinal\nprosthesis design, where electrodes are typically arranged on either a\nrectangular or hexagonal grid. Here we optimize the intraocular placement of\nepiretinal electrodes using dictionary learning. Importantly, the optimization\nprocess is informed by a previously established and psychophysically validated\nmodel of simulated prosthetic vision. We systematically evaluate three\ndifferent electrode placement strategies across a wide range of possible\nphosphene shapes and recommend electrode arrangements that maximize visual\nsubfield coverage. In the near future, our work may guide the prototyping of\nnext-generation neuroprostheses."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: NEMAR: An open access data, tools, and compute resource operating on\n  NeuroElectroMagnetic data"}, {"role": "assistant", "content": "To take advantage of recent and ongoing advances in large-scale computational\nmethods, and to preserve the scientific data created by publicly funded\nresearch projects, data archives must be created as well as standards for\nspecifying, identifying, and annotating deposited data. The OpenNeuro.org\narchive, begun as a repository for magnetic resonance imaging (MRI) data, is\nsuch an archive. We present a gateway to OpenNeuro for human electrophysiology\ndata (BIDS-formatted EEG and MEG, as well as intracranial data). The NEMAR\ngateway allows users to visualize electrophysiological data, including\ntime-domain and frequency-domain dynamics time locked to sets of experimental\nevents recorded using BIDS- and HED-formatted data annotation. In addition,\nNEMAR allows users to process archived EEG data on the XSEDE high-performance\nresources at SDSC in conjunction with the Neuroscience Gateway (nsgportal.org),\na freely available and easy to use portal to leverage high-performance\ncomputing resources for neuroscience research."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Determining clinically relevant features in cytometry data using\n  persistent homology"}, {"role": "assistant", "content": "Cytometry experiments yield high-dimensional point cloud data that is\ndifficult to interpret manually. Boolean gating techniques coupled with\ncomparisons of relative abundances of cellular subsets is the current standard\nfor cytometry data analysis. However, this approach is unable to capture more\nsubtle topological features hidden in data, especially if those features are\nfurther masked by data transforms or significant batch effects or\ndonor-to-donor variations in clinical data. Analysis of publicly available\ncytometry data describing non-na\\\"ive CD8+ T cells in COVID-19 patients and\nhealthy controls shows that systematic structural differences exist between\nsingle cell protein expressions in COVID-19 patients and healthy controls. We\nidentify proteins of interest by a decision-tree based classifier, sample\npoints randomly and compute persistence diagrams from these sampled points. The\nresulting persistence diagrams identify regions in cytometry datasets of\nvarying density and identify protruded structures such as `elbows'. We compute\nWasserstein distances between these persistence diagrams for random pairs of\nhealthy controls and COVID-19 patients and find that systematic structural\ndifferences exist between COVID-19 patients and healthy controls in the\nexpression data for T-bet, Eomes, and Ki-67. Further analysis shows that\nexpression of T-bet and Eomes are significantly downregulated in COVID-19\npatient non-na\\\"ive CD8+ T cells compared to healthy controls. This\ncounter-intuitive finding may indicate that canonical effector CD8+ T cells are\nless prevalent in COVID-19 patients than healthy controls. This method is\napplicable to any cytometry dataset for discovering novel insights through\ntopological data analysis which may be difficult to ascertain otherwise with a\nstandard gating strategy or existing bioinformatic tools."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Using digital traces to build prospective and real-time county-level\n  early warning systems to anticipate COVID-19 outbreaks in the United States"}, {"role": "assistant", "content": "The ongoing COVID-19 pandemic continues to affect communities around the\nworld. To date, almost 6 million people have died as a consequence of COVID-19,\nand more than one-quarter of a billion people are estimated to have been\ninfected worldwide. The design of appropriate and timely mitigation strategies\nto curb the effects of this and future disease outbreaks requires close\nmonitoring of their spatio-temporal trajectories. We present machine learning\nmethods to anticipate sharp increases in COVID-19 activity in US counties in\nreal-time. Our methods leverage Internet-based digital traces -- e.g.,\ndisease-related Internet search activity from the general population and\nclinicians, disease-relevant Twitter micro-blogs, and outbreak trajectories\nfrom neighboring locations -- to monitor potential changes in population-level\nhealth trends. Motivated by the need for finer spatial-resolution\nepidemiological insights to improve local decision-making, we build upon\nprevious retrospective research efforts originally conceived at the state level\nand in the early months of the pandemic. Our methods -- tested in real-time and\nin an out-of-sample manner on a subset of 97 counties distributed across the US\n-- frequently anticipated sharp increases in COVID-19 activity 1-6 weeks before\nthe onset of local outbreaks (defined as the time when the effective\nreproduction number $R_t$ becomes larger than 1 consistently). Given the\ncontinued emergence of COVID-19 variants of concern -- such as the most recent\none, Omicron -- and the fact that multiple countries have not had full access\nto vaccines, the framework we present, while conceived for the county-level in\nthe US, could be helpful in countries where similar data sources are available."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A user-friendly tool to convert photon counting data to the open-source\n  Photon-HDF5 file format"}, {"role": "assistant", "content": "Photon-HDF5 is an open-source and open file format for storing\nphoton-counting data from single molecule microscopy experiments, introduced to\nsimplify data exchange and increase the reproducibility of data analysis. Part\nof the Photon-HDF5 ecosystem, is phconvert, an extensible python library that\nallows converting proprietary formats into Photon-HDF5 files. However, its use\nrequires some proficiency with command line instructions, the python\nprogramming language, and the YAML markup format. This creates a significant\nbarrier for potential users without that expertise, but who want to benefit\nfrom the advantages of releasing their files in an open format. In this work,\nwe present a GUI that lowers this barrier, thus simplifying the use of\nPhoton-HDF5. This tool uses the phconvert python library to convert data files\noriginally saved in proprietary data formats to Photon-HDF5 files, without\nusers having to write a single line of code. Because reproducible analyses\ndepend on essential experimental information, such as laser power or sample\ndescription, the GUI also includes (currently limited) functionality to\nassociate valid metadata with the converted file, without having to write any\nYAML. Finally, the GUI includes several productivity-enhancing features such as\nwhole-directory batch conversion and the ability to re-run a failed batch, only\nconverting the files that could not be converted in the previous run."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Clique-Based Method for Improving Motif Scanning Accuracy"}, {"role": "assistant", "content": "We present a new approach for improving motif scanning accuracy, based on\nanalysis of in-between similarity. Given a set of motifs obtained from a\nscanning process, we construct an associated weighted graph. We also compute\nthe expected weight of an edge in such a graph. It turns out that restricting\nresults to the maximal clique in the graph, computed with respect to the\nexpected weight, greatly increases precision, hence improves accuracy of the\nscan. We tested the method on an ungapped motif-characterized protein family\nfrom five plant proteomes. The method was applied to three iterative motif\nscanners - PSI-BLAST, JackHMMer and IGLOSS - with very good results"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Local accumulation times in a diffusion-trapping model of synaptic\n  receptor dynamics"}, {"role": "assistant", "content": "The lateral diffusion and trapping of neurotransmitter receptors within the\npostsynaptic membrane of a neuron plays a key role in determining synaptic\nstrength and plasticity. Trapping is mediated by the reversible binding of\nreceptors to scaffolding proteins (slots) within a synapse. In this paper we\nintroduce a new method for analyzing the transient dynamics of synapses in a\ndiffusion-trapping model of receptor trafficking. Given a population of\nspatially distributed synapses, each of which has a fixed number of slots, we\ncalculate the rate of relaxation to the steady-state distribution of bound\nslots (synaptic weights) in terms of a set of local accumulation times.\nAssuming that the rates of exocytosis and endocytosis are sufficiently slow, we\nshow that the steady-state synaptic weights are independent of each other\n(purely local). On the other hand, the local accumulation time of a given\nsynapse depends on the number of slots and the spatial location of all the\nsynapses, indicating a form of transient heterosynaptic plasticity. This\nsuggests that local accumulation time measurements could provide useful\ninformation regarding the distribution of synaptic weights within a dendrite."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Using genome-wide expression compendia to study microorganisms"}, {"role": "assistant", "content": "A gene expression compendium is a heterogeneous collection of gene expression\nexperiments assembled from data collected for diverse purposes. The widely\nvaried experimental conditions and genetic backgrounds across samples creates a\ntremendous opportunity for gaining a systems level understanding of the\ntranscriptional responses that influence phenotypes. Variety in experimental\ndesign is particularly important for studying microbes, where the\ntranscriptional responses integrate many signals and demonstrate plasticity\nacross strains including response to what nutrients are available and what\nmicrobes are present. Advances in high-throughput measurement technology have\nmade it feasible to construct compendia for many microbes. In this review we\ndiscuss how these compendia are constructed and analyzed to reveal\ntranscriptional patterns."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Implications of Mortality Displacement for Effect Modification and\n  Selection Bias"}, {"role": "assistant", "content": "Mortality displacement is the concept that deaths are moved forward in time\n(e.g., a few days, several months, and years) by exposure from when they would\noccur without the exposure, which is common in environmental time-series\nstudies. Using concepts of a frail population and loss of life expectancy, it\nis understood that mortality displacement may decrease rate ratio (RR). Such\ndecreases are thought to be minimal or substantial depending on study\npopulations. Environmental epidemiologists have interpreted RR considering\nmortality displacement. This theoretical paper reveals that mortality\ndisplacement can be formulated as a built-in selection bias of RR in Cox models\ndue to unmeasured risk factors independent from exposure of interest, and\nmortality displacement can also be viewed as an effect modifier by integrating\nthe concepts of rate and loss of life expectancy. Thus, depending on the\nframework through which we view bias, mortality displacement can be categorized\nas selection bias in the bias taxonomy of epidemiology, and simultaneously\nmortality displacement can be seen as an effect modifier. This dichotomy\nprovides useful implications regarding policy, effect modification, exposure\ntime-windows selection, and generalizability, specifically why research in\nepidemiology may produce unexpected and heterogeneous RR over different studies\nand sub-populations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: StrokeSight: A Novel EEG-Based Diagnostic System for Strokes Using\n  Spectral Analysis and Deep Learning"}, {"role": "assistant", "content": "A stroke is defined as a neurologic deficit arising from an interruption in\nblood supply to the brain. According to the World Health Organization, over 15\nmillion people suffer from strokes annually, of which almost 70% die or are\npermanently disabled. Effective treatment must be administered within one hour\nto prevent irreversible brain damage. Unfortunately, the current gold standards\nfor diagnosis, CT and MRI, are time-consuming, expensive, and immobile.\nElectroencephalograms reveal biomarkers of strokes while being inexpensive and\navailable for remote use, but no system exists that utilizes them for this\npurpose. To address this issue, we created StrokeSight, a novel, open-source\nweb application that automatically provides a full diagnosis and visualization\nof ischemic and hemorrhagic strokes in under 50 seconds using 60-second\nelectroencephalograms. We first calculated the averaged power spectral\ndensities for 132, 60-second electroencephalogram readings, which we then used\nto train three deep neural networks that respectively predict a stroke type\n(control/ischemic/hemorrhagic), location (left/right hemisphere), and severity\n(small/large) with accuracies of 97.5%, 94.4%, and 100%. StrokeSight also\nimplements a novel process to visualize spectral abnormalities caused by\nstrokes. Azimuthal equidistant projection and multivariate spline interpolation\nare used to reshape 3D electrodes onto a head-shaped 2D plane and then a\ncontour map of each frequency band power is created, allowing neurologists to\nquickly and accurately interpret electroencephalogram data. StrokeSight could\nact as a revolutionary solution for stroke care that drastically improves the\nspeed, cost efficiency, and accessibility of stroke diagnosis while allowing\nfor personalized treatment and interpretation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Low-fat diets and testosterone in men: Systematic review and\n  meta-analysis of intervention studies"}, {"role": "assistant", "content": "Background: Higher endogenous testosterone levels are associated with reduced\nchronic disease risk and mortality. Since the mid-20th century, there have been\nsignificant changes in dietary patterns, and men's testosterone levels have\ndeclined in western countries. Cross-sectional studies show inconsistent\nassociations between fat intake and testosterone in men.\n  Methods: Studies eligible for inclusion were intervention studies, with\nminimal confounding variables, comparing the effect of low-fat vs high-fat\ndiets on men's sex hormones. 9 databases were searched from their inception to\nOctober 2020, yielding 6 eligible studies, with a total of 206 participants.\nRandom effects meta-analyses were performed using Cochrane's Review Manager\nsoftware. Cochrane's risk of bias tool was used for quality assessment.\n  Results: There were significant decreases in sex hormones on low-fat vs\nhigh-fat diets. Standardised mean differences with 95% confidence intervals\n(CI) for outcomes were: total testosterone [-0.38 (95% CI -0.75 to -0.01) P =\n0.04]; free testosterone [-0.37 (95% CI -0.63 to -0.11) P = 0.005]; urinary\ntestosterone [-0.38 (CI 95% -0.66 to -0.09) P = 0.009], and dihydrotestosterone\n[-0.3 (CI 95% -0.56 to -0.03) P = 0.03]. There were no significant differences\nfor luteinising hormone or sex hormone binding globulin. Subgroup analysis for\ntotal testosterone, European and American men, showed a stronger effect [-0.52\n(95% CI -0.75 to -0.3) P < 0.001].\n  Conclusions: Low-fat diets appear to decrease testosterone levels in men, but\nfurther randomised controlled trials are needed to confirm this effect. Men\nwith European ancestry may experience a greater decrease in testosterone, in\nresponse to a low-fat diet."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Interpretable RNA Foundation Model from Unannotated Data for Highly\n  Accurate RNA Structure and Function Predictions"}, {"role": "assistant", "content": "Non-coding RNA structure and function are essential to understanding various\nbiological processes, such as cell signaling, gene expression, and\npost-transcriptional regulations. These are all among the core problems in the\nRNA field. With the rapid growth of sequencing technology, we have accumulated\na massive amount of unannotated RNA sequences. On the other hand, expensive\nexperimental observatory results in only limited numbers of annotated data and\n3D structures. Hence, it is still challenging to design computational methods\nfor predicting their structures and functions. The lack of annotated data and\nsystematic study causes inferior performance. To resolve the issue, we propose\na novel RNA foundation model (RNA-FM) to take advantage of all the 23 million\nnon-coding RNA sequences through self-supervised learning. Within this\napproach, we discover that the pre-trained RNA-FM could infer sequential and\nevolutionary information of non-coding RNAs without using any labels.\nFurthermore, we demonstrate RNA-FM's effectiveness by applying it to the\ndownstream secondary/3D structure prediction, SARS-CoV-2 genome structure and\nevolution prediction, protein-RNA binding preference modeling, and gene\nexpression regulation modeling. The comprehensive experiments show that the\nproposed method improves the RNA structural and functional modelling results\nsignificantly and consistently. Despite only being trained with unlabelled\ndata, RNA-FM can serve as the foundational model for the field."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Modeling COVID-19 vaccine-induced immunological memory development and\n  its links to antibody level and infectiousness"}, {"role": "assistant", "content": "COVID-19 vaccines have proven to be effective against SARS-CoV-2 infection.\nHowever, the dynamics of vaccine-induced immunological memory development and\nneutralizing antibodies generation are not fully understood, limiting vaccine\ndevelopment and vaccination regimen determination. Herein, we constructed a\nmathematical model to characterize the vaccine-induced immune response based on\nfitting the viral infection and vaccination datasets. With the example of\nCoronaVac, we revealed the association between vaccine-induced immunological\nmemory development and neutralizing antibody levels. The establishment of the\nintact immunological memory requires more than 6 months after the first and\nsecond doses, after that a booster shot can induce high levels neutralizing\nantibodies. By introducing the maximum viral load and recovery time after viral\ninfection, we quantitatively studied the protective effect of vaccines against\nviral infection. Accordingly, we optimized the vaccination regimen, including\ndose and vaccination timing, and predicted the effect of the fourth dose. Last,\nby combining the viral transmission model, we showed the suppression of virus\ntransmission by vaccination, which may be instructive for the development of\npublic health policies."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Topological Data Analysis of Human Brain Networks Through Order\n  Statistics"}, {"role": "assistant", "content": "Understanding the common topological characteristics of the human brain\nnetwork across a population is central to understanding brain functions. The\nabstraction of human connectome as a graph has been pivotal in gaining insights\non the topological properties of the brain network. The development of\ngroup-level statistical inference procedures in brain graphs while accounting\nfor the heterogeneity and randomness still remains a difficult task. In this\nstudy, we develop a robust statistical framework based on persistent homology\nusing the order statistics for analyzing brain networks. The use of order\nstatistics greatly simplifies the computation of the persistent barcodes. We\nvalidate the proposed methods using comprehensive simulation studies and\nsubsequently apply to the resting-state functional magnetic resonance images.\nWe found a statistically significant topological difference between the male\nand female brain networks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Leveraging Reaction-aware Substructures for Retrosynthesis Analysis"}, {"role": "assistant", "content": "Retrosynthesis analysis is a critical task in organic chemistry central to\nmany important industries. Previously, various machine learning approaches have\nachieved promising results on this task by representing output molecules as\nstrings and autoregressively decoded token-by-token with generative models.\nText generation or machine translation models in natural language processing\nwere frequently utilized approaches. The token-by-token decoding approach is\nnot intuitive from a chemistry perspective because some substructures are\nrelatively stable and remain unchanged during reactions. In this paper, we\npropose a substructure-level decoding model, where the substructures are\nreaction-aware and can be automatically extracted with a fully data-driven\napproach. Our approach achieved improvement over previously reported models,\nand we find that the performance can be further boosted if the accuracy of\nsubstructure extraction is improved. The substructures extracted by our\napproach can provide users with better insights for decision-making compared to\nexisting methods. We hope this work will generate interest in this fast growing\nand highly interdisciplinary area on retrosynthesis prediction and other\nrelated topics."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Accurate Clinical Toxicity Prediction using Multi-task Deep Neural Nets\n  and Contrastive Molecular Explanations"}, {"role": "assistant", "content": "Explainable ML for molecular toxicity prediction is a promising approach for\nefficient drug development and chemical safety. A predictive ML model of\ntoxicity can reduce experimental cost and time while mitigating ethical\nconcerns by significantly reducing animal and clinical testing. Herein, we use\na deep learning framework for simultaneously modeling in vitro, in vivo, and\nclinical toxicity data. Two different molecular input representations are used:\nMorgan fingerprints and pre-training SMILES embeddings. A multi-task deep\nlearning model accurately predicts toxicity for all endpoints, including\nclinical, as indicated by AUROC and balanced accuracy. In particular, SMILES\nembeddings as input to the multi-task model improved clinical toxicity\npredictions compared to existing models in MoleculeNet benchmark. Additionally,\nour multi-task approach is comprehensive in the sense that it is comparable to\nstate-of-the-art approaches for specific endpoints in in vitro, in vivo and\nclinical platforms. Through both the multi-task model and transfer learning, we\nwere able to indicate the minimal need of in vivo data for clinical toxicity\npredictions. To provide confidence and explain the model's predictions, we\nadapt a post-hoc contrastive explanation method that returns pertinent positive\nand pertinent negative features, which correspond well to known mutagenic and\nreactive toxicophores, such as unsubstituted bonded heteroatoms, aromatic\namines, and Michael receptors. Furthermore, toxicophore recovery by pertinent\nfeature analysis captures more of the in vitro (53%) and in vivo (56%), rather\nthan of the clinical (8%), endpoints, and indeed uncovers a preference in known\ntoxicophore data towards in vitro and in vivo experimental data. To our\nknowledge, this is the first contrastive explanation, using both present and\nabsent substructures, for predictions of clinical and in vivo molecular\ntoxicity."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The Poisson algorithm: a simple method to simulate stochastic epidemic\n  models with generally distributed residence times"}, {"role": "assistant", "content": "Epidemic models are used to analyze the progression or outcome of an epidemic\nunder different control policies like vaccinations, quarantines, lockdowns, use\nof face-masks, pharmaceutical interventions, etc. When these models accurately\nrepresent real-life situations, they may become an important tool in the\ndecision-making process. Among these models, compartmental models are very\npopular and assume individuals move along a series of compartments that\ndescribe their current health status. Nevertheless, these models are mostly\nMarkovian, that is, the time in each compartment follows an exponential\ndistribution. In epidemic models, exponential sojourn times are most of the\ntimes unrealistic, for instance, they imply that the probability that a patient\nwill recover from some disease in the next time unit is independent of the time\nthe patient has been sick. This is an important restriction that prevents these\nmodels from being widely accepted and trusted by decision-makers. In spite of\nthe need to incorporate algorithms to tackle the problem, literature on the\ntopic is scarce. Here, we introduce a novel approach to simulate general\nstochastic epidemic models that accepts any distribution for the sojourn times\nthat is efficient."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Optimality of intercellular signaling: direct transport versus diffusion"}, {"role": "assistant", "content": "Intercellular signaling has an important role in organism development, but\nnot all communication occurs using the same mechanism. Here, we analyze the\nenergy efficiency of intercellular signaling by two canonical mechanisms:\ndiffusion of signaling molecules and direct transport mediated by signaling\ncellular protrusions. We show that efficient contact formation for direct\ntransport can be established by an optimal rate of projecting protrusions,\nwhich depends on the availability of information about the location of the\ntarget cell. The optimal projection rate also depends on how signaling\nmolecules are transported along the protrusion, in particular the ratio of the\nenergy cost for contact formation and molecule synthesis. Also, we compare the\nefficiency of the two signaling mechanisms, under various model parameters. We\nfind that the direct transport is favored over the diffusion when transporting\na large amount of signaling molecules. There is a critical number of signaling\nmolecules at which the efficiency of the two mechanisms are the same. The\ncritical number is small when the distance between cells is far, which helps\nexplain why protrusion-based mechanisms are observed in long-range cellular\ncommunications."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: ProTranslator: zero-shot protein function prediction using textual\n  description"}, {"role": "assistant", "content": "Accurately finding proteins and genes that have a certain function is the\nprerequisite for a broad range of biomedical applications. Despite the\nencouraging progress of existing computational approaches in protein function\nprediction, it remains challenging to annotate proteins to a novel function\nthat is not collected in the Gene Ontology and does not have any annotated\nproteins. This limitation, a side effect from the widely-used multi-label\nclassification problem setting of protein function prediction, hampers the\nprogress of studying new pathways and biological processes, and further slows\ndown research in various biomedical areas. Here, we tackle this problem by\nannotating proteins to a function only based on its textual description so that\nwe do not need to know any associated proteins for this function. The key idea\nof our method ProTranslator is to redefine protein function prediction as a\nmachine translation problem, which translates the description word sequence of\na function to the amino acid sequence of a protein. We can then transfer\nannotations from functions that have similar textual description to annotate a\nnovel function. We observed substantial improvement in annotating novel\nfunctions and sparsely annotated functions on CAFA3, SwissProt and GOA\ndatasets. We further demonstrated how our method accurately predicted gene\nmembers for a given pathway in Reactome, KEGG and MSigDB only based on the\npathway description. Finally, we showed how ProTranslator enabled us to\ngenerate the textual description instead of the function label for a set of\nproteins, providing a new scheme for protein function prediction. We envision\nProTranslator will give rise to a protein function \"search engine\" that returns\na list of proteins based on the free text queried by the user."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: In silico evaluation of Paxlovid's pharmacometrics for SARS-CoV-2: a\n  multiscale approach"}, {"role": "assistant", "content": "Paxlovid is a promising, orally bioavailable novel drug for SARS--CoV--2 with\nexcellent safety profiles. Our main goal here is to explore the pharmacometric\nfeatures of this new antiviral. To provide a detailed assessment of Paxlovid,\nwe propose a hybrid multiscale mathematical approach. We demonstrate that the\nresults of the present \\textit{in silico} evaluation match the clinical\nexpectations remarkably well: on the one hand, our computations successfully\nreplicate the outcome of an actual \\textit{in vitro} experiment; on the other\nhand we verify both the sufficiency and the necessity of Paxlovid's two main\ncomponents (nirmatrelvir and ritonavir) for a simplified \\textit{in vivo} case.\nMoreover, in the simulated context of our computational framework we visualize\nthe importance of early interventions, and identify the time window where a\nunit--length delay causes the highest level of tissue damage. Finally, the\nresults' sensitivity to the diffusion coefficient of the virus is explored in\ndetails."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Data augmentation and multimodal learning for predicting drug response\n  in patient-derived xenografts from gene expressions and histology images"}, {"role": "assistant", "content": "Patient-derived xenografts (PDXs) are an appealing platform for preclinical\ndrug studies because the in vivo environment of PDXs helps preserve tumor\nheterogeneity and usually better mimics drug response of patients with cancer\ncompared to CCLs. We investigate multimodal neural network (MM-Net) and data\naugmentation for drug response prediction in PDXs. The MM-Net learns to predict\nresponse using drug descriptors, gene expressions (GE), and histology\nwhole-slide images (WSIs) where the multi-modality refers to the tumor\nfeatures. We explore whether the integration of WSIs with GE improves\npredictions as compared with models that use GE alone. We use two methods to\naddress the limited number of response values: 1) homogenize drug\nrepresentations which allows to combine single-drug and drug-pairs treatments\ninto a single dataset, 2) augment drug-pair samples by switching the order of\ndrug features which doubles the sample size of all drug-pair samples. These\nmethods enable us to combine single-drug and drug-pair treatments, allowing us\nto train multimodal and unimodal neural networks (NNs) without changing\narchitectures or the dataset. Prediction performance of three unimodal NNs\nwhich use GE are compared to assess the contribution of data augmentation\nmethods. NN that uses the full dataset which includes the original and the\naugmented drug-pair treatments as well as single-drug treatments significantly\noutperforms NNs that ignore either the augmented drug-pairs or the single-drug\ntreatments. In assessing the contribution of multimodal learning based on the\nMCC metric, MM-Net statistically significantly outperforms all the baselines.\nOur results show that data augmentation and integration of histology images\nwith GE can improve prediction performance of drug response in PDXs."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: SBMLDiagrams: A python package to process and visualize SBML layout and\n  render"}, {"role": "assistant", "content": "Summary: The Systems Biology Markup Language (SBML) is an extensible standard\nformat for exchanging biochemical models. One of the extensions for SBML is the\nSBML Layout and Render package. This allows modelers to describe a biochemical\nmodel as a pathway diagram. However, up to now there has been little support to\nhelp users easily add and retrieve such information from SBML. In this\napplication note, we describe a new Python package called SBMLDiagrams. This\npackage allows a user to add layout and render information or retrieve it using\na straightforward Python API. The package uses skia-python to support the\nrendering of the diagrams, allowing export to commons formats such as PNG or\nPDF. Availability: SBMLDiagrams is publicly available and licensed under the\nliberal MIT open-source license. The package is available for all major\nplatforms. The source code has been deposited at GitHub\n(github.com/sys-bio/SBMLDiagrams). Users can install the package using the\nstandard pip installation mechanism: pip install SBMLDiagrams. Contact:\nhsauro@uw.edu."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: LAST: Latent Space Assisted Adaptive Sampling for Protein Trajectories"}, {"role": "assistant", "content": "Molecular dynamics (MD) simulation is widely used to study protein\nconformations and dynamics. However, conventional simulation suffers from being\ntrapped in some local energy minima that are hard to escape. Thus, most\ncomputational time is spent sampling in the already visited regions. This leads\nto an inefficient sampling process and further hinders the exploration of\nprotein movements in affordable simulation time. The advancement of deep\nlearning provides new opportunities for protein sampling. Variational\nautoencoders are a class of deep learning models to learn a low-dimensional\nrepresentation (referred to as the latent space) that can capture the key\nfeatures of the input data. Based on this characteristic, we proposed a new\nadaptive sampling method, latent space assisted adaptive sampling for protein\ntrajectories (LAST), to accelerate the exploration of protein conformational\nspace. This method comprises cycles of (i) variational autoencoders training,\n(ii) seed structure selection on the latent space and (iii) conformational\nsampling through additional MD simulations. The proposed approach is validated\nthrough the sampling of four structures of two protein systems: two metastable\nstates of E. Coli adenosine kinase (ADK) and two native states of Vivid (VVD).\nIn all four conformations, seed structures were shown to lie on the boundary of\nconformation distributions. Moreover, large conformational changes were\nobserved in a shorter simulation time when compared with conventional MD (cMD)\nsimulations in both systems. In metastable ADK simulations, LAST explored two\ntransition paths toward two stable states while cMD became trapped in an energy\nbasin. In VVD light state simulations, LAST was three times faster than cMD\nsimulation with a similar conformational space."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Joint Track Machine Learning: An autonomous method for measuring 6DOF\n  TKA kinematics from single-plane x-ray images"}, {"role": "assistant", "content": "Dynamic radiographic measurement of 3D TKA kinematics has provided important\ninformation for implant design and surgical technique for over 30 years.\nHowever, current methods of measuring TKA kinematics are too cumbersome or\ntime-consuming for practical clinical application. Even state-of-the-art\ntechniques require human-supervised initialization or human supervision\nthroughout the entire optimization process. Elimination of human supervision\ncould potentially bring this technology into clinical practicality. Therefore,\nwe propose a fully autonomous pipeline for quantifying TKA kinematics from\nsingle-plane imaging. First, a convolutional neural network segments the\nfemoral and tibial implants from the image. Second, segmented images are\ncompared to Normalized Fourier Descriptor shape libraries for initial pose\nestimates. Lastly, a Lipschitzian optimization routine minimizes the difference\nbetween the segmented image and the projected implant. This technique reliably\nreproduces human-supervised kinematics measurements from internal datasets and\nexternal validation studies, with RMS differences of less than 0.7mm and\n4{\\deg} for internal studies and 0.8mm and 1.7{\\deg} for external validation\nstudies. This performance indicates that it will soon be practical to perform\nthese measurements in a clinical setting."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A whole-body multi-scale mathematical model for dynamic simulation of\n  the metabolism in man"}, {"role": "assistant", "content": "We propose a whole-body model of the metabolism in man as well as a\ngeneralized approach for modeling metabolic networks. Using this approach, we\nare able to write a large metabolic network in a systematic and compact way. We\ndemonstrate the approach using a whole-body model of the metabolism of the\nthree macronutrients, carbohydrates, proteins and lipids. The model contains 7\norgans, 16 metabolites and 31 enzymatic reactions. All reaction rates are\ndescribed by Michaelis-Menten kinetics with an addition of a hormonal regulator\nbased on the two hormones insulin and glucagon. We incorporate ingestion of\nfood in order to simulate metabolite concentrations during the feed-fast cycle.\nThe model can simulate several days due to the inclusion of storage forms\n(glycogen, muscle protein and lipid droplets), that can be depleted if food is\nnot ingested regularly. A physiological model incorporating complex cellular\nmetabolism and whole-body mass dynamics can be used in virtual clinical trials.\nSuch trials can be used to improve the development of medicine, treatment\nstrategies such as control algorithms, and increase the likelihood of a\nsuccessful clinical trial."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: FlavorDB2: An Updated Database of Flavor Molecules"}, {"role": "assistant", "content": "Flavor is expressed through interaction of molecules via gustatory and\nolfactory mechanisms. Knowing the utility of flavor molecules in food and\nfragrances, it is valuable to add a comprehensive repository of flavor\ncompounds characterizing their flavor profile, chemical properties, regulatory\nstatus, consumption statistics, taste/aroma threshold values, reported uses in\nfood categories, and synthesis. FlavorDB2\n(https://cosylab.iiitd.edu.in/flavordb2/) is an updated database of flavor\nmolecules with an user-friendly interface. This repository simplifies the\nsearch for flavor molecules, their attributes and offers a range of\napplications including food pairing. FlavorDB2 serves as a standard repository\nof flavor compounds."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Image and graph convolution networks improve microbiome-based machine\n  learning accuracy"}, {"role": "assistant", "content": "The human gut microbiome is associated with a large number of disease\netiologies. As such, it is a natural candidate for machine learning based\nbiomarker development for multiple diseases and conditions. The microbiome is\noften analyzed using 16S rRNA gene sequencing. However, several properties of\nmicrobial 16S rRNA gene sequencing hinder machine learning, including\nnon-uniform representation, a small number of samples compared with the\ndimension of each sample, and sparsity of the data, with the majority of\nbacteria present in a small subset of samples. We suggest two novel methods to\ncombine information from different bacteria and improve data representation for\nmachine learning using bacterial taxonomy. iMic and gMic translate the\nmicrobiome to images and graphs respectively, and convolutional neural networks\nare then applied to the graph or image. We show that both algorithms improve\nperformance of static 16S rRNA gene sequence-based machine learning compared to\nthe best state-of-the-art methods. Furthermore, these methods ease the\ninterpretation of the classifiers. iMic is then extended to dynamic microbiome\nsamples, and an iMic explainable AI algorithm is proposed to detect bacteria\nrelevant to each condition."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The Relationship Between Insulin Resistance Neutrophil to Lymphocyte\n  Ratio"}, {"role": "assistant", "content": "Aim: There is increasing interest in the role of chronic inflammation on\npathogenesis of various disease, and one of its markers, high NLR is associated\nwith various mortality and morbidity risk. Insulin resistance (IR) might be one\npotential associate factors, as suggested in preclinical studies. However,\nepidemiological studies are scarce which investigated the association between\nNLR, and insulin resistance (IR) and they included only diabetes mellitus\npatients, not the general population. This study aims to determine if there is\na direct correlation between NLR and IR in the US general population. Methods:\nThe sample consists of 3,307 from general population, provided by National\nHealth and Nutrition Examination Survey (NHANES). Homeostasis Model Assessment\nof Insulin Resistance (HOMA-IR) value was calculated to evaluate insulin\nresistance. We investigated the relationship between their NLR and HOMA-IR\nvalues by bivariate and multivariate linear regression analyses. As insulin use\ncould results in inaccurate HOMA-IR estimation, we excluded them and ran the\nanalyses in subgroup analyses. Results: There was a relationship shown when\ninsulin users were included, having a beta coefficient value of 0.010 (95%\nconfidence interval [CI] of 0.003-0.017). However, when insulin users were\nexcluded, the beta value decreased to 0.004 (95% CI of -0.006-0.015). The\nstatistical significance was not reached when age, sex, and body mass index\nwere adjusted for in the multivariate analyses. Conclusion: There is no visible\nrelationship between IR and NLR in the general population. IR might not explain\nthe variation of NLR value in healthy people, and further studies are needed to\nreveal the associated factor of high NLR."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Slim: interoperable slide microscopy viewer and annotation tool for\n  imaging data science and computational pathology"}, {"role": "assistant", "content": "The exchange of large and complex slide microscopy imaging data in biomedical\nresearch and pathology practice is impeded by a lack of data standardization\nand interoperability, which is detrimental to the reproducibility of scientific\nfindings and clinical integration of technological innovations. Slim is an\nopen-source, web-based slide microscopy viewer that implements the\ninternationally accepted Digital Imaging and Communications in Medicine (DICOM)\nstandard to achieve interoperability with a multitude of existing medical\nimaging systems. We showcase the capabilities of Slim as the slide microscopy\nviewer of the NCI Imaging Data Commons and demonstrate how the viewer enables\ninteractive visualization of traditional brightfield microscopy and\nhighly-multiplexed immunofluorescence microscopy images from The Cancer Genome\nAtlas and Human Tissue Atlas Network, respectively, using standard DICOMweb\nservices. We further show how Slim enables the collection of standardized image\nannotations for the development or validation of machine learning models and\nthe visual interpretation of model inference results in the form of\nsegmentation masks, spatial heat maps, or image-derived measurements."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Resource allocation determines alternate cell fate in Bistable Genetic\n  Switch"}, {"role": "assistant", "content": "Living cells need a constant availability of certain resources to have a\nsustained gene expression process. Limited availability of cellular resources\nfor gene expression, like ribosomes, along with a variation of resource\naffinity, significantly modifies the system dynamics. Factors like the\nvariation in rate of binding, or variation in efficiency of the recruited\nresource have the potential to affect crucial dynamical phenomena like cell\nfate determination. In this paper, we have taken a very important motif, a\nbistable genetic toggle switch, and explored the effect of resource imbalance\nin this circuit in terms of the bifurcations taking place. We show that initial\nasymmetric biasing to resource via resource affinity or gene copy number,\nsignificantly modifies the cell fate transition, both in pitchfork and saddle\nnode type bifurcation. Our study establishes that in a limited resource\nenvironment, controlled resource allocation can be an important factor for\nrobust functioning of the synthetic or cellular genetic switches."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Bayesian inference for models of moult duration and timing"}, {"role": "assistant", "content": "Moult is an essential life-history event in mammals and birds, as the\nmaintenance of fur and feathers is critical for survival. Despite this moult\nremains a poorly understood life-history event. This may in part be because the\nrobust analysis of moult observations requires non-standard statistical\ntechniques. We present extensions to existing moult phenology models which\naccommodate features of real world moult datasets, such as repeated measures\ndata and misclassified data. We describe the theory behind the extended moult\nphenology models, and demonstrate that the extensions can improve inferences\nunder a wide range of sampling conditions. We implement a Bayesian inference\nframework for existing and extended moult phenology models in moultmcmc , an R\npackage using fast Hamiltonian Monte Carlo sampling. Our package provides an\ninterface for modelling moult phenology data from real world datasets and\nthereby further facilitates the uptake of appropriate statistical methods for\nsuch data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The evidence contained in the P-value is context dependent"}, {"role": "assistant", "content": "In a recent opinion article, Muff et al. recapitulate well-known objections\nto the Neyman-Pearson Null-Hypothesis Significance Testing (NHST) framework and\ncall for reforming our practices in statistical reporting. We agree with them\non several important points: the significance threshold P<0.05 is only a\nconvention, chosen as a compromise between type I and II error rates;\ntransforming the p-value into a dichotomous statement leads to a loss of\ninformation; and p-values should be interpreted together with other statistical\nindicators, in particular effect sizes and their uncertainty. In our view, a\nlot of progress in reporting results can already be achieved by keeping these\nthree points in mind. We were surprised and worried, however, by Muff et al.'s\nsuggestion to interpret the p-value as a \"gradual notion of evidence\". Muff et\nal. recommend, for example, that a P-value > 0.1 should be reported as \"little\nor no evidence\" and a P-value of 0.001 as \"strong evidence\" in favor of the\nalternative hypothesis H1."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: DNA Storage Error Simulator: A Tool for Simulating Errors in Synthesis,\n  Storage, PCR and Sequencing"}, {"role": "assistant", "content": "DNA has many valuable characteristics that make it suitable for a long-term\nstorage medium, in particular its durability and high information density. DNA\ncan be stored safely for hundreds of years with virtually no degradation, in\ncontrast to hard disk drives which typically last for about 5 years.\nFurthermore, the duration of DNA-Storage can be extended to potentially up to\nthousands of years if it is desiccated and cooled in storage.\n  Advances in DNA technologies have made it possible to store the entirety of\nWikipedia in a test tube and read that information using a handheld sequencing\ndevice, although imperfections in writing (synthesis) and reading (sequencing)\nneed to be mitigated for it to be viable as a mainstream storage medium. New\nsequencing technologies, such as nanopore sequencing, aim to penetrate the\nconsumer world, thanks to their affordability and size. However, the error\ncharacteristics of nanopore sequencing are not yet well characterised.\n  DNA Storage Error Simulator models errors that can be introduced in all the\nphases of DNA storage workflow, including synthesis, storage, PCR for\namplification and finally sequencing. The error characteristics for sequencing\nand synthesis can be configured in all necessary detail or can be chosen from a\npredefined set of values based on available literature and our own analysis.\n  Availability: DNA Storage Error Simulator can be accessed online from:\nhttps://master.dbahb2jho41s4.amplifyapp.com\n(https://dnastorage.doc.ic.ac.uk/DNA-error-simulator)"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Drug Repurposing For SARS-COV-2 Using Molecular Docking"}, {"role": "assistant", "content": "Drug repurposing is an unconventional approach that is used to investigate\nnew therapeutic aids of existing and shelved drugs. Recent advancement in\ntechnologies and the availability of the data of genomics, proteomics,\ntranscriptomics, etc., and with the accessibility of large and reliable\ndatabase resources, there are abundantly of opportunities to discover drugs by\ndrug repurposing in an efficient manner. The recent pandemic of SARS-COV-2,\nthat caused the death of 6,245,750 human beings to date, has tremendously\nincrease the exceptional usage of bioinformatics tools in interpreting the\nmolecular characterizations of viral infections. In this paper, we have\nemployed various bioinformatics tools such as AutoDock-Vina, PyMol etc. We have\nfound a leading drug candidate Cepharanthine that has shown better results and\neffectiveness than recently used antiviral drug candidates such as Favipiravir,\nIDX184, Remedesivir, Ribavirin and etc. This paper has analyzed Cepharanthine\npotential therapeutic importance as a drug of choice in managing COVID-19\ncases. It is anticipated that proposed study would be beneficial for\nresearchers and medical practitioners in handling SARS-CoV-2 and its variant\nrelated diseases."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Online FDR Control for RNAseq Data"}, {"role": "assistant", "content": "Motivation: While the analysis of a single RNA sequencing (RNAseq) dataset\nhas been well described in the literature, modern research workflows often have\nadditional complexity in that related RNAseq experiments are performed\nsequentially over time. The simplest and most widely used analysis strategy\nignores the temporal aspects and analyses each dataset separately. However,\nthis can lead to substantial inflation of the overall false discovery rate\n(FDR). We propose applying recently developed methodology for online hypothesis\ntesting to analyse sequential RNAseq experiments in a principled way,\nguaranteeing FDR control at all times while never changing past decisions.\nResults: We show that standard offline approaches have variable control of FDR\nof related RNAseq experiments over time and a naively composed approach may\nimproperly change historic decisions. We demonstrate that the online FDR\nalgorithms are a principled way to guarantee control of FDR. Furthermore, in\ncertain simulation scenarios, we observe empirically that online approaches\nhave comparable power to offline approaches. Availability and Implementation:\nThe onlineFDR package is freely available at http:\n//www.bioconductor.org/packages/onlineFDR. Additional code used for the\nsimulation studies can be found at\nhttps://github.com/latlio/onlinefdr_rnaseq_simulation"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Comparison of aerosol emissions during specific speech tasks"}, {"role": "assistant", "content": "The study of aerosols and droplets emitted from the oral cavity has become\nincreasingly important throughout the COVID-19 pandemic. Studies show\nparticulates emitted while speaking were generally much smaller compared to\ncoughing or sneezing. However, recent investigations revealed that they are\nlarge enough to carry respiratory contagions. Although studies have shown that\nparticulate emissions do indeed occur during speech, to date, there is little\ninformation about the relative contribution of different speech sounds in\nproducing particle emissions. This study compares airborne aerosol generation\nin participants producing isolated speech sounds: fricative consonants, plosive\nconsonants, and vowel sounds. While participants produced isolated speech\ntasks, a planar beam of laser light, a high-speed camera, and image software\ncalculated the number of particulates detected overtime. This study compares\nairborne aerosols emitted by human participants at a distance of 2.54 cm\nbetween the laser sheet and the mouth and reveals statistically significant\nincreases in particulate counts over ambient dust distribution for all speech\nsounds. Vowel sounds were statistically greater than consonants, suggesting\nthat mouth opening, as opposed to place of vocal tract constriction or manner\nof sound production, might be the primary influence in the degree to which\nparticulates become aerosolized during speech. Results of this research will\ninform boundary conditions for computation models of aerosolized particulates\nduring speech."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Structural identifiability of compartmental models for infectious\n  disease transmission is influenced by data type"}, {"role": "assistant", "content": "If model identifiability is not confirmed, inferences from infectious disease\ntransmission models may not be reliable, so they might lead to misleading\nrecommendations. Structural identifiability analysis characterizes whether it\nis possible to obtain unique solutions for all unknown model parameters, given\nthe model structure. In this work, we studied the structural identifiability of\nsome typical deterministic compartmental models for infectious disease\ntransmission, focusing on the influence of the data type considered as model\noutput on the identifiability of unknown model parameters, including initial\nconditions. We defined 26 model versions, each having a unique combination of\nunderlying compartmental structure and data type(s) considered as model\noutput(s). Four compartmental model structures and three common data types in\ndisease surveillance (incidence, prevalence and detected vector counts) were\nstudied. The structural identifiability of some parameters varied depending on\nthe type of model output. In general, models with multiple data types as\noutputs had more structurally identifiable parameters, than did models with a\nsingle data type as output. This study highlights the importance of a careful\nconsideration of data types as an integral part of the inference process with\ncompartmental infectious disease transmission models."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Characterization of Blast Waveforms Produced by Different Driver Gasses\n  in an Open-Ended Shock Tube Model"}, {"role": "assistant", "content": "With the evolution of modern warfare and the increased use of improvised\nexplosive devices (IEDs), there has been an increase in blast-induced traumatic\nbrain injuries (bTBI) among military personnel and civilians. The increased\nprevalence of bTBI necessitates bTBI models that result in a properly scaled\ninjury for the model organism being used. The primary laboratory model for bTBI\nis the shock tube, wherein a compressed gas ruptures a thin membrane,\ngenerating a shockwave. To generate a shock wave that is properly scaled from\nhuman to rodent subjects the shock wave must have a short duration and high\npeak overpressure while fitting a Friedlander waveform, the ideal\nrepresentation of a blast wave. A large variety of factors have been\nexperimentally characterized in attempts to create an ideal waveform, however\nwe found current research on the gas composition being used to drive shock wave\nformation to be lacking. To better understand the effect the driver gas has on\nthe waveform being produced, we utilized a previously established murine shock\ntube bTBI model in conjunction with several distinct driver gasses. In\nagreement with previous findings, helium produced a shock wave most closely\nfitting the Friedlander waveform in contrast to the plateau-like waveforms\nproduced by some other gases. The peak pressure at the exit of the shock tube\nand 5 cm from the exit have a strong negative correlation with the density of\nthe gas being used: helium the least dense gas used produces the highest peak\noverpressure. Density of the driver gas also exerts a strong positive effect on\nthe duration of the shock wave, with helium producing the shortest duration\nwave. Due to its ability to produce a Friedlander waveform and produce a\nwaveform following proper injury scaling guidelines, helium is an ideal gas for\nuse in shock tube models for bTBI."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Prediction and experimental evidence of the optimisation of the angular\n  branching process in the thallus growth of Podospora anserina"}, {"role": "assistant", "content": "Based upon apical growth and hyphal branching, the two main processes that\ndrive the growth pattern of a fungal network, we propose here a two-dimensions\nsimulation based on a binary-tree modelling allowing us to extract the main\ncharacteristics of a generic thallus growth. In particular, we showed that, in\na homogeneous environment, the fungal growth can be optimized for exploration\nand exploitation of its surroundings with a specific angular distribution of\napical branching. Two complementary methods of extracting angle values have\nbeen used to confront the result of the simulation with experimental data\nobtained from the thallus growth of the saprophytic filamentous fungus\nPodospora anserina. Finally, we propose here a validated model that, while\nbeing computationally low-cost, is powerful enough to test quickly multiple\nconditions and constraints. It will allow in future works to deepen the\ncharacterization of the growth dynamic of fungal network, in addition to\nlaboratory experiments, that could be sometimes expensive, tedious or of\nlimited scope."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Simulation, Modeling and Prediction of a Pharmacodynamic Animal Tissue\n  Culture Compartment Model by Physical Informed Neural Network"}, {"role": "assistant", "content": "Compartment models of cell culture are widely used in cytology, pharmacology,\ntoxicology and other fields. Numerical simulation, data modeling and prediction\nof compartment models can be realized by traditional differential equation\nmodeling methods. At the same time, with the development of software and\nhardware, Physical Informed Neural Network (PINN) is widely used to solve\ndifferential equation models. This work models, simulates and predicts the cell\nculture compartment model based on the machine learning framework PyTorch with\nan 16 hidden layers neural network, including 8 linear layers and 8 feedback\nactive layers. The results showed a loss value of 0.0004853 for three-component\nfour-parameter quantitative pharmacodynamic model predictions in this way,\nwhich is evaluated by Mean Square Error (MSE). In summary, Physical Informed\nNeural Network can serve as an effective tool to deal with cell culture\ncompartment models and may perform better in dealing with big datasets."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Modeling membrane curvature generation using mechanics and machine\n  learning"}, {"role": "assistant", "content": "The deformation of cellular membranes regulates trafficking processes, such\nas exocytosis and endocytosis. Classically, the Helfrich continuum model is\nused to characterize the forces and mechanical parameters that cells tune to\naccomplish membrane shape changes. While this classical model effectively\ncaptures curvature generation, one of the core challenges in using it to\napproximate a biological process is selecting a set of mechanical parameters\n(including bending modulus and membrane tension) from a large set of reasonable\nvalues. We used the Helfrich model to generate a large synthetic dataset from a\nrandom sampling of realistic mechanical parameters and used this dataset to\ntrain machine learning models. These models produced promising results,\naccurately classifying model behavior and predicting membrane shape from\nmechanical parameters. We also note emerging methods in machine learning that\ncan leverage the physical insight of the Helfrich model to improve performance\nand draw greater insight into how cells control membrane shape change."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Human lumbar spine injury risk in dynamic combined compression and\n  flexion loading"}, {"role": "assistant", "content": "Anticipating changes to vehicle interiors with future automated driving\nsystems, the automobile industry recently has focused attention on crash\nresponse in relaxed postures with increased seatback recline. Prior research\nfound that this posture may result in greater risk of lumbar spine injury in\nthe event of a frontal crash. This study developed a lumbar spine injury risk\nfunction that estimated injury risk as a function of simultaneously applied\ncompression force and flexion moment. Force and moment failure data from 40\ncompression-flexion tests were utilized in a Weibull survival model, including\nappropriate data censoring. A mechanics-based injury metric was formulated,\nwhere lumbar spine compression force and flexion moment were normalized to\nspecimen geometry. Subject age was incorporated as a covariate to further\nimprove model fit. A weighting factor was included to adjust the influence of\nforce and moment, and parameter optimization yielded a value of 0.11. Thus, the\nnormalized compression force component had a greater effect on injury risk than\nthe normalized flexion moment component. Additionally, as force was nominally\nincreased, less moment was required to produce injury for a given age and\nspecimen geometry. The resulting injury risk function can be utilized to\nimprove occupant safety in the field."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multi-site benchmark classification of major depressive disorder using\n  machine learning on cortical and subcortical measures"}, {"role": "assistant", "content": "Machine learning (ML) techniques have gained popularity in the neuroimaging\nfield due to their potential for classifying neuropsychiatric disorders.\nHowever, the diagnostic predictive power of the existing algorithms has been\nlimited by small sample sizes, lack of representativeness, data leakage, and/or\noverfitting. Here, we overcome these limitations with the largest multi-site\nsample size to date (n=5,356) to provide a generalizable ML classification\nbenchmark of major depressive disorder (MDD). Using brain measures from\nstandardized ENIGMA analysis pipelines in FreeSurfer, we were able to classify\nMDD vs healthy controls (HC) with around 62% balanced accuracy, but when\nharmonizing the data using ComBat balanced accuracy dropped to approximately\n52%. Similar results were observed in stratified groups according to age of\nonset, antidepressant use, number of episodes and sex. Future studies\nincorporating higher dimensional brain imaging/phenotype features, and/or using\nmore advanced machine and deep learning methods may achieve more encouraging\nprospects."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Estimation of Field Inhomogeneity Map Following Magnitude-Based\n  Ambiguity-Resolved Water-Fat Separation"}, {"role": "assistant", "content": "PURPOSE: To extend magnitude-based PDFF (Proton Density Fat Fraction) and\n$R_2^*$ mapping with resolved water-fat ambiguity to calculate field\ninhomogeneity (field map) using the phase images.\n  THEORY: The estimation is formulated in matrix form, resolving the field map\nin a least-squares sense. PDFF and $R_2^*$ from magnitude fitting may be\nupdated using the estimated field maps.\n  METHODS: The limits of quantification of our voxel-independent implementation\nwere assessed. Bland-Altman was used to compare PDFF and field maps from our\nmethod against a reference complex-based method on 152 UK Biobank subjects (1.5\nT Siemens). A separate acquisition (3 T Siemens) presenting field\ninhomogeneities was also used.\n  RESULTS: The proposed field mapping was accurate beyond double the\ncomplex-based limit range. High agreement was obtained between the proposed\nmethod and the reference in UK Biobank (PDFF bias = -0.03 %, LoA (limits of\nagreement) [-0.1,0.1] %; Field map bias = 0.06 Hz, LoA = [-0.2,0.3] Hz). Robust\nfield mapping was observed at 3 T, for inhomogeneities over 300 Hz including\nrapid variation across edges.\n  CONCLUSION: Field mapping following magnitude-based water-fat separation with\nresolved water-fat ambiguity was demonstrated in-vivo and showed potential at\nhigh field."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Stability versus Meta-stability in a Skin Microbiome Model"}, {"role": "assistant", "content": "The skin microbiome plays an important role in the maintenance of a healthy\nskin. It is an ecosystem, composed of several species, competing for resources\nand interacting with the skin cells. Imbalance in the cutaneous microbiome,\nalso called dysbiosis, has been correlated with several skin conditions,\nincluding acne and atopic dermatitis. Generally, dysbiosis is linked to\ncolonization of the skin by a population of opportunistic pathogenic bacteria\n(for example C. acnes in acne or S. aureus in atopic dermatitis). Treatments\nconsisting in non-specific elimination of cutaneous microflora have shown\nconflicting results. It is therefore necessary to understand the factors\ninfluencing shifts of the skin microbiome composition. In this work, we\nintroduce a mathematical model based on ordinary differential equations, with 2\ntypes of bacteria populations (skin commensals and opportunistic pathogens) to\nstudy the mechanisms driving the dominance of one population over the other. By\nusing published experimental data, assumed to correspond to the observation of\nstable states in our model, we derive constraints that allow us to reduce the\nnumber of parameters of the model from 13 to 5. Interestingly, a meta-stable\nstate settled at around 2 days following the introduction of bacteria in the\nmodel, is followed by a reversed stable state after 300 hours. On the time\nscale of the experiments, we show that certain changes of the environment, like\nthe elevation of skin surface pH, create favorable conditions for the emergence\nand colonization of the skin by the opportunistic pathogen population. Such\npredictions help identifying potential therapeutic targets for the treatment of\nskin conditions involving dysbiosis of the microbiome, and question the\nimportance of meta-stable states in mathematical models of biological\nprocesses."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Creation and unification of development and life stage ontologies for\n  animals"}, {"role": "assistant", "content": "With the new era of genomics, an increasing number of animal species are\namenable to large-scale data generation. This had led to the emergence of new\nmulti-species ontologies to annotate and organize these data. While anatomy and\ncell types are well covered by these efforts, information regarding development\nand life stages is also critical in the annotation of animal data. Its lack can\nhamper our ability to answer comparative biology questions and to interpret\nfunctional results. We present here a collection of development and life stage\nontologies for 21 animal species, and their merge into a common multi-species\nontology. This work has allowed the integration and comparison of\ntranscriptomics data in 52 animal species."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Dryland evapotranspiration from remote sensing solar-induced chlorophyll\n  fluorescence: constraining an optimal stomatal model within a two-source\n  energy balance model"}, {"role": "assistant", "content": "Evapotranspiration (ET) represents the largest water loss flux in drylands,\nbut ET and its partition into plant transpiration (T) and soil evaporation (E)\nare poorly quantified, especially at fine temporal scales. Physically-based\nremote sensing models relying on sensible heat flux estimates, like the\ntwo-source energy balance model, could benefit from considering more explicitly\nthe key effect of stomatal regulation on dryland ET. The objective of this\nstudy is to assess the value of solar-induced chlorophyll fluorescence (SIF), a\nproxy for photosynthesis, to constrain the canopy conductance (Gc) of an\noptimal stomatal model within a two-source energy balance model in drylands. We\nassessed our ET estimation using in situ eddy covariance GPP as a benchmark,\nand compared with results from using the Contiguous solar-induced chlorophyll\nfluorescence (CSIF) remote sensing product instead of GPP, with and without the\neffect of root-zone soil moisture on the Gc. The estimated ET was robust across\nfour steppes and two tree-grass dryland ecosystem. Comparison of ET simulated\nagainst in situ GPP yielded an average R2 of 0.73 (0.86) and RMSE of 0.031\n(0.36) mm at half-hourly (daily) timescale. Including explicitly the soil\nmoisture effect on Gc, increased the R2 to 0.76 (0.89). For the CSIF model, the\naverage R2 for ET estimates also improved when including the effect of soil\nmoisture: from 0.65 (0.79) to 0.71 (0.84), with RMSE ranging between 0.023\n(0.22) and 0.043 (0.54) mm depending on the site. Our results demonstrate the\ncapacity of SIF to estimate subdaily and daily ET fluxes under very low ET\nconditions. SIF can provide effective vegetation signals to constrain stomatal\nconductance and partition ET into T and E in drylands. This approach could be\nextended for regional estimates using remote sensing SIF estimates such as\nCSIF, TROPOMI-SIF, or the upcoming FLEX mission, among others."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Functional Synthetic Biology"}, {"role": "assistant", "content": "Synthetic biologists have made great progress over the past decade in\ndeveloping methods for modular assembly of genetic sequences and in engineering\nbiological systems with a wide variety of functions in various contexts and\norganisms. However, current paradigms in the field entangle sequence and\nfunctionality in a manner that makes abstraction difficult, reduces engineering\nflexibility, and impairs predictability and design reuse. Functional Synthetic\nBiology aims to overcome these impediments by focusing the design of biological\nsystems on function, rather than on sequence. This reorientation will decouple\nthe engineering of biological devices from the specifics of how those devices\nare put to use, requiring both conceptual and organizational change, as well as\nsupporting software tooling. Realizing this vision of Functional Synthetic\nBiology will allow more flexibility in how devices are used, more opportunity\nfor reuse of devices and data, improvements in predictability, and reductions\nin technical risk and cost."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Integrative omics framework for characterization of coral reef\n  ecosystems from the Tara Pacific expedition"}, {"role": "assistant", "content": "Coral reef science is a fast-growing field propelled by the need to better\nunderstand coral health and resilience to devise strategies to slow reef loss\nresulting from environmental stresses. Key to coral resilience are the\nsymbiotic interactions established within a complex holobiont, i.e. the\nmultipartite assemblages comprising the host coral organism, endosymbiotic\ndinoflagellates, bacteria, archaea, fungi, and viruses. Tara Pacific is an\nambitious project built upon the experience of previous Tara Oceans\nexpeditions, and leveraging state-of-the-art sequencing technologies and\nanalyses to dissect the biodiversity and biocomplexity of the coral holobiont\nscreened across most archipelagos spread throughout the entire Pacific Ocean.\nHere we detail the Tara Pacific workflow for multi-omics data generation, from\nsample handling to nucleotide sequence data generation and deposition. This\nunique multidimensional framework also includes a large amount of concomitant\nmetadata collected side-by-side that provide new assessments of coral reef\nbiodiversity including micro-biodiversity and shape future investigations of\ncoral reef dynamics and their fate in the Anthropocene."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Studying the age of onset and detection of Chronic Myeloid Leukemia\n  using a three-stage stochastic model"}, {"role": "assistant", "content": "Chronic Myeloid Leukemia (CML) is a biphasic malignant clonal disorder that\nprogresses, first with a chronic phase, where the cells have enhanced\nproliferation only, and then to a blast phase, where the cells have the ability\nof self-renewal. It is well-recognized that the Philadelphia chromosome (which\ncontains the BCR-ABL fusion gene) is the \"hallmark of CML\". However, empirical\nstudies have shown that the mere presence of BCR-ABL may not be a sufficient\ncondition for the development of CML, and further modifications related to\ntumor suppressors may be necessary. Accordingly, we develop a three-mutation\nstochastic model of CML progression, with the three stages corresponding to the\nnon-malignant cells with BCR-ABL presence, the malignant cells in the chronic\nphase and the malignant cells in the blast phase. We demonstrate that the model\npredictions agree with age incidence data from the United States. Finally, we\ndevelop a framework for the retrospective estimation of the time of onset of\nmalignancy, from the time of detection of the cancer."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Analysis of social interactions in group-housed animals using dyadic\n  linear models"}, {"role": "assistant", "content": "Understanding factors affecting social interactions among animals is\nimportant for applied animal behavior research. Thus, there is a need to elicit\nstatistical models to analyze data collected from pairwise behavioral\ninteractions. In this study, we propose treating social interaction data as\ndyadic observations and propose a statistical model for their analysis. We\nperformed posterior predictive checks of the model through different validation\nstrategies: stratified 5-fold random cross-validation, block-by-social-group\ncross-validation, and block-by-focal-animals validation. The proposed model was\napplied to a pig behavior dataset collected from 797 growing pigs freshly\nremixed into 59 social groups that resulted in 10,032 records of directional\ndyadic interactions. The response variable was the duration in seconds that\neach animal spent delivering attacks on another group mate. Generalized linear\nmixed models were fitted. Fixed effects included sex, individual weight, prior\nnursery mate experience, and prior littermate experience of the two pigs in the\ndyad. Random effects included aggression giver, aggression receiver, dyad, and\nsocial group. A Bayesian framework was utilized for parameter estimation and\nposterior predictive model checking. Prior nursery mate experience was the only\nsignificant fixed effect. In addition, a weak but significant correlation\nbetween the random giver effect and the random receiver effect was obtained\nwhen analyzing the attacking duration. The predictive performance of the model\nvaried depending on the validation strategy, with substantially lower\nperformance from the block-by-social-group strategy than other validation\nstrategies. Collectively, this paper demonstrates a statistical model to\nanalyze interactive animal behaviors, particularly dyadic interactions."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Machine Learning Prediction of COVID-19 Severity Levels From Salivaomics\n  Data"}, {"role": "assistant", "content": "The clinical spectrum of severe acute respiratory syndrome coronavirus 2\n(SARS-CoV-2), the strain of coronavirus that caused the COVID-19 pandemic, is\nbroad, extending from asymptomatic infection to severe immunopulmonary\nreactions that, if not categorized properly, may be life-threatening.\nResearchers rate COVID-19 patients on a scale from 1 to 8 according to the\nseverity level of COVID-19, 1 being healthy and 8 being extremely sick, based\non a multitude of factors including number of clinic visits, days since the\nfirst sign of symptoms, and more. However, there are two issues with the\ncurrent state of severity level designation. Firstly, there exists variation\namong researchers in determining these patient scores, which may lead to\nimproper treatment. Secondly, researchers use a variety of metrics to determine\npatient severity level, including metrics involving plasma collection that\nrequire invasive procedures. This project aims to remedy both issues by\nintroducing a machine learning framework that unifies severity level\ndesignations based on noninvasive saliva biomarkers. Our results show that we\ncan successfully use machine learning on salivaomics data to predict the\nseverity level of COVID-19 patients, indicating the presence of viral load\nusing saliva biomarkers."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Drug prescription clusters in the UK Biobank: An assessment of drug-drug\n  interactions and patient outcomes in a large patient cohort"}, {"role": "assistant", "content": "In recent decades, there has been an increase in polypharmacy, the concurrent\nadministration of multiple drugs per patient. Studies have shown that\npolypharmacy is linked to adverse patient outcomes and there is interest in\nelucidating the exact causes behind this observation. In this paper, we are\nstudying the relationship between drug prescriptions, drug-drug interactions\n(DDIs) and patient mortality. Our focus is not so much on the number of\nprescribed drugs, the typical metric in polypharmacy research, but rather on\nthe specific combinations of drugs leading to a DDI. To learn the space of\nreal-world drug combinations, we first assessed the drug prescription landscape\nof the UK Biobank, a large patient data registry. We observed distinct drug\nconstellation patterns driven by the UK Biobank participants' disease status.\nWe show that these drug prescription clusters matter in terms of the number and\ntypes of expected DDIs, and may possibly explain observed differences in health\noutcomes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Blocker effect on diffusion resistance of a membrane channel. Dependence\n  on the blocker geometry"}, {"role": "assistant", "content": "Being motivated by recent progress in nanopore sensing, we develop a theory\nof the effect of large analytes, or blockers, trapped within the nanopore\nconfines, on diffusion flow of small solutes. The focus is on the nanopore\ndiffusion resistance which is the ratio of the solute concentration difference\nin the reservoirs connected by the nanopore to the solute flux driven by this\ndifference. Analytical expressions for the diffusion resistance are derived for\na cylindrically symmetric blocker whose axis coincides with the axis of a\ncylindrical nanopore in two limiting cases where the blocker radius changes\neither smoothly or abruptly. Comparison of our theoretical predictions with the\nresults obtained from Brownian dynamics simulations shows good agreement\nbetween the two."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Roughness of molecular property landscapes and its impact on\n  modellability"}, {"role": "assistant", "content": "In molecular discovery and drug design, structure-property relationships and\nactivity landscapes are often qualitatively or quantitatively analyzed to guide\nthe navigation of chemical space. The roughness (or smoothness) of these\nmolecular property landscapes is one of their most studied geometric\nattributes, as it can characterize the presence of activity cliffs, with\nrougher landscapes generally expected to pose tougher optimization challenges.\nHere, we introduce a general, quantitative measure for describing the roughness\nof molecular property landscapes. The proposed roughness index (ROGI) is\nloosely inspired by the concept of fractal dimension and strongly correlates\nwith the out-of-sample error achieved by machine learning models on numerous\nregression tasks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Flow Rate Independent Multiscale Liquid Biopsy for Precision Oncology"}, {"role": "assistant", "content": "Immunoaffinity-based liquid biopsies of circulating tumor cells (CTCs) hold\ngreat promise for cancer management, but typically suffer from low throughput,\nrelative complexity and post-processing limitations. Here we address these\nissues simultaneously by decoupling and independently optimizing the nano-,\nmicro- and macro-scales of an enrichment device that is simple to fabricate and\noperate. Unlike other affinity-based devices, our scalable mesh approach\nenables optimum capture conditions at any flow rate, as demonstrated with\nconstant capture efficiencies, above 75% between 50-200 uL/min. The device\nachieved 96% sensitivity and 100% specificity when used to detect CTCs in the\nblood of 79 cancer patients and 20 healthy controls. We demonstrate its post\nprocessing capacity with the identification of potential responders to immune\ncheckpoint inhibition therapy and the detection of HER2 positive breast cancer.\nThe results compare well with other assays, including clinical standards. This\nsuggests that our approach, which overcomes major limitations associated with\naffinity-based liquid biopsies, could help improve cancer management."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: PepSIRF + QIIME 2: software tools for automated, reproducible analysis\n  of highly-multiplexed serology data"}, {"role": "assistant", "content": "PepSIRF is a command-line, module-based open-source software package that\nfacilitates the analysis of data from highly-multiplexed serology assays (e.g.,\nPepSeq or PhIP-Seq). It has nine separate modules in its current release\n(v1.5.0): demux, info, subjoin, norm, bin, zscore, enrich, link, and deconv.\nThese modules can be used together to conduct analyses ranging from\ndemultiplexing raw high-throughput sequencing data to the identification of\nenriched peptides. QIIME 2 is an open-source, community-developed and\nplugin-based bioinformatics platform that focuses on data and analytical\ntransparency. QIIME 2's features include integrated and automatic tracking of\ndata provenance, a semantic type system, and built-in support for many types of\nuser interfaces. Here, we describe three new QIIME 2 plugins that allow users\nto conduct PepSIRF analyses within the QIIME 2 environment and extend the core\nfunctionality of PepSIRF in two key ways: 1) enabling generation of interactive\nvisualizations and 2) enabling automation of analysis pipelines that include\nmultiple PepSIRF modules."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Patterns of protection, infection, and detection: Country-level\n  effectiveness of COVID 19 vaccination in reducing mortality worldwide"}, {"role": "assistant", "content": "We investigated the negative relationship between mortality and COVID-19\nvaccination at ecological level, which has been established through clinical\ntrials and other investigations at the individual level. We conducted an\nexploratory, correlational, country-level analysis of open data centralized by\nOur World in Data concerning the cumulative COVID-19 mortality for the winter\nwave of the pandemic as function of the vaccination rate in October 2021. In\norder to disentangle the protective relationship from confounding processes, we\ncontrolled variables that capture country-level social development and level of\ntesting. We also deployed three segmentation tactics, distinguishing among\ncountries based on their level of COVID-19 testing, age structure, and types of\nvaccines used. Controlling for confounding factors did not highlight a\nstatistically significant global relationship between vaccination and\ncumulative mortality in the total country sample. As suggested by previous\nestimates at country level, a strong, significant, negative relationship\nbetween cumulative mortality and vaccination was highlighted through\nsegmentation analysis for countries positioned at the higher end of the social\ndevelopment spectrum. The strongest estimate for vaccine effectiveness at\necological level was obtained for countries that use Western-only vaccines.\nThis may partly reflect the higher effectiveness of Western vaccines in\ncomparison with the average of all vaccines in use; it may also derive from the\nlower social heterogeneity of countries included in this segment. COVID-19\ntesting has a significant and positive relationship with cumulative mortality\nfor all subsamples. This indicates that testing intensity should be controlled\nas a potential confounder in future ecological analyses of COVID-19 mortality."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Benefits and limitations of a new hydraulic performance model"}, {"role": "assistant", "content": "Purpose: Performance models are important tools for coaches and athletes to\noptimise competition outcomes or training schedules. A recently published\nhydraulic performance model has been reported to outperform established\nwork-balance models in predicting recovery during intermittent exercise. The\nnew hydraulic model was optimised to predict exercise recovery dynamics. In\nthis work, we hypothesised that the benefits of the model come at the cost of\ninaccurate predictions of metabolic responses to exercise such as\n$\\dot{V}_{\\mathrm{O}_2}$.\n  Methods: Hydraulic model predictions were compared to breath-by-breath\n$\\dot{V}_{\\mathrm{O}_2}$ data from 25 constant high-intensity exercise tests of\n5 participants (age $32\\pm7.8$ years, weight $73.6 \\pm 5.81$ kg,\n$\\dot{V}_{\\mathrm{O}_2\\mathrm{max}} \\; 3.59 \\pm 0.62$ L/min). Each test was\nperformed to volitional exhaustion on a cycle ergometer with a duration between\n2 and 12 min. The comparison focuses on the onset of $\\dot{V}_{\\mathrm{O}_2}$\nkinetics.\n  Results: On average, the hydraulic model predicted peak\n$\\dot{V}_{\\mathrm{O}_2}$ during exercise $216\\pm113$~s earlier than observed in\nthe data. The new hydraulic model also did not predict the so-called\n$\\dot{V}_{\\mathrm{O}_2}$ slow component and made the unrealistic assumption\nthat there is no $\\dot{V}_{\\mathrm{O}_2}$ at the onset of exercise.\n  Conclusion: While the new hydraulic model may be a powerful tool for\npredicting energy recovery, it should not be used to predict metabolic\nresponses during high-intensity exercise. The present study contributes towards\na more holistic picture of the benefits and limitations of the new hydraulic\nmodel. Data and code are published as open source."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Sampling the proteome by emerging single-molecule and mass-spectrometry\n  methods"}, {"role": "assistant", "content": "Mammalian cells have about 30,000-fold more protein molecules than mRNA\nmolecules. This larger number of molecules and the associated larger dynamic\nrange have major implications in the application of proteomics technologies. We\nexamine these implications for both liquid chromatography-tandem\nmass-spectrometry (LC-MS/MS) and single-molecule counting and provide estimates\non how many molecules are routinely measured in proteomics experiments by\nLC-MS/MS. We review strategies that have been helpful for counting billions of\nprotein molecules by LC-MS/MS and suggest that these strategies can benefit\nsingle-molecule methods, especially in mitigating the challenges of the wide\ndynamic range of the proteome. We also examine the theoretical possibilities\nfor scaling up single-molecule and mass-spectrometry proteomics approaches to\nquantifying the billions of protein molecules that make up the proteomes of our\ncells."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Choice of spatial discretisation influences the progression of viral\n  infection within multicellular tissues"}, {"role": "assistant", "content": "There has been an increasing recognition of the utility of models of the\nspatial dynamics of viral spread within tissues. Multicellular models, where\ncells are represented as discrete regions of space coupled to a virus density\nsurface, are a popular approach to capture these dynamics. Conventionally, such\nmodels are simulated by discretising the viral surface and depending on the\nrate of viral diffusion and other considerations, a finer or coarser\ndiscretisation may be used. The impact that this choice may have on the\nbehaviour of the system has not been studied. Here we demonstrate that, if\nrates of viral diffusion are small, then the choice of spatial discretisation\nof the viral surface can have quantitative and even qualitative influence on\nmodel outputs. We investigate in detail the mechanisms driving these phenomena\nand discuss the constraints on the design and implementation of multicellular\nviral dynamics models for different parameter configurations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Geometric analysis enables biological insight from complex\n  non-identifiable models using simple surrogates"}, {"role": "assistant", "content": "An enduring challenge in computational biology is to balance data quality and\nquantity with model complexity. Tools such as identifiability analysis and\ninformation criterion have been developed to harmonise this juxtaposition, yet\ncannot always resolve the mismatch between available data and the granularity\nrequired in mathematical models to answer important biological questions.\nOften, it is only simple phenomenological models, such as the logistic and\nGompertz growth models, that are identifiable from standard experimental\nmeasurements. To draw insights from the complex, non-identifiable models that\nincorporate key biological mechanisms of interest, we study the geometry of a\nmap in parameter space from the complex model to a simple, identifiable,\nsurrogate model. By studying how non-identifiable parameters in the complex\nmodel quantitatively relate to identifiable parameters in surrogate, we\nintroduce and exploit a layer of interpretation between the set of\nnon-identifiable parameters and the goodness-of-fit metric or likelihood\nstudied in typical identifiability analysis. We demonstrate our approach by\nanalysing a hierarchy of mathematical models for multicellular tumour spheroid\ngrowth. Typical data from tumour spheroid experiments are limited and noisy,\nand corresponding mathematical models are very often made arbitrarily complex.\nOur geometric approach is able to predict non-identifiabilities, subset\nnon-identifiable parameter spaces into identifiable parameter combinations that\nrelate to individual data features, and overall provide additional biological\ninsight from complex non-identifiable models."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Deep Learning and Health Informatics for Smart Monitoring and Diagnosis"}, {"role": "assistant", "content": "The connection between the design and delivery of health care services using\ninformation technology is known as health informatics. It involves data usage,\nvalidation, and transfer of an integrated medical analysis using neural\nnetworks of multi-layer deep learning techniques to analyze complex data. For\ninstance, Google incorporated ''DeepMind'' health mobile tool that integrates\n\\& leverage medical data needed to enhance professional healthcare delivery to\npatients. Moorfield Eye Hospital London introduced DeepMind Research Algorithms\nwith dozens of retinal scans attributes while DeepMind UCL handled the\nidentification of cancerous tissues using CT \\& MRI Scan tools. Atomise\nanalyzed drugs and chemicals with Deep Learning Neural Networks to identify\naccurate pre-clinical prescriptions. Health informatics makes medical care\nintelligent, interactive, cost-effective, and accessible; especially with DL\napplication tools for detecting the actual cause of diseases. The extensive use\nof neural network tools leads to the expansion of different medical disciplines\nwhich mitigates data complexity and enhances 3-4D overlap images using target\npoint label data detectors that support data augmentation, un-semi-supervised\nlearning, multi-modality and transfer learning architecture. Health science\nover the years focused on artificial intelligence tools for care delivery,\nchronic care management, prevention/wellness, clinical supports, and diagnosis.\nThe outcome of their research leads to cardiac arrest diagnosis through Heart\nSignal Computer-Aided Diagnostic tool (CADX) and other multifunctional deep\nlearning techniques that offer care, diagnosis \\& treatment. Health informatics\nprovides monitored outcomes of human body organs through medical images that\nclassify interstitial lung disease, detects image nodules for reconstruction \\&\ntumor segmentation. The emergent medical research applications gave rise to\nclinical-pathological human-level performing tools for handling Radiological,\nOphthalmological, and Dental diagnosis. This research will evaluate\nmethodologies, Deep learning architectures, approaches, bio-informatics,\nspecified function requirements, monitoring tools, ANN (artificial neural\nnetwork), data labeling \\& annotation algorithms that control data validation,\nmodeling, and diagnosis of different diseases using smart monitoring health\ninformatics applications."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Causality in cardiorespiratory signals in pediatric cardiac patients"}, {"role": "assistant", "content": "Four different Granger causality-based methods - one linear and three\nnonlinear (Granger Causality, Kernel Granger Causality, large-scale Nonlinear\nGranger Causality, and Neural Network Granger Causality) were used for\nassessment and causal-based quantification of the respiratory sinus arrythmia\n(RSA) in the group of pediatric cardiac patients, based on the single-lead ECG\nand impedance pneumography signals (the latter as the tidal volume curve\nequivalent). Each method was able to detect the dependency (in terms of causal\ninference) between respiratory and cardiac signals. The correlations between\nquantified RSA and the demographic parameters were also studied, but the\nresults differ for each method."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Review of Machine Learning and Algorithmic Methods for Protein\n  Phosphorylation Sites Prediction"}, {"role": "assistant", "content": "Post-translational modifications (PTMs) have key roles in extending the\nfunctional diversity of proteins and as a result, regulating diverse cellular\nprocesses in prokaryotic and eukaryotic organisms. Phosphorylation modification\nis a vital PTM that occurs in most proteins and plays a significant role in\nmany biological processes. Disorders in the phosphorylation process lead to\nmultiple diseases including neurological disorders and cancers. The purpose of\nthis review paper is to organize this body of knowledge associated with\nphosphorylation site (p-site) prediction to facilitate future research in this\nfield. At first, we comprehensively reviewed all related databases and\nintroduced all steps regarding dataset creation, data preprocessing and method\nevaluation in p-site prediction. Next, we investigated p-sites prediction\nmethods which fall into two computational groups: Algorithmic and Machine\nLearning (ML). Additionally, it was shown that there are basically two main\napproaches for p-sites prediction by ML: conventional and End-to-End deep\nlearning methods, which were given an overview for both of them. Moreover, this\nstudy introduced the most important feature extraction techniques which have\nmostly been used in p-site prediction. Finally, we created three test sets from\nnew proteins related to the 2022th released version of the dbPTM database based\non general and human species. Evaluation of the available online tools on the\ntest sets showed quite poor performance for p-sites prediction. Keywords:\nPhosphorylation, Machine Learning, Deep Learning, Post Translation\nModification, Databases"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Family based HLA imputation and optimization of haplo-identical\n  transplants"}, {"role": "assistant", "content": "Recently, haplo-identical transplantation with multiple HLA mismatches has\nbecome a viable option for system cell transplants. Haplotype sharing detection\nrequires imputation of donor and recipient. We show that even in\nhigh-resolution typing when all alleles are known, there is a 15% error rate in\nhaplotype phasing, and even more in low resolution typings. Similarly, in\nrelated donors, parents haplotypes should be imputed to determine what\nhaplotype each child inherited. We propose GRAMM (GRaph bAsed FaMilly\niMputation) to phase alleles in family pedigree HLA typing data, and in\nmother-cord blood unit pairs. We show that GRAMM has practically no phasing\nerrors when pedigree data are available. We apply GRAMM to simulations with\ndifferent typing resolutions as well as paired cord-mother typings, and show\nvery high phasing accuracy, and improved alleles imputation accuracy. We use\nGRAMM to detect recombination events and show that the rate of falsely detected\nrecombination events (False Positive Rate) in simulations is very low. We then\napply recombination detection to typed families to estimate the recombination\nrate in Israeli and Australian population datasets. The estimated recombination\nrate has an upper bound of 10-20% per family (1-4% per individual). GRAMM is\navailable at: https://gramm.math.biu.ac.il/."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Prognostic Significance of Tumor-Infiltrating Lymphocytes Using Deep\n  Learning on Pathology Images in Colorectal Cancers"}, {"role": "assistant", "content": "Purpose Tumor-infiltrating lymphocytes (TILs) have significant prognostic\nvalues in cancers. However, very few automated, deep-learning-based TIL scoring\nalgorithms have been developed for colorectal cancers (CRC). Methods We\ndeveloped an automated, multiscale LinkNet workflow for quantifying\ncellular-level TILs for CRC tumors using H&E-stained images. The predictive\nperformance of the automatic TIL scores (TIL) for disease progression and\noverall survival was evaluate using two international datasets, including 554\nCRC patients from The Cancer Genome Atlas (TCGA) and 1130 CRC patients from\nMolecular and Cellular Oncology (MCO). Results The LinkNet model provided an\noutstanding precision (0.9508), recall (0.9185), and overall F1 score (0.9347).\nClear dose-response relationships were observed between TILs and risk of\ndisease progression or death decreased in both TCGA and MCO cohorts. Both\nunivariate and multivariate Cox regression analyses for the TCGA data\ndemonstrated that patients with high TILs had significant (approx. 75%)\nreduction of risk for disease progression. In both MCO and TCGA studies, the\nTIL-high group was significantly associated with improved overall survival in\nunivariate analysis (30% and 54% reduction in risk, respectively). However,\npotential confounding was observed in the MCO dataset. The favorable effects of\nhigh TILs were consistently observed in different subgroups according to know\nrisk factors. Conclusion A deep-learning workflow for automatic TIL\nquantification based on LinkNet was successfully developed."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Simulating how animals learn: a new modelling framework applied to the\n  process of optimal foraging"}, {"role": "assistant", "content": "Animal learning has interested ecologists and psychologists for over a\ncentury. Mathematical models that explain how animals store and recall\ninformation have gained attention recently. Central to this work is statistical\ndecision theory (SDT), which relates information uptake in animals to Bayesian\ninference. SDT effectively explains many learning tasks in animals, but\nextending this theory to predict how animals will learn in changing\nenvironments still poses a challenge for ecologists. We addressed this\nshortcoming with a novel implementation of Bayesian Markov Chain Monte Carlo\n(MCMC) sampling to simulate how animals sample environmental information and\nlearn as a result. We applied our framework to an individual-based model\nsimulating complex foraging tasks encountered by wild animals. Simulated\n``animals\" learned behavioral strategies that optimized foraging returns simply\nby following the principles of an MCMC sampler. In these simulations,\nbehavioral plasticity was most conducive to efficient foraging in unpredictable\nand uncertain environments. Our model suggests that animals prioritize highly\nconcentrated resources even when these resources are less available overall, in\nline with existing knowledge on optimal foraging and ideal free distribution\ntheory. Our innovative computational modelling framework can be applied more\nwidely to simulate the learning of many other tasks in animals and humans."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A New Hyperelastic Lookup Table for RT-DC"}, {"role": "assistant", "content": "Real-time deformability cytometry (RT-DC) is an established method that\nquantifies features like size, shape, and stiffness for whole cell populations\non a single-cell level in real time. To extract the cell stiffness, a lookup\ntable (LUT) disentangles the experimentally derived steady state cell\ndeformation and the projected area, yielding the Young's modulus. So far, two\nlookup tables exists, but are limited to simple linear material models and\ncylindrical channel geometries. Here, we present two new lookup tables for\nRT-DC based on a neo-Hookean hyperelastic material numerically derived by\nsimulations based on the finite element method in square and cylindrical\nchannel geometries. At the same time, we quantify the influence of the\nshear-thinning behaviour of the surrounding medium on the stationary\ndeformation of cells in RT-DC and discuss the applicability and impact of the\nproposed LUTs regarding past and future RT-DC data analysis. Additionally, we\nprovide insights about the cell strain and stresses, as well as the influence\nresulting from the rotational symmetric assumption on the cell deformation and\nvolume estimation. The new lookup tables as well as the numerical cell shapes\nare made freely available."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Pattern-Based Prediction of Population Outbreaks"}, {"role": "assistant", "content": "Insect outbreaks are biotic disturbances in forests and agroecosystems that\ncause economic and ecological damage. This phenomenon depends on a variety of\nbiological and physical factors. The complexity and practical importance of the\nissue have made the problem of predicting outbreaks a focus of recent research.\nHere, we propose the Pattern-Based Prediction (PBP) method for predicting\npopulation outbreaks. It is based on the Alert Zone Procedure, combined with\nelements from machine learning. It uses information on previous time series\nvalues that precede an outbreak event as predictors of future outbreaks, which\ncan be useful when monitoring pest species. We illustrate the methodology using\nsimulated datasets and real time series data obtained by monitoring aphids in\nwheat crops in Southern Brazil. We obtained an average test accuracy of\n$84.6\\%$ in the simulation studies implemented with stochastic models, and\n$95.0\\%$ for predicting outbreaks using the real dataset. This shows the\nfeasibility of the PBP method in predicting outbreaks in population dynamics.\nWe benchmarked our results against established state-of-the-art machine\nlearning methods, namely Support Vector Machines, Deep Neural Networks, Long\nShort Term Memory and Random Forests. The PBP method yielded a competitive\nperformance, associated with higher true-positive rates in most comparisons,\nwhile being able to provide interpretability rather than being a black-box\nmethod. This is an improvement over current state-of-the-art machine learning\ntools, especially when being used by non-specialists, such as ecologists aiming\nto use a quantitative approach for pest monitoring. We provide open-source code\nto implement the PBP method in Python, through the \\texttt{pypbp} package,\nwhich may be directly downloaded from the Python Package Index server or\naccessed through \\url{https://pypbp-documentation.readthedocs.io}"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Topological AI forecasting of future dominating viral variants"}, {"role": "assistant", "content": "The understanding of the mechanisms of SARS-CoV-2 evolution and transmission\nis one of the greatest challenges of our time. By integrating artificial\nintelligence (AI), viral genomes isolated from patients, tens of thousands of\nmutational data, biophysics, bioinformatics, and algebraic topology, the\nSARS-CoV-2 evolution was revealed to be governed by infectivity-based natural\nselection. Two key mutation sites, L452 and N501 on the viral spike protein\nreceptor-binding domain (RBD), were predicted in summer 2020, long before they\noccur in prevailing variants Alpha, Beta, Gamma, Delta, Kappa, Theta, Lambda,\nMu, and Omicron. Recent studies identified a new mechanism of natural\nselection: antibody resistance. AI-based forecasting of Omicron's infectivity,\nvaccine breakthrough, and antibody resistance was later nearly perfectly\nconfirmed by experiments. The replacement of dominant BA.1 by BA.2 in later\nMarch was predicted in early February. On May 1, 2022, persistent\nLaplacian-based AI projected Omicron BA.4 and BA.5 to become the new dominating\nCOVID-19 variants. This prediction became reality in late June. Topological AI\nmodels offer accurate prediction of mutational impacts on the efficacy of\nmonoclonal antibodies (mAbs)."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Lack of corundum, carbon residues and revealing gaps on dental implants"}, {"role": "assistant", "content": "Surface modification is an important topic to improve dental implants.\nCorundum residues, which are part of current dental implant blasting,\ndisappeared on Straumann dental implants in recent publications. In our\ninvestigations of the surface of 4 different Straumann implants using scanning\nelectron microscopy (SEM) and energy-dispersive X-ray spectroscopy (EDX) we\nfound the following three main findings: surfaces are nearly corundum-free,\ndisseminated gap-framed corundum particles and significant molecular carbon\nresidues. The data strongly suggest that Straumann applies a modified surface\ntechnology on dental implants to remove corundum residues and involving unclear\ncarbons. One explanation could be, a Straumann patent involving a dextran\ncoating allowing easy corundum particle removal by aqueous solution, while\nunintended molecular carbon residues cannot explain all findings. This change\nof the production process without a new approval by the FDA would be a\nviolation of US federal law and the carbon bindings are a possible danger to\npatients."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Computing Phylo-k-mers"}, {"role": "assistant", "content": "Phylogenetically informed k-mers, or phylo-k-mers for short, are k-mers that\nare predicted to appear within a given genomic region at predefined locations\nof a fixed phylogeny. Given a reference alignment for this genomic region and\nassuming a phylogenetic model of sequence evolution, we can compute a\nprobability score for any given k-mer at any given tree node. The k-mers with\nsufficiently high probabilities can later be used to perform alignment-free\nphylogenetic classification of new sequences-a procedure recently proposed for\nthe phylogenetic placement of metabarcoding reads and the detection of novel\nvirus recombinants. While computing phylo-k-mers, we need to consider large\nnumbers of k-mers at each tree node, which warrants the development of\nefficient enumeration algorithms. We consider a formal definition of the\nproblem of phylo-k-mer computation: How to efficiently find all k-mers whose\nprobability lies above a user-defined threshold for a given tree node? We\ndescribe and analyze algorithms for this problem, relying on branch-and-bound\nand divideand-conquer techniques. We exploit the redundancy of adjacent windows\nof the alignment and the structure of the probability matrix to save on\ncomputation. Besides computational complexity analyses, we provide an empirical\nevaluation of the relative performance of their implementations on real-world\nand simulated data. The divide-and-conquer algorithms, which to the best of our\nknowledge are novel, are found to be clear improvements over the\nbranch-and-bound approach, especially when a large number of phylo-k-mers are\nfound."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Structural identifiability analysis of epidemic models based on\n  differential equations: A Primer"}, {"role": "assistant", "content": "The successful application of epidemic models hinges on our ability to\nestimate model parameters from limited observations reliably. An\noften-overlooked step before estimating model parameters consists of ensuring\nthat the model parameters are structurally identifiable from a given dataset.\nStructural identifiability analysis uncovers any existing parameter\ncorrelations that preclude their estimation from the observed variables. Here\nwe review and illustrate methods for structural identifiability analysis based\non a differential algebra approach using DAISY and Mathematica (Wolfram\nResearch). We demonstrate this approach through examples of compartmental\nepidemic models previously employed to study transmission dynamics and control.\nWe show that lack of structural identifiability may be remedied by\nincorporating additional observations from different model states or fixing\nsome parameters based on existing parameter correlations, or by reducing the\nnumber of parameters or state variables involved in the system dynamics. We\nalso underscore how structural identifiability analysis can help improve\ncompartmental diagrams of differential-equation models by indicating the\nobserved variables and the results of the structural identifiability analysis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The current state of single-cell proteomics data analysis"}, {"role": "assistant", "content": "Sound data analysis is essential to retrieve meaningful biological\ninformation from single-cell proteomics experiments. This analysis is carried\nout by computational methods that are assembled into workflows, and their\nimplementations influence the conclusions that can be drawn from the data. In\nthis work, we explore and compare the computational workflows that have been\nused over the last four years and identify a profound lack of consensus on how\nto analyze single-cell proteomics data. We highlight the need for benchmarking\nof computational workflows, standardization of computational tools and data, as\nwell as carefully designed experiments. Finally, we cover the current\nstandardization efforts that aim to fill the gap and list the remaining missing\npieces, and conclude with lessons learned from the replication of published\nsingle-cell proteomics analyses."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Data-driven spatio-temporal modelling of glioblastoma"}, {"role": "assistant", "content": "Mathematical oncology provides unique and invaluable insights into tumour\ngrowth on both the microscopic and macroscopic levels. This review presents\nstate-of-the-art modelling techniques and focuses on their role in\nunderstanding glioblastoma, a malignant form of brain cancer. For each\napproach, we summarise the scope, drawbacks, and assets. We highlight the\npotential clinical applications of each modelling technique and discuss the\nconnections between the mathematical models and the molecular and imaging data\nused to inform them. By doing so, we aim to prime cancer researchers with\ncurrent and emerging computational tools for understanding tumour progression.\nFinally, by providing an in-depth picture of the different modelling\ntechniques, we also aim to assist researchers who seek to build and develop\ntheir own models and the associated inference frameworks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Congruity of genomic and epidemiological data in modeling of local\n  cholera outbreaks"}, {"role": "assistant", "content": "Cholera continues to be a global health threat. Understanding how cholera\nspreads between locations is fundamental to the rational, evidence-based design\nof intervention and control efforts. Traditionally, cholera transmission models\nhave utilized cholera case count data. More recently, whole genome sequence\ndata has qualitatively described cholera transmission. Integrating these data\nstreams may provide much more accurate models of cholera spread, however no\nsystematic analyses have been performed so far to compare traditional\ncase-count models to the phylodynamic models from genomic data for cholera\ntransmission. Here, we use high-fidelity case count and whole genome sequencing\ndata from the 1991-1998 cholera epidemic in Argentina to directly compare the\nepidemiological model parameters estimated from these two data sources. We find\nthat phylodynamic methods applied to cholera genomics data provide comparable\nestimates that are in line with established methods. Our methodology represents\na critical step in building a framework for integrating case-count and genomic\ndata sources for cholera epidemiology and other bacterial pathogens."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Morpho-anatomical characterization of the urogenital schistosmiasis\n  vector Bulinus truncatus (Audouin, 1827) (Heterobranchia : Bulinidae) from\n  Southwestern Europe"}, {"role": "assistant", "content": "Urogenital schistosomiasis has been present naturally in the South of Europe\nsince the beginning of the 20 th century and nowadays its presence is also\nknown, at least imported by Sub-Saharan emigrants and tourists, in France,\nItaly, Portugal and Spain. One of the intermediate hosts of this trematode\npresent in Europe is the bulinid mollusc Bulinus truncatus, non-native species\nthat can be reached to Europe by humans and birds. In order to know this\nmollusc better, we carried out a morpho-anatomical study, of the shell, the\nreproductive system, radula, the respiratory organs and pseudobranch of several\npopulations from Italy, France and Spain. Spanish conchological material\nstudied comes from different populations, from material deposited in the \"Museo\nNacional de Ciencias Naturales\" of Madrid and the \"Museu de Ci{\\`e}ncies\nNaturals\" of Barcelona, as well as from its own material deposited in the\n\"Museu Valenci{\\`a} d'Hist{\\`o}ria Natural\" of Alginet (Valencia). The shell\ngrowth in captivity and the estimation of the population age of B. truncatus\nfrom El Ejido (Almer{\\'i}a, Spain), has also been studied. Finally, the finding\nof aphallic and euphallic specimens in the different populations of southern\nEurope studied is presented and taxonomic and ecological data of the genus\nBulinus are shown."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Brain structure can mediate or moderate the relationship of behavior to\n  brain function and transcriptome. A preliminary study"}, {"role": "assistant", "content": "Abnormalities in motor-control behavior, which have been with concussion and\nhead acceleration events (HAE), can be quantified using virtual reality (VR)\ntechnologies. Motor-control behavior has been consistently mapped to the\nbrain's somatomotor network (SM) using both structural (sMRI) and functional\nMRI (fMRI). However, no studies habe integrated HAE, motor-control behavior,\nsMRI and fMRI measures. Here, brain networks important for motor-control were\nhypothesized to show changes in tractography-based diffusion weighted imaging\n[difference in fractional anisotropy (dFA)] and resting-state fMRI (rs-fMRI)\nmeasures in collegiate American football players across the season, and that\nthese measures would relate to VR-based motor-control. We firther tested if\nnine inflammation-related miRNAs were associated with\nbehavior-structure-function variables. Using permutation-based mediation and\nmoderation methods, we found that across-season dFA from the SM structural\nconnectome (SM-dFA) mediated the relationship between across-season VR-based\nSensory-motor Reactivity (dSR) and rs-fMRI SM fingerprint similarity (p = 0.007\nand Teff = 47%). The interaction between dSR and SM-dFA also predicted (pF =\n0.036, pbeta3 = 0.058) across-season levels of dmiRNA-30d through\npermutation-based moderation analysis. These results suggest (1) that\nmotor-control is in a feedback relationship with brain structure and function,\n(2) behavior-structure-function can be connected to HAE, and (3)\nbehavior-structure might predict molecular biology measures."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Metabolic Model-based Ecological Modeling for Probiotic Design"}, {"role": "assistant", "content": "The microbial community composition in the human gut has a profound effect on\nhuman health. This observation has lead to extensive use of microbiome\ntherapies, including over-the-counter ``probiotic\" treatments intended to alter\nthe composition of the microbiome. Despite so much promise and commercial\ninterest, the factors that contribute to the success or failure of\nmicrobiome-targeted treatments remain unclear. We investigate the biotic\ninteractions that lead to successful engraftment of a novel bacterial strain\nintroduced to the microbiome as in probiotic treatments. We use pairwise\ngenome-scale metabolic modeling with a generalized resource allocation\nconstraint to build a network of interactions between 818 species with well\ndeveloped models available in the AGORA database. We create induced sub-graphs\nusing the taxa present in samples from three experimental engraftment studies\nand assess the likelihood of invader engraftment based on network structure. To\ndo so, we use a set of dynamical models designed to reflect connect network\ntopology to growth dynamics. We show that a generalized Lotka-Volterra model\nhas strong ability to predict if a particular invader or probiotic will\nsuccessfully engraft into an individual's microbiome. Furthermore, we show that\nthe mechanistic nature of the model is useful for revealing which\nmicrobe-microbe interactions potentially drive engraftment."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: D-CryptO: Deep learning-based analysis of colon organoid morphology from\n  brightfield images"}, {"role": "assistant", "content": "Stem cell-derived organoids are a promising tool to model native human\ntissues as they resemble human organs functionally and structurally compared to\ntraditional monolayer cell-based assays. For instance, colon organoids can\nspontaneously develop crypt-like structures similar to those found in the\nnative colon. While analyzing the structural development of organoids can be a\nvaluable readout, using traditional image analysis tools makes it challenging\nbecause of the heterogeneities and the abstract nature of organoid\nmorphologies. To address this limitation, we developed and validated a deep\nlearning-based image analysis tool, named D-CryptO, for the classification of\norganoid morphology. D-CryptO can automatically assess the crypt formation and\nopacity of colorectal organoids from brightfield images to determine the extent\nof organoid structural maturity. To validate this tool, changes in organoid\nmorphology were analyzed during organoid passaging and short-term forskolin\nstimulation. To further demonstrate the potential of D-CryptO for drug testing,\norganoid structures were analyzed following treatments with a panel of\nchemotherapeutic drugs. With D-CryptO, subtle variations in how colon organoids\nresponded to the different chemotherapeutic drugs were detected, which suggest\npotentially distinct mechanisms of action. This tool could be expanded to other\norganoid types, like intestinal organoids, to facilitate 3D tissue\nmorphological analysis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Topological Data Analysis Study on Murine Pulmonary Arterial Trees\n  with Pulmonary Hypertension"}, {"role": "assistant", "content": "Pulmonary hypertension (PH), defined by a mean pulmonary arterial blood\npressure above 20 mmHg, is a cardiovascular disease impacting the pulmonary\nvasculature. PH is accompanied by vascular remodeling, wherein vessels become\nstiffer, large vessels dilate, and smaller vessels constrict. Some types of PH,\nincluding hypoxia-induced PH (HPH), lead to microvascular rarefaction. The goal\nof this study is to analyze the change in pulmonary arterial network\nmorphometry in the presence of HPH. To do so, we use novel methods from\ntopological data analysis (TDA), employing persistent homology to quantify\narterial network morphometry for control and hypertensive mice. These methods\nare used to characterize arterial trees extracted from micro-computed\ntomography (micro-CT) images. To compare results between control and\nhypertensive animals, we normalize generated networks using three pruning\nalgorithms. This proof-of-concept study shows that the pruning methods effects\nthe spatial tree statistics and complexities of the trees. Results show that\nHPH trees have higher depth and that the directional complexities correlate\nwith branch number, except for trees pruned by vessel radius, where the left\nand anterior complexity are lower compared to control trees. While more data is\nrequired to make a conclusion about the overall effect of HPH on network\ntopology, this study provides a framework for analyzing the topology of\nbiological networks and is a step towards the extraction of relevant\ninformation for diagnosing and detecting HPH."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Graph identification of proteins in tomograms (GRIP-Tomo)"}, {"role": "assistant", "content": "In this study, we present a method of pattern mining based on network theory\nthat enables the identification of protein structures or complexes from\nsynthetic volume densities, without the knowledge of predefined templates or\nhuman biases for refinement. We hypothesized that the topological connectivity\nof protein structures is invariant, and they are distinctive for the purpose of\nprotein identification from distorted data presented in volume densities.\nThree-dimensional densities of a protein or a complex from simulated\ntomographic volumes were transformed into mathematical graphs as observables.\nWe systematically introduced data distortion or defects such as missing\nfullness of data, the tumbling effect, and the missing wedge effect into the\nsimulated volumes, and varied the distance cutoffs in pixels to capture the\nvarying connectivity between the density cluster centroids in the presence of\ndefects. A similarity score between the graphs from the simulated volumes and\nthe graphs transformed from the physical protein structures in point data was\ncalculated by comparing their network theory order parameters including node\ndegrees, betweenness centrality, and graph densities. By capturing the\nessential topological features defining the heterogeneous morphologies of a\nnetwork, we were able to accurately identify proteins and homo-multimeric\ncomplexes from ten topologically distinctive samples without realistic noise\nadded. Our approach empowers future developments of tomogram processing by\nproviding pattern mining with interpretability, to enable the classification of\nsingle-domain protein native topologies as well as distinct single-domain\nproteins from multimeric complexes within noisy volumes."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Deciphering the interaction of genetic and epigenetic factors through\n  enhanced polymer models"}, {"role": "assistant", "content": "Cellular functions crucially depend on the precise regulation of gene\nexpression. This process involves complex biochemical reactions taking place on\nthe chromatin polymer in a tightly confined environment. Despite the\navailability of large data sets probing this process from multiple angles, we\nstill lack a quantitative understanding of how biochemical processes, governed\nby genetic sequence affinity, interact with the 3D polymer nature of the\nchromatin. Here we propose a new statistical polymer model which naturally\nincorporates observational data about sequence-driven biochemical processes,\nsuch as the binding of transcription factor proteins, in a 3D model of\nchromatin structure. We introduce a new algorithm for approximate Bayesian\ninference and show on a case study that our model not only provides better\npredictions of chromatin state compared to purely data-driven approaches, but\nalso gives a quantitative estimate of the relative importance of biochemical\nand polymer terms in determining chromatin state, leading to a significant\nrevision of previous estimates. Furthermore, we show that, with no additional\ninput from genome 3D structure data, our model can predict highly non-trivial\ngeometrical structures in the folding of DNA within the nucleus. Our model\ndemonstrates the importance of introducing physically realistic statistical\nmodels for predicting chromatin state from data and opens the way to a new\nclass of approaches to interpreting epigenomic data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: What cleaves? Is proteasomal cleavage prediction reaching a ceiling?"}, {"role": "assistant", "content": "Epitope vaccines are a promising direction to enable precision treatment for\ncancer, autoimmune diseases, and allergies. Effectively designing such vaccines\nrequires accurate prediction of proteasomal cleavage in order to ensure that\nthe epitopes in the vaccine are presented to T cells by the major\nhistocompatibility complex (MHC). While direct identification of proteasomal\ncleavage \\emph{in vitro} is cumbersome and low throughput, it is possible to\nimplicitly infer cleavage events from the termini of MHC-presented epitopes,\nwhich can be detected in large amounts thanks to recent advances in\nhigh-throughput MHC ligandomics. Inferring cleavage events in such a way\nprovides an inherently noisy signal which can be tackled with new developments\nin the field of deep learning that supposedly make it possible to learn\npredictors from noisy labels. Inspired by such innovations, we sought to\nmodernize proteasomal cleavage predictors by benchmarking a wide range of\nrecent methods, including LSTMs, transformers, CNNs, and denoising methods, on\na recently introduced cleavage dataset. We found that increasing model scale\nand complexity appeared to deliver limited performance gains, as several\nmethods reached about 88.5% AUC on C-terminal and 79.5% AUC on N-terminal\ncleavage prediction. This suggests that the noise and/or complexity of\nproteasomal cleavage and the subsequent biological processes of the antigen\nprocessing pathway are the major limiting factors for predictive performance\nrather than the specific modeling approach used. While biological complexity\ncan be tackled by more data and better models, noise and randomness inherently\nlimit the maximum achievable predictive performance. All our datasets and\nexperiments are available at\nhttps://github.com/ziegler-ingo/cleavage_prediction."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Spatio-temporal modeling of saltatory conduction in neurons using\n  Poisson-Nernst-Planck treatment and estimation of conduction velocity"}, {"role": "assistant", "content": "Action potential propagation along the axons and across the dendrites is the\nfoundation of the electrical activity observed in the brain and the rest of the\ncentral nervous system. Theoretical and numerical modeling of this action\npotential activity has long been a key focus area of electro-chemical neuronal\nmodeling. Specifically, considering the presence of nodes of Ranvier along the\nmyelinated axon, single-cable models of the propagation of action potential\nhave been popular. Building on these models, and considering a secondary\nelectrical conduction pathway below the myelin sheath, the double-cable model\nhas been proposed. Such cable theory based treatments have inherent limitations\nin their lack of a representation of the spatio-temporal evolution of the\nneuronal electro-chemistry. In contrast, a Poisson-Nernst-Planck (PNP) based\nelectro-diffusive framework accounts for the underlying spatio-temporal ionic\nconcentration dynamics and is a more comprehensive treatment. In this work, a\nhigh-fidelity implementation of the PNP model is demonstrated. This model is\nshown to produce results similar to the cable theory based electrical models,\nand in addition, the rich spatio-temporal evolution of the underlying ionic\ntransport is captured. Novel to this work is the extension of PNP model to\naxonal geometries with multiple nodes of Ranvier and multiple variants of the\nelectro-diffusive model - PNP without myelin, PNP with myelin, and PNP with the\nmyelin sheath and peri-axonal space. Further, we apply this spatio-temporal\nmodel to numerically estimate conduction velocity in a rat axon. Specifically,\nsaltatory conduction due to the presence of myelin sheath and the peri-axonal\nspace is investigated."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Misleading assertions, unjustified assumptions, and additional\n  limitations of a study by Patone et al., described in the article \"Risk of\n  Myocarditis After Sequential Doses of COVID-19 Vaccine and SARS-CoV-2\n  Infection by Age and Sex\""}, {"role": "assistant", "content": "We describe several shortcomings of a study by Patone et al, whose findings\nwere recently published in the American Heart Association Journal Circulation,\nincluding the following:\n  * The study's principal conclusion, as initially stated, begins \"Overall, the\nrisk of myocarditis is greater after SARS-CoV-2 infection than after COVID-19\nvaccination ....\" However, Patone et al never attempt to assess the incidence\nof myocarditis in their study population following SARS-CoV-2 infection.\nRather, they make an untenable assumption that all infections occurring in\ntheir study population are associated with (reported) positive COVID-19 tests.\nUsing publicly available data from the UK's ONS and NHS, we show that Patone et\nal's estimates, for the unvaccinated, of myocarditis incidence associated with\ninfection are likely overestimated by a factor of at least 1.58.\n  * The method Patone et al use to compute the incidence of myocarditis among\nthe unvaccinated after a positive COVID test may overestimate risk. The authors\nassume, without justification, that unvaccinated persons hospitalized during\nthe study period with positive-test-associated myocarditis would later choose\nto vaccinate with the same probability as unvaccinated persons who have had a\npositive COVID test. We present a plausibility argument that suggests a\npossible further exaggeration of myocarditis risk post infection by a factor of\n1.5.\n  * Patone et al fail to discuss important limitations of their study with\nrespect to guiding public health recommendations. For instance, at most 0.18%\nof SARS-CoV-2 cases that contributed to the study's finding were\nOmicron-variant cases. Thus, the study's estimates of myocarditis risk\nfollowing infection do not speak to the risk following Omicron infection, which\nis recognized to be milder than that of previous variants."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The arithmetic topology of genetic alignments"}, {"role": "assistant", "content": "We propose a novel mathematical paradigm for the study of genetic variation\nin sequence alignments. This framework originates from extending the notion of\npairwise relations, upon which current analysis is based on, to k-ary\ndissimilarity. This dissimilarity naturally leads to a generalization of\nsimplicial complexes by endowing simplices with weights, compatible with the\nboundary operator. We introduce the notion of k-stances and dissimilarity\ncomplex, the former encapsulating arithmetic as well as topological structure\nexpressing these k-ary relations. We study basic mathematical properties of\ndissimilarity complexes and show how this approach captures an entirely new\nlayer of biologically relevant viral dynamics in the context of SARS-CoV-2 and\nH1N1 flu genomic data."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Drug repositioning for Alzheimer's disease with transfer learning"}, {"role": "assistant", "content": "Deep Learning and DRUG-seq (Digital RNA with perturbation of genes) have\nattracted attention in drug discovery. However, the public DRUG-seq dataset is\ntoo small to be used for directly training a deep learning neural network from\nscratch. Inspired by the transfer learning technique, we pretrain a drug\nefficacy prediction neural network model with the Library of Integrated\nNetwork-based Cell-Signature (LINCS) L1000 data and then use human neural cell\nDRUG-seq data to fine-tune it. After training, the model is used for virtual\nscreening to find potential drugs for Alzheimer's disease (AD) treatment.\nFinally, we find 27 potential drugs for AD treatment including Irsogladine\n(PDE4 inhibitor), Tasquinimod (HDAC4 selective inhibitor), Suprofen (dual\nCOX-1/COX-2 inhibitor) et al."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Interactive cohort exploration for spinocerebellar ataxias using\n  synthetic cohort data for visualization"}, {"role": "assistant", "content": "Motivation: A crucial step to understand and also to communicate clinical\ndata either from scientific research or clinical routine practice is\nvisualizing it. However, visualization generally comes with great effort due to\nthe lack of suitable tools or significant technical knowledge about data\nhandling and subsequent visualization. The solution presented in this work\noffers an easy-to-use software tool that enables various kinds of plotting\nfunctions. Due to the easy and intuitive design, the entrance barrier to using\nthe viewer tool is very low, and little to no onboarding is required before\ncreating the first plot. However, patient data are obviously subject to strict\ndata protection. Consequently, the traceability of subjects should be avoided,\nwhich can be overcome by generation of synthetic cohorts. Methods: The\nvisualization tool is developed as an open-source solution implemented as a\nweb-based service consisting of a data module as well as an interface module\nusing modern technologies. The virtual cohort was created in the scope of this\nwork to be able to deploy a version without violating any data protection\nguidelines. This cohort containing artificial patients is generated from a\nnoise-adding model that preserves important aspects of the original data, such\nthat it is a realistic dataset ready to be explored by users. Results: This\nwork presents SCAview, an user-friendly, interactive cohort explorer that aims\nto enable data handling for visualization in a clickable interface. The service\nis deployed and can be tested with a virtual cohort employed for privacy\nreasons. In order to get access please contact the corresponding author\n(address below). Availability: http://idsn.dzne.de - In order to get a user and\npassword please contact philipp.wegner@dzne.de Contact: philipp.wegner@dzne.de"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: On the number of nucleoproteins in the assembly of coronaviruses:\n  Consequences for COVID-19"}, {"role": "assistant", "content": "The multifunctional nucleoproteins play important role in the life cycle of\ncoronaviruses. The assessment of their quantities is of general interest for\nthe assembly of virions and medical applications. The proliferating\nnucleoproteins induce the related (auto)immune response and via binding to host\nRNA affect various regulation mechanisms. In this report we briefly summarize\nand comment the available experimental data on the subject concerned."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Tuning hyperparameters of doublet-detection methods for single-cell RNA\n  sequencing data"}, {"role": "assistant", "content": "The existence of doublets in single-cell RNA sequencing (scRNA-seq) data\nposes a great challenge in downstream data analysis. Computational\ndoublet-detection methods have been developed to remove doublets from scRNA-seq\ndata. Yet, the default hyperparameter settings of those methods may not provide\noptimal performance. Here, we propose a strategy to tune hyperparameters for a\ncutting-edge doublet-detection method. We utilize a full factorial design to\nexplore the relationship between hyperparameters and detection accuracy on 16\nreal scRNA-seq datasets. The optimal hyperparameters are obtained by a response\nsurface model and convex optimization. We show that the optimal hyperparameters\nprovide top performance across scRNA-seq datasets under various biological\nconditions. Our tuning strategy can be applied to other computational\ndoublet-detection methods. It also offers insights into hyperparameter tuning\nfor broader computational methods in scRNA-seq data analysis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Vital Measurements of Hospitalized COVID-19 Patients as a Predictor of\n  Long COVID: An EHR-based Cohort Study from the RECOVER Program in N3C"}, {"role": "assistant", "content": "It is shown that various symptoms could remain in the stage of post-acute\nsequelae of SARS-CoV-2 infection (PASC), otherwise known as Long COVID. A\nnumber of COVID patients suffer from heterogeneous symptoms, which severely\nimpact recovery from the pandemic. While scientists are trying to give an\nunambiguous definition of Long COVID, efforts in prediction of Long COVID could\nplay an important role in understanding the characteristic of this new disease.\nVital measurements (e.g. oxygen saturation, heart rate, blood pressure) could\nreflect body's most basic functions and are measured regularly during\nhospitalization, so among patients diagnosed COVID positive and hospitalized,\nwe analyze the vital measurements of first 7 days since the hospitalization\nstart date to study the pattern of the vital measurements and predict Long\nCOVID with the information from vital measurements."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Hypergraph Analysis Toolbox for Chromosome Conformation"}, {"role": "assistant", "content": "Recent advances in biological technologies, such as multi-way chromosome\nconformation capture (3C), require development of methods for analysis of\nmulti-way interactions. Hypergraphs are mathematically tractable objects that\ncan be utilized to precisely represent and analyze multi-way interactions. Here\nwe present the Hypergraph Analysis Toolbox (HAT), a software package for\nvisualization and analysis of multi-way interactions in complex systems."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Biological Random Walks: multi-omics integration for disease gene\n  prioritization"}, {"role": "assistant", "content": "Motivation: Over the past decade, network-based approaches have proven useful\nin identifying disease modules within the human interactome, often providing\ninsights into key mechanisms and guiding the quest for therapeutic targets.\nThis is all the more important, since experimental investigation of potential\ngene candidates is an expensive task, thus not always a feasible option. On the\nother hand, many sources of biological information exist beyond the interactome\nand an important research direction is the design of effective techniques for\ntheir integration. Results: In this work, we introduce the Biological Random\nWalks (BRW) approach for disease gene prioritization in the human interactome.\nThe proposed framework leverages multiple biological sources within an\nintegrated framework. We perform an extensive, comparative study of BRW's\nperformance against well-established baselines. Availability and\nimplementation: All code is publicly available and can be downloaded at\n\\url{https://github.com/LeoM93/BiologicalRandomWalks}. We used publicly\navailable datasets, details on their retrieval and preprocessing are provided\nin the supplementary material."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Machine learning strategies to predict late adverse effects in childhood\n  acute lymphoblastic leukemia survivors"}, {"role": "assistant", "content": "Acute lymphoblastic leukemia is the most frequent pediatric cancer.\nApproximately two third of survivors develop one or more health complications\nknown as late adverse effects following their treatments. The existing measures\noffered to patients during their follow-up visits to the hospital are rather\nstandardized for all childhood cancer survivors and not necessarily\npersonalized for childhood ALL survivors. As a result, late adverse effects may\nbe underdiagnosed and, in most cases, only taken care of following their\nappearance. Thus, it is necessary to predict these treatment-related conditions\nearlier in order to prevent them and enhance the survivors' health. Multiple\nstudies have investigated the development of late adverse effects prediction\ntools to offer better personalized follow-up methods. However, no solution\nintegrated the usage of neural networks to date. In this work, we developed\ngraph-based parameters-efficient neural networks and promoted their\ninterpretability with multiple post-hoc analyses. We first proposed a new\ndisease-specific VO$_2$ peak prediction model that does not require patients to\nparticipate to a physical function test (e.g., 6-minute walk test) and further\ncreated an obesity prediction model using clinical variables that are available\nfrom the end of childhood ALL treatment as well as genomic variables. Our\nsolutions were able to achieve better performance than linear and tree-based\nmodels on small cohorts of patients ($\\leq$ 223) for both tasks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Machine Learning Algorithms for Predicting in-Hospital Mortality in\n  Patients with ST-Segment Elevation Myocardial Infar"}, {"role": "assistant", "content": "Acute myocardial infarction (AMI) is one of the most severe manifestation of\ncoronary artery disease. ST-segment elevation myocardial infarction (STEMI) is\nthe most serious type of AMI. We proposed to develop a machine learning\nalgorithm based on the home page of electronic medical record (HPEMR) for\npredicting in-hospital mortality of patients with STEMI in the early stage.\nMethods: This observational study applied clinical information collected\nbetween 2013 and 2017 from 7 tertiary hospitals in Shenzhen, China. The\npatients' STEMI data were used to train 4 different machine learning algorithms\nto predict in-hospital mortality among the patients with STEMI, including\nLogistic Regression, Support Vector Machine, Gradient Boosting Decision Tree,\nand Artificial Neuron network. Results: A total of 5865 patients with STEMI\nwere enrolled in our study. The model was developed by considering 3 types of\nvariables, which included demographic data, diagnosis and comorbidities, and\nhospitalization information basing on HPEMR. The association of selected\nfeatures using univariant logistic regression was reported. Specially, for the\ncomorbidities, atrial fibrillation (OR: 11.0; 95% CI: 5.64 - 20.2), acute renal\nfailure (OR: 9.75; 95% CI: 3.81 - 25.0), type 2 diabetic nephropathy (OR: 5.45;\n95% CI: 1.57 - 19.0), acute heart failure (OR: 6.05; 95% CI: 1.99 - 14.9), and\ncardiac function grade IV (OR: 28.6; 95% CI: 20.6 - 39.6) were found to be\nassociated with a high odds of death. Within the test dataset, our model showed\na good discrimination ability as measured by area under the receiver operating\ncharacteristic curve (AUC; 0.879) (95% CI: 0.825 - 0.933)."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Antibiotic-dependent instability of homeostatic plasticity for growth\n  and environmental load"}, {"role": "assistant", "content": "Reducing antibiotic usage in livestock animals has become an urgent issue\nworldwide to prevent antimicrobial resistance. Here, abuse of chlortetracycline\n(CTC), a versatile antibacterial agent, on the performance, blood components,\nfecal microbiota, and organic acid concentration in calves was investigated.\nJapanese Black calves were fed milk replacer containing CTC at 10 g/kg (CON) or\n0 g/kg (EXP). Growth performance was not affected by CTC administration.\nHowever, CTC administration altered the correlation between fecal organic acids\nand bacterial genera. Machine learning methods such as association analysis,\nlinear discriminant analysis, and energy landscape analysis revealed that CTC\nadministration affected according to certain rules the population of various\ntypes of fecal bacteria. It is particularly interesting that the population of\nseveral methane-producing bacteria was high in the CON, and that of\nLachnospiraceae, a butyrate-producing bacteria, was high in the EXP at 60 d of\nage. Furthermore, statistical causal inference based on machine learning data\nestimated that CTC treatment affects the entire intestinal environment,\ninhibiting butyrate production for growth and biological defense, which may be\nattributed to methanogens in feces. Thus, these observations highlight the\nmultiple harmful impacts of antibiotics on intestinal health and the potential\nproduction of greenhouse gas in the calves."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Genetic Sequence compression using Machine Learning and Arithmetic\n  Encoding Decoding Techniques"}, {"role": "assistant", "content": "We live in a period where bio-informatics is rapidly expanding, a significant\nquantity of genomic data has been produced as a result of the advancement of\nhigh-throughput genome sequencing technology, raising concerns about the costs\nassociated with data storage and transmission. The question of how to properly\ncompress data from genomic sequences is still open. Previously many researcher\nproposed many compression method on this topic DNA Compression without machine\nlearning and with machine learning approach. Extending a previous research, we\npropose a new architecture like modified DeepDNA and we have propose a new\nmethodology be deploying a double base-ed strategy for compression of DNA\nsequences. And validated the results by experimenting on three sizes of\ndatasets are 100, 243, 356. The experimental outcomes highlight our improved\napproach's superiority over existing approaches for analyzing the human\nmitochondrial genome data, such as DeepDNA."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Probabilistic estimation of microarray data reliability and underlying\n  gene expression"}, {"role": "assistant", "content": "Background: The availability of high throughput methods for measurement of\nmRNA concentrations makes the reliability of conclusions drawn from the data\nand global quality control of samples and hybridization important issues. We\naddress these issues by an information theoretic approach, applied to\ndiscretized expression values in replicated gene expression data.\n  Results: Our approach yields a quantitative measure of two important\nparameter classes: First, the probability $P(\\sigma | S)$ that a gene is in the\nbiological state $\\sigma$ in a certain variety, given its observed expression\n$S$ in the samples of that variety. Second, sample specific error probabilities\nwhich serve as consistency indicators of the measured samples of each variety.\nThe method and its limitations are tested on gene expression data for\ndeveloping murine B-cells and a $t$-test is used as reference. On a set of\nknown genes it performs better than the $t$-test despite the crude\ndiscretization into only two expression levels. The consistency indicators,\ni.e. the error probabilities, correlate well with variations in the biological\nmaterial and thus prove efficient.\n  Conclusions: The proposed method is effective in determining differential\ngene expression and sample reliability in replicated microarray data. Already\nat two discrete expression levels in each sample, it gives a good explanation\nof the data and is comparable to standard techniques."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Development of a Multiphoton Fluorescence Lifetime Imaging Microscopy\n  (FLIM) system using a Streak Camera"}, {"role": "assistant", "content": "We report the development and detailed calibration of a multiphoton\nfluorescence lifetime imaging system (FLIM) using a streak camera. The present\nsystem is versatile with high spatial (0.2 micron) and temporal (50 psec)\nresolution and allows rapid data acquisition and reliable and reproducible\nlifetime determinations. The system was calibrated with standard fluorescent\ndyes and the lifetime values obtained were in very good agreement with values\nreported in literature for these dyes. We also demonstrate the applicability of\nthe system to FLIM studies in cellular specimens including stained pollen\ngrains and fibroblast cells expressing green fluorescent protein. The lifetime\nvalues obtained matched well with those reported earlier by other groups for\nthese same specimens. Potential applications of the present system include the\nmeasurement of intracellular physiology and Fluorescence Resonance Energy\nTransfer (FRET) imaging which are discussed in the context of live cell\nimaging."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Idl Signal Processing Library 1.0"}, {"role": "assistant", "content": "We make available a library of documented IDL .pro files as well as a\nshareable object library that allows IDL to call routines from LAPACK. The\nroutines are for use in the spectral analysis of time series data. The primary\nfocus of these routines are David Thomson's multitaper methods but a whole\nrange of functions will be made available in future revisions of the\nsubmission. At present routines are provided to carry out the following\noperations: calculate prolate spheroidal sequences and eigenvalues, project\ntime-series into frequency bands, calculate spectral estimates with or without\nmoving windows, and calculate the cross-coherence between two time series as a\nfunction of frequency as well as the coherence between frequencies for a single\ntime series."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Response kinetics of tethered bacteria to stepwise changes in nutrient\n  concentration"}, {"role": "assistant", "content": "We examined the changes in swimming behaviour of the bacterium Rhodobacter\nsphaeroides in response to stepwise changes in a nutrient (propionate),\nfollowing the prestimulus motion, the initial response and the adaptation to\nthe sustained concentration of the chemical. This was carried out by tethering\nmotile cells by their flagella to glass slides and following the rotational\nbehaviour of their cell bodies in response to the nutrient change. Computerised\nmotion analysis was used to analyse the behaviour. Distributions of run and\nstop times were obtained from rotation data for tethered cells. Exponential and\nWeibull fits for these distributions, and variability in individual responses\nare discussed. In terms of parameters derived from the run and stop time\ndistributions, we compare the responses to stepwise changes in the nutrient\nconcentration and the long-term behaviour of 84 cells under twelve propionate\nconcentration levels from 1 nM to 25 mM. We discuss traditional assumptions for\nthe random walk approximation to bacterial swimming and compare them with the\nobserved R. sphaeroides motile behaviour."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Solvent content of protein crystals from diffraction intensities by\n  Independent Component Analysis"}, {"role": "assistant", "content": "An analysis of the protein content of several crystal forms of proteins has\nbeen performed. We apply a new numerical technique, the Independent Component\nAnalysis (ICA), to determine the volume fraction of the asymmetric unit\noccupied by the protein. This technique requires only the crystallographic data\nof structure factors as input."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Identification in models of biochemical reactions"}, {"role": "assistant", "content": "We introduce, analyze, and implement a new method for parameter\nidentification for system of ordinary differential equations that are used to\nmodel sets of biochemical reactions. Our method relies on the integral\nformulation of the ODE system and a method of linear least squares applied to\nthe integral equations. Certain variants of this method are also introduced in\nthis paper."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Microelectromagnets for the manipulation of biological systems"}, {"role": "assistant", "content": "Microelectromagnet devices, a ring trap and a matrix, were developed for the\nmicroscopic control of biological systems. The ring trap is a circular Au wire\nwith an insulator on top. The matrix has two arrays of straight Au wires, one\narray perpendicular to the other, that are separated and topped by insulating\nlayers. Microelectromagnets can produce strong magnetic fields to stably\nmanipulate magnetically tagged biological systems in a fluid. Moreover, by\ncontrolling the currents flowing through the wires, a microelectromagnet matrix\ncan move a peak in the magnetic field magnitude continuously over the surface\nof the device, generate multiple peaks simultaneously and control them\nindependently. These capabilities of a matrix can be used to trap, continuously\ntransport, assemble, separate and sort biological samples on micrometer length\nscales. Combining microelectromagnets with microfluidic systems, chip-based\nexperimental systems can be realized for novel applications in biological and\nbiomedical studies."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Barrier Penetration Model for DNA Double Strand Separation"}, {"role": "assistant", "content": "A barrier penetration model has been proposed to explain the spontaneous\nmelting of the DNA oligomers into two separate single strands whereas the\npartially melted intermediate states are shown to be the bound state solution\nof the same effective potential that generates the barrier."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Open Mass Spectrometry Search Algorithm"}, {"role": "assistant", "content": "Large numbers of MS/MS peptide spectra generated in proteomics experiments\nrequire efficient, sensitive and specific algorithms for peptide\nidentification. In the Open Mass Spectrometry Search Algorithm [OMSSA],\nspecificity is calculated by a classic probability score using an explicit\nmodel for matching experimental spectra to sequences. At default thresholds,\nOMSSA matches more spectra from a standard protein cocktail than a comparable\nalgorithm. OMSSA is designed to be faster than published algorithms in\nsearching large MS/MS datasets."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Finite Width Model Sequence Comparison"}, {"role": "assistant", "content": "Sequence comparison is a widely used computational technique in modern\nmolecular biology. In spite of the frequent use of sequence comparisons the\nimportant problem of assigning statistical significance to a given degree of\nsimilarity is still outstanding. Analytical approaches to filling this gap\nusually make use of an approximation that neglects certain correlations in the\ndisorder underlying the sequence comparison algorithm. Here, we use the longest\ncommon subsequence problem, a prototype sequence comparison problem, to\nanalytically establish that this approximation does make a difference to\ncertain sequence comparison statistics. In the course of establishing this\ndifference we develop a method that can systematically deal with these disorder\ncorrelations."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Predicting Genetic Regulatory Response using Classification: Yeast\n  Stress Response"}, {"role": "assistant", "content": "We present a novel classification-based algorithm called GeneClass for\nlearning to predict gene regulatory response. Our approach is motivated by the\nhypothesis that in simple organisms such as Saccharomyces cerevisiae, we can\nlearn a decision rule for predicting whether a gene is up- or down-regulated in\na particular experiment based on (1) the presence of binding site subsequences\n(``motifs'') in the gene's regulatory region and (2) the expression levels of\nregulators such as transcription factors in the experiment (``parents''). Thus\nour learning task integrates two qualitatively different data sources:\ngenome-wide cDNA microarray data across multiple perturbation and mutant\nexperiments along with motif profile data from regulatory sequences. Rather\nthan focusing on the regression task of predicting real-valued gene expression\nmeasurements, GeneClass performs the classification task of predicting +1 and\n-1 labels, corresponding to up- and down-regulation beyond the levels of\nbiological and measurement noise in microarray measurements. GeneClass uses the\nAdaboost learning algorithm with a margin-based generalization of decision\ntrees called alternating decision trees. In computational experiments based on\nthe Gasch S. cerevisiae dataset, we show that the GeneClass method predicts up-\nand down-regulation on held-out experiments with high accuracy. We explore a\nrange of experimental setups related to environmental stress response, and we\nretrieve important regulators, binding site motifs, and relationships between\nregulators and binding sites that are known to be associated to specific stress\nresponse pathways. Our method thus provides predictive hypotheses, suggests\nbiological experiments, and provides interpretable insight into the structure\nof genetic regulatory networks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Rate-dependent propagation of cardiac action potentials in a\n  one-dimensional fiber"}, {"role": "assistant", "content": "Action potential duration (APD) restitution, which relates APD to the\npreceding diastolic interval (DI), is a useful tool for predicting the onset of\nabnormal cardiac rhythms. However, it is known that different pacing protocols\nlead to different APD restitution curves (RCs). This phenomenon, known as APD\nrate-dependence, is a consequence of memory in the tissue. In addition to APD\nrestitution, conduction velocity restitution also plays an important role in\nthe spatiotemporal dynamics of cardiac tissue. We present new results\nconcerning rate-dependent restitution in the velocity of propagating action\npotentials in a one-dimensional fiber. Our numerical simulations show that,\nindependent of the amount of memory in the tissue, waveback velocity exhibits\npronounced rate-dependence and the wavefront velocity does not. Moreover, the\ndiscrepancy between waveback velocity RCs is most significant for small DI. We\nprovide an analytical explanation of these results, using a system of coupled\nmaps to relate the wavefront and waveback velocities. Our calculations show\nthat waveback velocity rate-dependence is due to APD restitution, not memory."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Computation of amplification for systems arising from cellular signaling\n  pathways"}, {"role": "assistant", "content": "A commonly employed measure of the signal amplification properties of an\ninput/output system is its induced L2 norm, sometimes also known as \"H\ninfinity\" gain. In general, however, it is extremely difficult to compute the\nnumerical value for this norm, or even to check that it is finite, unless the\nsystem being studied is linear. This paper describes a class of systems for\nwhich it is possible to reduce this computation to that of finding the norm of\nan associated linear system. In contrast to linearization approaches, a precise\nvalue, not an estimate, is obtained for the full nonlinear model. The class of\nsystems that we study arose from the modeling of certain biological\nintracellular signaling cascades, but the results should be of wider\napplicability."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Dependence of RNA secondary structure on the energy model"}, {"role": "assistant", "content": "We analyze a microscopic RNA model, which includes two widely used models as\nlimiting cases, namely it contains terms for bond as well as for stacking\nenergies. We numerically investigate possible changes in the qualitative and\nquantitative behaviour while going from one model to the other; in particular\nwe test, whether a transition occurs, when continuously moving from one model\nto the other. For this we calculate various thermodynamic quantities, both at\nzero temperature as well as at finite temperatures. All calculations can be\ndone efficiently in polynomial time by a dynamic programming algorithm. We do\nnot find a sign for transition between the models, but the critical exponent\n$\\nu$ of the correlation length, describing the phase transition in all models\nto an ordered low-temperature phase, seems to depend continuously on the model.\nFinally, we apply the epsilon-Coupling method, to study low excitations. The\nexponent $\\theta$ describing the energy-scaling of the excitations seems to\ndepend not much on the energy model."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Nonstationary time series analysis of heart rate variability"}, {"role": "assistant", "content": "An analysis of the RR-interval time series, $t_i$, is presented for the case\nin which the average time, $\\bar{t}$, changes slowly. In particular, $\\bar{t}$\nand a short-time scale variability parameter, $V$, are simultaneously measured\nwhile $\\bar{t}$ decreases for subjects in the reclined position. The initial\ndecrease in $\\bar{t}$ is usually linear with $V$ yielding parameters that can\nbe related to physiological quantities."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Predicting Genetic Regulatory Response Using Classification"}, {"role": "assistant", "content": "We present a novel classification-based method for learning to predict gene\nregulatory response. Our approach is motivated by the hypothesis that in simple\norganisms such as Saccharomyces cerevisiae, we can learn a decision rule for\npredicting whether a gene is up- or down-regulated in a particular experiment\nbased on (1) the presence of binding site subsequences (``motifs'') in the\ngene's regulatory region and (2) the expression levels of regulators such as\ntranscription factors in the experiment (``parents''). Thus our learning task\nintegrates two qualitatively different data sources: genome-wide cDNA\nmicroarray data across multiple perturbation and mutant experiments along with\nmotif profile data from regulatory sequences. We convert the regression task of\npredicting real-valued gene expression measurement to a classification task of\npredicting +1 and -1 labels, corresponding to up- and down-regulation beyond\nthe levels of biological and measurement noise in microarray measurements. The\nlearning algorithm employed is boosting with a margin-based generalization of\ndecision trees, alternating decision trees. This large-margin classifier is\nsufficiently flexible to allow complex logical functions, yet sufficiently\nsimple to give insight into the combinatorial mechanisms of gene regulation. We\nobserve encouraging prediction accuracy on experiments based on the Gasch S.\ncerevisiae dataset, and we show that we can accurately predict up- and\ndown-regulation on held-out experiments. Our method thus provides predictive\nhypotheses, suggests biological experiments, and provides interpretable insight\ninto the structure of genetic regulatory networks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multiple sequence alignment based on set covers"}, {"role": "assistant", "content": "We introduce a new heuristic for the multiple alignment of a set of\nsequences. The heuristic is based on a set cover of the residue alphabet of the\nsequences, and also on the determination of a significant set of blocks\ncomprising subsequences of the sequences to be aligned. These blocks are\nobtained with the aid of a new data structure, called a suffix-set tree, which\nis constructed from the input sequences with the guidance of the\nresidue-alphabet set cover and generalizes the well-known suffix tree of the\nsequence set. We provide performance results on selected BAliBASE amino-acid\nsequences and compare them with those yielded by some prominent approaches."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Computational Methods and Results for Structured Multiscale Models of\n  Tumor Invasion"}, {"role": "assistant", "content": "We present multiscale models of cancer tumor invasion with components at the\nmolecular, cellular, and tissue levels. We provide biological justifications\nfor the model components, present computational results from the model, and\ndiscuss the scientific-computing methodology used to solve the model equations.\nThe models and methodology presented in this paper form the basis for\ndeveloping and treating increasingly complex, mechanistic models of tumor\ninvasion that will be more predictive and less phenomenological. Because many\nof the features of the cancer models, such as taxis, aging and growth, are seen\nin other biological systems, the models and methods discussed here also provide\na template for handling a broader range of biological problems."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Variable selection from random forests: application to gene expression\n  data"}, {"role": "assistant", "content": "Random forest is a classification algorithm well suited for microarray data:\nit shows excellent performance even when most predictive variables are noise,\ncan be used when the number of variables is much larger than the number of\nobservations, and returns measures of variable importance. Thus, it is\nimportant to understand the performance of random forest with microarray data\nand its use for gene selection.\n  We first show the effects of changes in parameters of random forest on the\nprediction error. Then we present an approach for gene selection that uses\nmeasures of variable importance and error rate, and is targeted towards the\nselection of small sets of genes. Using simulated and real microarray data, we\nshow that the gene selection procedure yields small sets of genes while\npreserving predictive accuracy.\n  Availability: All code is available as an R package, varSelRF, from CRAN,\nhttp://cran.r-project.org/src/contrib/PACKAGES.html, or from the supplementary\nmaterial page.\n  Supplementary information:\nhttp://ligarto.org/rdiaz/Papers/rfVS/randomForestVarSel.html"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A methodology for determining amino-acid substitution matrices from set\n  covers"}, {"role": "assistant", "content": "We introduce a new methodology for the determination of amino-acid\nsubstitution matrices for use in the alignment of proteins. The new methodology\nis based on a pre-existing set cover on the set of residues and on the\nundirected graph that describes residue exchangeability given the set cover.\nFor fixed functional forms indicating how to obtain edge weights from the set\ncover and, after that, substitution-matrix elements from weighted distances on\nthe graph, the resulting substitution matrix can be checked for performance\nagainst some known set of reference alignments and for given gap costs. Finding\nthe appropriate functional forms and gap costs can then be formulated as an\noptimization problem that seeks to maximize the performance of the substitution\nmatrix on the reference alignment set. We give computational results on the\nBAliBASE suite using a genetic algorithm for optimization. Our results indicate\nthat it is possible to obtain substitution matrices whose performance is either\ncomparable to or surpasses that of several others, depending on the particular\nscenario under consideration."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Modeling multi-cellular systems using sub-cellular elements"}, {"role": "assistant", "content": "We introduce a model for describing the dynamics of large numbers of\ninteracting cells. The fundamental dynamical variables in the model are\nsub-cellular elements, which interact with each other through phenomenological\nintra- and inter-cellular potentials. Advantages of the model include i)\nadaptive cell-shape dynamics, ii) flexible accommodation of additional\nintra-cellular biology, and iii) the absence of an underlying grid. We present\nhere a detailed description of the model, and use successive mean-field\napproximations to connect it to more coarse-grained approaches, such as\ndiscrete cell-based algorithms and coupled partial differential equations. We\nalso discuss efficient algorithms for encoding the model, and give an example\nof a simulation of an epithelial sheet. Given the biological flexibility of the\nmodel, we propose that it can be used effectively for modeling a range of\nmulti-cellular processes, such as tumor dynamics and embryogenesis."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Combinatorial rules of icosahedral capsid growth"}, {"role": "assistant", "content": "A model of growth of icosahedral viral capsids is proposed. It takes into\naccount the diversity of hexamers' compositions, leading to definite capsid\nsize. We show that the observed yield of capsid production implies a very high\nlevel of self-organization of elementary building blocks. The exact number of\ndifferent protein dimers composing hexamers is related to the size of a given\ncapsid, labeled by its T-number. Simple rules determining these numbers for\neach value of T are deduced and certain consequences are discussed."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Quantitative Measure of Stability in Gene Regulatory Networks"}, {"role": "assistant", "content": "A quantitative measure of stability in stochastic dynamics starts to emerge\nin recent experiments on bioswitches. This quantity, similar to the potential\nfunction in mathematics, is deeply rooted in biology, dated back at the\nbeginning of quantitative description of biological processes: the adaptive\nlandscape of Wright (1932) and the development landscape of Waddington (1940).\nNevertheless, its quantitative implication has been frequently challenged by\nbiologists. Recent progresses in quantitative biology begin to meet those\noutstanding challenges."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Modified Iterative IOM Approach for Optimization of Biochemical\n  Systems"}, {"role": "assistant", "content": "The presented previously indirect optimization method (IOM) developed within\nbiochemical systems theory (BST) provides a versatile and mathematically\ntractable optimization strategy for biochemical systems. However, due to the\nlocal approximations nature of the BST formalism, the iterative version of this\ntechnique possibly does not yield the true optimum solution. In this work, an\nalgorithm is proposed to obtain the correct and consistent optimum steady-state\noperating point of biochemical systems. The existing linear optimization\nproblem of the direct IOM approach is modified by adding an equality constraint\nof describing the consistency of solutions between the S-system and the\noriginal model. Lagrangian analysis is employed to derive the first order\nnecessary optimality conditions for the above modified optimization problem.\nThis leads to a procedure that may be regarded as a modified iterative IOM\napproach in which the optimization objective function includes an extra linear\nterm. The extra term contains a comparison of metabolite concentration\nderivatives with respect to the enzyme activities between the S-system and the\noriginal model and ensures that the new algorithm is still carried out within\nlinear programming techniques. The presented framework is applied to several\nbiochemical systems and shown to the tractability and effectiveness of the\nmethod. The simulation is also studied to investigate the convergence\nproperties of the algorithm and to give a performance comparison of standard\nand modified iterative IOM approach."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Statistical Predictive Models in Ecology: Comparison of Performances and\n  Assessment of Applicability"}, {"role": "assistant", "content": "Ecological systems are governed by complex interactions which are mainly\nnonlinear. In order to capture this complexity and nonlinearity, statistical\nmodels recently gained popularity. However, although these models are commonly\napplied in ecology, there are no studies to date aiming to assess the\napplicability and performance. We provide an overview for nature of the wide\nrange of the data sets and predictive variables, from both aquatic and\nterrestrial ecosystems with different scales of time-dependent dynamics, and\nthe applicability and robustness of predictive modeling methods on such data\nsets by comparing different statistical modeling approaches. The methods\nconsidered k-NN, LDA, QDA, generalized linear models (GLM) feedforward\nmultilayer backpropagation networks and pseudo-supervised network ARTMAP. For\necosystems involving time-dependent dynamics and periodicities whose frequency\nare possibly less than the time scale of the data considered, GLM and\nconnectionist neural network models appear to be most suitable and robust,\nprovided that a predictive variable reflecting these time-dependent dynamics\nincluded in the model either implicitly or explicitly. For spatial data, which\ndoes not include any time-dependence comparable to the time scale covered by\nthe data, on the other hand, neighborhood based methods such as k-NN and ARTMAP\nproved to be more robust than other methods considered in this study. In\naddition, for predictive modeling purposes, first a suitable, computationally\ninexpensive method should be applied to the problem at hand a good predictive\nperformance of which would render the computational cost and efforts associated\nwith complex variants unnecessary."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Kernel methods in genomics and computational biology"}, {"role": "assistant", "content": "Support vector machines and kernel methods are increasingly popular in\ngenomics and computational biology, due to their good performance in real-world\napplications and strong modularity that makes them suitable to a wide range of\nproblems, from the classification of tumors to the automatic annotation of\nproteins. Their ability to work in high dimension, to process non-vectorial\ndata, and the natural framework they provide to integrate heterogeneous data\nare particularly relevant to various problems arising in computational biology.\nIn this chapter we survey some of the most prominent applications published so\nfar, highlighting the particular developments in kernel methods triggered by\nproblems in biology, and mention a few promising research directions likely to\nexpand in the future."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Maximum likelihood estimation of phylogenetic tree and substitution\n  rates via generalized neighbor-joining and the EM algorithm"}, {"role": "assistant", "content": "A central task in the study of molecular sequence data from present-day\nspecies is the reconstruction of the ancestral relationships. The most\nestablished approach to tree reconstruction is the maximum likelihood (ML)\nmethod. In this method, evolution is described in terms of a discrete-state\ncontinuous-time Markov process on a phylogenetic tree. The substitution rate\nmatrix, that determines the Markov process, can be estimated using the\nexpectation maximization (EM) algorithm. Unfortunately, an exhaustive search\nfor the ML phylogenetic tree is computationally prohibitive for large data\nsets. In such situations, the neighbor-joining (NJ) method is frequently used\nbecause of its computational speed. The NJ method reconstructs trees by\nclustering neighboring sequences recursively, based on pairwise comparisons\nbetween the sequences. The NJ method can be generalized such that\nreconstruction is based on comparisons of subtrees rather than pairwise\ndistances. In this paper, we present an algorithm for simultaneous substitution\nrate estimation and phylogenetic tree reconstruction. The algorithm iterates\nbetween the EM algorithm for estimating substitution rates and the generalized\nNJ method for tree reconstruction. Preliminary results of the approach are\nencouraging."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Information based clustering: Supplementary material"}, {"role": "assistant", "content": "This technical report provides the supplementary material for a paper\nentitled \"Information based clustering\", to appear shortly in Proceedings of\nthe National Academy of Sciences (USA). In Section I we present in detail the\niterative clustering algorithm used in our experiments and in Section II we\ndescribe the validation scheme used to determine the statistical significance\nof our results. Then in subsequent sections we provide all the experimental\nresults for three very different applications: the response of gene expression\nin yeast to different forms of environmental stress, the dynamics of stock\nprices in the Standard and Poor's 500, and viewer ratings of popular movies. In\nparticular, we highlight some of the results that seem to deserve special\nattention. All the experimental results and relevant code, including a freely\navailable web application, can be found at\nhttp://www.genomics.princeton.edu/biophysics-theory ."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Information based clustering"}, {"role": "assistant", "content": "In an age of increasingly large data sets, investigators in many different\ndisciplines have turned to clustering as a tool for data analysis and\nexploration. Existing clustering methods, however, typically depend on several\nnontrivial assumptions about the structure of data. Here we reformulate the\nclustering problem from an information theoretic perspective which avoids many\nof these assumptions. In particular, our formulation obviates the need for\ndefining a cluster \"prototype\", does not require an a priori similarity metric,\nis invariant to changes in the representation of the data, and naturally\ncaptures non-linear relations. We apply this approach to different domains and\nfind that it consistently produces clusters that are more coherent than those\nextracted by existing algorithms. Finally, our approach provides a way of\nclustering based on collective notions of similarity rather than the\ntraditional pairwise measures."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Co-transport-induced instability of membrane voltage in tip-growing\n  cells"}, {"role": "assistant", "content": "A salient feature of stationary patterns in tip-growing cells is the key role\nplayed by the symports and antiports, membrane proteins that translocate two\nionic species at the same time. It is shown that these co-transporters\ndestabilize generically the membrane voltage if the two translocated ions\ndiffuse differently and carry a charge of opposite (same) sign for symports\n(antiports). Orders of magnitude obtained for the time and lengthscale are in\nagreement with experiments. A weakly nonlinear analysis characterizes the\nbifurcation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Surprises in approximating Levenshtein distances"}, {"role": "assistant", "content": "The Levenshtein distance is an important tool for the comparison of symbolic\nsequences, with many appearances in genome research, linguistics and other\nareas. For efficient applications, an approximation by a distance of smaller\ncomputational complexity is highly desirable. However, our comparison of the\nLevenshtein with a generic dictionary-based distance indicates their\nstatistical independence. This suggests that a simplification along this line\nmight not be possible without restricting the class of sequences. Several other\nprobabilistic properties are briefly discussed, emphasizing various questions\nthat deserve further investigation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Statistical Properties of the Interbeat Interval Cascade in Human\n  Subjects"}, {"role": "assistant", "content": "Statistical properties of interbeat intervals cascade are evaluated by\nconsidering the joint probability distribution $P(\\Delta x_2,\\tau_2;\\Delta\nx_1,\\tau_1)$ for two interbeat increments $\\Delta x_1$ and $\\Delta x_2$ of\ndifferent time scales $\\tau_1$ and $\\tau_2$. We present evidence that the\nconditional probability distribution $P(\\Delta x_2,\\tau_2|\\Delta x_1,\\tau_1)$\nmay obey a Chapman-Kolmogorov equation. The corresponding Kramers-Moyal (KM)\ncoefficients are evaluated. It is shown that while the first and second KM\ncoefficients, i.e., the drift and diffusion coefficients, take on well-defined\nand significant values, the higher-order coefficients in the KM expansion are\nvery small. As a result, the joint probability distributions of the increments\nin the interbeat intervals obey a Fokker-Planck equation. The method provides a\nnovel technique for distinguishing the two classes of subjects in terms of the\ndrift and diffusion coefficients, which behave differently for two classes of\nthe subjects, namely, healthy subjects and those with congestive heart failure."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: New Computational Approaches to Analysis of Interbeat Intervals in Human\n  Subjects"}, {"role": "assistant", "content": "We investigate the Markov nature, Cascade of information from large time\nscale to small scale and extended self similarity properties of the beat to\nbeat fluctuations of healthy subjects as well as those with congestive heart\nfailure. To check the Markov nature, we use a novel inverse method that\nutilizes a set of data to construct a simple equation that governs the\nstochastic process for which the data have been measured, hence enabling us to\nreconstruct the stochastic process. The inverse method provides a novel\ntechnique for distinguishing the two classes of subjects in terms of a drift\nand a diffusion coefficients which behave completely differently for the two\nclasses of subjects.To investigate the cascade of information from large to\nsmall time scales we also analyze the statistical properties of interbeat\nintervals cascade by considering the joint probability distribution for two\ninterbeat increments. As a result, the joint probability distributions of the\nincrements in the interbeat intervals obey a Fokker-Planck equation. Finally we\nanalyze the extended self-similarity (ESS) in the beat-to-beat fluctuations in\nthe heart rates of healthy and congestive heart failure subjects.The proposed\nmethods provide the novel techniques for distinguishing the two classes of\nsubjects in terms of the drift and diffusion coefficients, intermittency\nexponents which behave differently for two classes of the subjects, namely,\nhealthy subjects and those with congestive heart failure."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A quantitative model for refilling of the sarcoplasmic reticulum during\n  vascular smooth muscle asynchronous [Ca2+] oscillations"}, {"role": "assistant", "content": "We have developed a quantitative model for the creation of cytoplasmic Ca2+\ngradients near the inner surface of the plasma membrane (PM). In particular we\nsimulated the refilling of the sarcoplasmic reticulum (SR) via PM-SR junctions\nduring asynchronous [Ca2+] oscillations in smooth muscle cells of the rabbit\ninferior vena cava. We have combined confocal microscopy data on the [Ca2+]\noscillations, force transduction data from cell contraction studies and\nelectron microscopic images to build a basis for computational simulations that\nmodel the transport of calcium ions from Na+/Ca2+ exchangers (NCX) on the PM to\nsarcoplasmic/endoplasmic reticulum Ca2+ ATPase (SERCA) pumps on the SR as a\nthree-dimensional random walk through the PM-SR junctional cytoplasmic spaces.\nElectron microscopic ultrastructural images of the smooth muscle cells were\nelaborated with software algorithms to produce a very clear and dimensionally\naccurate picture of the PM-SR junctions. From this study, we conclude that it\nis plausible and possible for enough Ca2+ to pass through the PM-SR junctions\nto replete the SR during the regenerative Ca2+ release, which underlies agonist\ninduced asynchronous Ca2+ oscillations in vascular smooth muscle."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: The pharmacophore kernel for virtual screening with support vector\n  machines"}, {"role": "assistant", "content": "We introduce a family of positive definite kernels specifically optimized for\nthe manipulation of 3D structures of molecules with kernel methods. The kernels\nare based on the comparison of the three-points pharmacophores present in the\n3D structures of molecul es, a set of molecular features known to be\nparticularly relevant for virtual screening applications. We present a\ncomputationally demanding exact implementation of these kernels, as well as\nfast approximations related to the classical fingerprint-based approa ches.\nExperimental results suggest that this new approach outperforms\nstate-of-the-art algorithms based on the 2D structure of mol ecules for the\ndetection of inhibitors of several drug targets."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Spectral analysis of gene expression profiles using gene networks"}, {"role": "assistant", "content": "Microarrays have become extremely useful for analysing genetic phenomena, but\nestablishing a relation between microarray analysis results (typically a list\nof genes) and their biological significance is often difficult. Currently, the\nstandard approach is to map a posteriori the results onto gene networks to\nelucidate the functions perturbed at the level of pathways. However,\nintegrating a priori knowledge of the gene networks could help in the\nstatistical analysis of gene expression data and in their biological\ninterpretation. Here we propose a method to integrate a priori the knowledge of\na gene network in the analysis of gene expression data. The approach is based\non the spectral decomposition of gene expression profiles with respect to the\neigenfunctions of the graph, resulting in an attenuation of the high-frequency\ncomponents of the expression profiles with respect to the topology of the\ngraph. We show how to derive unsupervised and supervised classification\nalgorithms of expression profiles, resulting in classifiers with biological\nrelevance. We applied the method to the analysis of a set of expression\nprofiles from irradiated and non-irradiated yeast strains. It performed at\nleast as well as the usual classification but provides much more biologically\nrelevant results and allows a direct biological interpretation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Form follows function -- how PufX increases the efficiency of the\n  light-harvesting complexes of Rhodobacter sphaeroides"}, {"role": "assistant", "content": "Some species of purple bacteria as, e.g., Rhodobacter sphaeroides contain the\nprotein PufX. Concurrently, the light harvesting complexes 1 (LH1) form dimers\nof open rings. In mutants without PufX, the LH1s are closed rings and\nphotosynthesis breaks down, because the ubiquinone exchange at the reaction\ncenter is blocked. Thus, PufX is regarded essential for quinone exchange.\n  In contrast to this view, which implicitly treats the LH1s as obstacles to\nphotosynthesis, we propose that the primary purpose of PufX is to improve the\nefficiency of light harvesting by inducing the LH1 dimerization. Calculations\nwith a dipole model, which compare the photosynthetic efficiency of various\nconfigurations of monomeric and dimeric core complexes, show that the dimer can\nabsorb photons directly into the RC about 30% more efficient, when related to\nthe number of bacteriochlorophylls, but that the performance of the more\nsophisticated dimeric LH1 antenna degrades faster with structural\nperturbations. The calculations predict an optimal orientation of the reaction\ncenters relative to the LH1 dimer, which agrees well with the experimentally\nfound configuration.\n  For the increased required rigidity of the dimer additional modifications of\nthe LH1 subunits are necessary, which would lead to the observed ubiquinone\nblockage, when PufX is missing."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Targeted Projection Pursuit for Gene Expression Data Classification and\n  Visualisation"}, {"role": "assistant", "content": "We present a novel method for finding low dimensional views of high\ndimensional data: Targeted Projection Pursuit. The method proceeds by finding\nprojections of the data that best approximate a target view. Two versions of\nthe method are introduced; one version based on Procrustes analysis and one\nbased on a single layer perceptron. These versions are capable of finding\northogonal or non-orthogonal projections respectively. The method is\nquantitatively and qualitatively compared with other dimension reduction\ntechniques. It is shown to find two-dimensional views that display the\nclassification of cancers from gene expression data with a visual separation\nequal to, or better than, existing dimension reduction techniques."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Overlapping Probabilities of Top Ranking Gene Lists, Hypergeometric\n  Distribution, and Stringency of Gene Selection Criterion"}, {"role": "assistant", "content": "When the same set of genes appear in two top ranking gene lists in two\ndifferent studies, it is often of interest to estimate the probability for this\nbeing a chance event. This overlapping probability is well known to follow the\nhypergeometric distribution. Usually, the lengths of top-ranking gene lists are\nassumed to be fixed, by using a pre-set criterion on, e.g., $p$-value for the\nt-test. We investigate how overlapping probability changes with the gene\nselection criterion, or simply, with the length of the top-ranking gene lists.\nIt is concluded that overlapping probability is indeed a function of the gene\nlist length, and its statistical significance should be quoted in the context\nof gene selection criterion."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Does Logarithm Transformation of Microarray Data Affect Ranking Order of\n  Differentially Expressed Genes?"}, {"role": "assistant", "content": "A common practice in microarray analysis is to transform the microarray raw\ndata (light intensity) by a logarithmic transformation, and the justification\nfor this transformation is to make the distribution more symmetric and\nGaussian-like. Since this transformation is not universally practiced in all\nmicroarray analysis, we examined whether the discrepancy of this treatment of\nraw data affect the \"high level\" analysis result. In particular, whether the\ndifferentially expressed genes as obtained by $t$-test, regularized t-test, or\nlogistic regression have altered rank orders due to presence or absence of the\ntransformation. We show that as much as 20%--40% of significant genes are\n\"discordant\" (significant only in one form of the data and not in both),\ndepending on the test being used and the threshold value for claiming\nsignificance. The t-test is more likely to be affected by logarithmic\ntransformation than logistic regression, and regularized $t$-test more affected\nthan t-test. On the other hand, the very top ranking genes (e.g. up to top\n20--50 genes, depending on the test) are not affected by the logarithmic\ntransformation."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Towards a model for protein production rates"}, {"role": "assistant", "content": "This submission is a duplicate of arXiv:q-bio/0602024 and has been removed."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Scaling graphs of heart rate time series in athletes demonstrate the\n  VLF, LF and HF regions"}, {"role": "assistant", "content": "Scaling analysis of heart rate time series has emerged as an useful tool for\nassessment of autonomic cardiac control. We investigate the heart rate time\nseries of ten athletes (five males and five females), by applying detrended\nfluctuation analysis (DFA). High resolution ECGs are recorded under\nstandardized resting conditions over 30 minutes and subsequently heart rate\ntime series are extracted and artefacts filtered. We find three distinct\nregions of scale-invariance, which correspond to the well-known VLF, LF, and HF\nbands in the power spectra of heart rate variability. The scaling exponents\nalpha are alphaHF: 1.15 [0.96-1.22], alphaLF: 0.68 [0.57-0.84], alphaVLF:\n0.83[0.82-0.99]; p<10^-5). In conclusion, DFA scaling exponents of heart rate\ntime series should be fitted to the VLF, LF, and HF ranges, respectively."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A Simple Solution of the Lotka-Volterra Equations"}, {"role": "assistant", "content": "In this work we consider a simple, approximate, tending toward exact,\nsolution of the system of two usual Lotka-Volterra differential equations.\nGiven solution is obtained by an iterative method. In any finite approximation\norder of this solution, exponents of the corresponding Lotka-Volterra variables\nhave simple, time polynomial form. When approximation order tends to infinity\nobtained approximate solution converges toward exact solution in some finite\ntime interval."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Granger Causality: Basic Theory and Application to Neuroscience"}, {"role": "assistant", "content": "Multi-electrode neurophysiological recordings produce massive quantities of\ndata. Multivariate time series analysis provides the basic framework for\nanalyzing the patterns of neural interactions in these data. It has long been\nrecognized that neural interactions are directional. Being able to assess the\ndirectionality of neuronal interactions is thus a highly desired capability for\nunderstanding the cooperative nature of neural computation. Research over the\nlast few years has shown that Granger causality is a key technique to furnish\nthis capability. The main goal of this article is to provide an expository\nintroduction to the concept of Granger causality. Mathematical frameworks for\nboth bivariate Granger causality and conditional Granger causality are\ndeveloped in detail with particular emphasis on their spectral representations.\nThe technique is demonstrated in numerical examples where the exact answers of\ncausal influences are known. It is then applied to analyze multichannel local\nfield potentials recorded from monkeys performing a visuomotor task. Our\nresults are shown to be physiologically interpretable and yield new insights\ninto the dynamical organization of large-scale oscillatory cortical networks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Lagrangian Approaches for a class of Matching Problems in Computational\n  Biology"}, {"role": "assistant", "content": "This paper presents efficient algorithms for solving the problem of aligning\na protein structure template to a query amino-acid sequence, known as protein\nthreading problem. We consider the problem as a special case of graph matching\nproblem. We give formal graph and integer programming models of the problem.\nAfter studying the properties of these models, we propose two kinds of\nLagrangian relaxation for solving them. We present experimental results on real\nlife instances showing the efficiency of our approaches."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A simple model of energy expenditure in human locomotion"}, {"role": "assistant", "content": "A simple harmonic oscillator model is proposed to describe the mechanical\npower involved in human locomotion. In this framework, by taking into account\nthe anthropometric parameters of a standard individual, we are able to\ncalculate the speed-power curves in human walking. The proposed model accounts\nfor the well known Margaria's law in which the cost ofthe human running\n(independent from the speed) is fixed to 1 Kcal/(Kg Km). The model includes the\neffects of a gentle slope (either positive or negative) and the effect due to\nthe mechanical response of the walking surface. The model results obtained in\nthe presence of a slope are in qualitative agreement with the experimental data\nobtained by A. Leonardi et al."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Dynamic behaviors in directed networks"}, {"role": "assistant", "content": "Motivated by the abundance of directed synaptic couplings in a real\nbiological neuronal network, we investigate the synchronization behavior of the\nHodgkin-Huxley model in a directed network. We start from the standard model of\nthe Watts-Strogatz undirected network and then change undirected edges to\ndirected arcs with a given probability, still preserving the connectivity of\nthe network. A generalized clustering coefficient for directed networks is\ndefined and used to investigate the interplay between the synchronization\nbehavior and underlying structural properties of directed networks. We observe\nthat the directedness of complex networks plays an important role in emerging\ndynamical behaviors, which is also confirmed by a numerical study of the\nsociological game theoretic voter model on directed networks."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Graph kernels based on tree patterns for molecules"}, {"role": "assistant", "content": "Motivated by chemical applications, we revisit and extend a family of\npositive definite kernels for graphs based on the detection of common subtrees,\ninitially proposed by Ramon et al. (2003). We propose new kernels with a\nparameter to control the complexity of the subtrees used as features to\nrepresent the graphs. This parameter allows to smoothly interpolate between\nclassical graph kernels based on the count of common walks, on the one hand,\nand kernels that emphasize the detection of large common subtrees, on the other\nhand. We also propose two modular extensions to this formulation. The first\nextension increases the number of subtrees that define the feature space, and\nthe second one removes noisy features from the graph representations. We\nvalidate experimentally these new kernels on binary classification tasks\nconsisting in discriminating toxic and non-toxic molecules with support vector\nmachines."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: An algorithm for real-time estimation of Mezcal fermentation parameters\n  based on redox potential measurements"}, {"role": "assistant", "content": "We present an algorithm for the continuous monitoring of the biomass and\nethanol concentrations and moreover the kinetic rate in the Mezcal fermentation\nprocess. This algorithm performs its task having only available the on-line\nmeasurements of the redox potential. The procedure includes an artificial\nneural network (ANN) that relates the redox potential to the ethanol and\nbiomass concentrations. Then a nonlinear-observer-based algorithm uses the\nbiomass estimations to infer the kinetic rate of this fermentation process. The\nmethod shows that the redox potential is a valuable indicator of microorganism\nmetabolic activity during the Mezcal fermentation. In addition, the estimated\nkinetic rate can be considered as a direct evidence of the presence of mixed\nculture growth in the process. In this work, the detailed design of the\nsoftware-sensor is presented, as well as its experimental application at the\nlaboratory level"}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A family tree of Markov models in systems biology"}, {"role": "assistant", "content": "Motivated by applications in systems biology, we seek a probabilistic\nframework based on Markov processes to represent intracellular processes. We\nreview the formal relationships between different stochastic models referred to\nin the systems biology literature. As part of this review, we present a novel\nderivation of the differential Chapman-Kolmogorov equation for a general\nmultidimensional Markov process made up of both continuous and jump processes.\nWe start with the definition of a time-derivative for a probability density but\nplace no restrictions on the probability distribution, in particular, we do not\nassume it to be confined to a region that has a surface (on which the\nprobability is zero). In our derivation, the master equation gives the jump\npart of the Markov process while the Fokker-Planck equation gives the\ncontinuous part. We thereby sketch a {}``family tree'' for stochastic models in\nsystems biology, providing explicit derivations of their formal relationship\nand clarifying assumptions involved."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Determination and Spectroscopy of Quantum Yields in\n  Bio/Chemiluminescence via Novel Light-Collection-Efficiency Calibration:\n  Reexamination of The Aqueous Luminol Chemiluminescence Standard"}, {"role": "assistant", "content": "We have developed a luminescence-measurement system for liquid\nbio/chemiluminescence that can obtain quantitative luminescence spectra as the\nabsolute total number of luminescence photons at each wavelength or photon\nenergy and quantum yields. Calibration of light-collection efficiency in the\nsystem is performed with a reference double-plate cell. This method is\napplicable to sample cells of any kind suitable for measurement, which is a\ngreat advantage over previous techniques in practical experiments. Using this\nsystem, the quantum yield of aqueous luminol chemiluminescence was obtained as\n1.23-+0.20%, which is in good agreement with previously reported values."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Integrated Cell Manipulation Systems"}, {"role": "assistant", "content": "A new type of microfluidic system for biological cell manipulation, a\nCMOS/microfluidic hybrid, is demonstrated. The hybrid system starts with a\ncustom-designed CMOS (complementary metal-oxide semiconductor) chip fabricated\nin a semiconductor foundry using standard integration circuit technology. A\nmicrofluidic channel is post-fabricated on top of the CMOS chip to provide\nbiocompatible environment. The motion of individual biological cells that are\ntagged with magnetic beads is directly controlled by the CMOS chip that\ngenerates localized magnetic filed patterns using an on-chip array of\nmicro-electromagnets. The speed and the programmability of the CMOS chip\nfurther allow for the dynamic reconfiguration of the magnetic fields,\nsubstantially increasing the manipulation capability of the hybrid system. The\nconcept of a hybrid system is verified by simultaneously manipulating\nindividual biological cells with microscopic resolution. A new operation\nprotocol that exploits the fast speed of electronics to trap and move a large\nnumber of cells with less power consumption is also demonstrated. Combining the\nadvantages of microelectronics, the CMOS/microfluidic hybrid approach presents\na new model for a multifunctional lab-on-a chip for biological and medical\napplications."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Heterogeneous Cell Population Dynamics: Equation-Free Uncertainty\n  Quantification Computations"}, {"role": "assistant", "content": "We propose a computational approach to modeling the collective dynamics of\npopulations of coupled heterogeneous biological oscillators. In contrast to\nMonte Carlo simulation, this approach utilizes generalized Polynomial Chaos\n(gPC) to represent random properties of the population, thus reducing the\ndynamics of ensembles of oscillators to dynamics of their (typically\nsignificantly fewer) representative gPC coefficients. Equation-Free (EF)\nmethods are employed to efficiently evolve these gPC coefficients in time and\ncompute their coarse-grained stationary state and/or limit cycle solutions,\ncircumventing the derivation of explicit, closed-form evolution equations.\nEnsemble realizations of the oscillators and their statistics can be readily\nreconstructed from these gPC coefficients. We apply this methodology to the\nsynchronization of yeast glycolytic oscillators coupled by the membrane\nexchange of an intracellular metabolite. The heterogeneity consists of a single\nrandom parameter, which accounts for glucose influx into a cell, with a\nGaussian distribution over the population. Coarse projective integration is\nused to accelerate the evolution of the population statistics in time. Coarse\nfixed-point algorithms in conjunction with a Poincar\\'e return map are used to\ncompute oscillatory solutions for the cell population and to quantify their\nstability."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Effective Sample Size: Quick Estimation of the Effect of Related Samples\n  in Genetic Case-Control Association Analyses"}, {"role": "assistant", "content": "Affected relatives are essential for pedigree linkage analysis, however, they\ncause a violation of the independent sample assumption in case-control\nassociation studies. To avoid the correlation between samples, a common\npractice is to take only one affected sample per pedigree in association\nanalysis. Although several methods exist in handling correlated samples, they\nare still not widely used in part because these are not easily implemented, or\nbecause they are not widely known. We advocate the effective sample size method\nas a simple and accessible approach for case-control association analysis with\ncorrelated samples. This method modifies the chi-square test statistic,\np-value, and 95% confidence interval of the odds-ratio by replacing the\napparent number of allele or genotype counts with the effective ones in the\nstandard formula, without the need for specialized computer programs. We\npresent a simple formula for calculating effective sample size for many types\nof relative pairs and relative sets. For allele frequency estimation, the\neffective sample size method captures the variance inflation exactly. For\ngenotype frequency, simulations showed that effective sample size provides a\nsatisfactory approximation. A gene which is previously identified as a type 1\ndiabetes susceptibility locus, the interferon-induced helicase gene (IFIH1), is\nshown to be significantly associated with rheumatoid arthritis when the\neffective sample size method is applied. This significant association is not\nestablished if only one affected sib per pedigree were used in the association\nanalysis. Relationship between the effective sample size method and other\nmethods -- the generalized estimation equation, variance of eigenvalues for\ncorrelation matrices, and genomic controls -- are discussed."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Effects of Selection Logging on Rainforest Productivity"}, {"role": "assistant", "content": "An analysis of data from 212 permanent sample plots provided no evidence of\nany decline in rainforest productivity after three cycles of selection logging\nin the tropical rainforests of north Queensland. Relative productivity was\ndetermined as the difference between observed diameter increments and\nincrements predicted from a diameter increment function which incorporated tree\nsize, stand density and site quality. Analyses of variance and regression\nanalyses revealed no significant decline in productivity after repeated\nharvesting. There is evidence to support the assertion that if any permanent\nproductivity decline exists, it does not exceed six per cent per harvest."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: A complete classification of epistatic two-locus models"}, {"role": "assistant", "content": "The study of epistasis is of great importance in statistical genetics in\nfields such as linkage and association analysis and QTL mapping. In an effort\nto classify the types of epistasis in the case of two biallelic loci Li and\nReich listed and described all models in the simplest case of 0/1 penetrance\nvalues. However, they left open the problem of finding a classification of\ntwo-locus models with continuous penetrance values. We provide a complete\nclassification of biallelic two-locus models. In addition to solving the\nclassification problem for dichotomous trait disease models, our results apply\nto any instance where real numbers are assigned to genotypes, and provide a\ncomplete framework for studying epistasis in QTL data. Our approach is\ngeometric and we show that there are 387 distinct types of two-locus models,\nwhich can be reduced to 69 when symmetry between loci and alleles is accounted\nfor. The model types are defined by 86 circuits, which are linear combinations\nof genotype values, each of which measures a fundamental unit of interaction.\nThe circuits provide information on epistasis beyond that contained in the\nadditive x add, add x dom, and dom x dom interaction terms. We discuss the\nconnection between our classification and standard epistatic models and\ndemonstrate its utility by analyzing a previously published dataset."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Genetic code on the dyadic plane"}, {"role": "assistant", "content": "We introduce the simple parametrization for the space of codons (triples of\nnucleotides) by 8\\times 8 table. This table (which we call the dyadic plane)\npossesses the natural 2-adic ultrametric. We show that after this\nparametrization the genetic code will be a locally constant map of the simple\nform. The local constancy of this map will describe degeneracy of the genetic\ncode.\n  The map of the genetic code defines 2-adic ultrametric on the space of amino\nacids. We show that hydrophobic amino acids will be clustered in two balls with\nrespect to this ultrametric. Therefore the introduced parametrization of space\nof codons exhibits the hidden regularity of the genetic code."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Epitope prediction improved by multitask support vector machines"}, {"role": "assistant", "content": "Motivation: In silico methods for the prediction of antigenic peptides\nbinding to MHC class I molecules play an increasingly important role in the\nidentification of T-cell epitopes. Statistical and machine learning methods, in\nparticular, are widely used to score candidate epitopes based on their\nsimilarity with known epitopes and non epitopes. The genes coding for the MHC\nmolecules, however, are highly polymorphic, and statistical methods have\ndifficulties to build models for alleles with few known epitopes. In this case,\nrecent works have demonstrated the utility of leveraging information across\nalleles to improve the performance of the prediction. Results: We design a\nsupport vector machine algorithm that is able to learn epitope models for all\nalleles simultaneously, by sharing information across similar alleles. The\nsharing of information across alleles is controlled by a user-defined measure\nof similarity between alleles. We show that this similarity can be defined in\nterms of supertypes, or more directly by comparing key residues known to play a\nrole in the peptide-MHC binding. We illustrate the potential of this approach\non various benchmark experiments where it outperforms other state-of-the-art\nmethods."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Coincident Frequencies and Relative Phases Among Female-Brain Signals\n  and Progesterone-Estrogen levels"}, {"role": "assistant", "content": "Fourier transform has become a basic tool for analyzing biological signals\n1,2,3. Mostly a fast Fourier transform is computed for a finite sequence of\ndata sample 4. This is the standard way apparatuses and modern computerized\ntechnology provide information, according with their frequency range, of the\nwell known brain signals Delta, Theta, Alpha 1, Alpha 2, Beta 1 and Beta 2\nfurnishing experts with electroencephalographic (EEG) profile of clinical use\nobtained from these short periods 5,6.\n  For long periods, an analogous novel procedure is established as follows:\nAssigning certain numerical value, i.e., the absolute power, to each brain\nsignal at certain sampling times, generates data that can be interpolated and\nextrapolated through a long period, yielding an absolute power function of time\nfor each signal 7. A further Fourier transform is then performed8,9, to analyze\nthese new functions, finding typical frequencies and their corresponding\nperiods for each one of these signals and, also, relative phases for coincident\nperiods between two or more signals. Our procedure of analysis presented here\ncan be applied, in principle, to any biological signal of interest."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: On the relationships between kinetic schemes and two-state single\n  molecule trajectories"}, {"role": "assistant", "content": "Trajectories of a signal that fluctuates between two states which originate\nfrom single molecule activities have become ubiquitous. Common examples are\ntrajectories of ionic flux through individual membrane-channels, and of photon\ncounts collected from diffusion, activity, and conformational changes of\nbiopolymers. By analyzing the trajectory, one wishes to deduce the underlying\nmechanism, which is usually described by a multi-substate kinetic scheme. In\nprevious works, we divided kinetic schemes that generate two-state trajectories\ninto two types: reducible schemes and irreducible schemes. We showed that all\nthe information in trajectories generated from reducible schemes is contained\nin the waiting time probability density functions (PDFs) of the two states. It\nfollows that reducible schemes with the same waiting time PDFs are not\ndistinguishable. In this work, we further characterize the topologies of\nkinetic schemes, now of irreducible schemes, and further study two-state\ntrajectories from the two types of scheme. We suggest various methods for\nextracting information about the underlying kinetic scheme from the trajectory\n(e. g., calculate the binned successive waiting times PDF and analyze the\nordered waiting times trajectory), and point out the advantages and\ndisadvantages of each. We show that the binned successive waiting times PDF is\nnot only more robust than other functions when analyzing finite trajectories,\nbut contains, in most cases, more information about the underlying kinetic\nscheme than other functions in the limit of infinitely long trajectories. For\nsome cases however, analyzing the ordered waiting times trajectory may supply\nunique information about the underlying kinetic scheme."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Multifractal analysis of normal RR heart-interbeat signals in power\n  spectra ranges"}, {"role": "assistant", "content": "Power spectral density is an accepted measure of heart rate variability. Two\nestimators of multifractal properties: Wavelet Transform Modulus Maxima and\nMultifractal Detrended Fluctuation Analysis are used to investigate\nmultifractal properties for the three strongly physiologically grounded\ncomponents of power spectra: low frequency (LF), very low frequency (VLF) and\nultra low frequency (ULV). Circadian rhythm changes are examined by\ndiscrimination of daily activity from nocturnal rest. Investigations consider\nnormal sinus rhythms of healthy 39 subjects which are grouped in two sets:\n5-hour wake series and 5-hour sleep series. Qualitative arguments are provided\nto conjecture the presence of stochastic persistence in LF range, loss of heart\nrate variability during night in VLF range and its increase in ULF."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Symbolic Reachability Analysis of Genetic Regulatory Networks using\n  Qualitative Abstractions"}, {"role": "assistant", "content": "The switch-like character of gene regulation has motivated the use of hybrid,\ndiscrete-continuous models of genetic regulatory networks. While powerful\ntechniques for the analysis, verification, and control of hybrid systems have\nbeen developed, the specificities of the biological application domain pose a\nnumber of challenges, notably the absence of quantitative information on\nparameter values and the size and complexity of networks of biological\ninterest. We introduce a method for the analysis of reachability properties of\ngenetic regulatory networks that is based on a class of discontinuous\npiecewise-affine (PA) differential equations well-adapted to the above\nconstraints. More specifically, we introduce a hyperrectangular partition of\nthe state space that forms the basis for a discrete abstraction preserving the\nsign of the derivatives of the state variables. The resulting discrete\ntransition system provides a conservative approximation of the qualitative\ndynamics of the network and can be efficiently computed in a symbolic manner\nfrom inequality constraints on the parameters. The method has been implemented\nin the computer tool Genetic Network Analyzer (GNA), which has been applied to\nthe analysis of a regulatory system whose functioning is not well-understood by\nbiologists, the nutritional stress response in the bacterium Escherichia coli."}]}
{"messages": [{"role": "system", "content": "You are an expert science teacher helping students understand biological research concepts."}, {"role": "user", "content": "Explain this biological research topic: Utilizing the information content in two-state trajectories"}, {"role": "assistant", "content": "The signal from many single molecule experiments monitoring molecular\nprocesses, such as enzyme turnover via fluorescence and opening and closing of\nion channel via the flux of ions, consists of a time series of stochastic on\nand off (or open and closed) periods, termed a two-state trajectory. This\nsignal reflects the dynamics in the underlying multi-substate on-off kinetic\nscheme (KS) of the process. The determination of the underlying KS is difficult\nand sometimes even impossible due to the loss of information in the mapping of\nthe mutli dimensional KS onto two dimensions. Here we introduce a new procedure\nthat efficiently and optimally relates the signal to all equivalent underlying\nKSs. This procedure partitions the space of KSs into canonical (unique) forms\nthat can handle any KS, and obtains the topology and other details of the\ncanonical form from the data without the need for fitting. Also established are\nrelationships between the data and the topology of the canonical form to the\non-off connectivity of a KS. The suggested canonical forms constitute a\npowerful tool in discriminating between KSs. Based on our approach, the upper\nbound on the information content in two state trajectories is determined."}]}
